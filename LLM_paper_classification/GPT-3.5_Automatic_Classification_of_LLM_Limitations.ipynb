{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68bde977",
   "metadata": {},
   "source": [
    "### Automated Classification of LLM Limitations in Academic Papers Using GPT-3.5 into two classes \n",
    "This script leverages the OpenAI GPT-3.5-turbo model to automatically classify academic papers based on whether their titles or abstracts explicitly mention limitations or challenges related to Large Language Models (LLMs)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106404ea",
   "metadata": {},
   "source": [
    "##### Prompt 1a: ACL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8092d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error reading progress file: invalid literal for int() with base 10: ''\n",
      "Last processed index: -1\n",
      "Successfully read 271 papers from the JSON file.\n",
      "Header written to CSV file.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   0%|                                                                       | 0/271 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Named Entity Recognition Under Domain Shift via Metric Learning for Life Sciences\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   0%|▏                                                              | 1/271 [00:02<09:25,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Assessing Logical Puzzle Solving in Large Language Models: Insights from a Minesweeper Case Study\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   1%|▍                                                              | 2/271 [00:03<08:14,  1.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Effective and Efficient Conversation Retrieval for Dialogue State Tracking with Implicit Text Summaries\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   1%|▋                                                              | 3/271 [00:05<07:35,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: On Linearizing Structured Data in Encoder-Decoder Language Models: Insights from Text-to-SQL\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   1%|▉                                                              | 4/271 [00:07<08:27,  1.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Measuring and Improving Chain-of-Thought Reasoning in Vision-Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   2%|█▏                                                             | 5/271 [00:09<07:51,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Adaptive Rank Selections for Low-Rank Approximation of Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   2%|█▍                                                             | 6/271 [00:10<07:32,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Unleashing the Emergent Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   3%|█▋                                                             | 7/271 [00:12<07:19,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: FPT: Feature Prompt Tuning for Few-shot Readability Assessment\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   3%|█▊                                                             | 8/271 [00:13<07:26,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Self-Prompting Large Language Models for Zero-Shot Open-Domain QA\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   3%|██                                                             | 9/271 [00:15<07:33,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Head-to-Tail: How Knowledgeable are Large Language Models (LLMs)? A.K.A. Will LLMs Replace Knowledge Graphs?\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   4%|██▎                                                           | 10/271 [00:17<07:19,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: kNN-ICL: Compositional Task-Oriented Parsing Generalization with Nearest Neighbor In-Context Learning\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   4%|██▌                                                           | 11/271 [00:18<06:57,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LLMs Are Few-Shot In-Context Low-Resource Language Learners\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   4%|██▋                                                           | 12/271 [00:20<06:50,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Rethinking Tabular Data Understanding with Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   5%|██▉                                                           | 13/271 [00:21<06:46,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: FLAP: Flow-Adhering Planning with Constrained Decoding in LLMs\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   5%|███▏                                                          | 14/271 [00:23<06:32,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Embrace Divergence for Richer Insights: A Multi-document Summarization Benchmark and a Case Study on Summarizing Diverse Information from News Articles\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   6%|███▍                                                          | 15/271 [00:25<06:56,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ALoRA: Allocating Low-Rank Adaptation for Fine-tuning Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   6%|███▋                                                          | 16/271 [00:26<07:01,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: InsCL: A Data-efficient Continual Learning Paradigm for Fine-tuning Large Language Models with Instructions\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   6%|███▉                                                          | 17/271 [00:28<07:10,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: An Examination of the Compositionality of Large Generative Vision-Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   7%|████                                                          | 18/271 [00:30<07:11,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Two Heads are Better than One: Nested PoE for Robust Defense Against Multi-Backdoors\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   7%|████▎                                                         | 19/271 [00:31<07:02,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: VertAttack: Taking Advantage of Text Classifiers’ Horizontal Vision\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   7%|████▌                                                         | 20/271 [00:33<07:12,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: BeLLM: Backward Dependency Enhanced Large Language Model for Sentence Embeddings\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   8%|████▊                                                         | 21/271 [00:35<07:14,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Assessing Factual Reliability of Large Language Model Knowledge\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   8%|█████                                                         | 22/271 [00:37<07:00,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Toolink: Linking Toolkit Creation and Using through Chain-of-Solving on Open-Source Model\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   8%|█████▎                                                        | 23/271 [00:38<07:00,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Neurocache: Efficient Vector Retrieval for Long-range Language Modeling\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   9%|█████▍                                                        | 24/271 [00:40<06:39,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Unveiling the Generalization Power of Fine-Tuned Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   9%|█████▋                                                        | 25/271 [00:41<06:42,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: A Closer Look at the Self-Verification Abilities of Large Language Models in Logical Reasoning\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  10%|█████▉                                                        | 26/271 [00:43<06:58,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Exploring Self-supervised Logic-enhanced Training for Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  10%|██████▏                                                       | 27/271 [00:45<06:41,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: MATHSENSEI: A Tool-Augmented Large Language Model for Mathematical Reasoning\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  10%|██████▍                                                       | 28/271 [00:47<06:50,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: CoUDA: Coherence Evaluation via Unified Data Augmentation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  11%|██████▋                                                       | 29/271 [00:49<07:26,  1.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: mEdIT: Multilingual Text Editing via Instruction Tuning\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  11%|██████▊                                                       | 30/271 [00:51<07:22,  1.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: On Large Language Models’ Hallucination with Regard to Known Facts\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  11%|███████                                                       | 31/271 [00:53<07:19,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Language Models Hallucinate, but May Excel at Fact Verification\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  12%|███████▎                                                      | 32/271 [00:54<07:21,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Ensuring Safe and High-Quality Outputs: A Guideline Library Approach for Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  12%|███████▌                                                      | 33/271 [00:56<07:02,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Topics, Authors, and Institutions in Large Language Model Research: Trends from 17K arXiv Papers\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  13%|███████▊                                                      | 34/271 [00:58<06:41,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: E5: Zero-shot Hierarchical Table Analysis using Augmented LLMs via Explain, Extract, Execute, Exhibit and Extrapolate\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  13%|████████                                                      | 35/271 [00:59<06:23,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: S3Eval: A Synthetic, Scalable, Systematic Evaluation Suite for Large Language Model\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  13%|████████▏                                                     | 36/271 [01:01<06:22,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: MMC: Advancing Multimodal Chart Understanding with Large-scale Instruction Tuning\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  14%|████████▍                                                     | 37/271 [01:03<06:47,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: AutoPRM: Automating Procedural Supervision for Multi-Step Reasoning via Controllable Question Decomposition\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  14%|████████▋                                                     | 38/271 [01:04<06:34,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: SEMQA: Semi-Extractive Multi-Source Question Answering\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  14%|████████▉                                                     | 39/271 [01:06<06:19,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Fine-Tuning Language Models with Reward Learning on Policy\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  15%|█████████▏                                                    | 40/271 [01:07<06:12,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: IterAlign: Iterative Constitutional Alignment of Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  15%|█████████▍                                                    | 41/271 [01:09<05:58,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: OrchestraLLM: Efficient Orchestration of Language Models for Dialogue State Tracking\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  15%|█████████▌                                                    | 42/271 [01:10<06:13,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Large Language Models Help Humans Verify Truthfulness – Except When They Are Convincingly Wrong\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  16%|█████████▊                                                    | 43/271 [01:12<06:18,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Evaluating Large Language Models as Generative User Simulators for Conversational Recommendation\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  16%|██████████                                                    | 44/271 [01:14<06:04,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: A Symbolic Framework for Evaluating Mathematical Reasoning and Generalisation with Transformers\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  17%|██████████▎                                                   | 45/271 [01:15<05:58,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: JAMDEC: Unsupervised Authorship Obfuscation using Constrained Decoding over Small Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  17%|██████████▌                                                   | 46/271 [01:17<05:58,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: MSciNLI: A Diverse Benchmark for Scientific Natural Language Inference\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  17%|██████████▊                                                   | 47/271 [01:19<06:02,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: SELF-GUARD: Empower the LLM to Safeguard Itself\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  18%|██████████▉                                                   | 48/271 [01:20<05:58,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: COSIGN: Contextual Facts Guided Generation for Knowledge Graph Completion\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  18%|███████████▏                                                  | 49/271 [01:22<06:08,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Toward Informal Language Processing: Knowledge of Slang in Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  18%|███████████▍                                                  | 50/271 [01:24<06:15,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Ghostbuster: Detecting Text Ghostwritten by Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  19%|███████████▋                                                  | 51/271 [01:25<06:08,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: End-to-End Beam Retrieval for Multi-Hop Question Answering\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  19%|███████████▉                                                  | 52/271 [01:27<06:21,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Leveraging Generative Large Language Models with Visual Instruction and Demonstration Retrieval for Multimodal Sarcasm Detection\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  20%|████████████▏                                                 | 53/271 [01:29<06:05,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Ungrammatical-syntax-based In-context Example Selection for Grammatical Error Correction\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  20%|████████████▎                                                 | 54/271 [01:30<05:56,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: BUFFET: Benchmarking Large Language Models for Few-shot Cross-lingual Transfer\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  20%|████████████▌                                                 | 55/271 [01:32<05:48,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: zrLLM: Zero-Shot Relational Learning on Temporal Knowledge Graphs with Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  21%|████████████▊                                                 | 56/271 [01:33<05:34,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Embodied Executable Policy Learning with Language-based Scene Summarization\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  21%|█████████████                                                 | 57/271 [01:35<05:21,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Metacognitive Prompting Improves Understanding in Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  21%|█████████████▎                                                | 58/271 [01:36<05:37,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: MART: Improving LLM Safety with Multi-round Automatic Red-Teaming\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  22%|█████████████▍                                                | 59/271 [01:38<05:32,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Routing to the Expert: Efficient Reward-guided Ensemble of Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  22%|█████████████▋                                                | 60/271 [01:39<05:27,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Automatic Generation of Model and Data Cards: A Step Towards Responsible AI\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  23%|█████████████▉                                                | 61/271 [01:41<05:42,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Are Multilingual LLMs Culturally-Diverse Reasoners? An Investigation into Multicultural Proverbs and Sayings\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  23%|██████████████▏                                               | 62/271 [01:43<06:19,  1.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: The Colorful Future of LLMs: Evaluating and Improving LLMs as Emotional Supporters for Queer Youth\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  23%|██████████████▍                                               | 63/271 [01:45<06:10,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: QualEval: Qualitative Evaluation for Model Improvement\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  24%|██████████████▋                                               | 64/271 [01:47<05:53,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: VisLingInstruct: Elevating Zero-Shot Learning in Multi-Modal Language Models with Autonomous Instruction Optimization\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  24%|██████████████▊                                               | 65/271 [01:49<05:56,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: A Wolf in Sheep’s Clothing: Generalized Nested Jailbreak Prompts can Fool Large Language Models Easily\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  24%|███████████████                                               | 66/271 [01:50<06:01,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Bridging the Novice-Expert Gap via Models of Decision-Making: A Case Study on Remediating Math Mistakes\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  25%|███████████████▎                                              | 67/271 [01:52<05:44,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ReTA: Recursively Thinking Ahead to Improve the Strategic Reasoning of Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  25%|███████████████▌                                              | 68/271 [01:53<05:25,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Program-Aided Reasoners (Better) Know What They Know\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  25%|███████████████▊                                              | 69/271 [01:55<05:16,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: First Tragedy, then Parse: History Repeats Itself in the New Era of Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  26%|████████████████                                              | 70/271 [01:56<05:04,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Found in the Middle: Permutation Self-Consistency Improves Listwise Ranking in Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  26%|████████████████▏                                             | 71/271 [01:58<05:19,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: From Language Modeling to Instruction Following: Understanding the Behavior Shift in LLMs after Instruction Tuning\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  27%|████████████████▍                                             | 72/271 [01:59<05:07,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LLM-based Medical Assistant Personalization with Short- and Long-Term Memory Coordination\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  27%|████████████████▋                                             | 73/271 [02:01<04:59,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: How Well Do Large Language Models Truly Ground?\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  27%|████████████████▉                                             | 74/271 [02:02<05:06,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: MILL: Mutual Verification with Large Language Models for Zero-Shot Query Expansion\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  28%|█████████████████▏                                            | 75/271 [02:04<05:05,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: PaD: Program-aided Distillation Can Teach Small Models Reasoning Better than Chain-of-thought Fine-tuning\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  28%|█████████████████▍                                            | 76/271 [02:06<05:01,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: MEGAVERSE: Benchmarking Large Language Models Across Languages, Modalities, Models and Tasks\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  28%|█████████████████▌                                            | 77/271 [02:07<04:57,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Unlocking Emergent Modularity in Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  29%|█████████████████▊                                            | 78/271 [02:09<05:20,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: PatentEval: Understanding Errors in Patent Generation\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  29%|██████████████████                                            | 79/271 [02:10<05:08,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Contextual Refinement of Translations: Large Language Models for Sentence and Document-Level Post-Editing\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  30%|██████████████████▎                                           | 80/271 [02:12<05:06,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: How Trustworthy are Open-Source LLMs? An Assessment under Malicious Demonstrations Shows their Vulnerabilities\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  30%|██████████████████▌                                           | 81/271 [02:14<04:58,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Paraphrase and Solve: Exploring and Exploiting the Impact of Surface Form on Mathematical Reasoning in Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  30%|██████████████████▊                                           | 82/271 [02:15<05:03,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: TriSum: Learning Summarization Ability from Large Language Models with Structured Rationale\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  31%|██████████████████▉                                           | 83/271 [02:17<05:19,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: GenRES: Rethinking Evaluation for Generative Relation Extraction in the Era of Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  31%|███████████████████▏                                          | 84/271 [02:19<05:16,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Evaluating In-Context Learning of Libraries for Code Generation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  31%|███████████████████▍                                          | 85/271 [02:20<05:09,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: TopicGPT: A Prompt-based Topic Modeling Framework\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  32%|███████████████████▋                                          | 86/271 [02:22<04:52,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ChatGPT as an Attack Tool: Stealthy Textual Backdoor Attack via Blackbox Generative Model Trigger\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  32%|███████████████████▉                                          | 87/271 [02:23<04:47,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LoRETTA: Low-Rank Economic Tensor-Train Adaptation for Ultra-Low-Parameter Fine-Tuning of Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  32%|████████████████████▏                                         | 88/271 [02:25<04:52,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Do Localization Methods Actually Localize Memorized Data in LLMs? A Tale of Two Benchmarks\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  33%|████████████████████▎                                         | 89/271 [02:27<04:46,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Instructional Fingerprinting of Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  33%|████████████████████▌                                         | 90/271 [02:28<04:52,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Uncertainty Quantification for In-Context Learning of Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  34%|████████████████████▊                                         | 91/271 [02:30<04:45,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: HelpSteer: Multi-attribute Helpfulness Dataset for SteerLM\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  34%|█████████████████████                                         | 92/271 [02:31<04:37,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: A Preference-driven Paradigm for Enhanced Translation with Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  34%|█████████████████████▎                                        | 93/271 [02:33<04:32,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Fair Abstractive Summarization of Diverse Perspectives\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  35%|█████████████████████▌                                        | 94/271 [02:34<04:37,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Making Language Models Better Tool Learners with Execution Feedback\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  35%|█████████████████████▋                                        | 95/271 [02:36<04:44,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Confronting LLMs with Traditional ML: Rethinking the Fairness of Large Language Models in Tabular Classifications\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  35%|█████████████████████▉                                        | 96/271 [02:38<04:36,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Ada-LEval: Evaluating long-context LLMs with length-adaptable benchmarks\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  36%|██████████████████████▏                                       | 97/271 [02:39<04:34,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Long-form evaluation of model editing\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  36%|██████████████████████▍                                       | 98/271 [02:41<04:34,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Analyzing the Role of Semantic Representations in the Era of Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  37%|██████████████████████▋                                       | 99/271 [02:42<04:22,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: TRAQ: Trustworthy Retrieval Augmented Question Answering via Conformal Prediction\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  37%|██████████████████████▌                                      | 100/271 [02:44<04:30,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: On-the-fly Definition Augmentation of LLMs for Biomedical NER\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  37%|██████████████████████▋                                      | 101/271 [02:46<04:36,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: This Land is Your, My Land: Evaluating Geopolitical Bias in Language Models through Territorial Disputes\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  38%|██████████████████████▉                                      | 102/271 [02:48<05:02,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Set-Aligning Framework for Auto-Regressive Event Temporal Graph Generation\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  38%|███████████████████████▏                                     | 103/271 [02:49<04:53,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Towards Improved Multi-Source Attribution for Long-Form Answer Generation\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  38%|███████████████████████▍                                     | 104/271 [02:51<04:40,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Can Knowledge Graphs Reduce Hallucinations in LLMs? : A Survey\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  39%|███████████████████████▋                                     | 105/271 [02:53<04:33,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Take One Step at a Time to Know Incremental Utility of Demonstration: An Analysis on Reranking for Few-Shot In-Context Learning\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  39%|███████████████████████▊                                     | 106/271 [02:54<04:38,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LM-Infinite: Zero-Shot Extreme Length Generalization for Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  39%|████████████████████████                                     | 107/271 [02:56<04:29,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: CONSCENDI: A Contrastive and Scenario-Guided Distillation Approach to Guardrail Models for Virtual Assistants\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  40%|████████████████████████▎                                    | 108/271 [02:58<04:34,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Advancing Beyond Identification: Multi-bit Watermark for Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  40%|████████████████████████▌                                    | 109/271 [02:59<04:22,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Better Zero-Shot Reasoning with Role-Play Prompting\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  41%|████████████████████████▊                                    | 110/271 [03:01<04:32,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: DoG-Instruct: Towards Premium Instruction-Tuning Data via Text-Grounded Instruction Wrapping\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  41%|████████████████████████▉                                    | 111/271 [03:03<04:48,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: MDR: Model-Specific Demonstration Retrieval at Inference Time for In-Context Learning\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  41%|█████████████████████████▏                                   | 112/271 [03:05<04:35,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Exploring Cross-Cultural Differences in English Hate Speech Annotations: From Dataset Construction to Analysis\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  42%|█████████████████████████▍                                   | 113/271 [03:06<04:19,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Enhancing Contextual Understanding in Large Language Models through Contrastive Decoding\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  42%|█████████████████████████▋                                   | 114/271 [03:08<04:37,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Rectifying Demonstration Shortcut in In-Context Learning\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  42%|█████████████████████████▉                                   | 115/271 [03:10<04:40,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Differentially Private Next-Token Prediction of Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  43%|██████████████████████████                                   | 116/271 [03:11<04:22,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Impossible Distillation for Paraphrasing and Summarization: How to Make High-quality Lemonade out of Small, Low-quality Model\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  43%|██████████████████████████▎                                  | 117/271 [03:13<04:25,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: TofuEval: Evaluating Hallucinations of LLMs on Topic-Focused Dialogue Summarization\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  44%|██████████████████████████▌                                  | 118/271 [03:15<04:10,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Fixing Rogue Memorization in Many-to-One Multilingual Translators of Extremely-Low-Resource Languages by Rephrasing Training Samples\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  44%|██████████████████████████▊                                  | 119/271 [03:16<04:18,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Flames: Benchmarking Value Alignment of LLMs in Chinese\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  44%|███████████████████████████                                  | 120/271 [03:18<04:09,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Generating Attractive and Authentic Copywriting from Customer Reviews\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  45%|███████████████████████████▏                                 | 121/271 [03:20<04:03,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Effective Long-Context Scaling of Foundation Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  45%|███████████████████████████▍                                 | 122/271 [03:21<04:08,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Aligning as Debiasing: Causality-Aware Alignment via Reinforcement Learning with Interventional Feedback\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  45%|███████████████████████████▋                                 | 123/271 [03:23<04:02,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Fake Alignment: Are LLMs Really Aligned Well?\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  46%|███████████████████████████▉                                 | 124/271 [03:24<03:51,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: In-context Learning Generalizes, But Not Always Robustly: The Case of Syntax\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  46%|████████████████████████████▏                                | 125/271 [03:26<03:49,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Anisotropy is Not Inherent to Transformers\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  46%|████████████████████████████▎                                | 126/271 [03:27<03:45,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Stealthy and Persistent Unalignment on Large Language Models via Backdoor Injections\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  47%|████████████████████████████▌                                | 127/271 [03:29<03:37,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Leveraging Code to Improve In-Context Learning for Semantic Parsing\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  47%|████████████████████████████▊                                | 128/271 [03:30<03:39,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: SportQA: A Benchmark for Sports Understanding in Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  48%|█████████████████████████████                                | 129/271 [03:32<03:57,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Revisiting subword tokenization: A case study on affixal negation in large language models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  48%|█████████████████████████████▎                               | 130/271 [03:34<04:00,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Teaching Language Models to Self-Improve through Interactive Demonstrations\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  48%|█████████████████████████████▍                               | 131/271 [03:36<03:49,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: MAGID: An Automated Pipeline for Generating Synthetic Multi-modal Datasets\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  49%|█████████████████████████████▋                               | 132/271 [03:37<03:42,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Does GPT-4 pass the Turing test?\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  49%|█████████████████████████████▉                               | 133/271 [03:39<03:36,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: You don’t need a personality test to know these models are unreliable: Assessing the Reliability of Large Language Models on Psychometric Instruments\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  49%|██████████████████████████████▏                              | 134/271 [03:40<03:33,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: CASA: Causality-driven Argument Sufficiency Assessment\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  50%|██████████████████████████████▍                              | 135/271 [03:42<03:47,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: MacGyver: Are Large Language Models Creative Problem Solvers?\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  50%|██████████████████████████████▌                              | 136/271 [03:44<03:35,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Enhancing Large Language Models Against Inductive Instructions with Dual-critique Prompting\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  51%|██████████████████████████████▊                              | 137/271 [03:45<03:26,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: GLiNER: Generalist Model for Named Entity Recognition using Bidirectional Transformer\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  51%|███████████████████████████████                              | 138/271 [03:47<03:25,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: XSTest: A Test Suite for Identifying Exaggerated Safety Behaviours in Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  51%|███████████████████████████████▎                             | 139/271 [03:48<03:18,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Fine-grained Gender Control in Machine Translation with Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  52%|███████████████████████████████▌                             | 140/271 [03:49<03:16,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LLatrieval: LLM-Verified Retrieval for Verifiable Generation\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  52%|███████████████████████████████▋                             | 141/271 [03:51<03:28,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: AudioChatLlama: Towards General-Purpose Speech Abilities for LLMs\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  52%|███████████████████████████████▉                             | 142/271 [03:53<03:23,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Evidence-Driven Retrieval Augmented Response Generation for Online Misinformation\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  53%|████████████████████████████████▏                            | 143/271 [03:54<03:16,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Understanding the Capabilities and Limitations of Large Language Models for Cultural Commonsense\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  53%|████████████████████████████████▍                            | 144/271 [03:56<03:10,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Do Large Language Models Rank Fairly? An Empirical Study on the Fairness of LLMs as Rankers\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  54%|████████████████████████████████▋                            | 145/271 [03:58<03:23,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: TabSQLify: Enhancing Reasoning Capabilities of LLMs Through Table Decomposition\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  54%|████████████████████████████████▊                            | 146/271 [03:59<03:22,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: RESPROMPT: Residual Connection Prompting Advances Multi-Step Reasoning in Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  54%|█████████████████████████████████                            | 147/271 [04:01<03:18,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: The ART of LLM Refinement: Ask, Refine, and Trust\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  55%|█████████████████████████████████▎                           | 148/271 [04:02<03:13,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ParallelPARC: A Scalable Pipeline for Generating Natural-Language Analogies\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  55%|█████████████████████████████████▌                           | 149/271 [04:04<03:11,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: TableLlama: Towards Open Large Generalist Models for Tables\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  55%|█████████████████████████████████▊                           | 150/271 [04:05<03:13,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Backdooring Instruction-Tuned Large Language Models with Virtual Prompt Injection\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  56%|█████████████████████████████████▉                           | 151/271 [04:07<03:19,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Exploring the Factual Consistency in Dialogue Comprehension of Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  56%|██████████████████████████████████▏                          | 152/271 [04:09<03:24,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Multilingual Pretraining and Instruction Tuning Improve Cross-Lingual Knowledge Alignment, But Only Shallowly\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  56%|██████████████████████████████████▍                          | 153/271 [04:11<03:16,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: DialogBench: Evaluating LLMs as Human-like Dialogue Systems\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  57%|██████████████████████████████████▋                          | 154/271 [04:12<03:08,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: CMB: A Comprehensive Medical Benchmark in Chinese\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  57%|██████████████████████████████████▉                          | 155/271 [04:14<03:04,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: SlimFit: Memory-Efficient Fine-Tuning of Transformer-based Models Using Training Dynamics\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  58%|███████████████████████████████████                          | 156/271 [04:15<03:00,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Effective Large Language Model Adaptation for Improved Grounding and Citation Generation\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  58%|███████████████████████████████████▎                         | 157/271 [04:17<02:57,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Assisting in Writing Wikipedia-like Articles From Scratch with Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  58%|███████████████████████████████████▌                         | 158/271 [04:18<02:50,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Grounding Gaps in Language Model Generations\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  59%|███████████████████████████████████▊                         | 159/271 [04:20<02:49,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Language Model Based Unsupervised Dependency Parsing with Conditional Mutual Information and Grammatical Constraints\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  59%|████████████████████████████████████                         | 160/271 [04:21<02:46,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Global Gallery: The Fine Art of Painting Culture Portraits through Multilingual Instruction Tuning\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  59%|████████████████████████████████████▏                        | 161/271 [04:23<02:52,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: MT-PATCHER: Selective and Extendable Knowledge Distillation from Large Language Models for Machine Translation\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  60%|████████████████████████████████████▍                        | 162/271 [04:24<02:44,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LinkPrompt: Natural and Universal Adversarial Attacks on Prompt-based Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  60%|████████████████████████████████████▋                        | 163/271 [04:26<02:40,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: CoE-SQL: In-Context Learning for Multi-Turn Text-to-SQL with Chain-of-Editions\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  61%|████████████████████████████████████▉                        | 164/271 [04:27<02:48,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ContraDoc: Understanding Self-Contradictions in Documents with Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  61%|█████████████████████████████████████▏                       | 165/271 [04:29<02:49,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: PlanRAG: A Plan-then-Retrieval Augmented Generation for Generative Large Language Models as Decision Makers\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  61%|█████████████████████████████████████▎                       | 166/271 [04:31<02:44,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: A Survey of Confidence Estimation and Calibration in Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  62%|█████████████████████████████████████▌                       | 167/271 [04:32<02:38,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Not All Metrics Are Guilty: Improving NLG Evaluation by Diversifying References\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  62%|█████████████████████████████████████▊                       | 168/271 [04:34<02:37,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ACLSum: A New Dataset for Aspect-based Summarization of Scientific Publications\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  62%|██████████████████████████████████████                       | 169/271 [04:35<02:34,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Intent-conditioned and Non-toxic Counterspeech Generation using Multi-Task Instruction Tuning with RLAIF\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  63%|██████████████████████████████████████▎                      | 170/271 [04:36<02:30,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Attacks, Defenses and Evaluations for LLM Conversation Safety: A Survey\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  63%|██████████████████████████████████████▍                      | 171/271 [04:38<02:42,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Mind’s Mirror: Distilling Self-Evaluation Capability and Comprehensive Thinking from Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  63%|██████████████████████████████████████▋                      | 172/271 [04:40<02:46,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Divergent Token Metrics: Measuring degradation to prune away LLM components – and optimize quantization\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  64%|██████████████████████████████████████▉                      | 173/271 [04:42<02:36,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Beyond Performance: Quantifying and Mitigating Label Bias in LLMs\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  64%|███████████████████████████████████████▏                     | 174/271 [04:43<02:30,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Instructing Large Language Models to Identify and Ignore Irrelevant Conditions\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  65%|███████████████████████████████████████▍                     | 175/271 [04:45<02:29,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: On the Effectiveness of Adversarial Robustness for Abuse Mitigation with Counterspeech\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  65%|███████████████████████████████████████▌                     | 176/271 [04:46<02:24,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Leveraging the Structure of Pre-trained Embeddings to Minimize Annotation Effort\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  65%|███████████████████████████████████████▊                     | 177/271 [04:48<02:22,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Adaptive-RAG: Learning to Adapt Retrieval-Augmented Large Language Models through Question Complexity\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  66%|████████████████████████████████████████                     | 178/271 [04:49<02:18,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Knowing What LLMs DO NOT Know: A Simple Yet Effective Self-Detection Method\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  66%|████████████████████████████████████████▎                    | 179/271 [04:51<02:24,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Are Large Language Model Temporally Grounded?\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  66%|████████████████████████████████████████▌                    | 180/271 [04:52<02:22,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: R-Tuning: Instructing Large Language Models to Say ‘I Don’t Know’\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  67%|████████████████████████████████████████▋                    | 181/271 [04:54<02:17,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Bridging the Gap between Different Vocabularies for LLM Ensemble\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  67%|████████████████████████████████████████▉                    | 182/271 [04:55<02:15,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: KnowLA: Enhancing Parameter-efficient Finetuning with Knowledgeable Adaptation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  68%|█████████████████████████████████████████▏                   | 183/271 [04:57<02:22,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Towards Reducing Diagnostic Errors with Interpretable Risk Prediction\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  68%|█████████████████████████████████████████▍                   | 184/271 [04:59<02:18,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: The steerability of large language models toward data-driven personas\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  68%|█████████████████████████████████████████▋                   | 185/271 [05:00<02:21,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: CERET: Cost-Effective Extrinsic Refinement for Text Generation\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  69%|█████████████████████████████████████████▊                   | 186/271 [05:02<02:28,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Parameter-Efficient Instruction Tuning of Large Language Models For Extreme Financial Numeral Labelling\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  69%|██████████████████████████████████████████                   | 187/271 [05:04<02:19,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LeanReasoner: Boosting Complex Logical Reasoning with Lean\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  69%|██████████████████████████████████████████▎                  | 188/271 [05:06<02:21,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: UICoder: Finetuning Large Language Models to Generate User Interface Code through Automated Feedback\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  70%|██████████████████████████████████████████▌                  | 189/271 [05:07<02:15,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: MisgenderMender: A Community-Informed Approach to Interventions for Misgendering\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  70%|██████████████████████████████████████████▊                  | 190/271 [05:09<02:11,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: From Quantity to Quality: Boosting LLM Performance with Self-Guided Data Selection for Instruction Tuning\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  70%|██████████████████████████████████████████▉                  | 191/271 [05:10<02:05,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Deceptive Semantic Shortcuts on Reasoning Chains: How Far Can Models Go without Hallucination?\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  71%|███████████████████████████████████████████▏                 | 192/271 [05:12<02:08,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Leveraging LLMs for Synthesizing Training Data Across Many Languages in Multilingual Dense Retrieval\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  71%|███████████████████████████████████████████▍                 | 193/271 [05:13<02:02,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: A Theory Guided Scaffolding Instruction Framework for LLM-Enabled Metaphor Reasoning\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  72%|███████████████████████████████████████████▋                 | 194/271 [05:15<02:01,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Learning to Compress Prompt in Natural Language Formats\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  72%|███████████████████████████████████████████▉                 | 195/271 [05:16<01:56,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Naive Bayes-based Context Extension for Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  72%|████████████████████████████████████████████                 | 196/271 [05:18<01:55,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Actively Learn from LLMs with Uncertainty Propagation for Generalized Category Discovery\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  73%|████████████████████████████████████████████▎                | 197/271 [05:19<01:53,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Large Language Models can Contrastively Refine their Generation for Better Sentence Representation Learning\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  73%|████████████████████████████████████████████▌                | 198/271 [05:21<01:49,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: SuperGLEBer: German Language Understanding Evaluation Benchmark\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  73%|████████████████████████████████████████████▊                | 199/271 [05:22<01:48,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: “You are an expert annotator”: Automatic Best–Worst-Scaling Annotations for Emotion Intensity Modeling\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  74%|█████████████████████████████████████████████                | 200/271 [05:24<01:45,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: What Matters in Training a GPT4-Style Language Model with Multimodal Inputs?\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  74%|█████████████████████████████████████████████▏               | 201/271 [05:26<01:51,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Defining and Detecting Vulnerability in Human Evaluation Guidelines: A Preliminary Study Towards Reliable NLG Evaluation\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  75%|█████████████████████████████████████████████▍               | 202/271 [05:27<01:51,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: SemRoDe: Macro Adversarial Training to Learn Representations that are Robust to Word-Level Attacks\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  75%|█████████████████████████████████████████████▋               | 203/271 [05:29<01:45,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: BUST: Benchmark for the evaluation of detectors of LLM-Generated Text\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  75%|█████████████████████████████████████████████▉               | 204/271 [05:30<01:42,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: AceGPT, Localizing Large Language Models in Arabic\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  76%|██████████████████████████████████████████████▏              | 205/271 [05:32<01:42,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Depression Detection in Clinical Interviews with LLM-Empowered Structural Element Graph\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  76%|██████████████████████████████████████████████▎              | 206/271 [05:33<01:38,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ARM: Alignment with Residual Energy-Based Model\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  76%|██████████████████████████████████████████████▌              | 207/271 [05:35<01:36,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Branch-Solve-Merge Improves Large Language Model Evaluation and Generation\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  77%|██████████████████████████████████████████████▊              | 208/271 [05:36<01:38,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Efficient End-to-End Visual Document Understanding with Rationale Distillation\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  77%|███████████████████████████████████████████████              | 209/271 [05:38<01:35,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Semi-Structured Chain-of-Thought: Integrating Multiple Sources of Knowledge for Improved Language Model Reasoning\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  77%|███████████████████████████████████████████████▎             | 210/271 [05:40<01:34,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Evaluating the Deductive Competence of Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  78%|███████████████████████████████████████████████▍             | 211/271 [05:41<01:30,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Large Human Language Models: A Need and the Challenges\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  78%|███████████████████████████████████████████████▋             | 212/271 [05:42<01:28,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: On Learning to Summarize with Large Language Models as References\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  79%|███████████████████████████████████████████████▉             | 213/271 [05:44<01:30,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Hallucination Diversity-Aware Active Learning for Text Summarization\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  79%|████████████████████████████████████████████████▏            | 214/271 [05:46<01:27,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Investigating Data Contamination in Modern Benchmarks for Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  79%|████████████████████████████████████████████████▍            | 215/271 [05:47<01:25,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Value FULCRA: Mapping Large Language Models to the Multidimensional Spectrum of Basic Human Value\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  80%|████████████████████████████████████████████████▌            | 216/271 [05:49<01:22,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: IndiBias: A Benchmark Dataset to Measure Social Biases in Language Models for Indian Context\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  80%|████████████████████████████████████████████████▊            | 217/271 [05:51<01:37,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Revisiting Zero-Shot Abstractive Summarization in the Era of Large Language Models from the Perspective of Position Bias\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  80%|█████████████████████████████████████████████████            | 218/271 [05:53<01:35,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Struc-Bench: Are Large Language Models Good at Generating Complex Structured Tabular Data?\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  81%|█████████████████████████████████████████████████▎           | 219/271 [05:54<01:28,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Unlocking Structure Measuring: Introducing PDD, an Automatic Metric for Positional Discourse Coherence\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  81%|█████████████████████████████████████████████████▌           | 220/271 [05:56<01:22,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: MultiParaDetox: Extending Text Detoxification with Parallel Data to New Languages\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  82%|█████████████████████████████████████████████████▋           | 221/271 [05:58<01:23,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: SKICSE: Sentence Knowable Information Prompted by LLMs Improves Contrastive Sentence Embeddings\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  82%|█████████████████████████████████████████████████▉           | 222/271 [05:59<01:18,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: A Multi-Aspect Framework for Counter Narrative Evaluation using Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  82%|██████████████████████████████████████████████████▏          | 223/271 [06:00<01:13,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: How does Multi-Task Training Affect Transformer In-Context Capabilities? Investigations with Function Classes\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  83%|██████████████████████████████████████████████████▍          | 224/271 [06:02<01:11,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Unveiling Divergent Inductive Biases of LLMs on Temporal Data\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  83%|██████████████████████████████████████████████████▋          | 225/271 [06:04<01:12,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: On Retrieval Augmentation and the Limitations of Language Model Training\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  83%|██████████████████████████████████████████████████▊          | 226/271 [06:05<01:08,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Advancing the Robustness of Large Language Models through Self-Denoised Smoothing\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  84%|███████████████████████████████████████████████████          | 227/271 [06:06<01:05,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Can LLM’s Generate Human-Like Wayfinding Instructions? Towards Platform-Agnostic Embodied Instruction Synthesis\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  84%|███████████████████████████████████████████████████▎         | 228/271 [06:08<01:05,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Discourse-Aware In-Context Learning for Temporal Expression Normalization\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  85%|███████████████████████████████████████████████████▌         | 229/271 [06:10<01:04,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ALOHa: A New Measure for Hallucination in Captioning Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  85%|███████████████████████████████████████████████████▊         | 230/271 [06:11<01:03,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Beyond Yes and No: Improving Zero-Shot LLM Rankers via Scoring Fine-Grained Relevance Labels\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  85%|███████████████████████████████████████████████████▉         | 231/271 [06:13<01:02,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LLM-Driven Knowledge Injection Advances Zero-Shot and Cross-Target Stance Detection\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  86%|████████████████████████████████████████████████████▏        | 232/271 [06:14<01:00,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Llama meets EU: Investigating the European political spectrum through the lens of LLMs\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  86%|████████████████████████████████████████████████████▍        | 233/271 [06:16<01:01,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Control-DAG: Constrained Decoding for Non-Autoregressive Directed Acyclic T5 using Weighted Finite State Automata\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  86%|████████████████████████████████████████████████████▋        | 234/271 [06:17<00:57,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Lost in Space: Probing Fine-grained Spatial Understanding in Vision and Language Resamplers\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  87%|████████████████████████████████████████████████████▉        | 235/271 [06:19<00:54,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: A Continued Pretrained LLM Approach for Automatic Medical Note Generation\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  87%|█████████████████████████████████████████████████████        | 236/271 [06:21<01:00,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Self-Improving for Zero-Shot Named Entity Recognition with Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  87%|█████████████████████████████████████████████████████▎       | 237/271 [06:23<00:56,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Language Models (Mostly) Do Not Consider Emotion Triggers When Predicting Emotion\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  88%|█████████████████████████████████████████████████████▌       | 238/271 [06:24<00:52,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: CPopQA: Ranking Cultural Concept Popularity by LLMs\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  88%|█████████████████████████████████████████████████████▊       | 239/271 [06:25<00:49,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: The Impact of Language on Arithmetic Proficiency: A Multilingual Investigation with Cross-Agent Checking Computation\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  89%|██████████████████████████████████████████████████████       | 240/271 [06:27<00:47,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Removing RLHF Protections in GPT-4 via Fine-Tuning\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  89%|██████████████████████████████████████████████████████▏      | 241/271 [06:29<00:50,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LifeTox: Unveiling Implicit Toxicity in Life Advice\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  89%|██████████████████████████████████████████████████████▍      | 242/271 [06:31<00:48,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Arithmetic Reasoning with LLM: Prolog Generation & Permutation\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  90%|██████████████████████████████████████████████████████▋      | 243/271 [06:33<00:48,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: MuLan: A Study of Fact Mutability in Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  90%|██████████████████████████████████████████████████████▉      | 244/271 [06:34<00:44,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Trusting Your Evidence: Hallucinate Less with Context-aware Decoding\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  90%|███████████████████████████████████████████████████████▏     | 245/271 [06:36<00:45,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: DoubleLingo: Causal Estimation with Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  91%|███████████████████████████████████████████████████████▎     | 246/271 [06:37<00:41,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Breaking the Language Barrier: Can Direct Inference Outperform Pre-Translation in Multilingual LLM Applications?\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  91%|███████████████████████████████████████████████████████▌     | 247/271 [06:39<00:38,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Low-code LLM: Graphical User Interface over Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  92%|███████████████████████████████████████████████████████▊     | 248/271 [06:41<00:38,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: DIALIGHT: Lightweight Multilingual Development and Evaluation of Task-Oriented Dialogue Systems with Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  92%|████████████████████████████████████████████████████████     | 249/271 [06:42<00:35,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: OpinionGPT: Modelling Explicit Biases in Instruction-Tuned LLMs\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  92%|████████████████████████████████████████████████████████▎    | 250/271 [06:44<00:34,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: RedCoast: A Lightweight Tool to Automate Distributed Training of LLMs on Any GPU/TPUs\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  93%|████████████████████████████████████████████████████████▍    | 251/271 [06:45<00:31,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Newspaper Signaling for Crisis Prediction\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  93%|████████████████████████████████████████████████████████▋    | 252/271 [06:47<00:30,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: FastFit: Fast and Effective Few-Shot Text Classification with a Multitude of Classes\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  93%|████████████████████████████████████████████████████████▉    | 253/271 [06:48<00:27,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: AgentQuest: A Modular Benchmark Framework to Measure Progress and Improve LLM Agents\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  94%|█████████████████████████████████████████████████████████▏   | 254/271 [06:50<00:26,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ZhuJiu-Knowledge: A Fairer Platform for Evaluating Multiple Knowledge Types in Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  94%|█████████████████████████████████████████████████████████▍   | 255/271 [06:51<00:24,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Rephrasing Invokes Better Generations for Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  94%|█████████████████████████████████████████████████████████▌   | 256/271 [06:53<00:22,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Exploring Compositional Generalization of Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  95%|█████████████████████████████████████████████████████████▊   | 257/271 [06:55<00:24,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LUCID: LLM-Generated Utterances for Complex and Interesting Dialogues\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  95%|██████████████████████████████████████████████████████████   | 258/271 [06:57<00:22,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Exploring Inherent Biases in LLMs within Korean Social Context: A Comparative Analysis of ChatGPT and GPT-4\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  96%|██████████████████████████████████████████████████████████▎  | 259/271 [06:59<00:21,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: To Clarify or not to Clarify: A Comparative Analysis of Clarification Classification with Fine-Tuning, Prompt Tuning, and Prompt Engineering\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  96%|██████████████████████████████████████████████████████████▌  | 260/271 [07:01<00:20,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Detecting Response Generation Not Requiring Factual Judgment\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  96%|██████████████████████████████████████████████████████████▋  | 261/271 [07:03<00:18,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Improving Repository-level Code Search with Text Conversion\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  97%|██████████████████████████████████████████████████████████▉  | 262/271 [07:04<00:16,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Investigating Web Corpus Filtering Methods for Language Model Development in Japanese\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  97%|███████████████████████████████████████████████████████████▏ | 263/271 [07:06<00:13,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Distilling Text Style Transfer With Self-Explanation From LLMs\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  97%|███████████████████████████████████████████████████████████▍ | 264/271 [07:08<00:11,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Coding Open-Ended Responses using Pseudo Response Generation by Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  98%|███████████████████████████████████████████████████████████▋ | 265/271 [07:09<00:09,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Cross-Task Generalization Abilities of Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  98%|███████████████████████████████████████████████████████████▊ | 266/271 [07:11<00:08,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: HybridBERT - Making BERT Pretraining More Efficient Through Hybrid Mixture of Attention Mechanisms\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  99%|████████████████████████████████████████████████████████████ | 267/271 [07:12<00:06,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Catch Me If You GPT: Tutorial on Deepfake Texts\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  99%|████████████████████████████████████████████████████████████▎| 268/271 [07:13<00:04,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Combating Security and Privacy Issues in the Era of Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  99%|████████████████████████████████████████████████████████████▌| 269/271 [07:15<00:03,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Explanation in the Era of Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers: 100%|████████████████████████████████████████████████████████████▊| 270/271 [07:17<00:01,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Human-AI Interaction in the Age of LLMs\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing papers: 100%|█████████████████████████████████████████████████████████████| 271/271 [07:19<00:00,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import json\n",
    "import csv\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "openai.api_key = ' '\n",
    "\n",
    "# keep track of progress with an index \n",
    "progress_file = 'progress.txt'\n",
    "\n",
    "def evaluate_paper_simple(title, summary):\n",
    "    prompt = f\"\"\"\n",
    "    Can you please tell me if the title or the abstract of the paper explicitly mentions any limitation or challenge that is directly related to Large Language Models (LLM)? Please consider as positive only the limitations of the models and not of other topics mentioned. If it does, please output 'yes', if it does not, please output 'no'.\n",
    "    Please consider only limitations that are explicitely related to LLMs, everything else answer with 'no'. \n",
    "    Title: {title}\n",
    "    Paper: {summary}\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            max_tokens=50,  \n",
    "            n=1,\n",
    "            stop=None,\n",
    "            temperature=0.5\n",
    "        )\n",
    "        return response.choices[0].message['content'].strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Error during API call: {e}\")\n",
    "        return None\n",
    "\n",
    "def read_papers_from_json(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            papers = json.load(file)\n",
    "        print(f\"Successfully read {len(papers)} papers from the JSON file.\")\n",
    "        return papers\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading JSON file: {e}\")\n",
    "        return []\n",
    "\n",
    "def get_last_processed_index():\n",
    "    if os.path.exists(progress_file):\n",
    "        try:\n",
    "            with open(progress_file, 'r') as file:\n",
    "                return int(file.read().strip())\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading progress file: {e}\")\n",
    "            return -1\n",
    "    return -1\n",
    "\n",
    "def save_progress(index):\n",
    "    try:\n",
    "        with open(progress_file, 'w') as file:\n",
    "            file.write(str(index))\n",
    "        print(f\"Progress saved at index: {index}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving progress: {e}\")\n",
    "\n",
    "file_path = 'Master_Thesis/data_crawling/acl_data/naacl2024_filtered.json'\n",
    "csv_file_path = 'LLM_paper_classification/acl_classification_yes_no_results/naacl2024_filtered_results.csv'\n",
    "\n",
    "last_index = get_last_processed_index()\n",
    "print(f\"Last processed index: {last_index}\")\n",
    "\n",
    "papers = read_papers_from_json(file_path)\n",
    "\n",
    "if not papers:\n",
    "    print(\"No papers to process. Exiting.\")\n",
    "    exit()\n",
    "\n",
    "if last_index >= len(papers):\n",
    "    last_index = -1\n",
    "\n",
    "with open(csv_file_path, mode='a', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    \n",
    "    if last_index == -1:\n",
    "        writer.writerow(['Title', 'Mentions LLM Limitations'])\n",
    "        print(\"Header written to CSV file.\")\n",
    "\n",
    "    for index, paper in enumerate(tqdm(papers, desc=\"Processing papers\"), start=0):\n",
    "#skipping the papers that were already processed \n",
    "        if index <= last_index:\n",
    "            continue\n",
    "\n",
    "        title = paper.get('title', 'No Title')\n",
    "        summary = paper.get('summary', 'No Summary')\n",
    "        try:\n",
    "            evaluation_result = evaluate_paper_simple(title, summary)\n",
    "\n",
    "            if evaluation_result is None:\n",
    "                print(f\"Skipping paper at index {index} due to API call failure.\")\n",
    "                continue\n",
    "\n",
    "            result = 'yes' if 'yes' in evaluation_result.lower() else 'no'\n",
    "\n",
    "            writer.writerow([title, result])\n",
    "            print(f\"Title: {title}\\nResult: {result}\\n\")\n",
    "\n",
    "            save_progress(index)\n",
    "\n",
    "            time.sleep(1)\n",
    "            \n",
    "        except openai.error.RateLimitError:\n",
    "            print(\"Rate limit exceeded. Please try again later.\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred at index {index}: {e}\")\n",
    "            break\n",
    "\n",
    "print(\"Processing complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a7a829",
   "metadata": {},
   "source": [
    "##### Prompt 1b: ArXIv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c31d337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error reading progress file: invalid literal for int() with base 10: ''\n",
      "Last processed index: -1\n",
      "Successfully read 3312 papers from the JSON file.\n",
      "Header written to CSV file.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   0%|                                                                      | 0/3312 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: PID Control-Based Self-Healing to Improve the Robustness of Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   0%|                                                            | 1/3312 [00:03<2:53:32,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Extracting Social Determinants of Health from Pediatric Patient Notes Using Large Language Models: Novel Corpus and Methods\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   0%|                                                            | 2/3312 [00:04<2:00:43,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Fairness in Large Language Models: A Taxonomic Survey\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   0%|                                                            | 3/3312 [00:06<1:41:09,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Algorithmic Collusion by Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   0%|                                                            | 4/3312 [00:07<1:32:35,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Recover: A Neuro-Symbolic Framework for Failure Detection and Recovery\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   0%|                                                            | 5/3312 [00:08<1:27:19,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Can Language Models Recognize Convincing Arguments?\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   0%|                                                            | 6/3312 [00:10<1:23:48,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: The Larger the Better? Improved LLM Code-Generation via Budget Reallocation\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   0%|▏                                                           | 7/3312 [00:12<1:28:56,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Training-Free Semantic Segmentation via LLM-Supervision\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   0%|▏                                                           | 8/3312 [00:13<1:32:11,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: How Much are LLMs Contaminated? A Comprehensive Survey and the LLMSanitize Library\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   0%|▏                                                           | 9/3312 [00:15<1:30:51,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Scaling Properties of Speech Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   0%|▏                                                          | 10/3312 [00:17<1:30:08,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: WavLLM: Towards Robust and Adaptive Speech Large Language Model\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   0%|▏                                                          | 11/3312 [00:18<1:27:28,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Face It Yourselves: An LLM-Based Two-Stage Strategy to Localize Configuration Errors via Logs\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   0%|▏                                                          | 12/3312 [00:20<1:25:32,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Learning to Plan for Language Modeling from Unlabeled Data\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   0%|▏                                                          | 13/3312 [00:21<1:30:59,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: RQ-RAG: Learning to Refine Queries for Retrieval Augmented Generation\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   0%|▏                                                          | 14/3312 [00:23<1:30:35,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Extensive Self-Contrast Enables Feedback-Free Language Model Alignment\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   0%|▎                                                          | 15/3312 [00:25<1:26:50,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: AI Act and Large Language Models (LLMs): When critical issues and privacy impact require human and ethical oversight\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   0%|▎                                                          | 16/3312 [00:26<1:31:45,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: EvoCodeBench: An Evolving Code Generation Benchmark Aligned with Real-World Code Repositories\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   1%|▎                                                          | 17/3312 [00:28<1:29:05,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Harnessing the Power of Large Language Model for Uncertainty Aware Graph Processing\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   1%|▎                                                          | 18/3312 [00:30<1:30:22,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: CHOPS: CHat with custOmer Profile Systems for Customer Service with LLMs\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   1%|▎                                                          | 19/3312 [00:31<1:28:22,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: A Review of Modern Recommender Systems Using Generative Models (Gen-RecSys)\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   1%|▎                                                          | 20/3312 [00:33<1:26:20,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: DiffAgent: Fast and Accurate Text-to-Image API Selection with Large Language Model\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   1%|▎                                                          | 21/3312 [00:34<1:24:10,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ParaICL: Towards Robust Parallel In-Context Learning\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   1%|▍                                                          | 22/3312 [00:36<1:22:24,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: CodeBenchGen: Creating Scalable Execution-based Code Generation Benchmarks\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   1%|▍                                                          | 23/3312 [00:37<1:26:55,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: DivTOD: Unleashing the Power of LLMs for Diversifying Task-Oriented Dialogue Representations\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   1%|▍                                                          | 24/3312 [00:39<1:25:35,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Comparing Bad Apples to Good Oranges: Aligning Large Language Models via Joint Preference Optimization\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   1%|▍                                                          | 25/3312 [00:40<1:25:44,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Humane Speech Synthesis through Zero-Shot Emotion and Disfluency Generation\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   1%|▍                                                          | 26/3312 [00:42<1:26:52,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Multi-hop Question Answering under Temporal Knowledge Editing\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   1%|▍                                                          | 27/3312 [00:43<1:23:54,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: PROMPT-SAW: Leveraging Relation-Aware Graphs for Textual Prompt Compression\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   1%|▍                                                          | 28/3312 [00:46<1:34:33,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Contextual AI Journaling: Integrating LLM and Time Series Behavioral Sensing Technology to Promote Self-Reflection and Well-being using the MindScape App\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   1%|▌                                                          | 29/3312 [00:47<1:29:00,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Dialectical Alignment: Resolving the Tension of 3H and Security Threats of LLMs\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   1%|▌                                                          | 30/3312 [00:49<1:34:15,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Edinburgh Clinical NLP at SemEval-2024 Task 2: Fine-tune your model unless you have access to GPT-4\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   1%|▌                                                          | 31/3312 [00:51<1:38:56,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Linguistic Calibration of Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   1%|▌                                                          | 32/3312 [00:52<1:32:23,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: NumeroLogic: Number Encoding for Enhanced LLMs' Numerical Reasoning\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   1%|▌                                                          | 33/3312 [00:54<1:29:41,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: MetaIE: Distilling a Meta Model from LLM for All Kinds of Information Extraction Tasks\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   1%|▌                                                          | 34/3312 [00:55<1:27:39,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Do Vision-Language Models Understand Compound Nouns?\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   1%|▌                                                          | 35/3312 [00:58<1:36:51,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: CoDa: Constrained Generation based Data Augmentation for Low-Resource NLP\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   1%|▋                                                          | 36/3312 [00:59<1:31:10,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Aurora-M: The First Open Source Multilingual Language Model Red-teamed according to the U.S. Executive Order\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   1%|▋                                                          | 37/3312 [01:01<1:31:16,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Small Language Models Learn Enhanced Reasoning Skills from Medical Textbooks\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   1%|▋                                                          | 38/3312 [01:02<1:26:57,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Controllable and Diverse Data Augmentation with Large Language Model for Low-Resource Open-Domain Dialogue Generation\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   1%|▋                                                          | 39/3312 [01:03<1:23:29,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Can LLMs Master Math? Investigating Large Language Models on Math Stack Exchange\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   1%|▋                                                          | 40/3312 [01:05<1:23:15,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Augmenting NER Datasets with LLMs: Towards Automated and Refined Annotation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   1%|▋                                                          | 41/3312 [01:07<1:23:13,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Exploring Unseen Environments with Robots using Large Language and Vision Models through a Procedurally Generated 3D Scene Representation\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   1%|▋                                                          | 42/3312 [01:08<1:24:24,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ST-LLM: Large Language Models Are Effective Temporal Learners\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   1%|▊                                                          | 43/3312 [01:10<1:22:34,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: A Comprehensive Study on NLP Data Augmentation for Hate Speech Detection: Legacy Methods, BERT, and LLMs\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   1%|▊                                                          | 44/3312 [01:11<1:22:58,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Instruction-Driven Game Engines on Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   1%|▊                                                          | 45/3312 [01:13<1:25:18,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Secret Keepers: The Impact of LLMs on Linguistic Markers of Personal Traits\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   1%|▊                                                          | 46/3312 [01:15<1:29:12,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: DeFT: Flash Tree-attention with IO-Awareness for Efficient Tree-search-based LLM Inference\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   1%|▊                                                          | 47/3312 [01:16<1:27:16,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: A Survey of using Large Language Models for Generating Infrastructure as Code\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   1%|▊                                                          | 48/3312 [01:17<1:23:35,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Is Factuality Decoding a Free Lunch for LLMs? Evaluation on Knowledge Editing Benchmark\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   1%|▊                                                          | 49/3312 [01:19<1:21:06,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Injecting New Knowledge into Large Language Models via Supervised Fine-Tuning\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   2%|▉                                                          | 50/3312 [01:20<1:22:19,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Multi-Conditional Ranking with Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   2%|▉                                                          | 51/3312 [01:22<1:22:24,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: EventGround: Narrative Reasoning by Grounding to Eventuality-centric Knowledge Graphs\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   2%|▉                                                          | 52/3312 [01:23<1:20:08,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Conceptual and Unbiased Reasoning in Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   2%|▉                                                          | 53/3312 [01:25<1:22:50,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: GPTA: Generative Prompt Tuning Assistant for Synergistic Downstream Neural Network Enhancement with LLMs\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   2%|▉                                                          | 54/3312 [01:27<1:23:23,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Wait, It's All Token Noise? Always Has Been: Interpreting LLM Behavior Using Shapley Value\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   2%|▉                                                          | 55/3312 [01:28<1:25:23,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Uncovering Bias in Large Vision-Language Models with Counterfactuals\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   2%|▉                                                          | 56/3312 [01:30<1:23:00,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: On-the-fly Definition Augmentation of LLMs for Biomedical NER\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   2%|█                                                          | 57/3312 [01:31<1:26:41,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Unsolvable Problem Detection: Evaluating Trustworthiness of Vision Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   2%|█                                                          | 58/3312 [01:33<1:23:31,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Are We on the Right Way for Evaluating Large Vision-Language Models?\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   2%|█                                                          | 59/3312 [01:34<1:21:36,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ReALM: Reference Resolution As Language Modeling\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   2%|█                                                          | 60/3312 [01:36<1:22:11,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Gecko: Versatile Text Embeddings Distilled from Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   2%|█                                                          | 61/3312 [01:37<1:25:38,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Convolutional Prompting meets Language Models for Continual Learning\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   2%|█                                                          | 62/3312 [01:39<1:23:40,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Towards Greener LLMs: Bringing Energy-Efficiency to the Forefront of LLM Inference\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   2%|█                                                          | 63/3312 [01:40<1:21:29,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Can LLMs Correct Physicians, Yet? Investigating Effective Interaction Methods in the Medical Domain\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   2%|█▏                                                         | 64/3312 [01:42<1:20:13,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LayerNorm: A key component in parameter-efficient fine-tuning\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   2%|█▏                                                         | 65/3312 [01:43<1:19:18,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LUQ: Long-text Uncertainty Quantification for LLMs\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   2%|█▏                                                         | 66/3312 [01:45<1:18:12,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ELITR-Bench: A Meeting Assistant Benchmark for Long-Context Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   2%|█▏                                                         | 67/3312 [01:46<1:17:16,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Using LLMs to Model the Beliefs and Preferences of Targeted Populations\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   2%|█▏                                                         | 68/3312 [01:47<1:16:38,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Shallow Cross-Encoders for Low-Latency Retrieval\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   2%|█▏                                                         | 69/3312 [01:49<1:18:31,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Distributed agency in second language learning and teaching through generative AI\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   2%|█▏                                                         | 70/3312 [01:51<1:21:01,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: H2RSVLM: Towards Helpful and Honest Remote Sensing Large Vision Language Model\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   2%|█▎                                                         | 71/3312 [01:52<1:23:07,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Unleashing the Potential of Large Language Models for Predictive Tabular Tasks in Data Science\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   2%|█▎                                                         | 72/3312 [01:54<1:30:07,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: The Future of Combating Rumors? Retrieval, Discrimination, and Generation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   2%|█▎                                                         | 73/3312 [01:56<1:29:13,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Measuring Taiwanese Mandarin Language Understanding\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   2%|█▎                                                         | 74/3312 [01:57<1:24:54,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ChatGPT v.s. Media Bias: A Comparative Study of GPT-3.5 and Fine-tuned Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   2%|█▎                                                         | 75/3312 [01:59<1:23:12,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: IndiBias: A Benchmark Dataset to Measure Social Biases in Language Models for Indian Context\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   2%|█▎                                                         | 76/3312 [02:00<1:22:27,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Fine-tuning Large Language Models for Automated Diagnostic Screening Summaries\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   2%|█▎                                                         | 77/3312 [02:02<1:22:37,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Accurate Block Quantization in LLMs with Outliers\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   2%|█▍                                                         | 78/3312 [02:03<1:20:56,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: User Modeling Challenges in Interactive AI Assistant Systems\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   2%|█▍                                                         | 79/3312 [02:04<1:19:26,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: The Impact of Prompts on Zero-Shot Detection of AI-Generated Text\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   2%|█▍                                                         | 80/3312 [02:06<1:20:37,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ITCMA: A Generative Agent Based on a Computational Consciousness Structure\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   2%|█▍                                                         | 81/3312 [02:08<1:22:06,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Can LLMs Learn from Previous Mistakes? Investigating LLMs' Errors to Boost for Reasoning\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   2%|█▍                                                         | 82/3312 [02:09<1:21:21,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: PURPLE: Making a Large Language Model a Better SQL Writer\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   3%|█▍                                                         | 83/3312 [02:11<1:26:22,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: On Large Language Models' Hallucination with Regard to Known Facts\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   3%|█▍                                                         | 84/3312 [02:12<1:24:10,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Large Language Model based Situational Dialogues for Second Language Learning\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   3%|█▌                                                         | 85/3312 [02:14<1:22:04,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Enhancing the General Agent Capabilities of Low-Parameter LLMs through Tuning and Multi-Branch Reasoning\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   3%|█▌                                                         | 86/3312 [02:15<1:21:11,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: DiJiang: Efficient Large Language Models through Compact Kernelization\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   3%|█▌                                                         | 87/3312 [02:17<1:27:04,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: MANGO: A Benchmark for Evaluating Mapping and Navigation Abilities of Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   3%|█▌                                                         | 88/3312 [02:19<1:25:00,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Towards a Robust Retrieval-Based Summarization System\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   3%|█▌                                                         | 89/3312 [02:20<1:22:04,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LLMSense: Harnessing LLMs for High-level Reasoning Over Spatiotemporal Sensor Traces\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   3%|█▌                                                         | 90/3312 [02:21<1:20:02,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Localizing Paragraph Memorization in Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   3%|█▌                                                         | 91/3312 [02:23<1:22:28,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Multi-Frame, Lightweight & Efficient Vision-Language Models for Question Answering in Autonomous Driving\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   3%|█▋                                                         | 92/3312 [02:25<1:21:21,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Target Span Detection for Implicit Harmful Content\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   3%|█▋                                                         | 93/3312 [02:26<1:19:08,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Developing Healthcare Language Model Embedding Spaces\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   3%|█▋                                                         | 94/3312 [02:27<1:19:19,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Bespoke Large Language Models for Digital Triage Assistance in Mental Health Care\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   3%|█▋                                                         | 95/3312 [02:29<1:19:21,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: GOLD: Generalized Knowledge Distillation via Out-of-Distribution-Guided Language Data Generation\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   3%|█▋                                                         | 96/3312 [02:30<1:20:03,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: InterDreamer: Zero-Shot Text to 3D Dynamic Human-Object Interaction\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   3%|█▋                                                         | 97/3312 [02:32<1:21:59,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: MagicLens: Self-Supervised Image Retrieval with Open-Ended Instructions\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   3%|█▋                                                         | 98/3312 [02:34<1:22:08,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Change-Agent: Towards Interactive Comprehensive Remote Sensing Change Interpretation and Analysis\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   3%|█▊                                                         | 99/3312 [02:35<1:21:49,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Retrieval-Enhanced Knowledge Editing for Multi-Hop Question Answering in Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   3%|█▊                                                        | 100/3312 [02:37<1:21:16,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: TOD3Cap: Towards 3D Dense Captioning in Outdoor Scenes\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   3%|█▊                                                        | 101/3312 [02:38<1:21:59,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: WaterJudge: Quality-Detection Trade-off when Watermarking Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   3%|█▊                                                        | 102/3312 [02:40<1:21:44,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: JDocQA: Japanese Document Question Answering Dataset for Generative Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   3%|█▊                                                        | 103/3312 [02:41<1:21:04,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Mixed Preference Optimization: Reinforcement Learning with Data Selection and Better Reference Model\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   3%|█▊                                                        | 104/3312 [02:43<1:22:05,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: BP4ER: Bootstrap Prompting for Explicit Reasoning in Medical Dialogue Generation\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   3%|█▊                                                        | 105/3312 [02:44<1:22:18,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Checkpoint Merging via Bayesian Optimization in LLM Pretraining\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   3%|█▊                                                        | 106/3312 [02:46<1:20:28,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Breaking the Length Barrier: LLM-Enhanced CTR Prediction in Long Textual User Behaviors\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   3%|█▊                                                        | 107/3312 [02:47<1:19:52,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Large Language Models Are Unconscious of Unreasonability in Math Problems\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   3%|█▉                                                        | 108/3312 [02:49<1:18:04,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: IVLMap: Instance-Aware Visual Language Grounding for Consumer Robot Navigation\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   3%|█▉                                                        | 109/3312 [02:50<1:20:24,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Plug-and-Play Grounding of Reasoning in Multimodal Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   3%|█▉                                                        | 110/3312 [02:52<1:19:41,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: MATEval: A Multi-Agent Discussion Framework for Advancing Open-Ended Text Evaluation\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   3%|█▉                                                        | 111/3312 [02:53<1:18:36,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Going Beyond Word Matching: Syntax Improves In-context Example Selection for Machine Translation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   3%|█▉                                                        | 112/3312 [02:55<1:17:20,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Ungrammatical-syntax-based In-context Example Selection for Grammatical Error Correction\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   3%|█▉                                                        | 113/3312 [02:56<1:16:39,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Fine-Tuning Language Models with Reward Learning on Policy\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   3%|█▉                                                        | 114/3312 [02:57<1:15:53,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: sDPO: Don't Use Your Data All at Once\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   3%|██                                                        | 115/3312 [02:59<1:16:17,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Dual-Personalizing Adapter for Federated Foundation Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   4%|██                                                        | 116/3312 [03:00<1:15:24,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Text Data-Centric Image Captioning with Interactive Prompts\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   4%|██                                                        | 117/3312 [03:02<1:17:45,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: MUGC: Machine Generated versus User Generated Content Detection\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   4%|██                                                        | 118/3312 [03:03<1:16:49,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Make Large Language Model a Better Ranker\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   4%|██                                                        | 119/3312 [03:05<1:17:12,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Mitigating Misleading Chain-of-Thought Reasoning with Selective Filtering\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   4%|██                                                        | 120/3312 [03:06<1:18:47,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Disentangling Length from Quality in Direct Preference Optimization\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   4%|██                                                        | 121/3312 [03:08<1:17:17,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Compressing Large Language Models by Streamlining the Unimportant Layer\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   4%|██▏                                                       | 122/3312 [03:09<1:16:03,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Code Comparison Tuning for Code Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   4%|██▏                                                       | 123/3312 [03:10<1:16:46,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: MFORT-QA: Multi-hop Few-shot Open Rich Table Question Answering\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   4%|██▏                                                       | 124/3312 [03:12<1:22:25,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Top Leaderboard Ranking = Top Coding Proficiency, Always? EvoEval: Evolving Coding Benchmarks via LLM\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   4%|██▏                                                       | 125/3312 [03:14<1:19:07,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: FACTOID: FACtual enTailment fOr hallucInation Detection\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   4%|██▏                                                       | 126/3312 [03:15<1:17:28,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: JailbreakBench: An Open Robustness Benchmark for Jailbreaking Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   4%|██▏                                                       | 127/3312 [03:16<1:18:19,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Automated Black-box Prompt Engineering for Personalized Text-to-Image Generation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   4%|██▏                                                       | 128/3312 [03:18<1:19:40,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Learning From Correctness Without Prompting Makes LLM Efficient Reasoner\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   4%|██▎                                                       | 129/3312 [03:20<1:20:05,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: CAUSE: Counterfactual Assessment of User Satisfaction Estimation in Task-Oriented Dialogue Systems\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   4%|██▎                                                       | 130/3312 [03:21<1:20:17,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LITA: Language Instructed Temporal-Localization Assistant\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   4%|██▎                                                       | 131/3312 [03:23<1:19:41,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Evaluating Large Language Models for Health-Related Text Classification Tasks with Public Social Media Data\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   4%|██▎                                                       | 132/3312 [03:24<1:19:17,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Towards LLM-RecSys Alignment with Textual ID Learning\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   4%|██▎                                                       | 133/3312 [03:26<1:19:22,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: TextCraftor: Your Text Encoder Can be Image Quality Controller\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   4%|██▎                                                       | 134/3312 [03:27<1:19:52,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: \"Sorry, Come Again?\" Prompting -- Enhancing Comprehension and Diminishing Hallucination with [PAUSE]-injected Optimal Paraphrasing\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   4%|██▎                                                       | 135/3312 [03:29<1:20:11,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: A State-of-the-practice Release-readiness Checklist for Generative AI-based Software Products\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   4%|██▍                                                       | 136/3312 [03:30<1:18:35,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Measuring Political Bias in Large Language Models: What Is Said and How It Is Said\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   4%|██▍                                                       | 137/3312 [03:31<1:17:26,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Duolando: Follower GPT with Off-Policy Reinforcement Learning for Dance Accompaniment\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   4%|██▍                                                       | 138/3312 [03:33<1:17:35,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Is Modularity Transferable? A Case Study through the Lens of Knowledge Distillation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   4%|██▍                                                       | 139/3312 [03:34<1:16:16,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Projective Methods for Mitigating Gender Bias in Pre-trained Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   4%|██▍                                                       | 140/3312 [03:36<1:15:14,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Long-form factuality in large language models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   4%|██▍                                                       | 141/3312 [03:37<1:15:04,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: CheckEval: Robust Evaluation Framework using Large Language Model via Checklist\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   4%|██▍                                                       | 142/3312 [03:39<1:17:19,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Understanding the Learning Dynamics of Alignment with Human Feedback\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   4%|██▌                                                       | 143/3312 [03:40<1:16:23,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: The Invalsi Benchmark: measuring Language Models Mathematical and Language understanding in Italian\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   4%|██▌                                                       | 144/3312 [03:41<1:16:23,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: NL-ITI: Optimizing Probing and Intervention for Improvement of ITI Method\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   4%|██▌                                                       | 145/3312 [03:43<1:15:14,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: SDSAT: Accelerating LLM Inference through Speculative Decoding with Semantic Adaptive Tokens\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   4%|██▌                                                       | 146/3312 [03:44<1:15:27,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Vulnerability Detection with Code Language Models: How Far Are We?\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   4%|██▌                                                       | 147/3312 [03:46<1:16:13,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: A Path Towards Legal Autonomy: An interoperable and explainable approach to extracting, transforming, loading and computing legal information using large language models, expert systems and Bayesian networks\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   4%|██▌                                                       | 148/3312 [03:47<1:16:35,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: SemRoDe: Macro Adversarial Training to Learn Representations That are Robust to Word-Level Attacks\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   4%|██▌                                                       | 149/3312 [03:49<1:15:23,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: BioMedLM: A 2.7B Parameter Language Model Trained On Biomedical Text\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   5%|██▋                                                       | 150/3312 [03:50<1:15:54,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Leveraging Large Language Models for Relevance Judgments in Legal Case Retrieval\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   5%|██▋                                                       | 151/3312 [03:51<1:15:13,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Improving Attributed Text Generation of Large Language Models via Preference Learning\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   5%|██▋                                                       | 152/3312 [03:53<1:15:02,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: BLADE: Enhancing Black-box Large Language Models with Small Domain-Specific Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   5%|██▋                                                       | 153/3312 [03:54<1:15:43,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Rejection Improves Reliability: Training LLMs to Refuse Unknown Questions Using RL from Knowledge Feedback\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   5%|██▋                                                       | 154/3312 [03:56<1:18:14,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Quantifying and Mitigating Unimodal Biases in Multimodal Large Language Models: A Causal Perspective\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   5%|██▋                                                       | 155/3312 [03:57<1:18:52,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LC-LLM: Explainable Lane-Change Intention and Trajectory Predictions with Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   5%|██▋                                                       | 156/3312 [03:59<1:22:39,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: IterAlign: Iterative Constitutional Alignment of Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   5%|██▋                                                       | 157/3312 [04:01<1:19:12,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Can LLMs Converse Formally? Automatically Assessing LLMs in Translating and Interpreting Formal Specifications\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   5%|██▊                                                       | 158/3312 [04:02<1:19:39,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Dual Instruction Tuning with Large Language Models for Mathematical Reasoning\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   5%|██▊                                                       | 159/3312 [04:04<1:19:26,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Toward Interactive Regional Understanding in Vision-Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   5%|██▊                                                       | 160/3312 [04:05<1:17:37,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Beyond Embeddings: The Promise of Visual Table in Multi-Modal Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   5%|██▊                                                       | 161/3312 [04:07<1:17:41,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Exploring the Deceptive Power of LLM-Generated Fake News: A Study of Real-World Detection Challenges\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   5%|██▊                                                       | 162/3312 [04:08<1:16:35,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Boosting Conversational Question Answering with Fine-Grained Retrieval-Augmentation and Self-Check\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   5%|██▊                                                       | 163/3312 [04:09<1:17:31,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Leveraging Large Language Models for Fuzzy String Matching in Political Science\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   5%|██▊                                                       | 164/3312 [04:11<1:22:21,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Exploring the Privacy Protection Capabilities of Chinese Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   5%|██▉                                                       | 165/3312 [04:13<1:20:52,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Oh! We Freeze: Improving Quantized Knowledge Distillation via Signal Propagation Analysis for Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   5%|██▉                                                       | 166/3312 [04:14<1:18:26,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Large Language Models as Financial Data Annotators: A Study on Effectiveness and Efficiency\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   5%|██▉                                                       | 167/3312 [04:16<1:17:59,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Large Language Models Produce Responses Perceived to be Empathic\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   5%|██▉                                                       | 168/3312 [04:17<1:18:45,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Juru: Legal Brazilian Large Language Model from Reputable Sources\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   5%|██▉                                                       | 169/3312 [04:19<1:22:00,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: For those who don't know (how) to ask: Building a dataset of technology questions for digital newcomers\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   5%|██▉                                                       | 170/3312 [04:20<1:21:04,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Don't Trust: Verify -- Grounding LLM Quantitative Reasoning with Autoformalization\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   5%|██▉                                                       | 171/3312 [04:22<1:20:33,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Large Language Models for Education: A Survey and Outlook\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   5%|███                                                       | 172/3312 [04:23<1:18:36,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Enhancing Legal Document Retrieval: A Multi-Phase Approach with Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   5%|███                                                       | 173/3312 [04:25<1:17:06,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: PerOS: Personalized Self-Adapting Operating Systems in the Cloud\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   5%|███                                                       | 174/3312 [04:26<1:18:38,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: COIG-CQIA: Quality is All You Need for Chinese Instruction Fine-tuning\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   5%|███                                                       | 175/3312 [04:28<1:19:47,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Supervisory Prompt Training\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   5%|███                                                       | 176/3312 [04:29<1:20:05,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Improving Pre-trained Language Model Sensitivity via Mask Specific losses: A case study on Biomedical NER\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   5%|███                                                       | 177/3312 [04:31<1:19:33,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: MAGIS: LLM-Based Multi-Agent Framework for GitHub Issue Resolution\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   5%|███                                                       | 178/3312 [04:32<1:17:43,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LISA: Layerwise Importance Sampling for Memory-Efficient Large Language Model Fine-Tuning\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   5%|███▏                                                      | 179/3312 [04:34<1:18:16,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: The Unreasonable Ineffectiveness of the Deeper Layers\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   5%|███▏                                                      | 180/3312 [04:36<1:23:31,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Addressing Social Misattributions of Large Language Models: An HCXAI-based Approach\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   5%|███▏                                                      | 181/3312 [04:37<1:20:46,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Exploring LLMs as a Source of Targeted Synthetic Textual Data to Minimize High Confidence Misclassifications\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   5%|███▏                                                      | 182/3312 [04:39<1:20:00,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ChroniclingAmericaQA: A Large-scale Question Answering Dataset based on Historical American Newspaper Pages\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   6%|███▏                                                      | 183/3312 [04:40<1:18:57,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Verbing Weirds Language (Models): Evaluation of English Zero-Derivation in Five LLMs\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   6%|███▏                                                      | 184/3312 [04:41<1:16:58,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ArabicaQA: A Comprehensive Dataset for Arabic Question Answering\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   6%|███▏                                                      | 185/3312 [04:43<1:15:37,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Assessment of Multimodal Large Language Models in Alignment with Human Values\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   6%|███▎                                                      | 186/3312 [04:44<1:15:13,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Accelerating Radio Spectrum Regulation Workflows with Large Language Models (LLMs)\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   6%|███▎                                                      | 187/3312 [04:46<1:14:12,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Are Compressed Language Models Less Subgroup Robust?\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   6%|███▎                                                      | 188/3312 [04:47<1:17:59,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Improving Text-to-Image Consistency via Automatic Prompt Optimization\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   6%|███▎                                                      | 189/3312 [04:49<1:18:31,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Evaluating the Efficacy of Prompt-Engineered Large Multimodal Models Versus Fine-Tuned Vision Transformers in Image-Based Security Applications\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   6%|███▎                                                      | 190/3312 [04:50<1:16:51,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Constructions Are So Difficult That Even Large Language Models Get Them Right for the Wrong Reasons\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   6%|███▎                                                      | 191/3312 [04:52<1:17:44,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Can multiple-choice questions really be useful in detecting the abilities of LLMs?\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   6%|███▎                                                      | 192/3312 [04:53<1:18:49,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Optimization-based Prompt Injection Attack to LLM-as-a-Judge\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   6%|███▍                                                      | 193/3312 [04:55<1:20:10,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Enhanced Short Text Modeling: Leveraging Large Language Models for Topic Refinement\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   6%|███▍                                                      | 194/3312 [04:56<1:19:10,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ExpressEdit: Video Editing with Natural Language and Sketching\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   6%|███▍                                                      | 195/3312 [04:58<1:17:40,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Not All Similarities Are Created Equal: Leveraging Data-Driven Biases to Inform GenAI Copyright Disputes\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   6%|███▍                                                      | 196/3312 [04:59<1:17:25,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Depending on yourself when you should: Mentoring LLM with RL agents to become the master in cybersecurity games\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   6%|███▍                                                      | 197/3312 [05:01<1:16:36,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Targeted Visualization of the Backbone of Encoder LLMs\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   6%|███▍                                                      | 198/3312 [05:02<1:17:13,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Language Models for Text Classification: Is In-Context Learning Enough?\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   6%|███▍                                                      | 199/3312 [05:04<1:22:09,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: \"You are an expert annotator\": Automatic Best-Worst-Scaling Annotations for Emotion Intensity Modeling\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   6%|███▌                                                      | 200/3312 [05:06<1:20:56,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: RuBia: A Russian Language Bias Detection Dataset\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   6%|███▌                                                      | 201/3312 [05:07<1:25:52,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Naive Bayes-based Context Extension for Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   6%|███▌                                                      | 202/3312 [05:09<1:24:07,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Large Language Models Are State-of-the-Art Evaluator for Grammatical Error Correction\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   6%|███▌                                                      | 203/3312 [05:11<1:27:20,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ILLUMINER: Instruction-tuned Large Language Models as Few-shot Intent Classifier and Slot Filler\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   6%|███▌                                                      | 204/3312 [05:12<1:24:06,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: KC-GenRe: A Knowledge-constrained Generative Re-ranking Method Based on Large Language Models for Knowledge Graph Completion\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   6%|███▌                                                      | 205/3312 [05:14<1:21:51,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: DGoT: Dynamic Graph of Thoughts for Scientific Abstract Generation\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   6%|███▌                                                      | 206/3312 [05:15<1:19:02,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Robust and Scalable Model Editing for Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   6%|███▋                                                      | 207/3312 [05:17<1:18:30,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LM-Combiner: A Contextual Rewriting Model for Chinese Grammatical Error Correction\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   6%|███▋                                                      | 208/3312 [05:18<1:16:35,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Disambiguate Entity Matching through Relation Discovery with Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   6%|███▋                                                      | 209/3312 [05:20<1:17:56,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Residual-based Language Models are Free Boosters for Biomedical Imaging\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   6%|███▋                                                      | 210/3312 [05:22<1:23:13,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: The Solution for the ICCV 2023 1st Scientific Figure Captioning Challenge\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   6%|███▋                                                      | 211/3312 [05:23<1:19:37,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Don't Listen To Me: Understanding and Exploring Jailbreak Prompts of Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   6%|███▋                                                      | 212/3312 [05:24<1:17:11,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: JMultiWOZ: A Large-Scale Japanese Multi-Domain Task-Oriented Dialogue Dataset\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   6%|███▋                                                      | 213/3312 [05:26<1:15:55,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ALISA: Accelerating Large Language Model Inference via Sparsity-Aware KV Caching\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   6%|███▋                                                      | 214/3312 [05:27<1:17:22,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Visual Hallucination: Definition, Quantification, and Prescriptive Remediations\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   6%|███▊                                                      | 215/3312 [05:29<1:15:51,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Automate Knowledge Concept Tagging on Math Questions with LLMs\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   7%|███▊                                                      | 216/3312 [05:30<1:14:29,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: A Hybrid Approach To Aspect Based Sentiment Analysis Using Transfer Learning\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   7%|███▊                                                      | 217/3312 [05:31<1:14:47,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: TwoStep: Multi-agent Task Planning using Classical Planners and Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   7%|███▊                                                      | 218/3312 [05:33<1:15:54,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: SeSaMe: A Framework to Simulate Self-Reported Ground Truth for Mental Health Sensing Studies\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   7%|███▊                                                      | 219/3312 [05:34<1:15:55,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: A Comprehensive Study of the Capabilities of Large Language Models for Vulnerability Detection\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   7%|███▊                                                      | 220/3312 [05:36<1:16:12,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Ontology Completion with Natural Language Inference and Concept Embeddings: An Analysis\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   7%|███▊                                                      | 221/3312 [05:37<1:15:18,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Exploring the Impact of the Output Format on the Evaluation of Large Language Models for Code Translation\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   7%|███▉                                                      | 222/3312 [05:39<1:15:32,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Generation of Asset Administration Shell with Large Language Model Agents: Interoperability in Digital Twins with Semantic Node\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   7%|███▉                                                      | 223/3312 [05:40<1:15:50,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Extracting Social Support and Social Isolation Information from Clinical Psychiatry Notes: Comparing a Rule-based NLP System and a Large Language Model\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   7%|███▉                                                      | 224/3312 [05:42<1:18:17,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Outcome-Constrained Large Language Models for Countering Hate Speech\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   7%|███▉                                                      | 225/3312 [05:43<1:17:21,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: MetaAligner: Conditional Weak-to-Strong Correction for Generalizable Multi-Objective Alignment of Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   7%|███▉                                                      | 226/3312 [05:45<1:17:10,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: RepairAgent: An Autonomous, LLM-Based Agent for Program Repair\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   7%|███▉                                                      | 227/3312 [05:46<1:15:22,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: The Strong Pull of Prior Knowledge in Large Language Models and Its Impact on Emotion Recognition\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   7%|███▉                                                      | 228/3312 [05:48<1:16:45,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Attribute First, then Generate: Locally-attributable Grounded Text Generation\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   7%|████                                                      | 229/3312 [05:49<1:16:25,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: DreamLIP: Language-Image Pre-training with Long Captions\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   7%|████                                                      | 230/3312 [05:51<1:14:54,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Language Rectified Flow: Advancing Diffusion Language Generation with Probabilistic Flows\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   7%|████                                                      | 231/3312 [05:52<1:14:33,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Comp4D: LLM-Guided Compositional 4D Scene Generation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   7%|████                                                      | 232/3312 [05:54<1:14:10,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: AIOS: LLM Agent Operating System\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   7%|████                                                      | 233/3312 [05:55<1:15:38,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Aligning with Human Judgement: The Role of Pairwise Preference in Large Language Model Evaluators\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   7%|████                                                      | 234/3312 [05:57<1:19:51,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: PropTest: Automatic Property Testing for Improved Visual Programming\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   7%|████                                                      | 235/3312 [05:58<1:18:19,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Towards Algorithmic Fidelity: Mental Health Representation across Demographics in Synthetic vs. Human-generated Data\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   7%|████▏                                                     | 236/3312 [06:00<1:23:01,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Do LLM Agents Have Regret? A Case Study in Online Learning and Games\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   7%|████▏                                                     | 237/3312 [06:02<1:26:43,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Towards Human-AI Deliberation: Design and Evaluation of LLM-Empowered Deliberative AI for AI-Assisted Decision-Making\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   7%|████▏                                                     | 238/3312 [06:04<1:26:00,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: An LLM-Based Digital Twin for Optimizing Human-in-the Loop Systems\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   7%|████▏                                                     | 239/3312 [06:05<1:26:01,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Iterative Refinement of Project-Level Code Context for Precise Code Generation with Compiler Feedback\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   7%|████▏                                                     | 240/3312 [06:07<1:21:41,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: All Artificial, Less Intelligence: GenAI through the Lens of Formal Verification\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   7%|████▏                                                     | 241/3312 [06:09<1:24:41,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Investigation of the effectiveness of applying ChatGPT in Dialogic Teaching Using Electroencephalography\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   7%|████▏                                                     | 242/3312 [06:10<1:27:14,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: CLHA: A Simple yet Effective Contrastive Learning Framework for Human Alignment\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   7%|████▎                                                     | 243/3312 [06:12<1:24:39,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Conversational Grounding: Annotation and Analysis of Grounding Acts and Grounding Units\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   7%|████▎                                                     | 244/3312 [06:13<1:20:52,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Can Large Language Models (or Humans) Distill Text?\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   7%|████▎                                                     | 245/3312 [06:15<1:18:12,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: NSINA: A News Corpus for Sinhala\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   7%|████▎                                                     | 246/3312 [06:16<1:17:22,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Elysium: Exploring Object-level Perception in Videos via MLLM\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   7%|████▎                                                     | 247/3312 [06:18<1:15:43,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Hallucination Detection in Foundation Models for Decision-Making: A Flexible Definition and Review of the State of the Art\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   7%|████▎                                                     | 248/3312 [06:19<1:15:36,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Harnessing the power of LLMs for normative reasoning in MASs\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   8%|████▎                                                     | 249/3312 [06:21<1:16:04,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LLMs Are Few-Shot In-Context Low-Resource Language Learners\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   8%|████▍                                                     | 250/3312 [06:22<1:16:24,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LARA: Linguistic-Adaptive Retrieval-Augmented LLMs for Multi-Turn Intent Classification\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   8%|████▍                                                     | 251/3312 [06:24<1:15:08,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Towards Automatic Evaluation for LLMs' Clinical Capabilities: Metric, Data, and Algorithm\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   8%|████▍                                                     | 252/3312 [06:25<1:15:58,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: CodeS: Natural Language to Code Repository via Multi-Layer Sketch\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   8%|████▍                                                     | 253/3312 [06:27<1:14:22,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Evaluating Large Language Models with Runtime Behavior of Program Execution\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   8%|████▍                                                     | 254/3312 [06:28<1:14:08,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: InstUPR : Instruction-based Unsupervised Passage Reranking with Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   8%|████▍                                                     | 255/3312 [06:30<1:19:47,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: $\\textit{LinkPrompt}$: Natural and Universal Adversarial Attacks on Prompt-based Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   8%|████▍                                                     | 256/3312 [06:31<1:19:18,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Re2LLM: Reflective Reinforcement Large Language Model for Session-based Recommendation\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   8%|████▌                                                     | 257/3312 [06:33<1:18:34,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: An Experiment with the Use of ChatGPT for LCSH Subject Assignment on Electronic Theses and Dissertations\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   8%|████▌                                                     | 258/3312 [06:34<1:16:29,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: How Reliable is Your Simulator? Analysis on the Limitations of Current LLM-based User Simulators for Conversational Recommendation\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   8%|████▌                                                     | 259/3312 [06:36<1:15:26,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Is There a One-Model-Fits-All Approach to Information Extraction? Revisiting Task Definition Biases\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   8%|████▌                                                     | 260/3312 [06:37<1:16:31,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Concurrent Linguistic Error Detection (CLED) for Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   8%|████▌                                                     | 261/3312 [06:39<1:20:23,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Dia-LLaMA: Towards Large Language Model-driven CT Report Generation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   8%|████▌                                                     | 262/3312 [06:40<1:18:04,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Synthesize Step-by-Step: Tools, Templates and LLMs as Data Generators for Reasoning-Based Chart VQA\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   8%|████▌                                                     | 263/3312 [06:42<1:17:24,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ChatDBG: An AI-Powered Debugging Assistant\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   8%|████▌                                                     | 264/3312 [06:43<1:17:17,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Enhanced Facet Generation with LLM Editing\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   8%|████▋                                                     | 265/3312 [06:45<1:15:57,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Is Watermarking LLM-Generated Code Robust?\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   8%|████▋                                                     | 266/3312 [06:46<1:16:58,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Large Language Models in Biomedical and Health Informatics: A Bibliometric Review\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   8%|████▋                                                     | 267/3312 [06:48<1:15:06,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Engineering Safety Requirements for Autonomous Driving with Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   8%|████▋                                                     | 268/3312 [06:49<1:13:55,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: AVicuna: Audio-Visual LLM with Interleaver and Context-Boundary Alignment for Temporal Referential Dialogue\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   8%|████▋                                                     | 269/3312 [06:51<1:14:25,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Large Language Models Offer an Alternative to the Traditional Approach of Topic Modelling\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   8%|████▋                                                     | 270/3312 [06:52<1:13:44,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: CoverUp: Coverage-Guided LLM-Based Test Generation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   8%|████▋                                                     | 271/3312 [06:54<1:19:26,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ALoRA: Allocating Low-Rank Adaptation for Fine-tuning Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   8%|████▊                                                     | 272/3312 [06:56<1:19:24,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: A Little Leak Will Sink a Great Ship: Survey of Transparency for Large Language Models from Start to Finish\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   8%|████▊                                                     | 273/3312 [06:57<1:18:01,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Opportunities and challenges in the application of large artificial intelligence models in radiology\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   8%|████▊                                                     | 274/3312 [06:58<1:15:48,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Can Language Models Pretend Solvers? Logic Code Simulation with LLMs\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   8%|████▊                                                     | 275/3312 [07:00<1:14:08,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LLMs as Compiler for Arabic Programming Language\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   8%|████▊                                                     | 276/3312 [07:02<1:20:29,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Argument Quality Assessment in the Age of Instruction-Following Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   8%|████▊                                                     | 277/3312 [07:03<1:18:11,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Qibo: A Large Language Model for Traditional Chinese Medicine\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   8%|████▊                                                     | 278/3312 [07:05<1:18:05,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Monotonic Paraphrasing Improves Generalization of Language Model Prompting\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   8%|████▉                                                     | 279/3312 [07:06<1:17:21,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: CBT-LLM: A Chinese Large Language Model for Cognitive Behavioral Therapy-based Mental Health Question Answering\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   8%|████▉                                                     | 280/3312 [07:08<1:16:29,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LlamBERT: Large-scale low-cost data annotation in NLP\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   8%|████▉                                                     | 281/3312 [07:09<1:16:21,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Leveraging Zero-Shot Prompting for Efficient Language Model Distillation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   9%|████▉                                                     | 282/3312 [07:11<1:15:50,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: TrustSQL: A Reliability Benchmark for Text-to-SQL Models with Diverse Unanswerable Questions\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   9%|████▉                                                     | 283/3312 [07:12<1:16:48,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Using Large Language Models for OntoClean-based Ontology Refinement\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   9%|████▉                                                     | 284/3312 [07:14<1:14:40,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: When LLM-based Code Generation Meets the Software Development Process\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   9%|████▉                                                     | 285/3312 [07:15<1:13:22,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ARO: Large Language Model Supervised Robotics Text2Skill Autonomous Learning\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   9%|█████                                                     | 286/3312 [07:16<1:13:37,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Computational Sentence-level Metrics Predicting Human Sentence Comprehension\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   9%|█████                                                     | 287/3312 [07:18<1:12:25,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: AttentionStore: Cost-effective Attention Reuse across Multi-turn Conversations in Large Language Model Serving\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   9%|█████                                                     | 288/3312 [07:19<1:13:53,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: The Frontier of Data Erasure: Machine Unlearning for Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   9%|█████                                                     | 289/3312 [07:21<1:13:05,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Leveraging Large Language Models for Preliminary Security Risk Analysis: A Mission-Critical Case Study\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   9%|█████                                                     | 290/3312 [07:22<1:16:16,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Ghost Sentence: A Tool for Everyday Users to Copyright Data from Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   9%|█████                                                     | 291/3312 [07:24<1:15:32,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LLMs Instruct LLMs:An Extraction and Editing Method\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   9%|█████                                                     | 292/3312 [07:25<1:15:42,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Towards a RAG-based Summarization Agent for the Electron-Ion Collider\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   9%|█████▏                                                    | 293/3312 [07:27<1:20:53,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Contact-aware Human Motion Generation from Textual Descriptions\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   9%|█████▏                                                    | 294/3312 [07:29<1:21:45,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: FEEL: A Framework for Evaluating Emotional Support Capability with Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   9%|█████▏                                                    | 295/3312 [07:30<1:20:16,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: SceneX:Procedural Controllable Large-scale Scene Generation via Large-language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   9%|█████▏                                                    | 296/3312 [07:32<1:17:33,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: MixRED: A Mix-lingual Relation Extraction Dataset\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   9%|█████▏                                                    | 297/3312 [07:33<1:18:21,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: EAGLE: A Domain Generalization Framework for AI-generated Text Detection\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   9%|█████▏                                                    | 298/3312 [07:35<1:23:08,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: AI for Biomedicine in the Era of Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   9%|█████▏                                                    | 299/3312 [07:37<1:22:38,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: SRLM: Human-in-Loop Interactive Social Robot Navigation with Large Language Model and Deep Reinforcement Learning\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   9%|█████▎                                                    | 300/3312 [07:38<1:18:19,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Differentially Private Next-Token Prediction of Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   9%|█████▎                                                    | 301/3312 [07:40<1:18:40,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Just another copy and paste? Comparing the security vulnerabilities of ChatGPT generated code and StackOverflow answers\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   9%|█████▎                                                    | 302/3312 [07:42<1:18:46,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Large language models for crowd decision making based on prompt design strategies using ChatGPT: models, analysis and challenges\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   9%|█████▎                                                    | 303/3312 [07:43<1:20:34,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Generative AI in Education: A Study of Educators' Awareness, Sentiments, and Influencing Factors\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   9%|█████▎                                                    | 304/3312 [07:45<1:18:42,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: MedPromptX: Grounded Multimodal Prompting for Chest X-ray Diagnosis\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   9%|█████▎                                                    | 305/3312 [07:46<1:19:27,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Long-CLIP: Unlocking the Long-Text Capability of CLIP\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   9%|█████▎                                                    | 306/3312 [07:48<1:18:00,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Can large language models explore in-context?\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   9%|█████▍                                                    | 307/3312 [07:49<1:16:10,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LimGen: Probing the LLMs for Generating Suggestive Limitations of Research Papers\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   9%|█████▍                                                    | 308/3312 [07:51<1:17:02,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Evaluating GPT-4 with Vision on Detection of Radiological Findings on Chest Radiographs\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   9%|█████▍                                                    | 309/3312 [07:52<1:16:54,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: CoLLEGe: Concept Embedding Generation for Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   9%|█████▍                                                    | 310/3312 [07:54<1:18:04,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Selectively Informative Description can Reduce Undesired Embedding Entanglements in Text-to-Image Personalization\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   9%|█████▍                                                    | 311/3312 [07:55<1:16:38,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Sphere Neural-Networks for Rational Reasoning\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   9%|█████▍                                                    | 312/3312 [07:57<1:16:47,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Bioinformatics and Biomedical Informatics with ChatGPT: Year One Review\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   9%|█████▍                                                    | 313/3312 [07:59<1:22:47,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Event Temporal Relation Extraction based on Retrieval-Augmented on LLMs\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:   9%|█████▍                                                    | 314/3312 [08:01<1:22:04,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Imagination Augmented Generation: Learning to Imagine Richer Context for Question Answering over Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  10%|█████▌                                                    | 315/3312 [08:02<1:19:59,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Comprehensive Reassessment of Large-Scale Evaluation Outcomes in LLMs: A Multifaceted Statistical Approach\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  10%|█████▌                                                    | 316/3312 [08:04<1:19:17,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: FollowIR: Evaluating and Teaching Information Retrieval Models to Follow Instructions\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  10%|█████▌                                                    | 317/3312 [08:05<1:18:34,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: An Exploratory Investigation into Code License Infringements in Large Language Model Training Datasets\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  10%|█████▌                                                    | 318/3312 [08:07<1:15:55,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Not All Attention is Needed: Parameter and Computation Efficient Transfer Learning for Multi-modal Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  10%|█████▌                                                    | 319/3312 [08:08<1:15:19,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: InstaSynth: Opportunities and Challenges in Generating Synthetic Instagram Data with ChatGPT for Sponsored Content Detection\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  10%|█████▌                                                    | 320/3312 [08:09<1:13:21,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: MSCoTDet: Language-driven Multi-modal Fusion for Improved Multispectral Pedestrian Detection\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  10%|█████▌                                                    | 321/3312 [08:11<1:14:00,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Investigating the Performance of Language Models for Completing Code in Functional Programming Languages: a Haskell Case Study\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  10%|█████▋                                                    | 322/3312 [08:12<1:12:28,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: CACA Agent: Capability Collaboration based AI Agent\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  10%|█████▋                                                    | 323/3312 [08:14<1:12:48,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Text clustering with LLM embeddings\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  10%|█████▋                                                    | 324/3312 [08:15<1:12:03,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Construction of a Japanese Financial Benchmark for Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  10%|█████▋                                                    | 325/3312 [08:17<1:19:08,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LLM2LLM: Boosting LLMs with Novel Iterative Data Enhancement\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  10%|█████▋                                                    | 326/3312 [08:19<1:18:25,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Magic for the Age of Quantized DNNs\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  10%|█████▋                                                    | 327/3312 [08:20<1:16:04,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Risk and Response in Large Language Models: Evaluating Key Threat Categories\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  10%|█████▋                                                    | 328/3312 [08:22<1:15:38,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: MasonTigers at SemEval-2024 Task 9: Solving Puzzles with an Ensemble of Chain-of-Thoughts\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  10%|█████▊                                                    | 329/3312 [08:23<1:17:16,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Comprehensive Evaluation and Insights into the Use of Large Language Models in the Automation of Behavior-Driven Development Acceptance Test Formulation\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  10%|█████▊                                                    | 330/3312 [08:25<1:17:03,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Adapprox: Adaptive Approximation in Adam Optimization via Randomized Low-Rank Matrices\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  10%|█████▊                                                    | 331/3312 [08:26<1:19:49,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Evidence-Driven Retrieval Augmented Response Generation for Online Misinformation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  10%|█████▊                                                    | 332/3312 [08:28<1:22:13,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: On Zero-Shot Counterspeech Generation by LLMs\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  10%|█████▊                                                    | 333/3312 [08:30<1:18:14,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: AutoRE: Document-Level Relation Extraction with Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  10%|█████▊                                                    | 334/3312 [08:31<1:17:23,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Evaluating the Performance of LLMs on Technical Language Processing tasks\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  10%|█████▊                                                    | 335/3312 [08:33<1:14:58,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: VidLA: Video-Language Alignment at Scale\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  10%|█████▉                                                    | 336/3312 [08:34<1:15:32,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Comparing Plausibility Estimates in Base and Instruction-Tuned Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  10%|█████▉                                                    | 337/3312 [08:36<1:14:36,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: The opportunities and risks of large language models in mental health\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  10%|█████▉                                                    | 338/3312 [08:37<1:19:43,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Can 3D Vision-Language Models Truly Understand Natural Language?\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  10%|█████▉                                                    | 339/3312 [08:39<1:18:07,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: VURF: A General-purpose Reasoning and Self-refinement Framework for Video Understanding\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  10%|█████▉                                                    | 340/3312 [08:40<1:17:31,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: MathVerse: Does Your Multi-modal LLM Truly See the Diagrams in Visual Math Problems?\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  10%|█████▉                                                    | 341/3312 [08:42<1:17:43,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Language Repository for Long Video Understanding\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  10%|█████▉                                                    | 342/3312 [08:44<1:19:34,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Parameter-Efficient Fine-Tuning for Large Models: A Comprehensive Survey\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  10%|██████                                                    | 343/3312 [08:45<1:16:50,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: RAmBLA: A Framework for Evaluating the Reliability of LLMs as Assistants in the Biomedical Domain\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  10%|██████                                                    | 344/3312 [08:47<1:14:39,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: A Chain-of-Thought Prompting Approach with LLMs for Evaluating Students' Formative Assessment Responses in Science\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  10%|██████                                                    | 345/3312 [08:48<1:15:24,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: The Era of Semantic Decoding\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  10%|██████                                                    | 346/3312 [08:50<1:15:06,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: EDT: Improving Large Language Models' Generation by Entropy-based Dynamic Temperature Sampling\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  10%|██████                                                    | 347/3312 [08:51<1:12:46,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Open Source Conversational LLMs do not know most Spanish words\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  11%|██████                                                    | 348/3312 [08:52<1:11:38,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Detoxifying Large Language Models via Knowledge Editing\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  11%|██████                                                    | 349/3312 [08:54<1:11:20,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ChatGPT Alternative Solutions: Large Language Models Survey\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  11%|██████▏                                                   | 350/3312 [08:55<1:11:31,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: gTBLS: Generating Tables from Text by Conditional Question Answering\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  11%|██████▏                                                   | 351/3312 [08:57<1:12:26,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Locating and Mitigating Gender Bias in Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  11%|██████▏                                                   | 352/3312 [08:58<1:13:40,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Pensieve: Retrospect-then-Compare Mitigates Visual Hallucination\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  11%|██████▏                                                   | 353/3312 [09:00<1:14:50,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Building Accurate Translation-Tailored LLMs with Language Aware Instruction Tuning\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  11%|██████▏                                                   | 354/3312 [09:01<1:13:05,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: From Large to Tiny: Distilling and Refining Mathematical Expertise for Math Word Problems with Weakly Supervision\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  11%|██████▏                                                   | 355/3312 [09:03<1:15:46,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: FIT-RAG: Black-Box RAG with Factual Information and Token Reduction\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  11%|██████▏                                                   | 356/3312 [09:04<1:14:51,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: WikiFactDiff: A Large, Realistic, and Temporally Adaptable Dataset for Atomic Factual Knowledge Update in Causal Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  11%|██████▎                                                   | 357/3312 [09:06<1:13:21,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Less but Better: Enabling Generalized Zero-shot Learning Towards Unseen Domains by Intrinsic Learning from Redundant LLM Semantics\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  11%|██████▎                                                   | 358/3312 [09:07<1:13:27,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Exploring the Potential of Large Language Models in Graph Generation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  11%|██████▎                                                   | 359/3312 [09:09<1:12:56,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Beyond Surface Similarity: Detecting Subtle Semantic Shifts in Financial Narratives\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  11%|██████▎                                                   | 360/3312 [09:10<1:12:58,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ChainLM: Empowering Large Language Models with Improved Chain-of-Thought Prompting\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  11%|██████▎                                                   | 361/3312 [09:12<1:11:23,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: From Perils to Possibilities: Understanding how Human (and AI) Biases affect Online Fora\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  11%|██████▎                                                   | 362/3312 [09:14<1:16:32,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Multi-role Consensus through LLMs Discussions for Vulnerability Detection\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  11%|██████▎                                                   | 363/3312 [09:15<1:15:21,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LLM-based Extraction of Contradictions from Patents\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  11%|██████▎                                                   | 364/3312 [09:17<1:17:59,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ERD: A Framework for Improving LLM Reasoning for Cognitive Distortion Classification\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  11%|██████▍                                                   | 365/3312 [09:18<1:17:28,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LayoutLLM: Large Language Model Instruction Tuning for Visually Rich Document Understanding\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  11%|██████▍                                                   | 366/3312 [09:20<1:19:13,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Dermacen Analytica: A Novel Methodology Integrating Multi-Modal Large Language Models with Machine Learning in tele-dermatology\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  11%|██████▍                                                   | 367/3312 [09:21<1:16:15,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Reinforcement Learning from Reflective Feedback (RLRF): Aligning and Improving LLMs via Fine-Grained Self-Reflection\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  11%|██████▍                                                   | 368/3312 [09:23<1:13:38,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: PeerGPT: Probing the Roles of LLM-based Peer Agents as Team Moderators and Participants in Children's Collaborative Learning\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  11%|██████▍                                                   | 369/3312 [09:24<1:14:08,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Improving the Robustness of Large Language Models via Consistency Alignment\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  11%|██████▍                                                   | 370/3312 [09:26<1:12:52,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Context Quality Matters in Training Fusion-in-Decoder for Extractive Open-Domain Question Answering\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  11%|██████▍                                                   | 371/3312 [09:27<1:13:33,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: MMIDR: Teaching Large Language Model to Interpret Multimodal Misinformation via Knowledge Distillation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  11%|██████▌                                                   | 372/3312 [09:29<1:12:16,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Deep Learning for Trajectory Data Management and Mining: A Survey and Beyond\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  11%|██████▌                                                   | 373/3312 [09:30<1:14:52,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Empowering Segmentation Ability to Multi-modal Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  11%|██████▌                                                   | 374/3312 [09:32<1:13:59,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: AI and Memory Wall\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  11%|██████▌                                                   | 375/3312 [09:33<1:13:30,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Multi-Level Feedback Generation with Large Language Models for Empowering Novice Peer Counselors\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  11%|██████▌                                                   | 376/3312 [09:35<1:15:05,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: From Handcrafted Features to LLMs: A Brief Survey for Machine Translation Quality Estimation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  11%|██████▌                                                   | 377/3312 [09:36<1:13:59,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Benchmarking Chinese Commonsense Reasoning of LLMs: From Chinese-Specifics to Reasoning-Memorization Correlations\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  11%|██████▌                                                   | 378/3312 [09:38<1:17:03,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Antisocial Analagous Behavior, Alignment and Human Impact of Google AI Systems: Evaluating through the lens of modified Antisocial Behavior Criteria by Human Interaction, Independent LLM Analysis, and AI Self-Reflection\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  11%|██████▋                                                   | 379/3312 [09:40<1:15:44,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Can ChatGPT Detect DeepFakes? A Study of Using Multimodal Large Language Models for Media Forensics\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  11%|██████▋                                                   | 380/3312 [09:41<1:13:15,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Protected group bias and stereotypes in Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  12%|██████▋                                                   | 381/3312 [09:42<1:11:51,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LLMs as Writing Assistants: Exploring Perspectives on Sense of Ownership and Reasoning\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  12%|██████▋                                                   | 382/3312 [09:44<1:11:24,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Ink and Individuality: Crafting a Personalised Narrative in the Age of LLMs\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  12%|██████▋                                                   | 383/3312 [09:45<1:10:28,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Reducing Large Language Model Bias with Emphasis on 'Restricted Industries': Automated Dataset Augmentation and Prejudice Quantification\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  12%|██████▋                                                   | 384/3312 [09:47<1:13:02,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Train & Constrain: Phonologically Informed Tongue-Twister Generation from Topics and Paraphrases\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  12%|██████▋                                                   | 385/3312 [09:50<1:31:03,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: RAR: Retrieving And Ranking Augmented MLLMs for Visual Recognition\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  12%|██████▊                                                   | 386/3312 [09:52<1:40:59,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Reverse Training to Nurse the Reversal Curse\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  12%|██████▊                                                   | 387/3312 [09:54<1:32:33,  1.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Bridge the Modality and Capacity Gaps in Vision-Language Model Selection\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  12%|██████▊                                                   | 388/3312 [09:55<1:26:34,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Chain-of-Interaction: Enhancing Large Language Models for Psychiatric Behavior Understanding by Dyadic Contexts\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  12%|██████▊                                                   | 389/3312 [09:56<1:21:29,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Information-Theoretic Distillation for Reference-less Summarization\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  12%|██████▊                                                   | 390/3312 [09:58<1:17:12,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: EthioLLM: Multilingual Large Language Models for Ethiopian Languages with Task Evaluation\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  12%|██████▊                                                   | 391/3312 [09:59<1:15:38,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Large Language Models meet Network Slicing Management and Orchestration\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  12%|██████▊                                                   | 392/3312 [10:01<1:14:40,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: RoleInteract: Evaluating the Social Interaction of Role-Playing Agents\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  12%|██████▉                                                   | 393/3312 [10:02<1:12:50,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Defending Against Indirect Prompt Injection Attacks With Spotlighting\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  12%|██████▉                                                   | 394/3312 [10:04<1:13:12,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: No more optimization rules: LLM-enabled policy-based multi-modal query optimizer\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  12%|██████▉                                                   | 395/3312 [10:05<1:14:19,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Teacher-Student Training for Debiasing: General Permutation Debiasing for Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  12%|██████▉                                                   | 396/3312 [10:07<1:14:13,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: CONLINE: Complex Code Generation and Refinement with Online Searching and Correctness Testing\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  12%|██████▉                                                   | 397/3312 [10:08<1:12:27,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: A Large Language Model Enhanced Sequential Recommender for Joint Video and Comment Recommendation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  12%|██████▉                                                   | 398/3312 [10:10<1:12:08,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Integrating Large Language Models for Severity Classification in Traffic Incident Management: A Machine Learning Approach\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  12%|██████▉                                                   | 399/3312 [10:11<1:13:59,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Motion Generation from Fine-grained Textual Descriptions\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  12%|███████                                                   | 400/3312 [10:13<1:13:30,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: FMM-Attack: A Flow-based Multi-modal Adversarial Attack on Video-based LLMs\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  12%|███████                                                   | 401/3312 [10:14<1:12:12,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: VSTAR: Generative Temporal Nursing for Longer Dynamic Video Synthesis\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  12%|███████                                                   | 402/3312 [10:16<1:13:37,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: An Entropy-based Text Watermarking Detection Method\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  12%|███████                                                   | 403/3312 [10:17<1:13:57,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Vi-Mistral-X: Building a Vietnamese Language Model with Advanced Continual Pre-training\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  12%|███████                                                   | 404/3312 [10:19<1:11:49,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LlamaFactory: Unified Efficient Fine-Tuning of 100+ Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  12%|███████                                                   | 405/3312 [10:20<1:11:00,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ManiPose: A Comprehensive Benchmark for Pose-aware Object Manipulation in Robotics\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  12%|███████                                                   | 406/3312 [10:22<1:10:12,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: BadEdit: Backdooring large language models by model editing\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  12%|███████▏                                                  | 407/3312 [10:23<1:09:40,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Adaptive Ensembles of Fine-Tuned Transformers for LLM-Generated Text Detection\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  12%|███████▏                                                  | 408/3312 [10:24<1:09:00,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Out-of-Distribution Detection Using Peer-Class Generated by Large Language Model\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  12%|███████▏                                                  | 409/3312 [10:26<1:09:29,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: PuzzleVQA: Diagnosing Multimodal Reasoning Challenges of Language Models with Abstract Visual Patterns\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  12%|███████▏                                                  | 410/3312 [10:27<1:09:51,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Polaris: A Safety-focused LLM Constellation Architecture for Healthcare\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  12%|███████▏                                                  | 411/3312 [10:29<1:08:54,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LeanReasoner: Boosting Complex Logical Reasoning with Lean\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  12%|███████▏                                                  | 412/3312 [10:30<1:08:15,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Mapping LLM Security Landscapes: A Comprehensive Stakeholder Risk Assessment Proposal\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  12%|███████▏                                                  | 413/3312 [10:32<1:07:49,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Reading Users' Minds from What They Say: An Investigation into LLM-based Empathic Mental Inference\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  12%|███████▎                                                  | 414/3312 [10:33<1:07:32,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Facilitating Pornographic Text Detection for Open-Domain Dialogue Systems via Knowledge Distillation of Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  13%|███████▎                                                  | 415/3312 [10:34<1:07:51,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Instruction Multi-Constraint Molecular Generation Using a Teacher-Student Large Language Model\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  13%|███████▎                                                  | 416/3312 [10:36<1:09:17,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: SumTra: A Differentiable Pipeline for Few-Shot Cross-Lingual Summarization\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  13%|███████▎                                                  | 417/3312 [10:37<1:09:33,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Technical Report: Competition Solution For BetterMixture\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  13%|███████▎                                                  | 418/3312 [10:39<1:08:38,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: From Representational Harms to Quality-of-Service Harms: A Case Study on Llama 2 Safety Safeguards\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  13%|███████▎                                                  | 419/3312 [10:40<1:09:23,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: A Study of Vulnerability Repair in JavaScript Programs with Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  13%|███████▎                                                  | 420/3312 [10:42<1:08:35,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: VL-ICL Bench: The Devil in the Details of Benchmarking Multimodal In-Context Learning\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  13%|███████▎                                                  | 421/3312 [10:43<1:10:23,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Automatic Summarization of Doctor-Patient Encounter Dialogues Using Large Language Model through Prompt Tuning\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  13%|███████▍                                                  | 422/3312 [10:45<1:12:51,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LLMs-based Few-Shot Disease Predictions using EHR: A Novel Approach Combining Predictive Agent Reasoning and Critical Agent Instruction\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  13%|███████▍                                                  | 423/3312 [10:47<1:17:05,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LLMLingua-2: Data Distillation for Efficient and Faithful Task-Agnostic Prompt Compression\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  13%|███████▍                                                  | 424/3312 [10:48<1:14:46,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Chain-of-Spot: Interactive Reasoning Improves Large Vision-Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  13%|███████▍                                                  | 425/3312 [10:49<1:13:23,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Dated Data: Tracing Knowledge Cutoffs in Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  13%|███████▍                                                  | 426/3312 [10:51<1:16:24,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Bypassing LLM Watermarks with Color-Aware Substitutions\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  13%|███████▍                                                  | 427/3312 [10:53<1:13:49,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Automatic Information Extraction From Employment Tribunal Judgements Using Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  13%|███████▍                                                  | 428/3312 [10:54<1:14:43,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Supporting Energy Policy Research with Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  13%|███████▌                                                  | 429/3312 [10:56<1:14:09,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Semantic Layering in Room Segmentation via LLMs\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  13%|███████▌                                                  | 430/3312 [10:57<1:12:23,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Yell At Your Robot: Improving On-the-Fly from Language Corrections\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  13%|███████▌                                                  | 431/3312 [10:59<1:12:01,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Toward Sustainable GenAI using Generation Directives for Carbon-Friendly Large Language Model Inference\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  13%|███████▌                                                  | 432/3312 [11:00<1:10:58,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: HYDRA: A Hyper Agent for Dynamic Compositional Visual Reasoning\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  13%|███████▌                                                  | 433/3312 [11:02<1:11:18,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Agent-FLAN: Designing Data and Methods of Effective Agent Tuning for Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  13%|███████▌                                                  | 434/3312 [11:03<1:11:59,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Compositional 3D Scene Synthesis with Scene Graph Guided Layout-Shape Generation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  13%|███████▌                                                  | 435/3312 [11:05<1:11:07,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: MELTing point: Mobile Evaluation of Language Transformers\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  13%|███████▋                                                  | 436/3312 [11:06<1:10:25,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Contextual Moral Value Alignment Through Context-Based Aggregation\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  13%|███████▋                                                  | 437/3312 [11:07<1:09:06,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: RelationVLM: Making Large Vision-Language Models Understand Visual Relations\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  13%|███████▋                                                  | 438/3312 [11:09<1:10:41,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Investigating Text Shortening Strategy in BERT: Truncation vs Summarization\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  13%|███████▋                                                  | 439/3312 [11:10<1:10:43,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Automated Data Curation for Robust Language Model Fine-Tuning\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  13%|███████▋                                                  | 440/3312 [11:12<1:10:26,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Instructing Large Language Models to Identify and Ignore Irrelevant Conditions\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  13%|███████▋                                                  | 441/3312 [11:13<1:09:08,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Pragmatic Competence Evaluation of Large Language Models for Korean\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  13%|███████▋                                                  | 442/3312 [11:15<1:09:32,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Enhancing Formal Theorem Proving: A Comprehensive Dataset for Training AI Models on Coq Code\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  13%|███████▊                                                  | 443/3312 [11:16<1:10:35,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LHMKE: A Large-scale Holistic Multi-subject Knowledge Evaluation Benchmark for Chinese Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  13%|███████▊                                                  | 444/3312 [11:18<1:11:45,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Chart-based Reasoning: Transferring Capabilities from LLMs to VLMs\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  13%|███████▊                                                  | 445/3312 [11:19<1:11:57,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: AlphaFin: Benchmarking Financial Analysis with Retrieval-Augmented Stock-Chain Framework\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  13%|███████▊                                                  | 446/3312 [11:21<1:11:36,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Factorized Learning Assisted with Large Language Model for Gloss-free Sign Language Translation\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  13%|███████▊                                                  | 447/3312 [11:22<1:11:55,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: AffineQuant: Affine Transformation Quantization for Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  14%|███████▊                                                  | 448/3312 [11:24<1:16:54,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: To Help or Not to Help: LLM-based Attentive Support for Human-Robot Group Interactions\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  14%|███████▊                                                  | 449/3312 [11:26<1:15:04,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: UniBind: LLM-Augmented Unified and Balanced Representation Space to Bind Them All\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  14%|███████▉                                                  | 450/3312 [11:27<1:13:45,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: RigorLLM: Resilient Guardrails for Large Language Models against Undesired Content\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  14%|███████▉                                                  | 451/3312 [11:29<1:11:54,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Securing Large Language Models: Threats, Vulnerabilities and Responsible Practices\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  14%|███████▉                                                  | 452/3312 [11:30<1:12:17,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: DetToolChain: A New Prompting Paradigm to Unleash Detection Ability of MLLM\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  14%|███████▉                                                  | 453/3312 [11:32<1:13:00,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Embodied LLM Agents Learn to Cooperate in Organized Teams\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  14%|███████▉                                                  | 454/3312 [11:33<1:12:20,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: WoLF: Wide-scope Large Language Model Framework for CXR Understanding\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  14%|███████▉                                                  | 455/3312 [11:35<1:12:23,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: CrossTune: Black-Box Few-Shot Classification with Label Enhancement\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  14%|███████▉                                                  | 456/3312 [11:36<1:12:31,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: VisionGPT: LLM-Assisted Real-Time Anomaly Detection for Safe Visual Navigation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  14%|████████                                                  | 457/3312 [11:38<1:12:22,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Third-Party Language Model Performance Prediction from Instruction\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  14%|████████                                                  | 458/3312 [11:39<1:10:31,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Towards Interpretable Hate Speech Detection using Large Language Model-extracted Rationales\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  14%|████████                                                  | 459/3312 [11:40<1:09:23,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Dr3: Ask Large Language Models Not to Give Off-Topic Answers in Open Domain Multi-Hop Question Answering\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  14%|████████                                                  | 460/3312 [11:42<1:09:45,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Interpretable User Satisfaction Estimation for Conversational Systems with Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  14%|████████                                                  | 461/3312 [11:44<1:13:08,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Improving Generalizability of Extracting Social Determinants of Health Using Large Language Models through Prompt-tuning\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  14%|████████                                                  | 462/3312 [11:45<1:12:54,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: RankPrompt: Step-by-Step Comparisons Make Language Models Better Reasoners\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  14%|████████                                                  | 463/3312 [11:47<1:10:35,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Advancing Time Series Classification with Multimodal Language Modeling\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  14%|████████▏                                                 | 464/3312 [11:48<1:10:43,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Characteristic AI Agents via Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  14%|████████▏                                                 | 465/3312 [11:49<1:09:14,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: OpenEval: Benchmarking Chinese LLMs across Capability, Alignment and Safety\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  14%|████████▏                                                 | 466/3312 [11:51<1:08:07,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Improving LoRA in Privacy-preserving Federated Learning\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  14%|████████▏                                                 | 467/3312 [11:52<1:08:40,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Leveraging Large Language Models to Extract Information on Substance Use Disorder Severity from Clinical Notes: A Zero-shot Learning Approach\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  14%|████████▏                                                 | 468/3312 [11:54<1:07:51,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: FinLlama: Financial Sentiment Classification for Algorithmic Trading Applications\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  14%|████████▏                                                 | 469/3312 [11:55<1:08:15,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Zero-Shot Multi-task Hallucination Detection\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  14%|████████▏                                                 | 470/3312 [11:57<1:10:16,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Reference-based Metrics Disprove Themselves in Question Generation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  14%|████████▏                                                 | 471/3312 [11:58<1:09:44,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Shifting the Lens: Detecting Malware in npm Ecosystem with Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  14%|████████▎                                                 | 472/3312 [12:00<1:09:36,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: TnT-LLM: Text Mining at Scale with Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  14%|████████▎                                                 | 473/3312 [12:01<1:10:11,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: EasyJailbreak: A Unified Framework for Jailbreaking Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  14%|████████▎                                                 | 474/3312 [12:03<1:09:40,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Syn-QA2: Evaluating False Assumptions in Long-tail Questions with Synthetic QA Datasets\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  14%|████████▎                                                 | 475/3312 [12:04<1:12:14,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: MineDreamer: Learning to Follow Instructions via Chain-of-Imagination for Simulated-World Control\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  14%|████████▎                                                 | 476/3312 [12:06<1:10:04,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: RouterBench: A Benchmark for Multi-LLM Routing System\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  14%|████████▎                                                 | 477/3312 [12:07<1:10:21,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: A Toolbox for Surfacing Health Equity Harms and Biases in Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  14%|████████▎                                                 | 478/3312 [12:09<1:09:02,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Supervised Fine-Tuning as Inverse Reinforcement Learning\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  14%|████████▍                                                 | 479/3312 [12:10<1:08:11,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: EnvGen: Generating and Adapting Environments via LLMs for Training Embodied Agents\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  14%|████████▍                                                 | 480/3312 [12:11<1:07:53,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: NovelQA: A Benchmark for Long-Range Novel Question Answering\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  15%|████████▍                                                 | 481/3312 [12:13<1:07:39,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Using Generative Text Models to Create Qualitative Codebooks for Student Evaluations of Teaching\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  15%|████████▍                                                 | 482/3312 [12:14<1:08:00,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Towards Enabling FAIR Dataspaces Using Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  15%|████████▍                                                 | 483/3312 [12:16<1:08:31,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: A Closer Look at Claim Decomposition\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  15%|████████▍                                                 | 484/3312 [12:17<1:08:25,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Investigating Markers and Drivers of Gender Bias in Machine Translations\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  15%|████████▍                                                 | 485/3312 [12:19<1:09:02,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: From explainable to interpretable deep learning for natural language processing in healthcare: how far from reality?\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  15%|████████▌                                                 | 486/3312 [12:20<1:09:21,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: QueryAgent: A Reliable and Efficient Reasoning Framework with Environmental Feedback based Self-Correction\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  15%|████████▌                                                 | 487/3312 [12:22<1:08:58,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: GPT-4 as Evaluator: Evaluating Large Language Models on Pest Management in Agriculture\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  15%|████████▌                                                 | 488/3312 [12:23<1:09:38,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Ensuring Safe and High-Quality Outputs: A Guideline Library Approach for Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  15%|████████▌                                                 | 489/3312 [12:25<1:08:30,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Agent3D-Zero: An Agent for Zero-shot 3D Understanding\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  15%|████████▌                                                 | 490/3312 [12:26<1:11:56,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: SSCAE -- Semantic, Syntactic, and Context-aware natural language Adversarial Examples generator\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  15%|████████▌                                                 | 491/3312 [12:28<1:11:31,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Metaphor Understanding Challenge Dataset for LLMs\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  15%|████████▌                                                 | 492/3312 [12:29<1:11:26,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: How Far Are We on the Decision-Making of LLMs? Evaluating LLMs' Gaming Ability in Multi-Agent Environments\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  15%|████████▋                                                 | 493/3312 [12:31<1:10:07,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Counting-Stars: A Simple, Efficient, and Reasonable Strategy for Evaluating Long-Context Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  15%|████████▋                                                 | 494/3312 [12:32<1:11:07,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Reasoning Abilities of Large Language Models: In-Depth Analysis on the Abstraction and Reasoning Corpus\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  15%|████████▋                                                 | 495/3312 [12:34<1:09:45,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Construction of Hyper-Relational Knowledge Graphs Using Pre-Trained Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  15%|████████▋                                                 | 496/3312 [12:35<1:13:22,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Meta-Prompting for Automating Zero-shot Visual Recognition with LLMs\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  15%|████████▋                                                 | 497/3312 [12:37<1:12:27,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Revisiting The Classics: A Study on Identifying and Rectifying Gender Stereotypes in Rhymes and Poems\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  15%|████████▋                                                 | 498/3312 [12:39<1:13:29,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LLaVA-UHD: an LMM Perceiving Any Aspect Ratio and High-Resolution Images\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  15%|████████▋                                                 | 499/3312 [12:40<1:12:53,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: HDLdebugger: Streamlining HDL debugging with Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  15%|████████▊                                                 | 500/3312 [12:41<1:10:28,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Let's Focus on Neuron: Neuron-Level Supervised Fine-tuning for Large Language Model\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  15%|████████▊                                                 | 501/3312 [12:43<1:10:36,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Linguacodus: A Synergistic Framework for Transformative Code Generation in Machine Learning Pipelines\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  15%|████████▊                                                 | 502/3312 [12:44<1:09:51,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Reinforcement Learning with Token-level Feedback for Controllable Text Generation\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  15%|████████▊                                                 | 503/3312 [12:46<1:09:29,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LLM3:Large Language Model-based Task and Motion Planning with Motion Failure Reasoning\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  15%|████████▊                                                 | 504/3312 [12:47<1:10:06,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: DEE: Dual-stage Explainable Evaluation Method for Text Generation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  15%|████████▊                                                 | 505/3312 [12:49<1:08:39,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Do CLIPs Always Generalize Better than ImageNet Models?\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  15%|████████▊                                                 | 506/3312 [12:50<1:07:33,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: VideoAgent: A Memory-augmented Multimodal Agent for Video Understanding\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  15%|████████▉                                                 | 507/3312 [12:52<1:14:40,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Collage Prompting: Budget-Friendly Visual Recognition with GPT-4V\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  15%|████████▉                                                 | 508/3312 [12:54<1:12:52,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: HateCOT: An Explanation-Enhanced Dataset for Generalizable Offensive Speech Detection via Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  15%|████████▉                                                 | 509/3312 [12:55<1:10:36,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LLM Guided Evolution -- The Automation of Models Advancing Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  15%|████████▉                                                 | 510/3312 [12:56<1:08:40,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: StyleChat: Learning Recitation-Augmented Memory in LLMs for Stylized Dialogue Generation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  15%|████████▉                                                 | 511/3312 [12:58<1:09:52,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: InsCL: A Data-efficient Continual Learning Paradigm for Fine-tuning Large Language Models with Instructions\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  15%|████████▉                                                 | 512/3312 [13:00<1:10:36,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: A Novel Paradigm Boosting Translation Capabilities of Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  15%|████████▉                                                 | 513/3312 [13:01<1:11:03,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Decoding Compressed Trust: Scrutinizing the Trustworthiness of Efficient LLMs Under Compression\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  16%|█████████                                                 | 514/3312 [13:03<1:11:06,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Scene-LLM: Extending Language Model for 3D Visual Understanding and Reasoning\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  16%|█████████                                                 | 515/3312 [13:04<1:10:30,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: X-LLaVA: Optimizing Bilingual Large Vision-Language Alignment\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  16%|█████████                                                 | 516/3312 [13:05<1:08:56,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Can LLM-Augmented autonomous agents cooperate?, An evaluation of their cooperative capabilities through Melting Pot\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  16%|█████████                                                 | 517/3312 [13:07<1:11:16,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: What Makes Math Word Problems Challenging for LLMs?\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  16%|█████████                                                 | 518/3312 [13:09<1:11:14,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: JORA: JAX Tensor-Parallel LoRA Library for Retrieval Augmented Fine-Tuning\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  16%|█████████                                                 | 519/3312 [13:10<1:09:15,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ConvSDG: Session Data Generation for Conversational Search\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  16%|█████████                                                 | 520/3312 [13:12<1:10:14,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Improving Dialogue Agents by Decomposing One Global Explicit Annotation with Local Implicit Multimodal Feedback\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  16%|█████████                                                 | 521/3312 [13:13<1:09:49,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: StateFlow: Enhancing LLM Task-Solving through State-Driven Workflows\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  16%|█████████▏                                                | 522/3312 [13:14<1:08:14,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Few-Shot VQA with Frozen LLMs: A Tale of Two Approaches\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  16%|█████████▏                                                | 523/3312 [13:16<1:07:28,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Reasoning in Transformers -- Mitigating Spurious Correlations and Reasoning Shortcuts\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  16%|█████████▏                                                | 524/3312 [13:17<1:06:25,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: SQ-LLaVA: Self-Questioning for Large Vision-Language Assistant\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  16%|█████████▏                                                | 525/3312 [13:19<1:06:51,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Logic Query of Thoughts: Guiding Large Language Models to Answer Complex Logic Queries with Knowledge Graphs\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  16%|█████████▏                                                | 526/3312 [13:20<1:06:19,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Cheap Ways of Extracting Clinical Markers from Texts\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  16%|█████████▏                                                | 527/3312 [13:22<1:05:22,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Data is all you need: Finetuning LLMs for Chip Design via an Automated design-data augmentation framework\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  16%|█████████▏                                                | 528/3312 [13:23<1:12:32,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Correcting misinformation on social media with a large language model\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  16%|█████████▎                                                | 529/3312 [13:25<1:12:48,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Evaluation Ethics of LLMs in Legal Domain\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  16%|█████████▎                                                | 530/3312 [13:27<1:11:54,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Training A Small Emotional Vision Language Model for Visual Art Comprehension\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  16%|█████████▎                                                | 531/3312 [13:28<1:09:07,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Enhancing Event Causality Identification with Rationale and Structure-Aware Causal Question Answering\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  16%|█████████▎                                                | 532/3312 [13:30<1:11:47,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Beyond Static Evaluation: A Dynamic Approach to Assessing AI Assistants' API Invocation Capabilities\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  16%|█████████▎                                                | 533/3312 [13:31<1:10:55,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Scaling Data Diversity for Fine-Tuning Language Models in Human Alignment\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  16%|█████████▎                                                | 534/3312 [13:33<1:10:48,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: PhD: A Prompted Visual Hallucination Evaluation Dataset\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  16%|█████████▎                                                | 535/3312 [13:34<1:14:04,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ProgGen: Generating Named Entity Recognition Datasets Step-by-step with Self-Reflexive Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  16%|█████████▍                                                | 536/3312 [13:36<1:11:36,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: m&m's: A Benchmark to Evaluate Tool-Use for multi-step multi-modal Tasks\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  16%|█████████▍                                                | 537/3312 [13:37<1:10:39,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: GOMA: Proactive Embodied Cooperative Communication via Goal-Oriented Mental Alignment\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  16%|█████████▍                                                | 538/3312 [13:39<1:10:03,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Large Language Models Powered Context-aware Motion Prediction\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  16%|█████████▍                                                | 539/3312 [13:40<1:08:27,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Pre-Trained Language Models Represent Some Geographic Populations Better Than Others\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  16%|█████████▍                                                | 540/3312 [13:42<1:07:34,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: SelfIE: Self-Interpretation of Large Language Model Embeddings\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  16%|█████████▍                                                | 541/3312 [13:43<1:12:08,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Human Centered AI for Indian Legal Text Analytics\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  16%|█████████▍                                                | 542/3312 [13:45<1:10:50,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: MIntRec2.0: A Large-scale Benchmark Dataset for Multimodal Intent Recognition and Out-of-scope Detection in Conversations\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  16%|█████████▌                                                | 543/3312 [13:46<1:09:23,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Towards Robustness and Diversity: Continual Learning in Dialog Generation with Text-Mixup and Batch Nuclear-Norm Maximization\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  16%|█████████▌                                                | 544/3312 [13:48<1:15:17,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Optimizing Language Augmentation for Multilingual Large Language Models: A Case Study on Korean\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  16%|█████████▌                                                | 545/3312 [13:50<1:12:26,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: A Comprehensive Study of Multimodal Large Language Models for Image Quality Assessment\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  16%|█████████▌                                                | 546/3312 [13:51<1:10:13,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Two-step Automated Cybercrime Coded Word Detection using Multi-level Representation Learning\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  17%|█████████▌                                                | 547/3312 [13:52<1:08:22,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Do Large Language Models understand Medical Codes?\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  17%|█████████▌                                                | 548/3312 [13:54<1:07:11,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Efficient Pruning of Large Language Model with Adaptive Estimation Fusion\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  17%|█████████▌                                                | 549/3312 [13:55<1:06:35,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: From Words to Routes: Applying Large Language Models to Vehicle Routing\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  17%|█████████▋                                                | 550/3312 [13:57<1:07:48,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LLM-based Conversational AI Therapist for Daily Functioning Screening and Psychotherapeutic Intervention via Everyday Smart Devices\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  17%|█████████▋                                                | 551/3312 [13:58<1:09:27,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Detecting Bias in Large Language Models: Fine-tuned KcBERT\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  17%|█████████▋                                                | 552/3312 [14:00<1:07:47,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Depression Detection on Social Media with Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  17%|█████████▋                                                | 553/3312 [14:01<1:08:00,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Uncovering Latent Themes of Messaging on Social Media by Integrating LLMs: A Case Study on Climate Campaigns\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  17%|█████████▋                                                | 554/3312 [14:03<1:07:06,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: PERL: Parameter Efficient Reinforcement Learning from Human Feedback\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  17%|█████████▋                                                | 555/3312 [14:04<1:06:11,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Apriori Knowledge in an Era of Computational Opacity: The Role of AI in Mathematical Discovery\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  17%|█████████▋                                                | 556/3312 [14:06<1:07:16,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Neural Erosion: Emulating Controlled Neurodegeneration and Aging in AI Systems\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  17%|█████████▊                                                | 557/3312 [14:07<1:08:31,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Can a GPT4-Powered AI Agent Be a Good Enough Performance Attribution Analyst?\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  17%|█████████▊                                                | 558/3312 [14:09<1:08:10,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: S3LLM: Large-Scale Scientific Software Understanding with LLMs using Source, Metadata, and Document\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  17%|█████████▊                                                | 559/3312 [14:10<1:07:51,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Enhancing LLM Factual Accuracy with RAG to Counter Hallucinations: A Case Study on Domain-Specific Queries in Private Knowledge-Bases\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  17%|█████████▊                                                | 560/3312 [14:12<1:08:22,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Using an LLM to Turn Sign Spottings into Spoken Language Sentences\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  17%|█████████▊                                                | 561/3312 [14:14<1:15:24,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: SocialGenPod: Privacy-Friendly Generative AI Social Web Applications with Decentralised Personal Data Stores\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  17%|█████████▊                                                | 562/3312 [14:15<1:14:08,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: TriSum: Learning Summarization Ability from Large Language Models with Structured Rationale\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  17%|█████████▊                                                | 563/3312 [14:17<1:12:40,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: CDGP: Automatic Cloze Distractor Generation based on Pre-trained Language Model\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  17%|█████████▉                                                | 564/3312 [14:18<1:11:21,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Uni-SMART: Universal Science Multimodal Analysis and Research Transformer\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  17%|█████████▉                                                | 565/3312 [14:20<1:10:46,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Large Language Model-informed ECG Dual Attention Network for Heart Failure Risk Prediction\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  17%|█████████▉                                                | 566/3312 [14:21<1:11:27,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: A Question on the Explainability of Large Language Models and the Word-Level Univariate First-Order Plausibility Assumption\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  17%|█████████▉                                                | 567/3312 [14:23<1:10:50,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Is Translation All You Need? A Study on Solving Multilingual Tasks with Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  17%|█████████▉                                                | 568/3312 [14:24<1:08:59,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: HawkEye: Training Video-Text LLMs for Grounding Text in Videos\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  17%|█████████▉                                                | 569/3312 [14:26<1:07:43,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Read between the lines -- Functionality Extraction From READMEs\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  17%|█████████▉                                                | 570/3312 [14:27<1:08:53,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Generative Region-Language Pretraining for Open-Ended Object Detection\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  17%|█████████▉                                                | 571/3312 [14:29<1:17:35,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ChatPattern: Layout Pattern Customization via Natural Language\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  17%|██████████                                                | 572/3312 [14:31<1:16:13,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Enhancing Human-Centered Dynamic Scene Understanding via Multiple LLMs Collaborated Reasoning\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  17%|██████████                                                | 573/3312 [14:32<1:12:16,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Intent-conditioned and Non-toxic Counterspeech Generation using Multi-Task Instruction Tuning with RLAIF\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  17%|██████████                                                | 574/3312 [14:34<1:11:07,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Large Language Models to Generate System-Level Test Programs Targeting Non-functional Properties\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  17%|██████████                                                | 575/3312 [14:35<1:11:07,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: CrossGLG: LLM Guides One-shot Skeleton-based 3D Action Recognition in a Cross-level Manner\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  17%|██████████                                                | 576/3312 [14:37<1:11:53,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: DRAGIN: Dynamic Retrieval Augmented Generation based on the Real-time Information Needs of Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  17%|██████████                                                | 577/3312 [14:38<1:09:30,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Are LLMs Good Cryptic Crossword Solvers?\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  17%|██████████                                                | 578/3312 [14:40<1:09:02,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Don't Half-listen: Capturing Key-part Information in Continual Instruction Tuning\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  17%|██████████▏                                               | 579/3312 [14:41<1:08:05,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: TextBlockV2: Towards Precise-Detection-Free Scene Text Spotting with Pre-trained Language Model\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  18%|██████████▏                                               | 580/3312 [14:43<1:07:34,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Knowledge Condensation and Reasoning for Knowledge-based VQA\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  18%|██████████▏                                               | 581/3312 [14:44<1:07:39,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Ignore Me But Don't Replace Me: Utilizing Non-Linguistic Elements for Pretraining on the Cybersecurity Domain\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  18%|██████████▏                                               | 582/3312 [14:46<1:12:11,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Lost in Overlap: Exploring Watermark Collision in LLMs\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  18%|██████████▏                                               | 583/3312 [14:48<1:13:45,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Large Language Models and User Trust: Consequence of Self-Referential Learning Loop and the Deskilling of Healthcare Professionals\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  18%|██████████▏                                               | 584/3312 [14:49<1:13:09,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Whose Side Are You On? Investigating the Political Stance of Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  18%|██████████▏                                               | 585/3312 [14:52<1:25:13,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Think Twice Before Assure: Confidence Estimation for Large Language Models through Reflection on Multiple Answers\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  18%|██████████▎                                               | 586/3312 [14:54<1:27:48,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ViTCN: Vision Transformer Contrastive Network For Reasoning\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  18%|██████████▎                                               | 587/3312 [14:56<1:33:31,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Right Place, Right Time! Towards ObjectNav for Non-Stationary Goals\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  18%|██████████▎                                               | 588/3312 [14:58<1:27:21,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Scaling Behavior of Machine Translation with Large Language Models under Prompt Injection Attacks\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  18%|██████████▎                                               | 589/3312 [14:59<1:22:36,  1.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Helpful or Harmful? Exploring the Efficacy of Large Language Models for Online Grooming Prevention\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  18%|██████████▎                                               | 590/3312 [15:01<1:21:43,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Images are Achilles' Heel of Alignment: Exploiting Visual Vulnerabilities for Jailbreaking Multimodal Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  18%|██████████▎                                               | 591/3312 [15:03<1:24:09,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Dynamic Memory Compression: Retrofitting LLMs for Accelerated Inference\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  18%|██████████▎                                               | 592/3312 [15:05<1:21:55,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: 3D-VLA: A 3D Vision-Language-Action Generative World Model\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  18%|██████████▍                                               | 593/3312 [15:07<1:31:46,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Quiet-STaR: Language Models Can Teach Themselves to Think Before Speaking\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  18%|██████████▍                                               | 594/3312 [15:10<1:34:39,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Large Language Models and Causal Inference in Collaboration: A Comprehensive Survey\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  18%|██████████▍                                               | 595/3312 [15:12<1:32:36,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Eyes Closed, Safety On: Protecting Multimodal LLMs via Image-to-Text Transformation\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  18%|██████████▍                                               | 596/3312 [15:13<1:26:52,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Enhancing Trust in Autonomous Agents: An Architecture for Accountability and Explainability through Blockchain and Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  18%|██████████▍                                               | 597/3312 [15:17<1:54:57,  2.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Less is More: Data Value Estimation for Visual Instruction Tuning\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  18%|██████████▍                                               | 598/3312 [15:19<1:42:22,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Logits of API-Protected LLMs Leak Proprietary Information\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  18%|██████████▍                                               | 599/3312 [15:20<1:33:19,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: VisionGPT-3D: A Generalized Multimodal Agent for Enhanced 3D Vision Understanding\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  18%|██████████▌                                               | 600/3312 [15:22<1:25:59,  1.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: MT-PATCHER: Selective and Extendable Knowledge Distillation from Large Language Models for Machine Translation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  18%|██████████▌                                               | 601/3312 [15:23<1:20:21,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: AdaShield: Safeguarding Multimodal Large Language Models from Structure-based Attack via Adaptive Shield Prompting\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  18%|██████████▌                                               | 602/3312 [15:25<1:22:04,  1.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LLM-based agents for automating the enhancement of user story quality: An early report\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  18%|██████████▌                                               | 603/3312 [15:27<1:23:52,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: \"Like a Nesting Doll\": Analyzing Recursion Analogies Generated by CS Students using Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  18%|██████████▌                                               | 604/3312 [15:29<1:20:10,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: GiT: Towards Generalist Vision Transformer through Universal Language Interface\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  18%|██████████▌                                               | 605/3312 [15:30<1:15:24,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Komodo: A Linguistic Expedition into Indonesia's Regional Languages\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  18%|██████████▌                                               | 606/3312 [15:32<1:14:52,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: BurstAttention: An Efficient Distributed Attention Framework for Extremely Long Sequences\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  18%|██████████▋                                               | 607/3312 [15:35<1:26:42,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: AVIBench: Towards Evaluating the Robustness of Large Vision-Language Model on Adversarial Visual-Instructions\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  18%|██████████▋                                               | 608/3312 [15:36<1:23:33,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Griffon v2: Advancing Multimodal Perception with High-Resolution Scaling and Visual-Language Co-Referring\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  18%|██████████▋                                               | 609/3312 [15:38<1:19:16,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: What Was Your Prompt? A Remote Keylogging Attack on AI Assistants\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  18%|██████████▋                                               | 610/3312 [15:39<1:15:27,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Dial-insight: Fine-tuning Large Language Models with High-Quality Domain-Specific Data Preventing Capability Collapse\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  18%|██████████▋                                               | 611/3312 [15:41<1:15:17,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Caveat Lector: Large Language Models in Legal Practice\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  18%|██████████▋                                               | 612/3312 [15:42<1:13:36,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Unveiling the Generalization Power of Fine-Tuned Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  19%|██████████▋                                               | 613/3312 [15:44<1:10:50,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Evaluating LLMs for Gender Disparities in Notable Persons\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  19%|██████████▊                                               | 614/3312 [15:45<1:08:27,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: USimAgent: Large Language Models for Simulating Search Users\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  19%|██████████▊                                               | 615/3312 [15:47<1:09:01,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ProSwitch: Knowledge-Guided Language Model Fine-Tuning to Generate Professional and Non-Professional Styled Text\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  19%|██████████▊                                               | 616/3312 [15:48<1:07:37,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Meta-Cognitive Analysis: Evaluating Declarative and Procedural Knowledge in Datasets and Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  19%|██████████▊                                               | 617/3312 [15:50<1:09:31,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Meaningful Learning: Advancing Abstract Reasoning in Large Language Models via Generic Fact Guidance\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  19%|██████████▊                                               | 618/3312 [15:52<1:10:04,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Large Language Models are Parallel Multilingual Learners\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  19%|██████████▊                                               | 619/3312 [15:53<1:09:01,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: UniCode: Learning a Unified Codebook for Multimodal Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  19%|██████████▊                                               | 620/3312 [15:55<1:08:17,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Circuit Transformer: End-to-end Circuit Design by Predicting the Next Gate\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  19%|██████████▉                                               | 621/3312 [15:56<1:08:14,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LAMP: A Language Model on the Map\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  19%|██████████▉                                               | 622/3312 [15:57<1:07:28,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Keyformer: KV Cache Reduction through Key Tokens Selection for Efficient Generative Inference\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  19%|██████████▉                                               | 623/3312 [15:59<1:06:28,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: CodeUltraFeedback: An LLM-as-a-Judge Dataset for Aligning Large Language Models to Coding Preferences\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  19%|██████████▉                                               | 624/3312 [16:00<1:07:17,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ChartInstruct: Instruction Tuning for Chart Comprehension and Reasoning\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  19%|██████████▉                                               | 625/3312 [16:02<1:07:01,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: VisionGPT: Vision-Language Understanding Agent Using Generalized Multimodal Framework\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  19%|██████████▉                                               | 626/3312 [16:03<1:07:02,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: AraTrust: An Evaluation of Trustworthiness for LLMs in Arabic\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  19%|██████████▉                                               | 627/3312 [16:05<1:06:58,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Re-Search for The Truth: Multi-round Retrieval-augmented Large Language Models are Strong Fake News Detectors\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  19%|██████████▉                                               | 628/3312 [16:06<1:05:42,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Evaluating the Application of Large Language Models to Generate Feedback in Programming Education\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  19%|███████████                                               | 629/3312 [16:08<1:04:57,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: AutoGuide: Automated Generation and Selection of State-Aware Guidelines for Large Language Model Agents\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  19%|███████████                                               | 630/3312 [16:09<1:05:19,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: The Human Factor in Detecting Errors of Large Language Models: A Systematic Literature Review and Future Research Directions\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  19%|███████████                                               | 631/3312 [16:11<1:04:54,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Exploring Prompt Engineering Practices in the Enterprise\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  19%|███████████                                               | 632/3312 [16:12<1:04:09,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Usable XAI: 10 Strategies Towards Exploiting Explainability in the LLM Era\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  19%|███████████                                               | 633/3312 [16:14<1:05:14,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LMStyle Benchmark: Evaluating Text Style Transfer for Chatbots\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  19%|███████████                                               | 634/3312 [16:15<1:08:15,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Bugs in Large Language Models Generated Code: An Empirical Study\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  19%|███████████                                               | 635/3312 [16:17<1:07:33,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Second-Order Information Matters: Revisiting Machine Unlearning for Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  19%|███████████▏                                              | 636/3312 [16:18<1:05:36,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Teaching Machines to Code: Smart Contract Translation with LLMs\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  19%|███████████▏                                              | 637/3312 [16:20<1:05:45,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Detecting Hallucination and Coverage Errors in Retrieval Augmented Generation for Controversial Topics\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  19%|███████████▏                                              | 638/3312 [16:21<1:06:23,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Evaluating Large Language Models as Generative User Simulators for Conversational Recommendation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  19%|███████████▏                                              | 639/3312 [16:23<1:12:37,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Cultural evolution in populations of Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  19%|███████████▏                                              | 640/3312 [16:25<1:10:43,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: DialogGen: Multi-modal Interactive Dialogue System for Multi-turn Text-to-Image Generation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  19%|███████████▏                                              | 641/3312 [16:26<1:09:25,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Simple and Scalable Strategies to Continually Pre-train Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  19%|███████████▏                                              | 642/3312 [16:28<1:07:33,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Steering LLMs Towards Unbiased Responses: A Causality-Guided Debiasing Framework\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  19%|███████████▎                                              | 643/3312 [16:29<1:08:29,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Strengthening Multimodal Large Language Model with Bootstrapped Preference Optimization\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  19%|███████████▎                                              | 644/3312 [16:30<1:06:36,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: SOTOPIA-$π$: Interactive Learning of Socially Intelligent Language Agents\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  19%|███████████▎                                              | 645/3312 [16:32<1:06:16,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: TeaMs-RL: Teaching LLMs to Teach Themselves Better Instructions via Reinforcement Learning\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  20%|███████████▎                                              | 646/3312 [16:33<1:05:45,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Zero-shot and Few-shot Generation Strategies for Artificial Clinical Records\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  20%|███████████▎                                              | 647/3312 [16:35<1:04:43,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: MedInsight: A Multi-Source Context Augmentation Framework for Generating Patient-Centric Medical Responses using Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  20%|███████████▎                                              | 648/3312 [16:36<1:05:06,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: DevBench: A Comprehensive Benchmark for Software Development\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  20%|███████████▎                                              | 649/3312 [16:38<1:06:33,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Call Me When Necessary: LLMs can Efficiently and Faithfully Reason over Structured Environments\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  20%|███████████▍                                              | 650/3312 [16:39<1:07:34,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Non-discrimination Criteria for Generative Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  20%|███████████▍                                              | 651/3312 [16:41<1:06:07,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Language models scale reliably with over-training and on downstream tasks\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  20%|███████████▍                                              | 652/3312 [16:42<1:07:01,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Automatic Interactive Evaluation for Large Language Models with State Aware Patient Simulator\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  20%|███████████▍                                              | 653/3312 [16:44<1:05:20,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Rich Semantic Knowledge Enhanced Large Language Models for Few-shot Chinese Spell Checking\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  20%|███████████▍                                              | 654/3312 [16:45<1:06:33,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Data-oriented Dynamic Fine-tuning Parameter Selection Strategy for FISH Mask based Efficient Fine-tuning\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  20%|███████████▍                                              | 655/3312 [16:47<1:06:33,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: SoK: Reducing the Vulnerability of Fine-tuned Language Models to Membership Inference Attacks\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  20%|███████████▍                                              | 656/3312 [16:48<1:05:00,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Software Vulnerability and Functionality Assessment using LLMs\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  20%|███████████▌                                              | 657/3312 [16:50<1:07:05,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Tastle: Distract Large Language Models for Automatic Jailbreak Attack\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  20%|███████████▌                                              | 658/3312 [16:51<1:07:42,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Do Large Language Models Solve ARC Visual Analogies Like People Do?\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  20%|███████████▌                                              | 659/3312 [16:53<1:08:06,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: SMART: Submodular Data Mixture Strategy for Instruction Tuning\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  20%|███████████▌                                              | 660/3312 [16:55<1:11:53,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: CoIN: A Benchmark of Continual Instruction tuNing for Multimodel Large Language Model\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  20%|███████████▌                                              | 661/3312 [16:56<1:10:43,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: From human experts to machines: An LLM supported approach to ontology and knowledge graph construction\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  20%|███████████▌                                              | 662/3312 [16:58<1:10:16,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LLM-Assisted Light: Leveraging Large Language Model Capabilities for Human-Mimetic Traffic Signal Control in Complex Urban Environments\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  20%|███████████▌                                              | 663/3312 [16:59<1:08:37,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Knowledge Conflicts for LLMs: A Survey\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  20%|███████████▋                                              | 664/3312 [17:01<1:10:31,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: OverleafCopilot: Empowering Academic Writing in Overleaf with Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  20%|███████████▋                                              | 665/3312 [17:03<1:08:10,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Is Context Helpful for Chat Translation Evaluation?\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  20%|███████████▋                                              | 666/3312 [17:04<1:08:13,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: StreamingDialogue: Prolonged Dialogue Learning via Long Context Compression with Minimal Losses\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  20%|███████████▋                                              | 667/3312 [17:06<1:09:18,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: HRLAIF: Improvements in Helpfulness and Harmlessness in Open-domain Reinforcement Learning From AI Feedback\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  20%|███████████▋                                              | 668/3312 [17:08<1:20:33,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Towards Personalized Evaluation of Large Language Models with An Anonymous Crowd-Sourcing Platform\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  20%|███████████▋                                              | 669/3312 [17:10<1:16:59,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Generative Pretrained Structured Transformers: Unsupervised Syntactic Language Models at Scale\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  20%|███████████▋                                              | 670/3312 [17:11<1:15:48,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: CleanAgent: Automating Data Standardization with LLM-based Agents\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  20%|███████████▊                                              | 671/3312 [17:15<1:34:37,  2.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Hierarchical Auto-Organizing System for Open-Ended Multi-Agent Navigation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  20%|███████████▊                                              | 672/3312 [17:16<1:29:38,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Mastering Text, Code and Math Simultaneously via Fusing Highly Specialized Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  20%|███████████▊                                              | 673/3312 [17:18<1:23:19,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: RECIPE4U: Student-ChatGPT Interaction Dataset in EFL Writing Education\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  20%|███████████▊                                              | 674/3312 [17:20<1:20:47,  1.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Efficient Prompt Tuning of Large Vision-Language Model for Fine-Grained Ship Classification\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  20%|███████████▊                                              | 675/3312 [17:21<1:16:51,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: A Moral Imperative: The Need for Continual Superalignment of Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  20%|███████████▊                                              | 676/3312 [17:23<1:13:20,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: TINA: Think, Interaction, and Action Framework for Zero-Shot Vision Language Navigation\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  20%|███████████▊                                              | 677/3312 [17:24<1:10:27,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Boosting Disfluency Detection with Large Language Model as Disfluency Generator\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  20%|███████████▊                                              | 678/3312 [17:26<1:09:40,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Learning to Watermark LLM-generated Text via Reinforcement Learning\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  21%|███████████▉                                              | 679/3312 [17:27<1:08:43,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Can Large Language Models Identify Authorship?\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  21%|███████████▉                                              | 680/3312 [17:29<1:12:03,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Large Language Models are Contrastive Reasoners\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  21%|███████████▉                                              | 681/3312 [17:31<1:11:07,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: AutoTRIZ: Artificial Ideation with TRIZ and Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  21%|███████████▉                                              | 682/3312 [17:32<1:10:04,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: PET-SQL: A Prompt-enhanced Two-stage Text-to-SQL Framework with Cross-consistency\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  21%|███████████▉                                              | 683/3312 [17:34<1:08:10,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: MoleculeQA: A Dataset to Evaluate Factual Accuracy in Molecular Comprehension\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  21%|███████████▉                                              | 684/3312 [17:35<1:06:48,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: TaskCLIP: Extend Large Vision-Language Model for Task Oriented Object Detection\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  21%|███████████▉                                              | 685/3312 [17:36<1:06:32,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Investigating the performance of Retrieval-Augmented Generation and fine-tuning for the development of AI-driven knowledge-based systems\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  21%|████████████                                              | 686/3312 [17:38<1:07:19,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: CHAI: Clustered Head Attention for Efficient LLM Inference\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  21%|████████████                                              | 687/3312 [17:40<1:06:21,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Generating Clarification Questions for Disambiguating Contracts\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  21%|████████████                                              | 688/3312 [17:41<1:05:31,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Big City Bias: Evaluating the Impact of Metropolitan Size on Computational Job Market Abilities of Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  21%|████████████                                              | 689/3312 [17:43<1:09:59,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Harnessing Artificial Intelligence to Combat Online Hate: Exploring the Challenges and Opportunities of Large Language Models in Hate Speech Detection\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  21%|████████████                                              | 690/3312 [17:44<1:08:33,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LG-Traj: LLM Guided Pedestrian Trajectory Prediction\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  21%|████████████                                              | 691/3312 [17:46<1:07:23,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Debatrix: Multi-dimensinal Debate Judge with Iterative Chronological Analysis Based on LLM\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  21%|████████████                                              | 692/3312 [17:47<1:05:29,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Training Small Multimodal Models to Bridge Biomedical Competency Gap: A Case Study in Radiology Imaging\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  21%|████████████▏                                             | 693/3312 [17:49<1:08:37,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Beyond Text: Frozen Large Language Models in Visual Signal Comprehension\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  21%|████████████▏                                             | 694/3312 [17:51<1:09:15,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Rethinking Generative Large Language Model Evaluation for Semantic Comprehension\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  21%|████████████▏                                             | 695/3312 [17:52<1:11:46,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LiveCodeBench: Holistic and Contamination Free Evaluation of Large Language Models for Code\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  21%|████████████▏                                             | 696/3312 [17:54<1:10:14,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Exploring Safety Generalization Challenges of Large Language Models via Code\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  21%|████████████▏                                             | 697/3312 [17:55<1:09:29,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: The Missing Piece in Model Editing: A Deep Dive into the Hidden Damage Brought By Model Editing\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  21%|████████████▏                                             | 698/3312 [17:57<1:11:28,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Beyond Memorization: The Challenge of Random Memory Access in Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  21%|████████████▏                                             | 699/3312 [17:59<1:09:22,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Fine-tuning Large Language Models with Sequential Instructions\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  21%|████████████▎                                             | 700/3312 [18:00<1:07:40,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Duwak: Dual Watermarks in Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  21%|████████████▎                                             | 701/3312 [18:02<1:07:45,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Transforming Competition into Collaboration: The Revolutionary Role of Multi-Agent Systems and Language Models in Modern Organizations\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  21%|████████████▎                                             | 702/3312 [18:03<1:05:42,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Synth$^2$: Boosting Visual-Language Models with Synthetic Captions and Image Embeddings\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  21%|████████████▎                                             | 703/3312 [18:05<1:11:31,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: FineMath: A Fine-Grained Mathematical Evaluation Benchmark for Chinese Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  21%|████████████▎                                             | 704/3312 [18:07<1:10:56,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Multi-modal Auto-regressive Modeling via Visual Words\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  21%|████████████▎                                             | 705/3312 [18:08<1:08:18,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: WorkArena: How Capable Are Web Agents at Solving Common Knowledge Work Tasks?\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  21%|████████████▎                                             | 706/3312 [18:10<1:08:53,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: StableToolBench: Towards Stable Large-Scale Benchmarking on Tool Learning of Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  21%|████████████▍                                             | 707/3312 [18:11<1:06:46,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: KnowCoder: Coding Structured Knowledge into LLMs for Universal Information Extraction\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  21%|████████████▍                                             | 708/3312 [18:13<1:06:03,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Improving Reinforcement Learning from Human Feedback Using Contrastive Rewards\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  21%|████████████▍                                             | 709/3312 [18:14<1:05:59,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Large, Small or Both: A Novel Data Augmentation Framework Based on Language Models for Debiasing Opinion Summarization\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  21%|████████████▍                                             | 710/3312 [18:16<1:07:28,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Characterization of Large Language Model Development in the Datacenter\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  21%|████████████▍                                             | 711/3312 [18:17<1:04:55,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Decomposing Disease Descriptions for Enhanced Pathology Detection: A Multi-Aspect Vision-Language Pre-training Framework\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  21%|████████████▍                                             | 712/3312 [18:19<1:09:00,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: generAItor: Tree-in-the-Loop Text Generation for Language Model Explainability and Adaptation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  22%|████████████▍                                             | 713/3312 [18:20<1:06:47,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Couler: Unified Machine Learning Workflow Optimization in Cloud\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  22%|████████████▌                                             | 714/3312 [18:22<1:07:42,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LLMvsSmall Model? Large Language Model Based Text Augmentation Enhanced Personality Detection Model\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  22%|████████████▌                                             | 715/3312 [18:24<1:09:14,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: SIFiD: Reassess Summary Factual Inconsistency Detection with LLM\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  22%|████████████▌                                             | 716/3312 [18:25<1:07:48,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Truth-Aware Context Selection: Mitigating the Hallucinations of Large Language Models Being Misled by Untruthful Contexts\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  22%|████████████▌                                             | 717/3312 [18:27<1:06:39,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: MAMMOTH: Massively Multilingual Modular Open Translation @ Helsinki\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  22%|████████████▌                                             | 718/3312 [18:28<1:07:55,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: MoAI: Mixture of All Intelligence for Large Language and Vision Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  22%|████████████▌                                             | 719/3312 [18:30<1:06:14,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: SmallToLarge (S2L): Scalable Data Selection for Fine-tuning Large Language Models by Summarizing Training Trajectories of Small Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  22%|████████████▌                                             | 720/3312 [18:31<1:04:48,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: SVD-LLM: Truncation-aware Singular Value Decomposition for Large Language Model Compression\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  22%|████████████▋                                             | 721/3312 [18:33<1:04:43,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: NavCoT: Boosting LLM-Based Vision-and-Language Navigation via Learning Disentangled Reasoning\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  22%|████████████▋                                             | 722/3312 [18:34<1:05:36,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Enhancing Depression-Diagnosis-Oriented Chat with Psychological State Tracking\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  22%|████████████▋                                             | 723/3312 [18:36<1:04:17,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Taming Pre-trained LLMs for Generalised Time Series Forecasting via Cross-modal Knowledge Distillation\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  22%|████████████▋                                             | 724/3312 [18:37<1:04:42,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: A Framework for Cost-Effective and Self-Adaptive LLM Shaking and Recovery Mechanism\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  22%|████████████▋                                             | 725/3312 [18:39<1:04:53,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: CKERC : Joint Large Language Models with Commonsense Knowledge for Emotion Recognition in Conversation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  22%|████████████▋                                             | 726/3312 [18:40<1:05:21,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: AesopAgent: Agent-driven Evolutionary System on Story-to-Video Production\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  22%|████████████▋                                             | 727/3312 [18:42<1:05:07,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Which LLM to Play? Convergence-Aware Online Model Selection with Time-Increasing Bandits\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  22%|████████████▋                                             | 728/3312 [18:43<1:03:56,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Action Reimagined: Text-to-Pose Video Editing for Dynamic Human Actions\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  22%|████████████▊                                             | 729/3312 [18:45<1:04:41,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Monitoring AI-Modified Content at Scale: A Case Study on the Impact of ChatGPT on AI Conference Peer Reviews\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  22%|████████████▊                                             | 730/3312 [18:46<1:03:17,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Narrating Causal Graphs with Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  22%|████████████▊                                             | 731/3312 [18:47<1:02:00,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: SPA: Towards A Computational Friendly Cloud-Base and On-Devices Collaboration Seq2seq Personalized Generation\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  22%|████████████▊                                             | 732/3312 [18:49<1:09:33,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: MRL Parsing Without Tears: The Case of Hebrew\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  22%|████████████▊                                             | 733/3312 [18:51<1:10:16,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Hybrid Human-LLM Corpus Construction and LLM Evaluation for Rare Linguistic Phenomena\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  22%|████████████▊                                             | 734/3312 [18:53<1:11:12,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: SMART: Automatically Scaling Down Language Models with Accuracy Guarantees for Reduced Processing Fees\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  22%|████████████▊                                             | 735/3312 [18:54<1:08:16,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: SELMA: Learning and Merging Skill-Specific Text-to-Image Experts with Auto-Generated Data\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  22%|████████████▉                                             | 736/3312 [18:56<1:05:32,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Naming, Describing, and Quantifying Visual Objects in Humans and LLMs\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  22%|████████████▉                                             | 737/3312 [18:57<1:06:22,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ERA-CoT: Improving Chain-of-Thought through Entity Relationship Analysis\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  22%|████████████▉                                             | 738/3312 [18:59<1:07:40,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: MEND: Meta dEmonstratioN Distillation for Efficient and Effective In-Context Learning\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  22%|████████████▉                                             | 739/3312 [19:00<1:06:44,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Exploring Large Language Models and Hierarchical Frameworks for Classification of Large Unstructured Legal Documents\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  22%|████████████▉                                             | 740/3312 [19:02<1:07:17,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Development of a Reliable and Accessible Caregiving Language Model (CaLM)\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  22%|████████████▉                                             | 741/3312 [19:04<1:07:45,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: DriveDreamer-2: LLM-Enhanced World Models for Diverse Driving Video Generation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  22%|████████████▉                                             | 742/3312 [19:05<1:06:38,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Can LLMs Separate Instructions From Data? And What Do We Even Mean By That?\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  22%|█████████████                                             | 743/3312 [19:07<1:08:36,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: The Power of Noise: Toward a Unified Multi-modal Knowledge Graph Representation Framework\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  22%|█████████████                                             | 744/3312 [19:08<1:07:06,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ConspEmoLLM: Conspiracy Theory Detection Using an Emotion-Based Large Language Model\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  22%|█████████████                                             | 745/3312 [19:10<1:05:57,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ALaRM: Align Language Models via Hierarchical Rewards Modeling\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  23%|█████████████                                             | 746/3312 [19:11<1:05:19,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ACT-MNMT Auto-Constriction Turning for Multilingual Neural Machine Translation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  23%|█████████████                                             | 747/3312 [19:13<1:05:33,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Real-Time Multimodal Cognitive Assistant for Emergency Medical Services\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  23%|█████████████                                             | 748/3312 [19:14<1:04:23,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Large Model driven Radiology Report Generation with Clinical Quality Reinforcement Learning\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  23%|█████████████                                             | 749/3312 [19:16<1:04:14,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Poisoning Programs by Un-Repairing Code: Security Concerns of AI-generated Code\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  23%|█████████████▏                                            | 750/3312 [19:17<1:05:32,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Smart-Infinity: Fast Large Language Model Training using Near-Storage Processing on a Real System\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  23%|█████████████▏                                            | 751/3312 [19:19<1:04:13,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: FashionReGen: LLM-Empowered Fashion Report Generation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  23%|█████████████▏                                            | 752/3312 [19:20<1:02:48,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Zero-Shot ECG Classification with Multimodal Learning and Test-time Clinical Knowledge Enhancement\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  23%|█████████████▏                                            | 753/3312 [19:22<1:03:47,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Elephants Never Forget: Testing Language Models for Memorization of Tabular Data\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  23%|█████████████▏                                            | 754/3312 [19:23<1:02:32,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: KELLMRec: Knowledge-Enhanced Large Language Models for Recommendation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  23%|█████████████▏                                            | 755/3312 [19:25<1:03:46,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: MedKP: Medical Dialogue with Knowledge Enhancement and Clinical Pathway Encoding\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  23%|█████████████▏                                            | 756/3312 [19:26<1:03:32,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Guiding Clinical Reasoning with Large Language Models via Knowledge Seeds\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  23%|█████████████▎                                            | 757/3312 [19:28<1:03:34,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Academically intelligent LLMs are not necessarily socially intelligent\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  23%|█████████████▎                                            | 758/3312 [19:29<1:03:58,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ContextGPT: Infusing LLMs Knowledge into Neuro-Symbolic Activity Recognition Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  23%|█████████████▎                                            | 759/3312 [19:31<1:06:45,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: AC-EVAL: Evaluating Ancient Chinese Language Understanding in Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  23%|█████████████▎                                            | 760/3312 [19:33<1:06:15,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Unraveling the Mystery of Scaling Laws: Part I\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  23%|█████████████▎                                            | 761/3312 [19:34<1:10:58,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: From English to ASIC: Hardware Implementation with Large Language Model\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  23%|█████████████▎                                            | 762/3312 [19:36<1:08:20,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: On the Consideration of AI Openness: Can Good Intent Be Abused?\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  23%|█████████████▎                                            | 763/3312 [19:37<1:06:48,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: QuantTune: Optimizing Model Quantization with Adaptive Outlier-Driven Fine Tuning\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  23%|█████████████▍                                            | 764/3312 [19:39<1:04:25,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Knowledge-aware Alert Aggregation in Large-scale Cloud Systems: a Hybrid Approach\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  23%|█████████████▍                                            | 765/3312 [19:40<1:03:35,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Unsupervised Real-Time Hallucination Detection based on the Internal States of Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  23%|█████████████▍                                            | 766/3312 [19:42<1:04:18,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: CoRAL: Collaborative Retrieval-Augmented Large Language Models Improve Long-tail Recommendation\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  23%|█████████████▍                                            | 767/3312 [19:43<1:02:36,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: RLingua: Improving Reinforcement Learning Sample Efficiency in Robotic Manipulations With Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  23%|█████████████▍                                            | 768/3312 [19:45<1:02:53,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Evolving Knowledge Distillation with Large Language Models and Active Learning\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  23%|█████████████▍                                            | 769/3312 [19:46<1:03:04,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: CLIcK: A Benchmark Dataset of Cultural and Linguistic Intelligence in Korean\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  23%|█████████████▍                                            | 770/3312 [19:48<1:02:47,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: What Makes Quantization for Large Language Models Hard? An Empirical Study from the Lens of Perturbation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  23%|█████████████▌                                            | 771/3312 [19:49<1:04:08,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: A Knowledge-Injected Curriculum Pretraining Framework for Question Answering\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  23%|█████████████▌                                            | 772/3312 [19:51<1:03:59,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Can LLMs' Tuning Methods Work in Medical Multimodal Domain?\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  23%|█████████████▌                                            | 773/3312 [19:52<1:05:29,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: DivCon: Divide and Conquer for Progressive Text-to-Image Generation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  23%|█████████████▌                                            | 774/3312 [19:54<1:08:26,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Amharic LLaMA and LLaVA: Multimodal LLMs for Low Resource Languages\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  23%|█████████████▌                                            | 775/3312 [19:56<1:07:25,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: From Instructions to Constraints: Language Model Alignment with Automatic Constraint Verification\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  23%|█████████████▌                                            | 776/3312 [19:57<1:05:21,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LIEDER: Linguistically-Informed Evaluation for Discourse Entity Recognition\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  23%|█████████████▌                                            | 777/3312 [19:59<1:04:45,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ArgMed-Agents: Explainable Clinical Decision Reasoning with Large Language Models via Argumentation Schemes\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  23%|█████████████▌                                            | 778/3312 [20:00<1:03:14,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Editing Conceptual Knowledge for Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  24%|█████████████▋                                            | 779/3312 [20:02<1:03:21,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: TRAD: Enhancing LLM Agents with Step-Wise Thought Retrieval and Aligned Decision\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  24%|█████████████▋                                            | 780/3312 [20:03<1:02:15,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Personalized LoRA for Human-Centered Text Understanding\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  24%|█████████████▋                                            | 781/3312 [20:04<1:02:29,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Mipha: A Comprehensive Overhaul of Multimodal Assistant with Small Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  24%|█████████████▋                                            | 782/3312 [20:06<1:03:59,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Can Large Language Models Automatically Score Proficiency of Written Essays?\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  24%|█████████████▋                                            | 783/3312 [20:08<1:03:48,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Fine-grainedly Synthesize Streaming Data Based On Large Language Models With Graph Structure Understanding For Data Sparsity\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  24%|█████████████▋                                            | 784/3312 [20:09<1:02:39,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: FedPIT: Towards Privacy-preserving and Few-shot Federated Instruction Tuning\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  24%|█████████████▋                                            | 785/3312 [20:11<1:04:50,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Low-dose CT Denoising with Language-engaged Dual-space Alignment\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  24%|█████████████▊                                            | 786/3312 [20:12<1:03:26,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: FMPAF: How Do Fed Chairs Affect the Financial Market? A Fine-grained Monetary Policy Analysis Framework on Their Language\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  24%|█████████████▊                                            | 787/3312 [20:14<1:02:33,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Large Language Models on Fine-grained Emotion Detection Dataset with Data Augmentation and Transfer Learning\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  24%|█████████████▊                                            | 788/3312 [20:15<1:02:41,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Can LLM Substitute Human Labeling? A Case Study of Fine-grained Chinese Address Entity Recognition Dataset for UAV Delivery\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  24%|█████████████▊                                            | 789/3312 [20:17<1:04:52,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: RepoHyper: Better Context Retrieval Is All You Need for Repository-Level Code Completion\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  24%|█████████████▊                                            | 790/3312 [20:18<1:04:14,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Reframe Anything: LLM Agent for Open World Video Reframing\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  24%|█████████████▊                                            | 791/3312 [20:20<1:03:04,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: A Preliminary Exploration of YouTubers' Use of Generative-AI in Content Creation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  24%|█████████████▊                                            | 792/3312 [20:21<1:01:36,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Few-Shot Cross-Lingual Transfer for Prompting Large Language Models in Low-Resource Languages\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  24%|█████████████▉                                            | 793/3312 [20:23<1:02:29,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Detectors for Safe and Reliable LLMs: Implementations, Uses, and Limitations\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  24%|█████████████▉                                            | 794/3312 [20:24<1:01:15,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Calibrating Large Language Models Using Their Generations Only\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  24%|█████████████▉                                            | 795/3312 [20:25<1:01:39,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Thread Detection and Response Generation using Transformers with Prompt Optimisation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  24%|█████████████▉                                            | 796/3312 [20:27<1:00:43,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: GPT as Psychologist? Preliminary Evaluations for GPT-4V on Visual Affective Computing\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  24%|█████████████▉                                            | 797/3312 [20:28<1:01:51,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: KG-Rank: Enhancing Large Language Models for Medical QA with Knowledge Graphs and Ranking Techniques\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  24%|█████████████▉                                            | 798/3312 [20:30<1:01:23,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LTGC: Long-tail Recognition via Leveraging LLMs-driven Generated Content\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  24%|█████████████▉                                            | 799/3312 [20:31<1:02:35,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Optimizing LLM Queries in Relational Workloads\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  24%|██████████████                                            | 800/3312 [20:33<1:02:35,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: MP2D: An Automated Topic Shift Dialogue Generation Framework Leveraging Knowledge Graphs\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  24%|██████████████                                            | 801/3312 [20:34<1:01:11,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: $\\textbf{S}^2$IP-LLM: Semantic Space Informed Prompt Learning with LLM for Time Series Forecasting\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  24%|██████████████                                            | 802/3312 [20:36<1:01:32,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ClinicalMamba: A Generative Clinical Language Model on Longitudinal Clinical Notes\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  24%|██████████████                                            | 803/3312 [20:37<1:02:22,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ItD: Large Language Models Can Teach Themselves Induction through Deduction\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  24%|██████████████                                            | 804/3312 [20:39<1:00:54,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: FLAP: Flow-Adhering Planning with Constrained Decoding in LLMs\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  24%|██████████████                                            | 805/3312 [20:40<1:01:47,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Decoding the AI Pen: Techniques and Challenges in Detecting AI-Generated Text\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  24%|██████████████                                            | 806/3312 [20:42<1:00:58,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: A Novel Nuanced Conversation Evaluation Framework for Large Language Models in Mental Health\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  24%|██████████████▏                                           | 807/3312 [20:43<1:00:11,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: A Benchmark of Domain-Adapted Large Language Models for Generating Brief Hospital Course Summaries\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  24%|██████████████▏                                           | 808/3312 [20:45<1:01:05,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Are Large Language Models Aligned with People's Social Intuitions for Human-Robot Interactions?\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  24%|██████████████▏                                           | 809/3312 [20:46<1:00:14,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Alignment Studio: Aligning Large Language Models to Particular Contextual Regulations\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  24%|██████████████▋                                             | 810/3312 [20:47<59:52,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: DP-TabICL: In-Context Learning with Differentially Private Tabular Data\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  24%|██████████████▋                                             | 811/3312 [20:49<59:23,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Decomposing Vision-based LLM Predictions for Auto-Evaluation with GPT-4\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  25%|██████████████▏                                           | 812/3312 [20:50<1:02:46,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: PipeRAG: Fast Retrieval-Augmented Generation via Algorithm-System Co-design\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  25%|██████████████▏                                           | 813/3312 [20:52<1:02:04,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Tuning-Free Accountable Intervention for LLM Deployment -- A Metacognitive Approach\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  25%|██████████████▎                                           | 814/3312 [20:53<1:01:58,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Can Large Language Models Play Games? A Case Study of A Self-Play Approach\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  25%|██████████████▎                                           | 815/3312 [20:55<1:01:03,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: GEAR: An Efficient KV Cache Compression Recipe for Near-Lossless Generative Inference of LLM\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  25%|██████████████▎                                           | 816/3312 [20:56<1:00:49,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Beyond Finite Data: Towards Data-free Out-of-distribution Generalization via Extrapolation\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  25%|██████████████▎                                           | 817/3312 [20:58<1:01:49,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Unfamiliar Finetuning Examples Control How Language Models Hallucinate\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  25%|██████████████▎                                           | 818/3312 [20:59<1:03:19,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Cost-Performance Optimization for Processing Low-Resource Language Tasks Using Commercial LLMs\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  25%|██████████████▎                                           | 819/3312 [21:01<1:03:10,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: VLM-PL: Advanced Pseudo Labeling approach Class Incremental Object Detection with Vision-Language Model\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  25%|██████████████▎                                           | 820/3312 [21:03<1:07:19,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ChatASU: Evoking LLM's Reflexion to Truly Understand Aspect Sentiment in Dialogues\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  25%|██████████████▍                                           | 821/3312 [21:04<1:05:50,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Tapilot-Crossing: Benchmarking and Evolving LLMs Towards Interactive Data Analysis Agents\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  25%|██████████████▍                                           | 822/3312 [21:06<1:03:26,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LLM4Decompile: Decompiling Binary Code with Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  25%|██████████████▍                                           | 823/3312 [21:07<1:04:14,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ERBench: An Entity-Relationship based Automatically Verifiable Hallucination Benchmark for Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  25%|██████████████▍                                           | 824/3312 [21:09<1:04:41,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Debiasing Multimodal Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  25%|██████████████▍                                           | 825/3312 [21:10<1:02:55,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Harnessing Multi-Role Capabilities of Large Language Models for Open-Domain Question Answering\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  25%|██████████████▍                                           | 826/3312 [21:12<1:02:00,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Tracing the Roots of Facts in Multilingual Language Models: Independent, Shared, and Transferred Knowledge\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  25%|██████████████▍                                           | 827/3312 [21:13<1:01:36,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Overcoming Reward Overoptimization via Adversarial Policy Optimization with Lightweight Uncertainty Estimation\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  25%|██████████████▌                                           | 828/3312 [21:15<1:00:39,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Towards a Psychology of Machines: Large Language Models Predict Human Memory\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  25%|██████████████▌                                           | 829/3312 [21:16<1:01:28,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Inverse Design of Photonic Crystal Surface Emitting Lasers is a Sequence Modeling Problem\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  25%|██████████████▌                                           | 830/3312 [21:18<1:01:04,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Med3DInsight: Enhancing 3D Medical Image Understanding with 2D Multi-Modal Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  25%|██████████████▌                                           | 831/3312 [21:19<1:01:44,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ELLA: Equip Diffusion Models with LLM for Enhanced Semantic Alignment\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  25%|██████████████▌                                           | 832/3312 [21:21<1:02:01,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ChatUIE: Exploring Chat-based Unified Information Extraction using Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  25%|██████████████▌                                           | 833/3312 [21:22<1:04:21,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Benchmarking Large Language Models for Molecule Prediction Tasks\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  25%|██████████████▌                                           | 834/3312 [21:24<1:02:22,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Can we obtain significant success in RST discourse parsing by using Large Language Models?\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  25%|██████████████▌                                           | 835/3312 [21:25<1:01:50,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Are Human Conversations Special? A Large Language Model Perspective\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  25%|██████████████▋                                           | 836/3312 [21:27<1:03:21,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Is this the real life? Is this just fantasy? The Misleading Success of Simulating Social Interactions With LLMs\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  25%|██████████████▋                                           | 837/3312 [21:28<1:01:32,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Can't Remember Details in Long Documents? You Need Some R&R\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  25%|██████████████▋                                           | 838/3312 [21:30<1:00:53,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: DiffChat: Learning to Chat with Text-to-Image Synthesis Models for Interactive Image Creation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  25%|██████████████▋                                           | 839/3312 [21:31<1:00:48,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Tell me the truth: A system to measure the trustworthiness of Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  25%|██████████████▋                                           | 840/3312 [21:33<1:01:05,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: An In-depth Evaluation of GPT-4 in Sentence Simplification with Error-based Human Assessment\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  25%|██████████████▋                                           | 841/3312 [21:34<1:00:04,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: SecGPT: An Execution Isolation Architecture for LLM-Based Systems\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  25%|██████████████▋                                           | 842/3312 [21:36<1:07:38,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Automatic and Universal Prompt Injection Attacks against Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  25%|██████████████▊                                           | 843/3312 [21:38<1:10:47,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Few shot chain-of-thought driven reasoning to prompt LLMs for open ended medical question answering\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  25%|██████████████▊                                           | 844/3312 [21:40<1:08:42,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Evaluating Biases in Context-Dependent Health Questions\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  26%|██████████████▊                                           | 845/3312 [21:41<1:06:55,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: iScore: Visual Analytics for Interpreting How Language Models Automatically Score Summaries\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  26%|██████████████▊                                           | 846/3312 [21:43<1:05:17,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LLMs in the Imaginarium: Tool Learning through Simulated Trial and Error\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  26%|██████████████▊                                           | 847/3312 [21:44<1:05:00,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: SnapNTell: Enhancing Entity-Centric Visual Question Answering with Retrieval Augmented Multimodal LLM\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  26%|██████████████▊                                           | 848/3312 [21:47<1:21:11,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: How Far Are We from Intelligent Visual Deductive Reasoning?\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  26%|██████████████▊                                           | 849/3312 [21:49<1:17:46,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Common 7B Language Models Already Possess Strong Math Capabilities\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  26%|██████████████▉                                           | 850/3312 [21:51<1:16:34,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ObjectCompose: Evaluating Resilience of Vision-Based Models on Object-to-Background Compositional Changes\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  26%|██████████████▉                                           | 851/3312 [21:52<1:13:19,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Fact-Checking the Output of Large Language Models via Token-Level Uncertainty Quantification\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  26%|██████████████▉                                           | 852/3312 [21:54<1:13:08,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Telecom Language Models: Must They Be Large?\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  26%|██████████████▉                                           | 853/3312 [21:56<1:13:09,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: QAQ: Quality Adaptive Quantization for LLM KV Cache\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  26%|██████████████▉                                           | 854/3312 [21:57<1:07:52,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Teaching Large Language Models to Reason with Reinforcement Learning\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  26%|██████████████▉                                           | 855/3312 [21:59<1:06:38,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: CAT: Enhancing Multimodal Large Language Model to Answer Questions in Dynamic Audio-Visual Scenarios\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  26%|██████████████▉                                           | 856/3312 [22:00<1:06:53,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Wiki-TabNER:Advancing Table Interpretation Through Named Entity Recognition\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  26%|███████████████                                           | 857/3312 [22:02<1:05:42,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: GraphInstruct: Empowering Large Language Models with Graph Understanding and Reasoning Capability\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  26%|███████████████                                           | 858/3312 [22:03<1:04:01,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Do Large Language Model Understand Multi-Intent Spoken Language ?\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  26%|███████████████                                           | 859/3312 [22:05<1:04:36,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Pearl: A Review-driven Persona-Knowledge Grounded Conversational Recommendation Dataset\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  26%|███████████████                                           | 860/3312 [22:06<1:03:32,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Low-Resource Court Judgment Summarization for Common Law Systems\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  26%|███████████████                                           | 861/3312 [22:08<1:04:33,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Membership Inference Attacks and Privacy in Topic Modeling\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  26%|███████████████                                           | 862/3312 [22:10<1:05:57,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Feedback-Generation for Programming Exercises With GPT-4\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  26%|███████████████                                           | 863/3312 [22:11<1:04:25,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Acceleron: A Tool to Accelerate Research Ideation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  26%|███████████████▏                                          | 864/3312 [22:13<1:02:18,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Discriminative Probing and Tuning for Text-to-Image Generation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  26%|███████████████▏                                          | 865/3312 [22:14<1:01:41,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Online Adaptation of Language Models with a Memory of Amortized Contexts\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  26%|███████████████▏                                          | 866/3312 [22:16<1:00:44,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Can Your Model Tell a Negation from an Implicature? Unravelling Challenges With Intent Encoders\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  26%|███████████████▏                                          | 867/3312 [22:17<1:01:58,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: HaluEval-Wild: Evaluating Hallucinations of Language Models in the Wild\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  26%|███████████████▏                                          | 868/3312 [22:19<1:00:51,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Effectiveness Assessment of Recent Large Vision-Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  26%|███████████████▋                                            | 869/3312 [22:20<59:42,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Proxy-RLHF: Decoupling Generation and Alignment in Large Language Model with Proxy\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  26%|███████████████▊                                            | 870/3312 [22:21<59:20,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Advancing Biomedical Text Mining with Community Challenges\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  26%|███████████████▊                                            | 871/3312 [22:23<59:51,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Can Small Language Models be Good Reasoners for Sequential Recommendation?\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  26%|███████████████▎                                          | 872/3312 [22:24<1:00:48,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Federated Recommendation via Hybrid Retrieval Augmented Generation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  26%|███████████████▎                                          | 873/3312 [22:26<1:02:36,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: UltraWiki: Ultra-fine-grained Entity Set Expansion with Negative Seed Entities\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  26%|███████████████▎                                          | 874/3312 [22:28<1:02:52,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: DEEP-ICL: Definition-Enriched Experts for Language Model In-Context Learning\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  26%|███████████████▎                                          | 875/3312 [22:29<1:02:49,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Evaluation of LLMs on Syntax-Aware Code Fill-in-the-Middle Tasks\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  26%|███████████████▎                                          | 876/3312 [22:31<1:03:49,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Aligners: Decoupling LLMs and Alignment\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  26%|███████████████▎                                          | 877/3312 [22:32<1:02:27,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Self-Evaluation of Large Language Model based on Glass-box Features\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  27%|███████████████▍                                          | 878/3312 [22:34<1:01:24,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Large Language Models are In-Context Molecule Learners\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  27%|███████████████▍                                          | 879/3312 [22:35<1:00:34,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Generative AI for Synthetic Data Generation: Methods, Challenges and the Future\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  27%|███████████████▍                                          | 880/3312 [22:37<1:00:41,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Metric-aware LLM inference for regression and scoring\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  27%|███████████████▍                                          | 881/3312 [22:38<1:02:48,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Improving Retrieval in Theme-specific Applications using a Corpus Topical Taxonomy\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  27%|███████████████▍                                          | 882/3312 [22:40<1:02:27,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Privacy-preserving Fine-tuning of Large Language Models through Flatness\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  27%|███████████████▍                                          | 883/3312 [22:41<1:01:24,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Exploring LLM-based Agents for Root Cause Analysis\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  27%|████████████████                                            | 884/3312 [22:43<59:52,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Can Large Language Models Reason and Plan?\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  27%|████████████████                                            | 885/3312 [22:44<59:23,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Artificial Intelligence Exploring the Patent Field\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  27%|████████████████                                            | 886/3312 [22:46<59:02,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Quantifying Contamination in Evaluating Code Generation Capabilities of Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  27%|████████████████                                            | 887/3312 [22:47<58:26,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Can Large Language Models do Analytical Reasoning?\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  27%|████████████████                                            | 888/3312 [22:49<58:15,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Enhancing chest X-ray datasets with privacy-preserving large language models and multi-type annotations: a data-driven approach for improved classification\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  27%|████████████████                                            | 889/3312 [22:50<58:27,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Guiding Enumerative Program Synthesis with Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  27%|███████████████▌                                          | 890/3312 [22:52<1:00:40,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: FaaF: Facts as a Function for the evaluation of generated text\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  27%|███████████████▌                                          | 891/3312 [22:53<1:02:08,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: SaulLM-7B: A pioneering Large Language Model for Law\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  27%|███████████████▌                                          | 892/3312 [22:55<1:05:59,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: KIWI: A Dataset of Knowledge-Intensive Writing Instructions for Answering Research Questions\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  27%|███████████████▋                                          | 893/3312 [22:56<1:03:11,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Are Language Models Puzzle Prodigies? Algorithmic Puzzles Unveil Serious Challenges in Multimodal Reasoning\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  27%|███████████████▋                                          | 894/3312 [22:58<1:06:54,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ShortGPT: Layers in Large Language Models are More Redundant Than You Expect\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  27%|███████████████▋                                          | 895/3312 [23:00<1:04:23,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: The Boy Who Survived: Removing Harry Potter from an LLM is harder than reported\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  27%|███████████████▋                                          | 896/3312 [23:01<1:03:00,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Evaluating the Elementary Multilingual Capabilities of Large Language Models with MultiQ\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  27%|███████████████▋                                          | 897/3312 [23:03<1:02:59,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Popeye: A Unified Visual-Language Model for Multi-Source Ship Detection from Remote Sensing Imagery\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  27%|███████████████▋                                          | 898/3312 [23:04<1:03:19,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: PPTC-R benchmark: Towards Evaluating the Robustness of Large Language Models for PowerPoint Task Completion\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  27%|███████████████▋                                          | 899/3312 [23:06<1:03:40,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: German also Hallucinates! Inconsistency Detection in News Summaries with the Absinth Dataset\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  27%|███████████████▊                                          | 900/3312 [23:08<1:09:13,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Towards Safe and Aligned Large Language Models for Medicine\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  27%|███████████████▊                                          | 901/3312 [23:10<1:08:25,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Rapidly Developing High-quality Instruction Data and Evaluation Benchmark for Large Language Models with Minimal Human Effort: A Case Study on Japanese\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  27%|███████████████▊                                          | 902/3312 [23:12<1:11:33,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: General2Specialized LLMs Translation for E-commerce\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  27%|███████████████▊                                          | 903/3312 [23:13<1:07:07,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: K-Link: Knowledge-Link Graph from LLMs for Enhanced Representation Learning in Multivariate Time-Series Data\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  27%|███████████████▊                                          | 904/3312 [23:15<1:06:09,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: SheetAgent: A Generalist Agent for Spreadsheet Reasoning and Manipulation via Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  27%|███████████████▊                                          | 905/3312 [23:16<1:04:11,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: GPTopic: Dynamic and Interactive Topic Representations\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  27%|███████████████▊                                          | 906/3312 [23:18<1:02:41,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Multimodal Large Language Models to Support Real-World Fact-Checking\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  27%|███████████████▉                                          | 907/3312 [23:19<1:00:30,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: WaterMax: breaking the LLM watermark detectability-robustness-quality trade-off\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  27%|████████████████▍                                           | 908/3312 [23:21<59:59,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Benchmarking Hallucination in Large Language Models based on Unanswerable Math Word Problem\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  27%|████████████████▍                                           | 909/3312 [23:22<58:32,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Emotional Manipulation Through Prompt Engineering Amplifies Disinformation Generation in AI Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  27%|████████████████▍                                           | 910/3312 [23:23<58:36,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Prompt Mining for Language-based Human Mobility Forecasting\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  28%|████████████████▌                                           | 911/3312 [23:25<59:21,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Towards Efficient and Effective Unlearning of Large Language Models for Recommendation\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  28%|████████████████▌                                           | 912/3312 [23:26<59:17,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: CLongEval: A Chinese Benchmark for Evaluating Long-Context Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  28%|████████████████▌                                           | 913/3312 [23:28<58:21,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: GaLore: Memory-Efficient LLM Training by Gradient Low-Rank Projection\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  28%|████████████████▌                                           | 914/3312 [23:29<58:45,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: A Knowledge Plug-and-Play Test Bed for Open-domain Dialogue Generation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  28%|████████████████▌                                           | 915/3312 [23:31<59:13,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: TGPT-PINN: Nonlinear model reduction with transformed GPT-PINNs\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  28%|████████████████▌                                           | 916/3312 [23:32<59:01,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Mixture-of-LoRAs: An Efficient Multitask Tuning for Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  28%|████████████████▌                                           | 917/3312 [23:34<59:11,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Negating Negatives: Alignment without Human Positive Samples via Distributional Dispreference Optimization\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  28%|████████████████▋                                           | 918/3312 [23:35<58:15,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Human vs. Machine: Language Models and Wargames\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  28%|████████████████▋                                           | 919/3312 [23:37<58:48,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Japanese-English Sentence Translation Exercises Dataset for Automatic Grading\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  28%|████████████████▋                                           | 920/3312 [23:38<59:47,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Learn to Code Sustainably: An Empirical Study on LLM-based Green Code Generation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  28%|████████████████▏                                         | 921/3312 [23:40<1:01:21,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Scope of Large Language Models for Mining Emerging Opinions in Online Health Discourse\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  28%|████████████████▏                                         | 922/3312 [23:41<1:01:27,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Guardrail Baselines for Unlearning in LLMs\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  28%|████████████████▏                                         | 923/3312 [23:43<1:01:03,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Mad Libs Are All You Need: Augmenting Cross-Domain Document-Level Event Argument Data\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  28%|████████████████▏                                         | 924/3312 [23:44<1:00:38,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Should We Fear Large Language Models? A Structural Analysis of the Human Reasoning System for Elucidating LLM Capabilities and Risks Through the Lens of Heidegger's Philosophy\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  28%|████████████████▏                                         | 925/3312 [23:46<1:00:58,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Alpaca against Vicuna: Using LLMs to Uncover Memorization of LLMs\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  28%|████████████████▏                                         | 926/3312 [23:48<1:03:14,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: The WMDP Benchmark: Measuring and Reducing Malicious Use With Unlearning\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  28%|████████████████▏                                         | 927/3312 [23:49<1:01:01,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: CLEVR-POC: Reasoning-Intensive Visual Question Answering in Partially Observable Environments\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  28%|████████████████▊                                           | 928/3312 [23:51<59:07,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: MAGID: An Automated Pipeline for Generating Synthetic Multi-modal Datasets\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  28%|████████████████▊                                           | 929/3312 [23:52<59:10,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Towards Democratized Flood Risk Management: An Advanced AI Assistant Enabled by GPT-4 for Enhanced Interpretability and Public Engagement\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  28%|████████████████▎                                         | 930/3312 [23:54<1:00:23,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: SNIFFER: Multimodal Large Language Model for Explainable Out-of-Context Misinformation Detection\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  28%|████████████████▊                                           | 931/3312 [23:55<59:48,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: PARADISE: Evaluating Implicit Planning Skills of Language Models with Procedural Warnings and Tips Dataset\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  28%|████████████████▎                                         | 932/3312 [23:57<1:06:05,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Language Guided Exploration for RL Agents in Text Environments\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  28%|████████████████▎                                         | 933/3312 [23:59<1:06:31,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Angry Men, Sad Women: Large Language Models Reflect Gendered Stereotypes in Emotion Attribution\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  28%|████████████████▎                                         | 934/3312 [24:00<1:04:42,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: KnowAgent: Knowledge-Augmented Planning for LLM-Based Agents\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  28%|████████████████▎                                         | 935/3312 [24:02<1:02:18,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Learning to Use Tools via Cooperative and Interactive Agents\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  28%|████████████████▍                                         | 936/3312 [24:03<1:00:49,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Word Importance Explains How Prompts Affect Language Model Outputs\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  28%|████████████████▉                                           | 937/3312 [24:05<59:25,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: OPEx: A Component-Wise Analysis of LLM-Centric Agents in Embodied Instruction Following\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  28%|████████████████▍                                         | 938/3312 [24:06<1:00:07,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Knowledge Graphs as Context Sources for LLM-Based Explanations of Learning Recommendations\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  28%|████████████████▍                                         | 939/3312 [24:08<1:02:36,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Localized Zeroth-Order Prompt Optimization\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  28%|████████████████▍                                         | 940/3312 [24:09<1:01:27,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Data Augmentation using LLMs: Data Perspectives, Learning Paradigms and Challenges\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  28%|█████████████████                                           | 941/3312 [24:11<59:50,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Evidence-Focused Fact Summarization for Knowledge-Augmented Zero-Shot Question Answering\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  28%|█████████████████                                           | 942/3312 [24:12<59:48,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Multi-Scale Protein Language Model for Unified Molecular Modeling\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  28%|████████████████▌                                         | 943/3312 [24:14<1:01:13,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: WikiTableEdit: A Benchmark for Table Editing by Natural Language Instruction\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  29%|█████████████████                                           | 944/3312 [24:15<59:31,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Benchmarking the Text-to-SQL Capability of Large Language Models: A Comprehensive Evaluation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  29%|████████████████▌                                         | 945/3312 [24:17<1:02:44,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ImgTrojan: Jailbreaking Vision-Language Models with ONE Image\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  29%|████████████████▌                                         | 946/3312 [24:19<1:02:27,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: A Comprehensive Survey on Process-Oriented Automatic Text Summarization with Exploration of LLM-Based Methods\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  29%|████████████████▌                                         | 947/3312 [24:21<1:08:07,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: In Search of Truth: An Interrogation Approach to Hallucination Detection\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  29%|████████████████▌                                         | 948/3312 [24:22<1:05:44,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: MathScale: Scaling Instruction Tuning for Mathematical Reasoning\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  29%|████████████████▌                                         | 949/3312 [24:24<1:03:56,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: An Empirical Study of LLM-as-a-Judge for LLM Evaluation: Fine-tuned Judge Models are Task-specific Classifiers\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  29%|████████████████▋                                         | 950/3312 [24:26<1:05:59,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: DPPA: Pruning Method for Large Language Model to Model Merging\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  29%|████████████████▋                                         | 951/3312 [24:28<1:10:49,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Evaluating and Optimizing Educational Content with Large Language Model Judgments\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  29%|████████████████▋                                         | 952/3312 [24:29<1:06:47,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: EasyQuant: An Efficient Data-free Quantization Algorithm for LLMs\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  29%|████████████████▋                                         | 953/3312 [24:31<1:04:31,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Emerging Synergies Between Large Language Models and Machine Learning in Ecommerce Recommendations\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  29%|████████████████▋                                         | 954/3312 [24:32<1:02:14,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Towards Measuring and Modeling \"Culture\" in LLMs: A Survey\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  29%|████████████████▋                                         | 955/3312 [24:34<1:04:41,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Role Prompting Guided Domain Adaptation with General Capability Preserve for Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  29%|████████████████▋                                         | 956/3312 [24:35<1:02:15,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: CURATRON: Complete Robust Preference Data for Robust Alignment of Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  29%|█████████████████▎                                          | 957/3312 [24:37<59:57,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Towards Training A Chinese Large Language Model for Anesthesiology\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  29%|████████████████▊                                         | 958/3312 [24:38<1:01:06,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Causal Prompting: Debiasing Large Language Model Prompting based on Front-Door Adjustment\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  29%|████████████████▊                                         | 959/3312 [24:40<1:00:40,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Crossing Linguistic Horizons: Finetuning and Comprehensive Evaluation of Vietnamese Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  29%|████████████████▊                                         | 960/3312 [24:42<1:00:50,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Android in the Zoo: Chain-of-Action-Thought for GUI Agents\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  29%|████████████████▊                                         | 961/3312 [24:43<1:00:05,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Causal Walk: Debiasing Multi-Hop Fact Verification with Front-Door Adjustment\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  29%|█████████████████▍                                          | 962/3312 [24:44<58:54,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Privacy-Aware Semantic Cache for Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  29%|█████████████████▍                                          | 963/3312 [24:46<58:58,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: InjecAgent: Benchmarking Indirect Prompt Injections in Tool-Integrated Large Language Model Agents\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  29%|█████████████████▍                                          | 964/3312 [24:47<58:29,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Revisiting Meta-evaluation for Grammatical Error Correction\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  29%|█████████████████▍                                          | 965/3312 [24:49<59:47,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Found in the Middle: How Language Models Use Long Contexts Better via Plug-and-Play Positional Encoding\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  29%|█████████████████▌                                          | 966/3312 [24:50<58:36,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Modeling Collaborator: Enabling Subjective Vision Classification With Minimal Human Effort via LLM Tool-Use\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  29%|█████████████████▌                                          | 967/3312 [24:52<57:44,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Exploring the Limitations of Large Language Models in Compositional Relation Reasoning\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  29%|█████████████████▌                                          | 968/3312 [24:53<57:41,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ChatCite: LLM Agent with Human Workflow Guidance for Comparative Literature Summary\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  29%|█████████████████▌                                          | 969/3312 [24:55<57:46,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Eliciting Better Multilingual Structured Reasoning from LLMs through Code\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  29%|█████████████████▌                                          | 970/3312 [24:56<56:40,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Updating the Minimum Information about CLinical Artificial Intelligence (MI-CLAIM) checklist for generative modeling research\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  29%|█████████████████▌                                          | 971/3312 [24:58<56:03,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Wukong: Towards a Scaling Law for Large-Scale Recommendation\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  29%|█████████████████▌                                          | 972/3312 [24:59<55:45,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: DACO: Towards Application-Driven and Comprehensive Data Analysis via Code Generation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  29%|█████████████████▋                                          | 973/3312 [25:00<55:29,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Balancing Enhancement, Harmlessness, and General Capabilities: Enhancing Conversational LLMs with Direct RLHF\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  29%|█████████████████▋                                          | 974/3312 [25:02<54:57,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: SPUQ: Perturbation-Based Uncertainty Quantification for Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  29%|█████████████████▋                                          | 975/3312 [25:03<56:16,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Trial and Error: Exploration-Based Trajectory Optimization for LLM Agents\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  29%|█████████████████▋                                          | 976/3312 [25:05<56:20,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Enhancing LLM Safety via Constrained Direct Preference Optimization\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  29%|█████████████████▋                                          | 977/3312 [25:06<58:11,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: OffLanDat: A Community Based Implicit Offensive Language Dataset Generated by Large Language Model Through Prompt Engineering\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  30%|█████████████████▋                                          | 978/3312 [25:08<57:17,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Are More LLM Calls All You Need? Towards Scaling Laws of Compound Inference Systems\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  30%|█████████████████▋                                          | 979/3312 [25:09<58:52,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: RegionGPT: Towards Region Understanding Vision Language Model\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  30%|█████████████████▏                                        | 980/3312 [25:11<1:01:49,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Taming Throughput-Latency Tradeoff in LLM Inference with Sarathi-Serve\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  30%|█████████████████▏                                        | 981/3312 [25:13<1:00:42,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: FENICE: Factuality Evaluation of summarization based on Natural language Inference and Claim Extraction\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  30%|█████████████████▏                                        | 982/3312 [25:14<1:02:12,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: KnowPhish: Large Language Models Meet Multimodal Knowledge Graphs for Enhancing Reference-Based Phishing Detection\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  30%|█████████████████▏                                        | 983/3312 [25:16<1:00:45,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Non-autoregressive Sequence-to-Sequence Vision-Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  30%|█████████████████▏                                        | 984/3312 [25:17<1:00:45,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Birbal: An efficient 7B instruct-model fine-tuned with curated datasets\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  30%|█████████████████▏                                        | 985/3312 [25:19<1:05:47,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: PHAnToM: Personality Has An Effect on Theory-of-Mind Reasoning in Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  30%|█████████████████▎                                        | 986/3312 [25:21<1:03:31,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Towards Intent-Based Network Management: Large Language Models for Intent Extraction in 5G Core Networks\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  30%|█████████████████▎                                        | 987/3312 [25:23<1:07:30,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: TPLLM: A Traffic Prediction Framework Based on Pretrained Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  30%|█████████████████▎                                        | 988/3312 [25:25<1:06:30,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Not all Layers of LLMs are Necessary during Inference\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  30%|█████████████████▎                                        | 989/3312 [25:26<1:03:15,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Masked Thought: Simply Masking Partial Reasoning Steps Can Improve Mathematical Reasoning Learning of Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  30%|█████████████████▎                                        | 990/3312 [25:28<1:03:51,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Cognition is All You Need -- The Next Layer of AI Above Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  30%|█████████████████▎                                        | 991/3312 [25:29<1:03:17,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Using LLMs for the Extraction and Normalization of Product Attribute Values\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  30%|█████████████████▎                                        | 992/3312 [25:31<1:03:50,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Large language models surpass human experts in predicting neuroscience results\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  30%|█████████████████▍                                        | 993/3312 [25:32<1:01:23,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Leveraging Weakly Annotated Data for Hate Speech Detection in Code-Mixed Hinglish: A Feasibility-Driven Transfer Learning Approach with Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  30%|█████████████████▍                                        | 994/3312 [25:34<1:00:35,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: adaptMLLM: Fine-Tuning Multilingual Language Models on Low-Resource Languages with Integrated LLM Playgrounds\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  30%|█████████████████▍                                        | 995/3312 [25:36<1:06:15,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Automated Generation of Multiple-Choice Cloze Questions for Assessing English Vocabulary Using GPT-turbo 3.5\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  30%|█████████████████▍                                        | 996/3312 [25:38<1:05:20,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Breaking the Language Barrier: Can Direct Inference Outperform Pre-Translation in Multilingual LLM Applications?\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  30%|█████████████████▍                                        | 997/3312 [25:39<1:01:35,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Large Language Model-Based Evolutionary Optimizer: Reasoning with elitism\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  30%|█████████████████▍                                        | 998/3312 [25:41<1:04:50,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Unveiling Hidden Links Between Unseen Security Entities\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  30%|█████████████████▍                                        | 999/3312 [25:43<1:03:23,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Topic Aware Probing: From Sentence Length Prediction to Idiom Identification how reliant are Neural Language Models on Topic?\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  30%|█████████████████▏                                       | 1000/3312 [25:44<1:00:50,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LLM-Oriented Retrieval Tuner\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  30%|█████████████████▏                                       | 1001/3312 [25:45<1:00:20,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Vanilla Transformers are Transfer Capability Teachers\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  30%|█████████████████▊                                         | 1002/3312 [25:47<59:39,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: SciAssess: Benchmarking LLM Proficiency in Scientific Literature Analysis\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  30%|█████████████████▊                                         | 1003/3312 [25:49<59:49,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Multi-perspective Improvement of Knowledge Graph Completion with Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  30%|█████████████████▎                                       | 1004/3312 [25:50<1:00:15,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: AS-ES Learning: Towards Efficient CoT Learning in Small Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  30%|█████████████████▉                                         | 1005/3312 [25:52<58:26,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Analyzing and Adapting Large Language Models for Few-Shot Multilingual NLU: Are We There Yet?\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  30%|█████████████████▉                                         | 1006/3312 [25:53<56:36,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: To Generate or to Retrieve? On the Effectiveness of Artificial Contexts for Medical Open-Domain Question Answering\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  30%|█████████████████▉                                         | 1007/3312 [25:55<57:44,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LLM vs. Lawyers: Identifying a Subset of Summary Judgments in a Large UK Case Law Dataset\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  30%|█████████████████▎                                       | 1008/3312 [25:56<1:00:27,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Online Training of Large Language Models: Learn while chatting\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  30%|█████████████████▎                                       | 1009/3312 [25:58<1:01:02,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Predicting Learning Performance with Large Language Models: A Study in Adult Literacy\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  30%|█████████████████▉                                         | 1010/3312 [25:59<59:24,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: CatCode: A Comprehensive Evaluation Framework for LLMs On the Mixture of Code and Text\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  31%|██████████████████                                         | 1011/3312 [26:01<57:28,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: NPHardEval4V: A Dynamic Reasoning Benchmark of Multimodal Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  31%|██████████████████                                         | 1012/3312 [26:02<57:52,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: WebCiteS: Attributed Query-Focused Summarization on Chinese Web Search Results with Citations\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  31%|██████████████████                                         | 1013/3312 [26:04<56:46,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: How Multimodal Integration Boost the Performance of LLM for Optimization: Case Study on Capacitated Vehicle Routing Problems\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  31%|██████████████████                                         | 1014/3312 [26:05<56:50,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Derivative-Free Optimization for Low-Rank Adaptation in Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  31%|██████████████████                                         | 1015/3312 [26:07<59:07,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Differentially Private Synthetic Data via Foundation Model APIs 2: Text\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  31%|█████████████████▍                                       | 1016/3312 [26:09<1:06:44,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Decode Neural signal as Speech\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  31%|█████████████████▌                                       | 1017/3312 [26:10<1:03:16,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Can LLMs Generate Architectural Design Decisions? -An Exploratory Empirical study\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  31%|█████████████████▌                                       | 1018/3312 [26:12<1:01:08,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Improving LLM Code Generation with Grammar Augmentation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  31%|█████████████████▌                                       | 1019/3312 [26:13<1:00:16,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Towards Comprehensive Vietnamese Retrieval-Augmented Generation and Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  31%|██████████████████▏                                        | 1020/3312 [26:15<58:05,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: SCHEMA: State CHangEs MAtter for Procedure Planning in Instructional Videos\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  31%|█████████████████▌                                       | 1021/3312 [26:17<1:02:24,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: SERVAL: Synergy Learning between Vertical Models and LLMs towards Oracle-Level Zero-shot Medical Prediction\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  31%|█████████████████▌                                       | 1022/3312 [26:18<1:02:37,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ReMatch: Retrieval Enhanced Schema Matching with LLMs\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  31%|█████████████████▌                                       | 1023/3312 [26:20<1:02:28,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: In-Context Sharpness as Alerts: An Inner Representation Perspective for Hallucination Mitigation\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  31%|█████████████████▌                                       | 1024/3312 [26:22<1:01:37,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Fantastic Semantics and Where to Find Them: Investigating Which Layers of Generative LLMs Reflect Lexical Semantics\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  31%|██████████████████▎                                        | 1025/3312 [26:23<59:48,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Infusing Knowledge into Large Language Models with Contextual Prompts\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  31%|██████████████████▎                                        | 1026/3312 [26:25<58:09,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Logic Rules as Explanations for Legal Case Retrieval\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  31%|█████████████████▋                                       | 1027/3312 [26:26<1:01:18,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: GuardT2I: Defending Text-to-Image Models from Adversarial Prompts\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  31%|█████████████████▋                                       | 1028/3312 [26:28<1:01:53,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Ever-Evolving Memory by Blending and Refining the Past\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  31%|█████████████████▋                                       | 1029/3312 [26:30<1:03:18,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Fine Tuning vs. Retrieval Augmented Generation for Less Popular Knowledge\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  31%|█████████████████▋                                       | 1030/3312 [26:31<1:01:21,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: MovieLLM: Enhancing Long Video Understanding with AI-Generated Movies\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  31%|██████████████████▎                                        | 1031/3312 [26:33<59:22,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: The Implicit Bias of Heterogeneity towards Invariance and Causality\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  31%|██████████████████▍                                        | 1032/3312 [26:34<58:47,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: CR-LT-KGQA: A Knowledge Graph Question Answering Dataset Requiring Commonsense Reasoning and Long-Tail Knowledge\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  31%|█████████████████▊                                       | 1033/3312 [26:36<1:00:03,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Breaking Down the Defenses: A Comparative Survey of Attacks on Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  31%|██████████████████▍                                        | 1034/3312 [26:37<57:48,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Right for Right Reasons: Large Language Models for Verifiable Commonsense Knowledge Graph Question Answering\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  31%|██████████████████▍                                        | 1035/3312 [26:39<58:46,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: On the Compressibility of Quantized Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  31%|██████████████████▍                                        | 1036/3312 [26:40<58:02,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Automatic Question-Answer Generation for Long-Tail Knowledge\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  31%|██████████████████▍                                        | 1037/3312 [26:42<58:37,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LM4OPT: Unveiling the Potential of Large Language Models in Formulating Mathematical Optimization Problems\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  31%|██████████████████▍                                        | 1038/3312 [26:43<57:19,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Large Language Multimodal Models for 5-Year Chronic Disease Cohort Prediction Using EHR Data\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  31%|██████████████████▌                                        | 1039/3312 [26:45<56:17,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: A Cross-Modal Approach to Silent Speech with LLM-Enhanced Recognition\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  31%|██████████████████▌                                        | 1040/3312 [26:46<55:42,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Improving the Validity of Automatically Generated Feedback via Reinforcement Learning\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  31%|██████████████████▌                                        | 1041/3312 [26:48<54:56,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Analysis of Privacy Leakage in Federated Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  31%|██████████████████▌                                        | 1042/3312 [26:49<54:51,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: NoMAD-Attention: Efficient LLM Inference on CPUs Through Multiply-add-free Attention\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  31%|██████████████████▌                                        | 1043/3312 [26:51<55:37,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Dissecting Language Models: Machine Unlearning via Selective Pruning\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  32%|██████████████████▌                                        | 1044/3312 [26:52<56:16,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: AutoDefense: Multi-Agent LLM Defense against Jailbreak Attacks\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  32%|██████████████████▌                                        | 1045/3312 [26:54<55:37,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Accelerating Greedy Coordinate Gradient via Probe Sampling\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  32%|██████████████████▋                                        | 1046/3312 [26:55<57:01,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: SceneCraft: An LLM Agent for Synthesizing 3D Scene as Blender Code\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  32%|██████████████████▋                                        | 1047/3312 [26:57<55:34,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Mitigating Catastrophic Forgetting in Large Language Models with Self-Synthesized Rehearsal\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  32%|██████████████████▋                                        | 1048/3312 [26:58<55:38,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: IntactKV: Improving Large Language Model Quantization by Keeping Pivot Tokens Intact\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  32%|██████████████████▋                                        | 1049/3312 [26:59<55:48,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: API Is Enough: Conformal Prediction for Large Language Models Without Logit-Access\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  32%|██████████████████▋                                        | 1050/3312 [27:01<54:35,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Data-free Multi-label Image Recognition via LLM-powered Prompt Tuning\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  32%|██████████████████▋                                        | 1051/3312 [27:02<54:26,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: The Case for Animal-Friendly AI\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  32%|██████████████████▋                                        | 1052/3312 [27:04<58:24,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: DMoERM: Recipes of Mixture-of-Experts for Effective Reward Modeling\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  32%|██████████████████▊                                        | 1053/3312 [27:06<56:47,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: RAGged Edges: The Double-Edged Sword of Retrieval-Augmented Chatbots\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  32%|██████████████████▊                                        | 1054/3312 [27:07<55:50,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Balancing Exploration and Exploitation in LLM using Soft RLLF for Enhanced Negation Understanding\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  32%|██████████████████▊                                        | 1055/3312 [27:09<57:53,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: STAR: Constraint LoRA with Dynamic Active Learning for Data-Efficient Fine-Tuning of Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  32%|██████████████████▊                                        | 1056/3312 [27:10<59:10,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: A Survey of AI-generated Text Forensic Systems: Detection, Attribution, and Characterization\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  32%|██████████████████▊                                        | 1057/3312 [27:12<57:44,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: MuseGraph: Graph-oriented Instruction Tuning of Large Language Models for Generic Graph Mining\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  32%|██████████████████▏                                      | 1058/3312 [27:14<1:07:10,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ParallelPARC: A Scalable Pipeline for Generating Natural-Language Analogies\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  32%|██████████████████▏                                      | 1059/3312 [27:16<1:02:53,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LLM-PQ: Serving LLM on Heterogeneous Clusters with Phase-Aware Partition and Adaptive Quantization\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  32%|██████████████████▏                                      | 1060/3312 [27:17<1:04:04,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Evaluating Large Language Models as Virtual Annotators for Time-series Physical Sensing Data\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  32%|██████████████████▎                                      | 1061/3312 [27:19<1:02:36,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LLaMoCo: Instruction Tuning of Large Language Models for Optimization Code Generation\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  32%|██████████████████▉                                        | 1062/3312 [27:20<59:24,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: OpenGraph: Towards Open Graph Foundation Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  32%|██████████████████▉                                        | 1063/3312 [27:22<57:25,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Towards Accurate Lip-to-Speech Synthesis in-the-Wild\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  32%|██████████████████▉                                        | 1064/3312 [27:23<57:51,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LAB: Large-Scale Alignment for ChatBots\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  32%|██████████████████▉                                        | 1065/3312 [27:25<55:58,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LLMCRIT: Teaching Large Language Models to Use Criteria\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  32%|██████████████████▎                                      | 1066/3312 [27:27<1:00:56,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: FaiMA: Feature-aware In-context Learning for Multi-domain Aspect-based Sentiment Analysis\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  32%|███████████████████                                        | 1067/3312 [27:28<58:42,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Reading Subtext: Evaluating Large Language Models on Short Story Summarization with Writers\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  32%|███████████████████                                        | 1068/3312 [27:30<59:10,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Towards Full Authorship with AI: Supporting Revision with AI-Generated Views\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  32%|███████████████████                                        | 1069/3312 [27:31<59:06,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: AutoAttacker: A Large Language Model Guided System to Implement Automatic Cyber-attacks\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  32%|███████████████████                                        | 1070/3312 [27:33<56:52,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Peacock: A Family of Arabic Multimodal Large Language Models and Benchmarks\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  32%|██████████████████▍                                      | 1071/3312 [27:34<1:00:27,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Attribute Structuring Improves LLM-Based Evaluation of Clinical Text Summaries\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  32%|██████████████████▍                                      | 1072/3312 [27:36<1:01:09,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Predictions from language models for multiple-choice tasks are not robust under variation of scoring methods\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  32%|███████████████████                                        | 1073/3312 [27:38<59:01,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: MALTO at SemEval-2024 Task 6: Leveraging Synthetic Data for LLM Hallucination Detection\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  32%|███████████████████▏                                       | 1074/3312 [27:39<58:04,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ATP: Enabling Fast LLM Serving via Attention on Top Principal Keys\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  32%|███████████████████▏                                       | 1075/3312 [27:40<56:17,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Differentially Private Knowledge Distillation via Synthetic Text Generation\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  32%|███████████████████▏                                       | 1076/3312 [27:42<55:32,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: An Interpretable Ensemble of Graph and Language Models for Improving Search Relevance in E-Commerce\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  33%|███████████████████▏                                       | 1077/3312 [27:43<56:21,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Mitigating Reversal Curse in Large Language Models via Semantic-aware Permutation Training\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  33%|███████████████████▏                                       | 1078/3312 [27:45<55:42,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: AtP*: An efficient and scalable method for localizing LLM behaviour to components\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  33%|███████████████████▏                                       | 1079/3312 [27:46<54:46,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Playing NetHack with LLMs: Potential & Limitations as Zero-Shot Agents\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  33%|███████████████████▏                                       | 1080/3312 [27:48<56:27,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: DiaHalu: A Dialogue-level Hallucination Evaluation Benchmark for Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  33%|███████████████████▎                                       | 1081/3312 [27:49<55:41,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Large Language Models for Simultaneous Named Entity Extraction and Spelling Correction\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  33%|███████████████████▎                                       | 1082/3312 [27:51<57:24,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ROME: Memorization Insights from Text, Probability and Hidden State in Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  33%|███████████████████▎                                       | 1083/3312 [27:52<55:41,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Do Zombies Understand? A Choose-Your-Own-Adventure Exploration of Machine Cognition\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  33%|███████████████████▎                                       | 1084/3312 [27:54<54:44,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: TempCompass: Do Video LLMs Really Understand Videos?\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  33%|███████████████████▎                                       | 1085/3312 [27:55<56:06,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LUCID: LLM-Generated Utterances for Complex and Interesting Dialogues\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  33%|███████████████████▎                                       | 1086/3312 [27:57<59:36,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Hierarchical Indexing for Retrieval-Augmented Opinion Summarization\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  33%|███████████████████▎                                       | 1087/3312 [27:59<58:45,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LLMs for Targeted Sentiment in News Headlines: Exploring Different Levels of Prompt Prescriptiveness\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  33%|███████████████████▍                                       | 1088/3312 [28:00<57:04,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Rethinking Tokenization: Crafting Better Tokenizers for Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  33%|███████████████████▍                                       | 1089/3312 [28:02<57:06,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Text classification of column headers with a controlled vocabulary: leveraging LLMs for metadata enrichment\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  33%|███████████████████▍                                       | 1090/3312 [28:03<57:01,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Private Benchmarking to Prevent Contamination and Improve Comparative Evaluation of LLMs\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  33%|███████████████████▍                                       | 1091/3312 [28:05<56:05,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Invariant Test-Time Adaptation for Vision-Language Model Generalization\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  33%|███████████████████▍                                       | 1092/3312 [28:06<54:38,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Crimson: Empowering Strategic Reasoning in Cybersecurity through Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  33%|███████████████████▍                                       | 1093/3312 [28:08<55:11,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Semi-Instruct: Bridging Natural-Instruct and Self-Instruct for Code Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  33%|███████████████████▍                                       | 1094/3312 [28:09<54:04,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Never-Ending Embodied Robot Learning\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  33%|███████████████████▌                                       | 1095/3312 [28:11<53:43,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Teach LLMs to Phish: Stealing Private Information from Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  33%|███████████████████▌                                       | 1096/3312 [28:12<59:03,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: DPP-Based Adversarial Prompt Searching for Lanugage Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  33%|███████████████████▌                                       | 1097/3312 [28:14<58:23,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Gender Bias in Large Language Models across Multiple Languages\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  33%|███████████████████▌                                       | 1098/3312 [28:15<55:52,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: SoftTiger: A Clinical Foundation Model for Healthcare Workflows\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  33%|███████████████████▌                                       | 1099/3312 [28:17<56:25,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Extracting Polymer Nanocomposite Samples from Full-Length Documents\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  33%|███████████████████▌                                       | 1100/3312 [28:19<56:49,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Gradient Cuff: Detecting Jailbreak Attacks on Large Language Models by Exploring Refusal Loss Landscapes\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  33%|███████████████████▌                                       | 1101/3312 [28:20<59:26,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Multimodal ArXiv: A Dataset for Improving Scientific Comprehension of Large Vision-Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  33%|███████████████████▋                                       | 1102/3312 [28:22<57:47,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Improving Socratic Question Generation using Data Augmentation and Preference Optimization\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  33%|██████████████████▉                                      | 1103/3312 [28:24<1:03:00,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: AXOLOTL: Fairness through Assisted Self-Debiasing of Large Language Model Outputs\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  33%|███████████████████                                      | 1104/3312 [28:25<1:02:23,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LLM-Ensemble: Optimal Large Language Model Ensemble Method for E-commerce Product Attribute Value Extraction\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  33%|███████████████████                                      | 1105/3312 [28:27<1:00:01,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: TELEClass: Taxonomy Enrichment and LLM-Enhanced Hierarchical Text Classification with Minimal Supervision\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  33%|███████████████████▋                                       | 1106/3312 [28:28<57:45,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LLMs in Political Science: Heralding a New Era of Visual Analysis\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  33%|███████████████████▋                                       | 1107/3312 [28:30<58:01,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: UniTS: Building a Unified Time Series Model\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  33%|███████████████████▋                                       | 1108/3312 [28:32<58:11,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: FAC$^2$E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  33%|███████████████████▊                                       | 1109/3312 [28:33<57:26,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: NewsBench: Systematic Evaluation of LLMs for Writing Proficiency and Safety Adherence in Chinese Journalistic Editorial Applications\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  34%|███████████████████▊                                       | 1110/3312 [28:35<56:15,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LoRA-as-an-Attack! Piercing LLM Safety Under The Share-and-Play Scenario\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  34%|███████████████████▊                                       | 1111/3312 [28:36<55:24,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Direct Alignment of Draft Model for Speculative Decoding with Chat-Fine-Tuned LLMs\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  34%|███████████████████▊                                       | 1112/3312 [28:38<57:12,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: PROC2PDDL: Open-Domain Planning Representations from Texts\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  34%|███████████████████▊                                       | 1113/3312 [28:39<57:27,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Resonance RoPE: Improving Context Length Generalization of Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  34%|███████████████████▊                                       | 1114/3312 [28:41<56:27,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Query-OPT: Optimizing Inference of Large Language Models via Multi-Query Instructions in Meeting Summarization\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  34%|███████████████████▊                                       | 1115/3312 [28:42<57:35,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: The Counterfeit Conundrum: Can Code Language Models Grasp the Nuances of Their Incorrect Generations?\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  34%|███████████████████▉                                       | 1116/3312 [28:44<56:48,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: The All-Seeing Project V2: Towards General Relation Comprehension of the Open World\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  34%|███████████████████▉                                       | 1117/3312 [28:45<55:07,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Loose LIPS Sink Ships: Asking Questions in Battleship with Language-Informed Program Sampling\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  34%|███████████████████▉                                       | 1118/3312 [28:47<54:04,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Towards Tracing Trustworthiness Dynamics: Revisiting Pre-training Period of Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  34%|███████████████████▉                                       | 1119/3312 [28:48<56:13,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Curiosity-driven Red-teaming for Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  34%|███████████████████▉                                       | 1120/3312 [28:50<55:53,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Heavy-Tailed Class Imbalance and Why Adam Outperforms Gradient Descent on Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  34%|███████████████████▉                                       | 1121/3312 [28:52<57:38,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ArCHer: Training Language Model Agents via Hierarchical Multi-Turn RL\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  34%|███████████████████▉                                       | 1122/3312 [28:53<56:04,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Compositional API Recommendation for Library-Oriented Code Generation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  34%|████████████████████                                       | 1123/3312 [28:54<55:14,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Crafting Knowledge: Exploring the Creative Mechanisms of Chat-Based Search Engines\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  34%|████████████████████                                       | 1124/3312 [28:56<54:19,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: On the Scaling Laws of Geographical Representation in Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  34%|████████████████████                                       | 1125/3312 [28:57<53:56,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Entity-Aware Multimodal Alignment Framework for News Image Captioning\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  34%|████████████████████                                       | 1126/3312 [28:59<54:27,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Wisdom of the Silicon Crowd: LLM Ensemble Prediction Capabilities Rival Human Crowd Accuracy\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  34%|███████████████████▍                                     | 1127/3312 [29:01<1:01:29,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: OpenMedLM: Prompt engineering can out-perform fine-tuning in medical question-answering with open-source large language models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  34%|████████████████████                                       | 1128/3312 [29:02<58:31,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: SoK: Exploring the Potential of Large Language Models for Improving Digital Forensic Investigation Efficiency\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  34%|████████████████████                                       | 1129/3312 [29:04<57:05,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Watermark Stealing in Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  34%|████████████████████▏                                      | 1130/3312 [29:05<55:31,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Deep Learning for Cross-Domain Data Fusion in Urban Computing: Taxonomy, Advances, and Outlook\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  34%|████████████████████▏                                      | 1131/3312 [29:07<54:34,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Generalizable Whole Slide Image Classification with Fine-Grained Visual-Semantic Interaction\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  34%|████████████████████▏                                      | 1132/3312 [29:08<56:20,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: SEED: Customize Large Language Models with Sample-Efficient Adaptation for Code Generation\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  34%|████████████████████▏                                      | 1133/3312 [29:10<55:50,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: RL-GPT: Integrating Reinforcement Learning and Code-as-policy\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  34%|████████████████████▏                                      | 1134/3312 [29:11<55:06,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: PlanGPT: Enhancing Urban Planning with Tailored Language Model and Efficient Retrieval\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  34%|████████████████████▏                                      | 1135/3312 [29:13<55:20,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: GSM-Plus: A Comprehensive Benchmark for Evaluating the Robustness of LLMs as Mathematical Problem Solvers\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  34%|████████████████████▏                                      | 1136/3312 [29:14<54:16,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Let LLMs Take on the Latest Challenges! A Chinese Dynamic Question Answering Benchmark\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  34%|████████████████████▎                                      | 1137/3312 [29:16<53:23,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: RiNALMo: General-Purpose RNA Language Models Can Generalize Well on Structure Prediction Tasks\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  34%|████████████████████▎                                      | 1138/3312 [29:17<54:25,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Memory-Augmented Generative Adversarial Transformers\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  34%|████████████████████▎                                      | 1139/3312 [29:19<54:41,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: PeLLE: Encoder-based language models for Brazilian Portuguese based on open data\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  34%|████████████████████▎                                      | 1140/3312 [29:20<53:31,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: PRSA: Prompt Reverse Stealing Attacks against Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  34%|████████████████████▎                                      | 1141/3312 [29:22<54:35,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Teaching Large Language Models an Unseen Language on the Fly\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  34%|████████████████████▎                                      | 1142/3312 [29:24<55:20,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Enhancing Long-Term Recommendation with Bi-level Learnable Large Language Model Planning\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  35%|████████████████████▎                                      | 1143/3312 [29:25<54:31,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Unveiling Typographic Deceptions: Insights of the Typographic Vulnerability in Large Vision-Language Model\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  35%|████████████████████▍                                      | 1144/3312 [29:27<55:28,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Whispers that Shake Foundations: Analyzing and Mitigating False Premise Hallucinations in Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  35%|████████████████████▍                                      | 1145/3312 [29:28<54:06,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Controllable Preference Optimization: Toward Controllable Multi-Objective Alignment\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  35%|████████████████████▍                                      | 1146/3312 [29:29<53:18,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Pointing out the Shortcomings of Relation Extraction Models with Semantically Motivated Adversarials\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  35%|████████████████████▍                                      | 1147/3312 [29:31<55:40,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Exploring the Efficacy of Large Language Models in Summarizing Mental Health Counseling Sessions: A Benchmark Study\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  35%|████████████████████▍                                      | 1148/3312 [29:33<54:11,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: FhGenie: A Custom, Confidentiality-preserving Chat AI for Corporate and Scientific Use\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  35%|████████████████████▍                                      | 1149/3312 [29:34<53:28,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: EyeGPT: Ophthalmic Assistant with Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  35%|████████████████████▍                                      | 1150/3312 [29:35<53:18,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Analyzing and Reducing Catastrophic Forgetting in Parameter Efficient Tuning\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  35%|████████████████████▌                                      | 1151/3312 [29:37<55:05,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: How do Large Language Models Handle Multilingualism?\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  35%|████████████████████▌                                      | 1152/3312 [29:39<56:45,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: On the Decision-Making Abilities in Role-Playing using Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  35%|████████████████████▌                                      | 1153/3312 [29:40<55:15,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ToolNet: Connecting Large Language Models with Massive Tools via Tool Graph\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  35%|████████████████████▌                                      | 1154/3312 [29:42<55:44,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: FlexLLM: A System for Co-Serving Large Language Model Inference and Parameter-Efficient Finetuning\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  35%|████████████████████▌                                      | 1155/3312 [29:43<56:26,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: NeuroPrune: A Neuro-inspired Topological Sparse Training Algorithm for Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  35%|████████████████████▌                                      | 1156/3312 [29:45<57:28,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Commonsense Ontology Micropatterns\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  35%|████████████████████▌                                      | 1157/3312 [29:47<56:16,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Learning to Compress Prompt in Natural Language Formats\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  35%|████████████████████▋                                      | 1158/3312 [29:48<55:55,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: CLLMs: Consistency Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  35%|████████████████████▋                                      | 1159/3312 [29:50<55:18,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Data Interpreter: An LLM Agent For Data Science\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  35%|███████████████████▉                                     | 1160/3312 [30:09<4:03:54,  6.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Simple linear attention language models balance the recall-throughput tradeoff\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  35%|███████████████████▉                                     | 1161/3312 [30:11<3:12:05,  5.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: FOFO: A Benchmark to Evaluate LLMs' Format-Following Capability\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  35%|███████████████████▉                                     | 1162/3312 [30:13<2:34:37,  4.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Large Language Models and Games: A Survey and Roadmap\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  35%|████████████████████                                     | 1163/3312 [30:14<2:02:59,  3.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: A New Era in LLM Security: Exploring Security Concerns in Real-World LLM-based Systems\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  35%|████████████████████                                     | 1164/3312 [30:15<1:42:16,  2.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Arithmetic Control of LLMs for Diverse User Preferences: Directional Preference Alignment with Multi-Objective Rewards\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  35%|████████████████████                                     | 1165/3312 [30:17<1:28:03,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Keeping LLMs Aligned After Fine-tuning: The Crucial Role of Prompt Templates\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  35%|████████████████████                                     | 1166/3312 [30:19<1:18:13,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Few-Shot Fairness: Unveiling LLM's Potential for Fairness-Aware Classification\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  35%|████████████████████                                     | 1167/3312 [30:20<1:11:49,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Language Models Represent Beliefs of Self and Others\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  35%|████████████████████                                     | 1168/3312 [30:21<1:04:58,  1.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: The First Place Solution of WSDM Cup 2024: Leveraging Large Language Models for Conversational Multi-Doc QA\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  35%|████████████████████                                     | 1169/3312 [30:23<1:02:03,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Large Language Models As Evolution Strategies\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  35%|████████████████████▏                                    | 1170/3312 [30:25<1:01:01,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Focus on Your Question! Interpreting and Mitigating Toxic CoT Problems in Commonsense Reasoning\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  35%|████████████████████▊                                      | 1171/3312 [30:26<58:58,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: How to think step-by-step: A mechanistic understanding of chain-of-thought reasoning\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  35%|████████████████████▉                                      | 1172/3312 [30:28<56:39,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Retrieval-based Full-length Wikipedia Generation for Emergent Events\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  35%|████████████████████▉                                      | 1173/3312 [30:29<54:21,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Towards Generalist Prompting for Large Language Models by Mental Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  35%|████████████████████▉                                      | 1174/3312 [30:31<57:01,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Learning or Self-aligning? Rethinking Instruction Fine-tuning\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  35%|████████████████████▉                                      | 1175/3312 [30:32<56:05,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Prospect Personalized Recommendation on Large Language Model-based Agent Platform\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  36%|████████████████████▉                                      | 1176/3312 [30:34<57:51,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: CogBench: a large language model walks into a psychology lab\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  36%|████████████████████▉                                      | 1177/3312 [30:36<56:12,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LLM Task Interference: An Initial Study on the Impact of Task-Switch in Conversational History\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  36%|████████████████████▉                                      | 1178/3312 [30:37<53:55,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Lemur: Log Parsing with Entropy Sampling and Chain-of-Thought Merging\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  36%|█████████████████████                                      | 1179/3312 [30:38<54:40,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: MIKO: Multimodal Intention Knowledge Distillation from Large Language Models for Social-Media Commonsense Discovery\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  36%|█████████████████████                                      | 1180/3312 [30:40<54:47,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: From Summary to Action: Enhancing Large Language Models for Complex Tasks with Open World APIs\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  36%|█████████████████████                                      | 1181/3312 [30:42<55:09,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: MedAide: Leveraging Large Language Models for On-Premise Medical Assistance on Edge Devices\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  36%|█████████████████████                                      | 1182/3312 [30:43<53:25,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Unsupervised Information Refinement Training of Large Language Models for Retrieval-Augmented Generation\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  36%|█████████████████████                                      | 1183/3312 [30:45<56:12,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Random Silicon Sampling: Simulating Human Sub-Population Opinion Using a Large Language Model Based on Group-Level Demographic Information\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  36%|█████████████████████                                      | 1184/3312 [30:46<57:14,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Cause and Effect: Can Large Language Models Truly Understand Causality?\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  36%|█████████████████████                                      | 1185/3312 [30:48<56:14,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Exploring Multilingual Human Value Concepts in Large Language Models: Is Value Alignment Consistent, Transferable and Controllable across Languages?\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  36%|█████████████████████▏                                     | 1186/3312 [30:49<54:34,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Small But Funny: A Feedback-Driven Approach to Humor Distillation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  36%|█████████████████████▏                                     | 1187/3312 [30:51<52:50,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Making Them Ask and Answer: Jailbreaking Large Language Models in Few Queries via Disguise and Reconstruction\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  36%|█████████████████████▏                                     | 1188/3312 [30:52<52:42,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Editing Factual Knowledge and Explanatory Ability of Medical Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  36%|█████████████████████▏                                     | 1189/3312 [30:54<55:06,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: No Token Left Behind: Reliable KV Cache Compression via Importance-Aware Mixed Precision Quantization\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  36%|█████████████████████▏                                     | 1190/3312 [30:55<54:25,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Benchmarking Large Language Models on Answering and Explaining Challenging Medical Questions\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  36%|█████████████████████▏                                     | 1191/3312 [30:57<55:22,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Token-Specific Watermarking with Enhanced Detectability and Semantic Coherence for Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  36%|█████████████████████▏                                     | 1192/3312 [30:59<55:51,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: MEGAnno+: A Human-LLM Collaborative Annotation System\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  36%|█████████████████████▎                                     | 1193/3312 [31:00<55:29,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Characterizing Truthfulness in Large Language Model Generations with Local Intrinsic Dimension\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  36%|█████████████████████▎                                     | 1194/3312 [31:02<54:10,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Multi-FAct: Assessing Multilingual LLMs' Multi-Regional Knowledge using FActScore\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  36%|█████████████████████▎                                     | 1195/3312 [31:03<53:41,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Datasets for Large Language Models: A Comprehensive Survey\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  36%|█████████████████████▎                                     | 1196/3312 [31:05<53:37,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Automated Discovery of Integral with Deep Learning\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  36%|█████████████████████▎                                     | 1197/3312 [31:06<52:39,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ResLoRA: Identity Residual Mapping in Low-Rank Adaption\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  36%|█████████████████████▎                                     | 1198/3312 [31:08<52:28,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Corpus-Steered Query Expansion with Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  36%|█████████████████████▎                                     | 1199/3312 [31:09<51:26,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Hire a Linguist!: Learning Endangered Languages with In-Context Linguistic Descriptions\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  36%|█████████████████████▍                                     | 1200/3312 [31:11<52:47,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: TroubleLLM: Align to Red Team Expert\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  36%|█████████████████████▍                                     | 1201/3312 [31:12<51:37,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Merino: Entropy-driven Design for Generative Language Models on IoT Devices\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  36%|█████████████████████▍                                     | 1202/3312 [31:14<52:50,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: A Survey on Recent Advances in LLM-Based Multi-turn Dialogue Systems\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  36%|█████████████████████▍                                     | 1203/3312 [31:15<51:41,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Exploring Multi-Document Information Consolidation for Scientific Sentiment Summarization\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  36%|█████████████████████▍                                     | 1204/3312 [31:17<55:06,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Constrained Decoding for Code Language Models via Efficient Left and Right Quotienting of Context-Sensitive Grammars\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  36%|█████████████████████▍                                     | 1205/3312 [31:18<54:32,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: FlattenQuant: Breaking Through the Inference Compute-bound for Large Language Models with Per-tensor Quantization\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  36%|█████████████████████▍                                     | 1206/3312 [31:20<55:23,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Collaborative decoding of critical tokens for boosting factuality of large language models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  36%|█████████████████████▌                                     | 1207/3312 [31:21<53:39,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Gradient-Free Adaptive Global Pruning for Pre-trained Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  36%|█████████████████████▌                                     | 1208/3312 [31:23<52:43,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: EmMark: Robust Watermarks for IP Protection of Embedded Quantized Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  37%|█████████████████████▌                                     | 1209/3312 [31:24<51:54,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Acquiring Linguistic Knowledge from Multimodal Input\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  37%|█████████████████████▌                                     | 1210/3312 [31:26<50:44,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Multitask Multilingual Model Adaptation with Featurized Low-Rank Mixtures\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  37%|█████████████████████▌                                     | 1211/3312 [31:27<50:49,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Pragmatic Instruction Following and Goal Assistance via Cooperative Language-Guided Inverse Planning\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  37%|█████████████████████▌                                     | 1212/3312 [31:28<50:05,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LLM-Resistant Math Word Problem Generation via Adversarial Attacks\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  37%|█████████████████████▌                                     | 1213/3312 [31:30<50:57,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: A Language Model based Framework for New Concept Placement in Ontologies\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  37%|████████████████████▉                                    | 1214/3312 [31:33<1:03:45,  1.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Researchy Questions: A Dataset of Multi-Perspective, Decompositional Questions for LLM Web Agents\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  37%|████████████████████▉                                    | 1215/3312 [31:34<1:00:36,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: JMLR: Joint Medical LLM and Retrieval Training for Enhancing Reasoning and Professional Question Answering Capability\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  37%|█████████████████████▋                                     | 1216/3312 [31:36<59:39,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: BlendSQL: A Scalable Dialect for Unifying Hybrid Question Answering in Relational Algebra\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  37%|█████████████████████▋                                     | 1217/3312 [31:37<56:21,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Automated Statistical Model Discovery with Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  37%|█████████████████████▋                                     | 1218/3312 [31:39<54:12,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Deep Learning Detection Method for Large Language Models-Generated Scientific Content\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  37%|████████████████████▉                                    | 1219/3312 [31:41<1:03:22,  1.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Self-Refinement of Language Models from External Proxy Metrics Feedback\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  37%|█████████████████████▋                                     | 1220/3312 [31:42<58:57,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Prediction-Powered Ranking of Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  37%|█████████████████████▊                                     | 1221/3312 [31:44<56:37,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: The Era of 1-bit LLMs: All Large Language Models are in 1.58 Bits\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  37%|█████████████████████▊                                     | 1222/3312 [31:46<56:31,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Massive Activations in Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  37%|█████████████████████▊                                     | 1223/3312 [31:47<56:34,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Evaluating Very Long-Term Conversational Memory of LLM Agents\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  37%|█████████████████████▊                                     | 1224/3312 [31:49<56:52,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Tower: An Open Multilingual Large Language Model for Translation-Related Tasks\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  37%|█████████████████████                                    | 1225/3312 [31:51<1:04:12,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: AmbigNLG: Addressing Task Ambiguity in Instruction for NLG\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  37%|█████████████████████                                    | 1226/3312 [31:53<1:02:10,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Case-Based or Rule-Based: How Do Transformers Do the Math?\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  37%|█████████████████████▊                                     | 1227/3312 [31:54<57:54,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: NextLevelBERT: Investigating Masked Language Modeling with Higher-Level Representations for Long Documents\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  37%|█████████████████████▉                                     | 1228/3312 [31:56<55:15,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Beyond prompt brittleness: Evaluating the reliability and consistency of political worldviews in LLMs\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  37%|█████████████████████▉                                     | 1229/3312 [31:57<55:33,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: SongComposer: A Large Language Model for Lyric and Melody Composition in Song Generation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  37%|█████████████████████▉                                     | 1230/3312 [31:59<55:41,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Are LLMs Capable of Data-based Statistical and Causal Reasoning? Benchmarking Advanced Quantitative Reasoning with Data\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  37%|█████████████████████▉                                     | 1231/3312 [32:00<53:28,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Variational Learning is Effective for Large Deep Networks\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  37%|█████████████████████▉                                     | 1232/3312 [32:02<53:37,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Agent-Pro: Learning to Evolve via Policy-Level Reflection and Optimization\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  37%|█████████████████████▉                                     | 1233/3312 [32:03<51:41,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: DropBP: Accelerating Fine-Tuning of Large Language Models by Dropping Backward Propagation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  37%|█████████████████████▉                                     | 1234/3312 [32:05<58:07,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: OmniACT: A Dataset and Benchmark for Enabling Multimodal Generalist Autonomous Agents for Desktop and Web\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  37%|██████████████████████                                     | 1235/3312 [32:07<54:58,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: TruthX: Alleviating Hallucinations by Editing Large Language Models in Truthful Space\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  37%|██████████████████████                                     | 1236/3312 [32:08<53:44,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Retrieval is Accurate Generation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  37%|██████████████████████                                     | 1237/3312 [32:10<54:00,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Predict the Next Word: Humans exhibit uncertainty in this task and language models _____\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  37%|██████████████████████                                     | 1238/3312 [32:11<52:22,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: BASES: Large-scale Web Search User Simulation with Large Language Model based Agents\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  37%|██████████████████████                                     | 1239/3312 [32:13<51:13,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Intensive Care as One Big Sequence Modeling Problem\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  37%|██████████████████████                                     | 1240/3312 [32:14<51:06,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: REAR: A Relevance-Aware Retrieval-Augmented Framework for Open-Domain Question Answering\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  37%|██████████████████████                                     | 1241/3312 [32:15<50:00,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Prescribing Large Language Models for Perioperative Care: What's The Right Dose for Pre-trained Models?\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  38%|██████████████████████▏                                    | 1242/3312 [32:18<56:59,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Can GPT-4 Identify Propaganda? Annotation and Detection of Propaganda Spans in News Articles\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  38%|██████████████████████▏                                    | 1243/3312 [32:19<54:28,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Training-Free Long-Context Scaling of Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  38%|██████████████████████▏                                    | 1244/3312 [32:20<52:34,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: DS-Agent: Automated Data Science by Empowering Large Language Models with Case-Based Reasoning\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  38%|██████████████████████▏                                    | 1245/3312 [32:22<52:31,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Deep Learning Based Named Entity Recognition Models for Recipes\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  38%|██████████████████████▏                                    | 1246/3312 [32:23<53:52,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Enhancing EEG-to-Text Decoding through Transferable Representations from Pre-trained Contrastive EEG-Text Masked Autoencoder\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  38%|██████████████████████▏                                    | 1247/3312 [32:25<52:12,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Consistency Matters: Explore LLMs Consistency From a Black-Box Perspective\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  38%|██████████████████████▏                                    | 1248/3312 [32:26<52:35,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Investigating Continual Pretraining in Large Language Models: Insights and Implications\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  38%|██████████████████████▏                                    | 1249/3312 [32:28<51:19,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Benchmarking GPT-4 on Algorithmic Problems: A Systematic Evaluation of Prompting Strategies\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  38%|██████████████████████▎                                    | 1250/3312 [32:29<52:23,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Determinants of LLM-assisted Decision-Making\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  38%|██████████████████████▎                                    | 1251/3312 [32:31<53:31,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LLMGuard: Guarding Against Unsafe LLM Behavior\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  38%|██████████████████████▎                                    | 1252/3312 [32:33<54:11,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: SoFA: Shielded On-the-fly Alignment via Priority Rule Following\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  38%|██████████████████████▎                                    | 1253/3312 [32:34<52:19,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: RECOST: External Knowledge Guided Data-efficient Instruction Tuning\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  38%|██████████████████████▎                                    | 1254/3312 [32:36<52:46,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Probing Multimodal Large Language Models for Global and Local Semantic Representations\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  38%|██████████████████████▎                                    | 1255/3312 [32:37<52:32,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Can LLM Generate Culturally Relevant Commonsense QA Data? Case Study in Indonesian and Sundanese\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  38%|██████████████████████▎                                    | 1256/3312 [32:39<57:11,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Mini-Ensemble Low-Rank Adapters for Parameter-Efficient Fine-Tuning\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  38%|██████████████████████▍                                    | 1257/3312 [32:41<58:33,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Speak Out of Turn: Safety Vulnerability of Large Language Models in Multi-turn Dialogue\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  38%|██████████████████████▍                                    | 1258/3312 [32:43<56:44,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Beyond the Known: Investigating LLMs Performance on Out-of-Domain Intent Detection\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  38%|██████████████████████▍                                    | 1259/3312 [32:44<54:40,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: MATHSENSEI: A Tool-Augmented Large Language Model for Mathematical Reasoning\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  38%|██████████████████████▍                                    | 1260/3312 [32:46<53:54,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Reasoning in Conversation: Solving Subjective Tasks through Dialogue Simulation for Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  38%|██████████████████████▍                                    | 1261/3312 [32:47<53:37,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Measuring Vision-Language STEM Skills of Neural Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  38%|██████████████████████▍                                    | 1262/3312 [32:49<54:21,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: When Scaling Meets LLM Finetuning: The Effect of Data, Model and Finetuning Method\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  38%|██████████████████████▍                                    | 1263/3312 [32:50<52:30,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Sora: A Review on Background, Technology, Limitations, and Opportunities of Large Vision Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  38%|██████████████████████▌                                    | 1264/3312 [32:52<50:56,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Benchmarking Data Science Agents\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  38%|██████████████████████▌                                    | 1265/3312 [32:53<50:07,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Metasql: A Generate-then-Rank Framework for Natural Language to SQL Translation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  38%|██████████████████████▌                                    | 1266/3312 [32:55<54:14,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Fact-and-Reflection (FaR) Improves Confidence Calibration of Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  38%|██████████████████████▌                                    | 1267/3312 [32:56<52:13,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Creating Suspenseful Stories: Iterative Planning with Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  38%|██████████████████████▌                                    | 1268/3312 [32:58<51:45,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Sinkhorn Distance Minimization for Knowledge Distillation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  38%|██████████████████████▌                                    | 1269/3312 [32:59<54:16,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Re-Ex: Revising after Explanation Reduces the Factual Errors in LLM Responses\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  38%|██████████████████████▌                                    | 1270/3312 [33:01<52:04,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Adapting to Teammates in a Cooperative Language Game\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  38%|██████████████████████▋                                    | 1271/3312 [33:03<55:50,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Leveraging Large Language Models for Learning Complex Legal Concepts through Storytelling\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  38%|██████████████████████▋                                    | 1272/3312 [33:04<53:07,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Towards Explainability and Fairness in Swiss Judgement Prediction: Benchmarking on a Multilingual Dataset\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  38%|██████████████████████▋                                    | 1273/3312 [33:06<52:23,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Pandora's White-Box: Increased Training Data Leakage in Open LLMs\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  38%|██████████████████████▋                                    | 1274/3312 [33:07<53:18,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Can Large Language Models Recall Reference Location Like Humans?\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  38%|██████████████████████▋                                    | 1275/3312 [33:09<51:22,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Benchmarking LLMs on the Semantic Overlap Summarization Task\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  39%|██████████████████████▋                                    | 1276/3312 [33:11<55:22,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Algorithmic Arbitrariness in Content Moderation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  39%|██████████████████████▋                                    | 1277/3312 [33:12<54:21,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: A Survey of Large Language Models in Cybersecurity\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  39%|██████████████████████▊                                    | 1278/3312 [33:13<52:04,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: WIPI: A New Web Threat for LLM-Driven Web Agents\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  39%|██████████████████████▊                                    | 1279/3312 [33:15<50:37,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Think Big, Generate Quick: LLM-to-SLM for Fast Autoregressive Decoding\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  39%|██████████████████████▊                                    | 1280/3312 [33:16<50:05,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: MobiLlama: Towards Accurate and Lightweight Fully Transparent GPT\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  39%|██████████████████████▊                                    | 1281/3312 [33:18<50:20,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Do Large Language Models Latently Perform Multi-Hop Reasoning?\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  39%|██████████████████████▊                                    | 1282/3312 [33:19<49:25,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Eight Methods to Evaluate Robust Unlearning in LLMs\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  39%|██████████████████████▊                                    | 1283/3312 [33:21<49:52,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Mysterious Projections: Multimodal LLMs Gain Domain-Specific Visual Capabilities Without Richer Cross-Modal Projections\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  39%|██████████████████████▊                                    | 1284/3312 [33:22<50:59,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: A Survey on Data Selection for Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  39%|██████████████████████▉                                    | 1285/3312 [33:24<49:58,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Language Agents as Optimizable Graphs\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  39%|██████████████████████▉                                    | 1286/3312 [33:25<48:56,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Rainbow Teaming: Open-Ended Generation of Diverse Adversarial Prompts\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  39%|██████████████████████▉                                    | 1287/3312 [33:27<49:47,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: A Surprising Failure? Multimodal LLMs and the NLVR Challenge\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  39%|██████████████████████▉                                    | 1288/3312 [33:28<50:27,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: OncoGPT: A Medical Conversational Model Tailored with Oncology Domain Expertise on a Large Language Model Meta-AI (LLaMA)\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  39%|██████████████████████▉                                    | 1289/3312 [33:30<50:43,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: If in a Crowdsourced Data Annotation Pipeline, a GPT-4\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  39%|██████████████████████▉                                    | 1290/3312 [33:31<50:32,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Political Compass or Spinning Arrow? Towards More Meaningful Evaluations for Values and Opinions in Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  39%|██████████████████████▉                                    | 1291/3312 [33:33<49:25,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: A Comprehensive Evaluation of Quantization Strategies for Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  39%|███████████████████████                                    | 1292/3312 [33:34<48:19,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: CodeChameleon: Personalized Encryption Framework for Jailbreaking Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  39%|███████████████████████                                    | 1293/3312 [33:35<49:25,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: SelectIT: Selective Instruction Tuning for Large Language Models via Uncertainty-Aware Self-Reflection\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  39%|███████████████████████                                    | 1294/3312 [33:37<50:05,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Look Before You Leap: Towards Decision-Aware and Generalizable Tool-Usage for Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  39%|███████████████████████                                    | 1295/3312 [33:38<49:01,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: HumanEval-XL: A Multilingual Code Generation Benchmark for Cross-lingual Natural Language Generalization\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  39%|███████████████████████                                    | 1296/3312 [33:40<49:27,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Adaptation of Biomedical and Clinical Pretrained Models to French Long Documents: A Comparative Study\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  39%|███████████████████████                                    | 1297/3312 [33:41<48:30,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: StructLM: Towards Building Generalist Models for Structured Knowledge Grounding\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  39%|███████████████████████                                    | 1298/3312 [33:43<49:24,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ESG Sentiment Analysis: comparing human and language model performance including GPT\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  39%|███████████████████████▏                                   | 1299/3312 [33:44<49:03,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LangGPT: Rethinking Structured Reusable Prompt Design Framework for LLMs from the Programming Language\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  39%|███████████████████████▏                                   | 1300/3312 [33:46<49:07,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Long-Context Language Modeling with Parallel Context Encoding\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  39%|███████████████████████▏                                   | 1301/3312 [33:47<49:57,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Multi-Bit Distortion-Free Watermarking for Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  39%|███████████████████████▏                                   | 1302/3312 [33:49<51:32,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Two-stage Generative Question Answering on Temporal Knowledge Graph Using Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  39%|███████████████████████▏                                   | 1303/3312 [33:50<50:27,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Aligning Large Language Models to a Domain-specific Graph Database\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  39%|███████████████████████▏                                   | 1304/3312 [33:52<49:28,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Retrieval Augmented Generation Systems: Automatic Dataset Creation, Evaluation and Boolean Agent Setup\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  39%|███████████████████████▏                                   | 1305/3312 [33:53<48:45,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Integrating Large Language Models with Graphical Session-Based Recommendation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  39%|███████████████████████▎                                   | 1306/3312 [33:55<49:33,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LLM-based Privacy Data Augmentation Guided by Knowledge Distillation with a Distribution Tutor for Medical Text Classification\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  39%|███████████████████████▎                                   | 1307/3312 [33:56<49:25,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LLMArena: Assessing Capabilities of Large Language Models in Dynamic Multi-Agent Environments\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  39%|███████████████████████▎                                   | 1308/3312 [33:58<51:58,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: On Languaging a Simulation Engine\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  40%|███████████████████████▎                                   | 1309/3312 [33:59<50:10,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Defending LLMs against Jailbreaking Attacks via Backtranslation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  40%|███████████████████████▎                                   | 1310/3312 [34:01<49:02,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: RetrievalQA: Assessing Adaptive Retrieval-Augmented Generation for Short-form Open-Domain Question Answering\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  40%|███████████████████████▎                                   | 1311/3312 [34:03<54:55,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ShieldLM: Empowering LLMs as Aligned, Customizable and Explainable Safety Detectors\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  40%|███████████████████████▎                                   | 1312/3312 [34:04<53:28,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Language-Specific Neurons: The Key to Multilingual Capabilities in Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  40%|███████████████████████▍                                   | 1313/3312 [34:06<52:26,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: RoCoIns: Enhancing Robustness of Large Language Models through Code-Style Instructions\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  40%|███████████████████████▍                                   | 1314/3312 [34:07<53:07,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: DenseMamba: State Space Models with Dense Hidden Connection for Efficient Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  40%|██████████████████████▋                                  | 1315/3312 [34:10<1:03:05,  1.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Predicting Sustainable Development Goals Using Course Descriptions -- from LLMs to Conventional Foundation Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  40%|███████████████████████▍                                   | 1316/3312 [34:12<59:39,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: HealMe: Harnessing Cognitive Reframing in Large Language Models for Psychotherapy\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  40%|███████████████████████▍                                   | 1317/3312 [34:13<55:31,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: From RAGs to riches: Using large language models to write documents for clinical trials\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  40%|███████████████████████▍                                   | 1318/3312 [34:14<52:57,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: MoZIP: A Multilingual Benchmark to Evaluate Large Language Models in Intellectual Property\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  40%|███████████████████████▍                                   | 1319/3312 [34:16<50:52,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Immunization against harmful fine-tuning attacks\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  40%|███████████████████████▌                                   | 1320/3312 [34:17<49:49,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Improving LLM-based Machine Translation with Systematic Self-Correction\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  40%|███████████████████████▌                                   | 1321/3312 [34:19<48:49,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Unraveling Babel: Exploring Multilingual Activation Patterns within Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  40%|███████████████████████▌                                   | 1322/3312 [34:20<52:19,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LLM Inference Unveiled: Survey and Roofline Model Insights\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  40%|███████████████████████▌                                   | 1323/3312 [34:22<51:47,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Language-guided Skill Learning with Temporal Variational Inference\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  40%|███████████████████████▌                                   | 1324/3312 [34:24<52:00,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: CodeS: Towards Building Open-source Language Models for Text-to-SQL\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  40%|███████████████████████▌                                   | 1325/3312 [34:25<50:56,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Personalized Federated Instruction Tuning via Neural Architecture Search\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  40%|███████████████████████▌                                   | 1326/3312 [34:27<53:59,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Data-freeWeight Compress and Denoise for Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  40%|███████████████████████▋                                   | 1327/3312 [34:28<52:09,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Finer: Investigating and Enhancing Fine-Grained Visual Concept Recognition in Large Vision Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  40%|███████████████████████▋                                   | 1328/3312 [34:30<51:40,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Chain-of-Discussion: A Multi-Model Framework for Complex Evidence-Based Question Answering\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  40%|███████████████████████▋                                   | 1329/3312 [34:31<49:57,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: PerLTQA: A Personal Long-Term Memory Dataset for Memory Classification, Retrieval, and Synthesis in Question Answering\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  40%|███████████████████████▋                                   | 1330/3312 [34:33<49:55,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: From Large Language Models and Optimization to Decision Optimization CoPilot: A Research Manifesto\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  40%|███████████████████████▋                                   | 1331/3312 [34:34<49:59,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: CFRet-DVQA: Coarse-to-Fine Retrieval and Efficient Tuning for Document Visual Question Answering\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  40%|███████████████████████▋                                   | 1332/3312 [34:36<48:50,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: HypoTermQA: Hypothetical Terms Dataset for Benchmarking Hallucination Tendency of LLMs\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  40%|███████████████████████▋                                   | 1333/3312 [34:37<47:51,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Defending Large Language Models against Jailbreak Attacks via Semantic Smoothing\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  40%|███████████████████████▊                                   | 1334/3312 [34:38<47:58,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Attacking LLM Watermarks by Exploiting Their Strengths\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  40%|███████████████████████▊                                   | 1335/3312 [34:40<47:58,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: How Can LLM Guide RL? A Value-Based Approach\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  40%|███████████████████████▊                                   | 1336/3312 [34:41<47:22,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: DrAttack: Prompt Decomposition and Reconstruction Makes Powerful LLM Jailbreakers\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  40%|███████████████████████▊                                   | 1337/3312 [34:43<47:08,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ChatMusician: Understanding and Generating Music Intrinsically with LLM\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  40%|███████████████████████▊                                   | 1338/3312 [34:44<47:43,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: PeriodicLoRA: Breaking the Low-Rank Bottleneck in LoRA Optimization\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  40%|███████████████████████▊                                   | 1339/3312 [34:46<49:43,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: What Generative Artificial Intelligence Means for Terminological Definitions\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  40%|███████████████████████▊                                   | 1340/3312 [34:47<48:43,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: AVI-Talking: Learning Audio-Visual Instructions for Expressive 3D Talking Face Generation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  40%|███████████████████████▉                                   | 1341/3312 [34:49<53:04,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: FuseChat: Knowledge Fusion of Chat Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  41%|███████████████████████▉                                   | 1342/3312 [34:51<52:08,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: NeSy is alive and well: A LLM-driven symbolic approach for better code comment data generation and classification\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  41%|███████████████████████▉                                   | 1343/3312 [34:52<50:42,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: UrbanGPT: Spatio-Temporal Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  41%|███████████████████████▉                                   | 1344/3312 [34:54<51:12,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Citation-Enhanced Generation for LLM-based Chatbots\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  41%|███████████████████████▉                                   | 1345/3312 [34:56<52:20,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Evaluating Robustness of Generative Search Engine on Adversarial Factual Questions\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  41%|███████████████████████▉                                   | 1346/3312 [34:57<52:28,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: How Large Language Models Encode Context Knowledge? A Layer-Wise Probing Study\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  41%|███████████████████████▉                                   | 1347/3312 [34:59<53:55,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Say More with Less: Understanding Prompt Learning Behaviors through Gist Compression\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  41%|████████████████████████                                   | 1348/3312 [35:00<53:10,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LSTP: Language-guided Spatial-Temporal Prompt Learning for Long-form Video-Text Understanding\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  41%|████████████████████████                                   | 1349/3312 [35:02<51:16,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LLMs with Chain-of-Thought Are Non-Causal Reasoners\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  41%|████████████████████████                                   | 1350/3312 [35:03<49:27,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Detecting Machine-Generated Texts by Multi-Population Aware Optimization for Maximum Mean Discrepancy\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  41%|████████████████████████                                   | 1351/3312 [35:05<49:03,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: EHRNoteQA: A Patient-Specific Question Answering Benchmark for Evaluating Large Language Models in Clinical Settings\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  41%|████████████████████████                                   | 1352/3312 [35:06<49:16,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Text Understanding and Generation Using Transformer Models for Intelligent E-commerce Recommendations\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  41%|████████████████████████                                   | 1353/3312 [35:08<49:47,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Don't Forget Your Reward Values: Language Model Alignment via Value-based Calibration\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  41%|████████████████████████                                   | 1354/3312 [35:10<51:35,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: GraphWiz: An Instruction-Following Language Model for Graph Problems\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  41%|████████████████████████▏                                  | 1355/3312 [35:11<51:10,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LoRA Meets Dropout under a Unified Framework\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  41%|████████████████████████▏                                  | 1356/3312 [35:12<49:40,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: From Noise to Clarity: Unraveling the Adversarial Suffix of Large Language Model Attacks via Translation of Text Embeddings\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  41%|████████████████████████▏                                  | 1357/3312 [35:14<48:28,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Likelihood-based Mitigation of Evaluation Bias in Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  41%|████████████████████████▏                                  | 1358/3312 [35:15<48:46,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Cognitive Bias in High-Stakes Decision-Making with LLMs\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  41%|████████████████████████▏                                  | 1359/3312 [35:17<49:18,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Sustainable Supercomputing for AI: GPU Power Capping at HPC Scale\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  41%|████████████████████████▏                                  | 1360/3312 [35:19<53:51,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: GreenLLaMA: A Framework for Detoxification with Explanations\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  41%|████████████████████████▏                                  | 1361/3312 [35:21<53:47,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Bootstrapping Cognitive Agents with a Large Language Model\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  41%|████████████████████████▎                                  | 1362/3312 [35:22<51:40,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LDB: A Large Language Model Debugger via Verifying Runtime Execution Step-by-step\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  41%|████████████████████████▎                                  | 1363/3312 [35:24<56:34,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Rethinking Software Engineering in the Foundation Model Era: A Curated Catalogue of Challenges in the Development of Trustworthy FMware\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  41%|████████████████████████▎                                  | 1364/3312 [35:26<55:26,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Generalization or Memorization: Data Contamination and Trustworthy Evaluation for Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  41%|████████████████████████▎                                  | 1365/3312 [35:27<53:44,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Evaluating Prompting Strategies for Grammatical Error Correction Based on Language Proficiency\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  41%|████████████████████████▎                                  | 1366/3312 [35:29<51:19,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: QuaCer-C: Quantitative Certification of Knowledge Comprehension in LLMs\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  41%|████████████████████████▎                                  | 1367/3312 [35:30<49:19,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Enforcing Temporal Constraints on Generative Agent Behavior with Reactive Synthesis\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  41%|████████████████████████▎                                  | 1368/3312 [35:32<50:33,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: PRP: Propagating Universal Perturbations to Attack Large Language Model Guard-Rails\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  41%|████████████████████████▍                                  | 1369/3312 [35:33<49:39,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Multimodal Instruction Tuning with Conditional Mixture of LoRA\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  41%|████████████████████████▍                                  | 1370/3312 [35:35<48:24,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: SemEval-2024 Task 8: Weighted Layer Averaging RoBERTa for Black-Box Machine-Generated Text Detection\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  41%|████████████████████████▍                                  | 1371/3312 [35:36<48:28,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: SportQA: A Benchmark for Sports Understanding in Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  41%|████████████████████████▍                                  | 1372/3312 [35:38<47:38,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: MATHWELL: Generating Educational Math Word Problems at Scale\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  41%|████████████████████████▍                                  | 1373/3312 [35:39<47:42,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: NaVid: Video-based VLM Plans the Next Step for Vision-and-Language Navigation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  41%|████████████████████████▍                                  | 1374/3312 [35:41<48:40,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Prompt Perturbation Consistency Learning for Robust Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  42%|████████████████████████▍                                  | 1375/3312 [35:42<49:19,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Linguistic Intelligence in Large Language Models for Telecommunications\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  42%|████████████████████████▌                                  | 1376/3312 [35:44<51:29,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: PRoLoRA: Partial Rotation Empowers More Parameter-Efficient LoRA\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  42%|████████████████████████▌                                  | 1377/3312 [35:46<52:17,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Measuring Bargaining Abilities of LLMs: A Benchmark and A Buyer-Enhancement Method\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  42%|████████████████████████▌                                  | 1378/3312 [35:47<50:40,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: OAG-Bench: A Human-Curated Benchmark for Academic Graph Mining\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  42%|████████████████████████▌                                  | 1379/3312 [35:48<49:04,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Empowering Large Language Model Agents through Action Learning\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  42%|████████████████████████▌                                  | 1380/3312 [35:50<49:36,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Enhancing Cloud-Based Large Language Model Processing with Elasticsearch and Transformer Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  42%|████████████████████████▌                                  | 1381/3312 [35:51<48:02,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: From COBIT to ISO 42001: Evaluating Cybersecurity Frameworks for Opportunities, Risks, and Regulatory Compliance in Commercializing Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  42%|████████████████████████▌                                  | 1382/3312 [35:53<48:34,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Look Before You Leap: Problem Elaboration Prompting Improves Mathematical Reasoning in Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  42%|████████████████████████▋                                  | 1383/3312 [35:54<47:31,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Stepwise Self-Consistent Mathematical Reasoning with Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  42%|████████████████████████▋                                  | 1384/3312 [35:56<49:51,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Increasing SAM Zero-Shot Performance on Multimodal Medical Images Using GPT-4 Generated Descriptive Prompts Without Human Annotation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  42%|████████████████████████▋                                  | 1385/3312 [35:58<49:39,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Chimera: A Lossless Decoding Method for Accelerating Large Language Models Inference by Fusing all Tokens\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  42%|████████████████████████▋                                  | 1386/3312 [35:59<49:11,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: HD-Eval: Aligning Large Language Model Evaluators Through Hierarchical Criteria Decomposition\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  42%|████████████████████████▋                                  | 1387/3312 [36:01<49:55,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Sparse MeZO: Less Parameters for Better Performance in Zeroth-Order LLM Fine-Tuning\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  42%|████████████████████████▋                                  | 1388/3312 [36:02<50:09,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: MemeCraft: Contextual and Stance-Driven Multimodal Meme Generation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  42%|████████████████████████▋                                  | 1389/3312 [36:04<51:59,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: How Do Humans Write Code? Large Models Do It the Same Way Too\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  42%|████████████████████████▊                                  | 1390/3312 [36:06<52:37,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LLMs Can Defend Themselves Against Jailbreaking in a Practical Manner: A Vision Paper\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  42%|████████████████████████▊                                  | 1391/3312 [36:07<50:06,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Hal-Eval: A Universal and Fine-grained Hallucination Evaluation Framework for Large Vision Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  42%|████████████████████████▊                                  | 1392/3312 [36:09<49:04,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Making Pre-trained Language Models Better Continual Few-Shot Relation Extractors\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  42%|████████████████████████▊                                  | 1393/3312 [36:10<47:39,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Foot In The Door: Understanding Large Language Model Jailbreaking via Cognitive Psychology\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  42%|████████████████████████▊                                  | 1394/3312 [36:12<53:29,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Leveraging ChatGPT in Pharmacovigilance Event Extraction: An Empirical Study\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  42%|████████████████████████▊                                  | 1395/3312 [36:14<58:26,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Exploring Failure Cases in Multimodal Reasoning About Physical Dynamics\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  42%|████████████████████████▊                                  | 1396/3312 [36:16<54:59,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: On Trojan Signatures in Large Language Models of Code\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  42%|████████████████████████▉                                  | 1397/3312 [36:17<51:41,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Fine-Grained Self-Endorsement Improves Factuality and Reasoning\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  42%|████████████████████████▉                                  | 1398/3312 [36:19<50:18,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: MegaScale: Scaling Large Language Model Training to More Than 10,000 GPUs\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  42%|████████████████████████▉                                  | 1399/3312 [36:20<48:15,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Towards Efficient Active Learning in NLP via Pretrained Representations\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  42%|████████████████████████▉                                  | 1400/3312 [36:22<48:26,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Selective \"Selective Prediction\": Reducing Unnecessary Abstention in Vision-Language Reasoning\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  42%|████████████████████████▉                                  | 1401/3312 [36:23<47:12,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Training Nonlinear Transformers for Efficient In-Context Learning: A Theoretical Learning and Generalization Analysis\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  42%|████████████████████████▉                                  | 1402/3312 [36:24<46:23,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Prompting LLMs to Compose Meta-Review Drafts from Peer-Review Narratives of Scholarly Manuscripts\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  42%|████████████████████████▉                                  | 1403/3312 [36:26<48:10,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: DOSA: A Dataset of Social Artifacts from Different Indian Geographical Subcultures\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  42%|█████████████████████████                                  | 1404/3312 [36:27<47:26,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: CI w/o TN: Context Injection without Task Name for Procedure Planning\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  42%|█████████████████████████                                  | 1405/3312 [36:29<47:17,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: AgentOhana: Design Unified Data and Training Pipeline for Effective Agent Learning\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  42%|█████████████████████████                                  | 1406/3312 [36:31<48:18,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Co-Supervised Learning: Improving Weak-to-Strong Generalization with Hierarchical Mixture of Experts\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  42%|█████████████████████████                                  | 1407/3312 [36:32<47:16,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Self-Retrieval: Building an Information Retrieval System with One Large Language Model\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  43%|█████████████████████████                                  | 1408/3312 [36:34<49:47,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: The Good and The Bad: Exploring Privacy Issues in Retrieval-Augmented Generation (RAG)\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  43%|█████████████████████████                                  | 1409/3312 [36:35<48:07,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: API-BLEND: A Comprehensive Corpora for Training and Benchmarking API LLMs\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  43%|█████████████████████████                                  | 1410/3312 [36:37<48:10,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Prejudice and Caprice: A Statistical Framework for Measuring Social Discrimination in Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  43%|█████████████████████████▏                                 | 1411/3312 [36:38<47:16,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Repetition Improves Language Model Embeddings\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  43%|█████████████████████████▏                                 | 1412/3312 [36:40<48:47,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: PREDILECT: Preferences Delineated with Zero-Shot Language-based Reasoning in Reinforcement Learning\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  43%|█████████████████████████▏                                 | 1413/3312 [36:41<47:40,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Explorations of Self-Repair in Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  43%|█████████████████████████▏                                 | 1414/3312 [36:42<46:28,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Safe Task Planning for Language-Instructed Multi-Robot Systems using Conformal Prediction\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  43%|█████████████████████████▏                                 | 1415/3312 [36:44<46:42,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Farsight: Fostering Responsible AI Awareness During AI Application Prototyping\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  43%|█████████████████████████▏                                 | 1416/3312 [36:46<47:34,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Ranking Entities along Conceptual Space Dimensions with LLMs: An Analysis of Fine-Tuning Strategies\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  43%|█████████████████████████▏                                 | 1417/3312 [36:47<48:57,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: GPTVQ: The Blessing of Dimensionality for LLM Quantization\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  43%|█████████████████████████▎                                 | 1418/3312 [36:49<47:32,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ArabianGPT: Native Arabic GPT-based Large Language Model\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  43%|█████████████████████████▎                                 | 1419/3312 [36:50<46:53,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: How (un)ethical are instruction-centric responses of LLMs? Unveiling the vulnerabilities of safety guardrails to harmful queries\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  43%|█████████████████████████▎                                 | 1420/3312 [36:52<47:36,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Causal Graph Discovery with Retrieval-Augmented Generation based Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  43%|█████████████████████████▎                                 | 1421/3312 [36:53<47:52,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: CFIR: Fast and Effective Long-Text To Image Retrieval for Large Corpora\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  43%|█████████████████████████▎                                 | 1422/3312 [36:55<50:02,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: CloChat: Understanding How People Customize, Interact, and Experience Personas in Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  43%|█████████████████████████▎                                 | 1423/3312 [36:56<49:37,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: DEEM: Dynamic Experienced Expert Modeling for Stance Detection\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  43%|█████████████████████████▎                                 | 1424/3312 [36:58<48:20,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Chitchat as Interference: Adding User Backstories to Task-Oriented Dialogues\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  43%|█████████████████████████▍                                 | 1425/3312 [37:00<49:40,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: GPT-HateCheck: Can LLMs Write Better Functional Tests for Hate Speech Detection?\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  43%|█████████████████████████▍                                 | 1426/3312 [37:01<49:56,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ChunkAttention: Efficient Self-Attention with Prefix-Aware KV Cache and Two-Phase Partition\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  43%|█████████████████████████▍                                 | 1427/3312 [37:03<48:15,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Enhancing ICU Patient Recovery: Using LLMs to Assist Nurses in Diary Writing\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  43%|█████████████████████████▍                                 | 1428/3312 [37:04<47:55,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Fine-Grained Detoxification via Instance-Level Prefixes for Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  43%|█████████████████████████▍                                 | 1429/3312 [37:07<56:08,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: DeMPT: Decoding-enhanced Multi-phase Prompt Tuning for Making LLMs Be Better Context-aware Translators\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  43%|█████████████████████████▍                                 | 1430/3312 [37:08<53:47,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: GraphEdit: Large Language Models for Graph Structure Learning\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  43%|█████████████████████████▍                                 | 1431/3312 [37:10<51:20,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Second-Order Fine-Tuning without Pain for LLMs:A Hessian Informed Zeroth-Order Optimizer\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  43%|█████████████████████████▌                                 | 1432/3312 [37:11<51:39,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Machine Unlearning of Pre-trained Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  43%|█████████████████████████▌                                 | 1433/3312 [37:13<50:57,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Where Visual Speech Meets Language: VSP-LLM Framework for Efficient and Context-Aware Visual Speech Processing\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  43%|█████████████████████████▌                                 | 1434/3312 [37:15<53:18,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Interactive-KBQA: Multi-Turn Interactions for Knowledge Base Question Answering with Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  43%|█████████████████████████▌                                 | 1435/3312 [37:17<55:37,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: AgentLite: A Lightweight Library for Building and Advancing Task-Oriented LLM Agent System\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  43%|█████████████████████████▌                                 | 1436/3312 [37:18<52:09,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Fine-tuning CLIP Text Encoders with Two-step Paraphrasing\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  43%|█████████████████████████▌                                 | 1437/3312 [37:20<51:25,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Large Multimodal Agents: A Survey\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  43%|█████████████████████████▌                                 | 1438/3312 [37:21<50:28,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Executing Natural Language-Described Algorithms with Large Language Models: An Investigation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  43%|█████████████████████████▋                                 | 1439/3312 [37:23<52:07,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: A First Look at GPT Apps: Landscape and Vulnerability\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  43%|█████████████████████████▋                                 | 1440/3312 [37:24<50:02,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Studying LLM Performance on Closed- and Open-source Data\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  44%|█████████████████████████▋                                 | 1441/3312 [37:26<47:58,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Evaluating the Performance of ChatGPT for Spam Email Detection\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  44%|█████████████████████████▋                                 | 1442/3312 [37:27<46:56,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: AttributionBench: How Hard is Automatic Attribution Evaluation?\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  44%|█████████████████████████▋                                 | 1443/3312 [37:29<47:24,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Getting Serious about Humor: Crafting Humor Datasets with Unfunny Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  44%|█████████████████████████▋                                 | 1444/3312 [37:30<47:38,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Gotcha! Don't trick me with unanswerable questions! Self-aligning Large Language Models for Responding to Unknown Questions\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  44%|█████████████████████████▋                                 | 1445/3312 [37:32<47:36,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Fine-tuning Large Language Models for Domain-specific Machine Translation\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  44%|█████████████████████████▊                                 | 1446/3312 [37:34<49:19,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: On the Multi-turn Instruction Following for Conversational Web Agents\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  44%|█████████████████████████▊                                 | 1447/3312 [37:35<47:25,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ToMBench: Benchmarking Theory of Mind in Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  44%|█████████████████████████▊                                 | 1448/3312 [37:37<47:36,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Unlocking the Power of Large Language Models for Entity Alignment\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  44%|█████████████████████████▊                                 | 1449/3312 [37:38<46:50,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: KIEval: A Knowledge-grounded Interactive Evaluation Framework for Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  44%|█████████████████████████▊                                 | 1450/3312 [37:39<46:05,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: CLoVe: Encoding Compositional Language in Contrastive Vision-Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  44%|█████████████████████████▊                                 | 1451/3312 [37:41<48:25,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Unintended Impacts of LLM Alignment on Global Representation\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  44%|█████████████████████████▊                                 | 1452/3312 [37:43<47:56,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Divide-or-Conquer? Which Part Should You Distill Your LLM?\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  44%|█████████████████████████▉                                 | 1453/3312 [37:44<47:34,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: tinyBenchmarks: evaluating LLMs with fewer examples\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  44%|█████████████████████████▉                                 | 1454/3312 [37:46<46:17,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Optimizing Language Models for Human Preferences is a Causal Inference Problem\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  44%|█████████████████████████▉                                 | 1455/3312 [37:47<48:32,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: AI-Augmented Brainwriting: Investigating the use of LLMs in group ideation\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  44%|█████████████████████████▉                                 | 1456/3312 [37:49<47:06,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: GenCeption: Evaluate Multimodal LLMs with Unlabeled Unimodal Data\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  44%|█████████████████████████▉                                 | 1457/3312 [37:51<49:37,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Mitigating Fine-tuning Jailbreak Attack with Backdoor Enhanced Alignment\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  44%|█████████████████████████▉                                 | 1458/3312 [37:52<47:36,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Mirror: A Multiple-perspective Self-Reflection Method for Knowledge-rich Reasoning\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  44%|█████████████████████████▉                                 | 1459/3312 [37:53<46:48,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: CriticBench: Benchmarking LLMs for Critique-Correct Reasoning\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  44%|██████████████████████████                                 | 1460/3312 [37:55<45:31,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: MobileLLM: Optimizing Sub-billion Parameter Language Models for On-Device Use Cases\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  44%|██████████████████████████                                 | 1461/3312 [37:57<49:38,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: RelayAttention for Efficient Large Language Model Serving with Long System Prompts\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  44%|██████████████████████████                                 | 1462/3312 [37:58<51:40,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Identifying Multiple Personalities in Large Language Models with External Evaluation\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  44%|██████████████████████████                                 | 1463/3312 [38:00<49:10,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Not All Experts are Equal: Efficient Expert Pruning and Skipping for Mixture-of-Experts Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  44%|██████████████████████████                                 | 1464/3312 [38:02<51:36,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Watermarking Makes Language Models Radioactive\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  44%|██████████████████████████                                 | 1465/3312 [38:03<51:29,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Zero-shot cross-lingual transfer in instruction tuning of large language model\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  44%|██████████████████████████                                 | 1466/3312 [38:05<49:09,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: DualFocus: Integrating Macro and Micro Perspectives in Multi-modal Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  44%|██████████████████████████▏                                | 1467/3312 [38:06<47:28,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: MT-Bench-101: A Fine-Grained Benchmark for Evaluating Large Language Models in Multi-Turn Dialogues\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  44%|██████████████████████████▏                                | 1468/3312 [38:08<48:15,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Generalizing Reward Modeling for Out-of-Distribution Preference Learning\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  44%|██████████████████████████▏                                | 1469/3312 [38:09<47:14,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Tokenization counts: the impact of tokenization on arithmetic in frontier LLMs\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  44%|██████████████████████████▏                                | 1470/3312 [38:11<46:22,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Scaling Efficient LLMs\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  44%|██████████████████████████▏                                | 1471/3312 [38:12<45:23,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Large Language Models as Urban Residents: An LLM Agent Framework for Personal Mobility Generation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  44%|██████████████████████████▏                                | 1472/3312 [38:14<48:43,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Back to Basics: Revisiting REINFORCE Style Optimization for Learning from Human Feedback in LLMs\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  44%|██████████████████████████▏                                | 1473/3312 [38:16<49:56,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Stop Reasoning! When Multimodal LLMs with Chain-of-Thought Reasoning Meets Adversarial Images\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  45%|██████████████████████████▎                                | 1474/3312 [38:17<48:09,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Chain-of-Thought Unfaithfulness as Disguised Accuracy\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  45%|██████████████████████████▎                                | 1475/3312 [38:19<46:13,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: IEPile: Unearthing Large-Scale Schema-Based Information Extraction Corpus\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  45%|██████████████████████████▎                                | 1476/3312 [38:20<45:25,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: An LLM-Enhanced Adversarial Editing System for Lexical Simplification\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  45%|██████████████████████████▎                                | 1477/3312 [38:21<45:26,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Unveiling Linguistic Regions in Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  45%|██████████████████████████▎                                | 1478/3312 [38:23<45:47,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: UFO: a Unified and Flexible Framework for Evaluating Factuality of Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  45%|██████████████████████████▎                                | 1479/3312 [38:25<46:07,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Visual Hallucinations of Multi-modal Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  45%|██████████████████████████▎                                | 1480/3312 [38:26<45:49,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Is Cognition and Action Consistent or Not: Investigating Large Language Model's Personality\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  45%|██████████████████████████▍                                | 1481/3312 [38:27<44:50,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ConceptMath: A Bilingual Concept-wise Benchmark for Measuring Mathematical Reasoning of Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  45%|██████████████████████████▍                                | 1482/3312 [38:29<44:51,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: OpenCodeInterpreter: Integrating Code Generation with Execution and Refinement\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  45%|██████████████████████████▍                                | 1483/3312 [38:31<49:09,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LLM-DA: Data Augmentation via Large Language Models for Few-Shot Named Entity Recognition\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  45%|██████████████████████████▍                                | 1484/3312 [38:32<47:44,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LLMs with Industrial Lens: Deciphering the Challenges and Prospects -- A Survey\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  45%|██████████████████████████▍                                | 1485/3312 [38:34<45:59,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Whose LLM is it Anyway? Linguistic Comparison and LLM Attribution for GPT-3.5, GPT-4 and Bard\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  45%|██████████████████████████▍                                | 1486/3312 [38:35<45:29,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Should We Respect LLMs? A Cross-Lingual Study on the Influence of Prompt Politeness on LLM Performance\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  45%|██████████████████████████▍                                | 1487/3312 [38:37<44:19,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Balanced Data Sampling for Language Model Training with Clustering\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  45%|██████████████████████████▌                                | 1488/3312 [38:38<44:32,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Towards Unified Task Embeddings Across Multiple Models: Bridging the Gap for Prompt-Based Large Language Models and Beyond\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  45%|██████████████████████████▌                                | 1489/3312 [38:39<44:47,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: \"My Answer is C\": First-Token Probabilities Do Not Match Text Answers in Instruction-Tuned Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  45%|██████████████████████████▌                                | 1490/3312 [38:41<45:51,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LLMBind: A Unified Modality-Task Integration Framework\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  45%|██████████████████████████▌                                | 1491/3312 [38:43<47:20,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Is ChatGPT the Future of Causal Text Mining? A Comprehensive Evaluation and Analysis\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  45%|██████████████████████████▌                                | 1492/3312 [38:44<47:47,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Do LLMs Implicitly Determine the Suitable Text Difficulty for Users?\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  45%|██████████████████████████▌                                | 1493/3312 [38:46<47:29,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: COBIAS: Contextual Reliability in Bias Assessment\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  45%|██████████████████████████▌                                | 1494/3312 [38:47<46:08,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Automating Psychological Hypothesis Generation with AI: Large Language Models Meet Causal Graph\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  45%|██████████████████████████▋                                | 1495/3312 [38:49<45:28,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Uncertainty-Aware Evaluation for Vision-Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  45%|██████████████████████████▋                                | 1496/3312 [38:50<45:35,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Transferring BERT Capabilities from High-Resource to Low-Resource Languages Using Vocabulary Matching\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  45%|██████████████████████████▋                                | 1497/3312 [38:52<47:13,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Enhancing Temporal Knowledge Graph Forecasting with Large Language Models via Chain-of-History Reasoning\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  45%|██████████████████████████▋                                | 1498/3312 [38:54<46:50,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Small Language Model Is a Good Guide for Large Language Model in Chinese Entity Relation Extraction\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  45%|██████████████████████████▋                                | 1499/3312 [38:55<46:03,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: OpenTab: Advancing Large Language Models as Open-domain Table Reasoners\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  45%|██████████████████████████▋                                | 1500/3312 [38:56<45:47,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Rethinking Scientific Summarization Evaluation: Grounding Explainable Metrics on Facet-aware Benchmark\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  45%|██████████████████████████▋                                | 1501/3312 [38:58<45:03,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Rule or Story, Which is a Better Commonsense Expression for Talking with Large Language Models?\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  45%|██████████████████████████▊                                | 1502/3312 [38:59<44:47,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: INSTRUCTIR: A Benchmark for Instruction Following of Information Retrieval Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  45%|██████████████████████████▊                                | 1503/3312 [39:01<44:00,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Understanding and Patching Compositional Reasoning in LLMs\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  45%|██████████████████████████▊                                | 1504/3312 [39:02<45:14,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Triad: A Framework Leveraging a Multi-Role LLM-based Agent to Solve Knowledge Base Question Answering\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  45%|██████████████████████████▊                                | 1505/3312 [39:04<47:28,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Hint-before-Solving Prompting: Guiding LLMs to Effectively Utilize Encoded Knowledge\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  45%|██████████████████████████▊                                | 1506/3312 [39:06<46:02,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Mitigating Biases of Large Language Models in Stance Detection with Calibration\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  46%|██████████████████████████▊                                | 1507/3312 [39:07<45:04,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Leveraging Large Language Models for Concept Graph Recovery and Question Answering in NLP Education\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  46%|██████████████████████████▊                                | 1508/3312 [39:08<44:25,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: CEV-LM: Controlled Edit Vector Language Model for Shaping Natural Language Generations\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  46%|██████████████████████████▉                                | 1509/3312 [39:10<45:58,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Double-I Watermark: Protecting Model Copyright for LLM Fine-tuning\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  46%|██████████████████████████▉                                | 1510/3312 [39:11<44:43,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Can Language Models Act as Knowledge Bases at Scale?\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  46%|██████████████████████████▉                                | 1511/3312 [39:13<47:37,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Qsnail: A Questionnaire Dataset for Sequential Question Generation\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  46%|██████████████████████████▉                                | 1512/3312 [39:15<48:40,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Take the Bull by the Horns: Hard Sample-Reweighted Continual Training Improves LLM Generalization\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  46%|██████████████████████████▉                                | 1513/3312 [39:16<46:29,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Can Large Language Models Detect Misinformation in Scientific News Reporting?\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  46%|██████████████████████████▉                                | 1514/3312 [39:18<45:24,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Copilot Evaluation Harness: Evaluating LLM-Guided Software Programming\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  46%|██████████████████████████▉                                | 1515/3312 [39:19<45:29,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Word-Sequence Entropy: Towards Uncertainty Estimation in Free-Form Medical Question Answering Applications and Beyond\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  46%|███████████████████████████                                | 1516/3312 [39:21<47:43,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Eagle: Ethical Dataset Given from Real Interactions\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  46%|███████████████████████████                                | 1517/3312 [39:23<47:17,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Enhancing Robotic Manipulation with AI Feedback from Multimodal Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  46%|███████████████████████████                                | 1518/3312 [39:24<45:37,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: COPR: Continual Human Preference Learning via Optimal Policy Regularization\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  46%|███████████████████████████                                | 1519/3312 [39:26<46:11,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Content Conditional Debiasing for Fair Text Embedding\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  46%|███████████████████████████                                | 1520/3312 [39:27<46:23,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Assisting in Writing Wikipedia-like Articles From Scratch with Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  46%|███████████████████████████                                | 1521/3312 [39:29<45:42,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Towards Understanding Counseling Conversations: Domain Knowledge and Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  46%|███████████████████████████                                | 1522/3312 [39:30<45:31,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Learning to Reduce: Optimal Representations of Structured Data in Prompting Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  46%|███████████████████████████▏                               | 1523/3312 [39:32<47:39,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Do Machines and Humans Focus on Similar Code? Exploring Explainability of Large Language Models in Code Summarization\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  46%|███████████████████████████▏                               | 1524/3312 [39:34<48:05,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Understanding the Dataset Practitioners Behind Large Language Model Development\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  46%|███████████████████████████▏                               | 1525/3312 [39:35<46:14,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Bangla AI: A Framework for Machine Translation Utilizing Large Language Models for Ethnic Media\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  46%|███████████████████████████▏                               | 1526/3312 [39:37<45:29,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Recursive Speculative Decoding: Accelerating LLM Inference via Sampling Without Replacement\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  46%|███████████████████████████▏                               | 1527/3312 [39:38<45:38,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: TOOLVERIFIER: Generalization to New Tools via Self-Verification\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  46%|███████████████████████████▏                               | 1528/3312 [39:40<45:58,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Automatic Histograms: Leveraging Language Models for Text Dataset Exploration\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  46%|███████████████████████████▏                               | 1529/3312 [39:41<45:37,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: MM-Soc: Benchmarking Multimodal Large Language Models in Social Media Platforms\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  46%|███████████████████████████▎                               | 1530/3312 [39:43<45:04,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: BIRCO: A Benchmark of Information Retrieval Tasks with Complex Objectives\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  46%|███████████████████████████▎                               | 1531/3312 [39:44<43:55,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Driving Generative Agents With Their Personality\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  46%|███████████████████████████▎                               | 1532/3312 [39:46<45:49,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: FanOutQA: Multi-Hop, Multi-Document Question Answering for Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  46%|███████████████████████████▎                               | 1533/3312 [39:47<44:36,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: EXACT-Net:EHR-guided lung tumor auto-segmentation for non-small cell lung cancer radiotherapy\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  46%|███████████████████████████▎                               | 1534/3312 [39:49<48:50,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Diet-ODIN: A Novel Framework for Opioid Misuse Detection with Interpretable Dietary Patterns\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  46%|███████████████████████████▎                               | 1535/3312 [39:50<46:22,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Coercing LLMs to do and reveal (almost) anything\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  46%|███████████████████████████▎                               | 1536/3312 [39:52<46:26,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Is LLM-as-a-Judge Robust? Investigating Universal Adversarial Attacks on Zero-shot LLM Assessment\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  46%|███████████████████████████▍                               | 1537/3312 [39:53<44:30,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: OlympiadBench: A Challenging Benchmark for Promoting AGI with Olympiad-Level Bilingual Multimodal Scientific Problems\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  46%|███████████████████████████▍                               | 1538/3312 [39:55<44:55,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Can Watermarks Survive Translation? On the Cross-lingual Consistency of Text Watermark for Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  46%|███████████████████████████▍                               | 1539/3312 [39:56<44:15,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Hallucinations or Attention Misdirection? The Path to Strategic Value Extraction in Business Using Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  46%|███████████████████████████▍                               | 1540/3312 [39:58<43:17,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: What's in a Name? Auditing Large Language Models for Race and Gender Bias\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  47%|███████████████████████████▍                               | 1541/3312 [39:59<44:18,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Analysing The Impact of Sequence Composition on Language Model Pre-Training\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  47%|███████████████████████████▍                               | 1542/3312 [40:01<44:44,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Making Reasoning Matter: Measuring and Improving Faithfulness of Chain-of-Thought Reasoning\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  47%|███████████████████████████▍                               | 1543/3312 [40:02<44:08,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Distillation Contrastive Decoding: Improving LLMs Reasoning with Contrastive Decoding and Distillation\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  47%|███████████████████████████▌                               | 1544/3312 [40:04<43:02,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Large Language Models are Vulnerable to Bait-and-Switch Attacks for Generating Harmful Content\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  47%|███████████████████████████▌                               | 1545/3312 [40:05<42:36,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Exploring ChatGPT and its Impact on Society\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  47%|███████████████████████████▌                               | 1546/3312 [40:07<44:20,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: SYNFAC-EDIT: Synthetic Imitation Edit Feedback for Factual Alignment in Clinical Summarization\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  47%|███████████████████████████▌                               | 1547/3312 [40:08<44:56,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Could We Have Had Better Multilingual LLMs If English Was Not the Central Language?\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  47%|███████████████████████████▌                               | 1548/3312 [40:10<46:15,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Calibrating Large Language Models with Sample Consistency\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  47%|███████████████████████████▌                               | 1549/3312 [40:12<45:59,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Beyond Probabilities: Unveiling the Misalignment in Evaluating Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  47%|███████████████████████████▌                               | 1550/3312 [40:13<44:30,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: $Se^2$: Sequential Example Selection for In-Context Learning\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  47%|███████████████████████████▋                               | 1551/3312 [40:14<43:27,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: An Explainable Transformer-based Model for Phishing Email Detection: A Large Language Model Approach\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  47%|███████████████████████████▋                               | 1552/3312 [40:16<44:35,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Kuaiji: the First Chinese Accounting Large Language Model\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  47%|███████████████████████████▋                               | 1553/3312 [40:18<44:44,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Semantic Mirror Jailbreak: Genetic Algorithm Based Jailbreak Prompts Against Open-source LLMs\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  47%|███████████████████████████▋                               | 1554/3312 [40:19<44:46,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Large Language Models are Advanced Anonymizers\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  47%|███████████████████████████▋                               | 1555/3312 [40:21<44:45,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LLM4SBR: A Lightweight and Effective Framework for Integrating Large Language Models in Session-based Recommendation\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  47%|███████████████████████████▋                               | 1556/3312 [40:22<45:16,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Beyond Hate Speech: NLP's Challenges and Opportunities in Uncovering Dehumanizing Language\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  47%|███████████████████████████▋                               | 1557/3312 [40:24<43:46,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LLM Based Multi-Agent Generation of Semi-structured Documents from Semantic Templates in the Public Administration Domain\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  47%|███████████████████████████▊                               | 1558/3312 [40:25<42:43,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: CriticBench: Evaluating Large Language Models as Critic\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  47%|███████████████████████████▊                               | 1559/3312 [40:26<42:16,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Factual Consistency Evaluation of Summarisation in the Era of Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  47%|███████████████████████████▊                               | 1560/3312 [40:28<41:45,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LongRoPE: Extending LLM Context Window Beyond 2 Million Tokens\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  47%|███████████████████████████▊                               | 1561/3312 [40:29<42:06,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Breaking the Barrier: Utilizing Large Language Models for Industrial Recommendation Systems through an Inferential Knowledge Graph\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  47%|███████████████████████████▊                               | 1562/3312 [40:31<41:50,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Unlocking Instructive In-Context Learning with Tabular Prompting for Relational Triple Extraction\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  47%|███████████████████████████▊                               | 1563/3312 [40:32<41:21,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: From Text to CQL: Bridging Natural Language and Corpus Search Engine\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  47%|███████████████████████████▊                               | 1564/3312 [40:33<41:07,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Ouroboros: Speculative Decoding with Large Model Enhanced Drafting\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  47%|███████████████████████████▉                               | 1565/3312 [40:35<42:54,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: $\\infty$Bench: Extending Long Context Evaluation Beyond 100K Tokens\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  47%|███████████████████████████▉                               | 1566/3312 [40:37<43:02,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Neeko: Leveraging Dynamic LoRA for Efficient Multi-Character Role-Playing Agent\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  47%|███████████████████████████▉                               | 1567/3312 [40:38<43:54,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: An Evaluation of Large Language Models in Bioinformatics Research\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  47%|███████████████████████████▉                               | 1568/3312 [40:40<44:18,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: SaGE: Evaluating Moral Consistency in Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  47%|███████████████████████████▉                               | 1569/3312 [40:41<44:27,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Investigating Multilingual Instruction-Tuning: Do Polyglot Models Demand for Multilingual Instructions?\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  47%|███████████████████████████▉                               | 1570/3312 [40:43<44:02,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: KInIT at SemEval-2024 Task 8: Fine-tuned LLMs for Multilingual Machine-Generated Text Detection\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  47%|███████████████████████████▉                               | 1571/3312 [40:44<42:47,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Self-Distillation Bridges Distribution Gap in Language Model Fine-Tuning\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  47%|████████████████████████████                               | 1572/3312 [40:46<44:27,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: GCOF: Self-iterative Text Generation for Copywriting Using Large Language Model\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  47%|████████████████████████████                               | 1573/3312 [40:47<43:25,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Privacy-Preserving Instructions for Aligning Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  48%|████████████████████████████                               | 1574/3312 [40:49<43:12,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Unsupervised Text Style Transfer via LLMs and Attention Masking with Multi-way Interactions\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  48%|████████████████████████████                               | 1575/3312 [40:50<42:50,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: UniGraph: Learning a Cross-Domain Graph Foundation Model From Natural Language\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  48%|████████████████████████████                               | 1576/3312 [40:52<45:50,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: FLAME: Self-Supervised Low-Resource Taxonomy Expansion using Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  48%|████████████████████████████                               | 1577/3312 [40:53<45:11,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Data-driven Discovery with Large Generative Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  48%|████████████████████████████                               | 1578/3312 [40:55<43:43,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: CODIS: Benchmarking Context-Dependent Visual Comprehension for Multimodal Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  48%|████████████████████████████▏                              | 1579/3312 [40:56<43:43,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: A Comprehensive Study of Multilingual Confidence Estimation on Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  48%|████████████████████████████▏                              | 1580/3312 [40:58<42:46,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: KorNAT: LLM Alignment Benchmark for Korean Social Values and Common Knowledge\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  48%|████████████████████████████▏                              | 1581/3312 [40:59<42:36,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Hybrid Reasoning Based on Large Language Models for Autonomous Car Driving\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  48%|████████████████████████████▏                              | 1582/3312 [41:01<42:03,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: User-LLM: Efficient LLM Contextualization with User Embeddings\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  48%|████████████████████████████▏                              | 1583/3312 [41:02<42:01,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Knowledge Graph Enhanced Large Language Model Editing\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  48%|████████████████████████████▏                              | 1584/3312 [41:04<42:08,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: APTQ: Attention-aware Post-Training Mixed-Precision Quantization for Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  48%|████████████████████████████▏                              | 1585/3312 [41:05<41:43,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: A Multimodal In-Context Tuning Approach for E-Commerce Product Description Generation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  48%|████████████████████████████▎                              | 1586/3312 [41:06<41:59,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: WinoViz: Probing Visual Properties of Objects Under Different States\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  48%|████████████████████████████▎                              | 1587/3312 [41:08<41:52,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: BBA: Bi-Modal Behavioral Alignment for Reasoning with Large Vision-Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  48%|████████████████████████████▎                              | 1588/3312 [41:09<41:14,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: DyVal 2: Dynamic Evaluation of Large Language Models by Meta Probing Agents\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  48%|████████████████████████████▎                              | 1589/3312 [41:11<40:56,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Cognitive Visual-Language Mapper: Advancing Multimodal Comprehension with Enhanced Visual Knowledge Alignment\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  48%|████████████████████████████▎                              | 1590/3312 [41:13<44:13,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Are LLMs Effective Negotiators? Systematic Evaluation of the Multifaceted Capabilities of LLMs in Negotiation Dialogues\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  48%|████████████████████████████▎                              | 1591/3312 [41:14<42:57,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ActiveRAG: Revealing the Treasures of Knowledge via Active Learning\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  48%|████████████████████████████▎                              | 1592/3312 [41:15<42:06,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LLMs Meet Long Video: Advancing Long Video Comprehension with An Interactive Visual Adapter in LLMs\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  48%|████████████████████████████▍                              | 1593/3312 [41:17<41:31,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ARL2: Aligning Retrievers for Black-box Large Language Models via Self-guided Adaptive Relevance Labeling\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  48%|████████████████████████████▍                              | 1594/3312 [41:18<43:05,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Exploring the Limits of Semantic Image Compression at Micro-bits per Pixel\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  48%|████████████████████████████▍                              | 1595/3312 [41:20<43:25,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: FinGPT-HPC: Efficient Pretraining and Finetuning Large Language Models for Financial Applications with High-Performance Computing\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  48%|████████████████████████████▍                              | 1596/3312 [41:21<43:34,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: OMGEval: An Open Multilingual Generative Evaluation Benchmark for Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  48%|████████████████████████████▍                              | 1597/3312 [41:23<43:45,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: AgentScope: A Flexible yet Robust Multi-Agent Platform\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  48%|████████████████████████████▍                              | 1598/3312 [41:24<43:04,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: RITFIS: Robust input testing framework for LLMs-based intelligent software\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  48%|████████████████████████████▍                              | 1599/3312 [41:26<42:23,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Round Trip Translation Defence against Large Language Model Jailbreaking Attacks\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  48%|████████████████████████████▌                              | 1600/3312 [41:27<42:15,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ProSparse: Introducing and Enhancing Intrinsic Activation Sparsity within Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  48%|████████████████████████████▌                              | 1601/3312 [41:29<42:53,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: From Self-Attention to Markov Models: Unveiling the Dynamics of Generative Transformers\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  48%|████████████████████████████▌                              | 1602/3312 [41:30<42:34,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: The Lay Person's Guide to Biomedicine: Orchestrating Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  48%|████████████████████████████▌                              | 1603/3312 [41:32<42:10,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: GradSafe: Detecting Unsafe Prompts for LLMs via Safety-Critical Gradient Analysis\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  48%|████████████████████████████▌                              | 1604/3312 [41:33<42:44,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Retrieval Helps or Hurts? A Deeper Dive into the Efficacy of Retrieval Augmentation to Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  48%|████████████████████████████▌                              | 1605/3312 [41:35<42:16,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ProPD: Dynamic Token Tree Pruning and Generation for LLM Parallel Decoding\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  48%|████████████████████████████▌                              | 1606/3312 [41:36<41:19,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Retrieval-Augmented Data Augmentation for Low-Resource Domain Tasks\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  49%|████████████████████████████▋                              | 1607/3312 [41:38<45:07,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: STENCIL: Submodular Mutual Information Based Weak Supervision for Cold-Start Active Learning\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  49%|████████████████████████████▋                              | 1608/3312 [41:40<48:19,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: RefuteBench: Evaluating Refuting Instruction-Following for Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  49%|████████████████████████████▋                              | 1609/3312 [41:42<46:00,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Potential and Challenges of Model Editing for Social Debiasing\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  49%|████████████████████████████▋                              | 1610/3312 [41:43<46:02,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Learning to Poison Large Language Models During Instruction Tuning\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  49%|████████████████████████████▋                              | 1611/3312 [41:45<45:17,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LLM Jailbreak Attack versus Defense Techniques -- A Comprehensive Study\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  49%|████████████████████████████▋                              | 1612/3312 [41:46<44:30,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: CAMELoT: Towards Large Language Models with Training-Free Consolidated Associative Memory\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  49%|████████████████████████████▋                              | 1613/3312 [41:48<43:17,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Ranking Large Language Models without Ground Truth\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  49%|████████████████████████████▊                              | 1614/3312 [41:49<43:38,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Large Language Models for Data Annotation: A Survey\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  49%|████████████████████████████▊                              | 1615/3312 [41:51<43:30,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: DrBenchmark: A Large Language Understanding Evaluation Benchmark for French Biomedical Domain\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  49%|████████████████████████████▊                              | 1616/3312 [41:52<43:23,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Explaining Relationships Among Research Papers\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  49%|████████████████████████████▊                              | 1617/3312 [41:54<45:15,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: The Wolf Within: Covert Injection of Malice into MLLM Societies via an MLLM Operative\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  49%|████████████████████████████▊                              | 1618/3312 [41:56<45:25,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Structure Guided Prompt: Instructing Large Language Model in Multi-Step Reasoning by Exploring Graph Structure of the Text\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  49%|████████████████████████████▊                              | 1619/3312 [41:57<44:54,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Harnessing Large Language Models as Post-hoc Correctors\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  49%|████████████████████████████▊                              | 1620/3312 [41:59<44:17,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Reliable LLM-based User Simulator for Task-Oriented Dialogue Systems\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  49%|████████████████████████████▉                              | 1621/3312 [42:00<42:57,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: EvoGrad: A Dynamic Take on the Winograd Schema Challenge with Human Adversaries\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  49%|████████████████████████████▉                              | 1622/3312 [42:02<42:05,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ChatEL: Entity Linking with Chatbots\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  49%|████████████████████████████▉                              | 1623/3312 [42:03<44:17,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: A Simple but Effective Approach to Improve Structured Language Model Output for Information Extraction\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  49%|████████████████████████████▉                              | 1624/3312 [42:05<44:01,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: TofuEval: Evaluating Hallucinations of LLMs on Topic-Focused Dialogue Summarization\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  49%|████████████████████████████▉                              | 1625/3312 [42:06<42:34,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Investigating Cultural Alignment of Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  49%|████████████████████████████▉                              | 1626/3312 [42:08<43:25,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Smaug: Fixing Failure Modes of Preference Optimisation with DPO-Positive\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  49%|████████████████████████████▉                              | 1627/3312 [42:09<43:52,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: RoCode: A Dataset for Measuring Code Intelligence from Problem Definitions in Romanian\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  49%|█████████████████████████████                              | 1628/3312 [42:11<43:35,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: How Easy is It to Fool Your Multimodal LLMs? An Empirical Analysis on Deceptive Prompts\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  49%|█████████████████████████████                              | 1629/3312 [42:12<42:57,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Soft Self-Consistency Improves Language Model Agents\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  49%|█████████████████████████████                              | 1630/3312 [42:14<42:06,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Can Large Language Models be Good Emotional Supporter? Mitigating Preference Bias on Emotional Support Conversation\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  49%|█████████████████████████████                              | 1631/3312 [42:16<43:36,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Bayesian Reward Models for LLM Alignment\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  49%|█████████████████████████████                              | 1632/3312 [42:17<42:57,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Benchmarking Retrieval-Augmented Generation for Medicine\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  49%|█████████████████████████████                              | 1633/3312 [42:19<42:44,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Is the System Message Really Important to Jailbreaks in Large Language Models?\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  49%|█████████████████████████████                              | 1634/3312 [42:20<41:57,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Defending Jailbreak Prompts via In-Context Adversarial Game\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  49%|█████████████████████████████▏                             | 1635/3312 [42:22<41:45,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Are ELECTRA's Sentence Embeddings Beyond Repair? The Case of Semantic Textual Similarity\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  49%|█████████████████████████████▏                             | 1636/3312 [42:23<43:13,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: TreeEval: Benchmark-Free Evaluation of Large Language Models through Tree Planning\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  49%|█████████████████████████████▏                             | 1637/3312 [42:25<42:42,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: CIF-Bench: A Chinese Instruction-Following Benchmark for Evaluating the Generalizability of Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  49%|█████████████████████████████▏                             | 1638/3312 [42:26<43:18,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ELAD: Explanation-Guided Large Language Models Active Distillation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  49%|█████████████████████████████▏                             | 1639/3312 [42:28<42:08,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Event-level Knowledge Editing\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  50%|█████████████████████████████▏                             | 1640/3312 [42:29<42:09,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Slot-VLM: SlowFast Slots for Video-Language Modeling\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  50%|█████████████████████████████▏                             | 1641/3312 [42:31<41:24,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Identifying Semantic Induction Heads to Understand In-Context Learning\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  50%|█████████████████████████████▎                             | 1642/3312 [42:32<40:42,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Stable Knowledge Editing in Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  50%|█████████████████████████████▎                             | 1643/3312 [42:34<47:27,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Effective and Efficient Conversation Retrieval for Dialogue State Tracking with Implicit Text Summaries\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  50%|█████████████████████████████▎                             | 1644/3312 [42:37<51:34,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Text-Guided Molecule Generation with Diffusion Language Model\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  50%|█████████████████████████████▎                             | 1645/3312 [42:39<53:32,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: SiLLM: Large Language Models for Simultaneous Machine Translation\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  50%|█████████████████████████████▎                             | 1646/3312 [42:41<54:09,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Learning to Check: Unleashing Potentials for Self-Correction in Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  50%|█████████████████████████████▎                             | 1647/3312 [42:42<52:58,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: SoMeLVLM: A Large Vision Language Model for Social Media Processing\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  50%|█████████████████████████████▎                             | 1648/3312 [42:44<48:33,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Understanding the effects of language-specific class imbalance in multilingual fine-tuning\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  50%|█████████████████████████████▍                             | 1649/3312 [42:45<45:48,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Code Needs Comments: Enhancing Code LLMs with Comment Augmentation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  50%|█████████████████████████████▍                             | 1650/3312 [42:47<43:45,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: An Autonomous Large Language Model Agent for Chemical Literature Data Mining\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  50%|█████████████████████████████▍                             | 1651/3312 [42:48<43:23,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: TRAP: Targeted Random Adversarial Prompt Honeypot for Black-Box Identification\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  50%|█████████████████████████████▍                             | 1652/3312 [42:50<41:42,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Can GNN be Good Adapter for LLMs?\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  50%|█████████████████████████████▍                             | 1653/3312 [42:51<42:53,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Comparing Inferential Strategies of Humans and Large Language Models in Deductive Reasoning\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  50%|█████████████████████████████▍                             | 1654/3312 [42:53<41:31,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: GlórIA -- A Generative and Open Large Language Model for Portuguese\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  50%|█████████████████████████████▍                             | 1655/3312 [42:54<40:33,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Prompt Stealing Attacks Against Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  50%|█████████████████████████████▌                             | 1656/3312 [42:56<41:32,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: GumbelSoft: Diversified Language Model Watermarking via the GumbelMax-trick\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  50%|█████████████████████████████▌                             | 1657/3312 [42:57<43:05,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: A Literature Review of Literature Reviews in Pattern Analysis and Machine Intelligence\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  50%|█████████████████████████████▌                             | 1658/3312 [42:59<42:00,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Large Language Model-based Human-Agent Collaboration for Complex Task Solving\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  50%|█████████████████████████████▌                             | 1659/3312 [43:00<40:44,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: OPDAI at SemEval-2024 Task 6: Small LLMs can Accelerate Hallucination Detection with Weakly Supervised Data\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  50%|█████████████████████████████▌                             | 1660/3312 [43:02<41:05,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Chain of Thought Empowers Transformers to Solve Inherently Serial Problems\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  50%|█████████████████████████████▌                             | 1661/3312 [43:03<40:41,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Exploring the Impact of Table-to-Text Methods on Augmenting LLM-based Question Answering with Domain Hybrid Data\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  50%|█████████████████████████████▌                             | 1662/3312 [43:04<40:05,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: MoELoRA: Contrastive Learning Guided Mixture of Experts on Parameter-Efficient Fine-Tuning for Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  50%|█████████████████████████████▌                             | 1663/3312 [43:06<40:25,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Instruction-tuned Language Models are Better Knowledge Learners\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  50%|█████████████████████████████▋                             | 1664/3312 [43:08<41:24,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: PromptKD: Distilling Student-Friendly Knowledge for Generative Language Models via Prompt Tuning\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  50%|█████████████████████████████▋                             | 1665/3312 [43:09<41:27,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: PANDA: Preference Adaptation for Enhancing Domain-Specific Abilities of LLMs\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  50%|█████████████████████████████▋                             | 1666/3312 [43:11<45:04,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Identifying Factual Inconsistency in Summaries: Towards Effective Utilization of Large Language Model\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  50%|█████████████████████████████▋                             | 1667/3312 [43:12<43:00,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Fine-Tuning, Prompting, In-Context Learning and Instruction-Tuning: How Many Labelled Samples Do We Need?\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  50%|█████████████████████████████▋                             | 1668/3312 [43:14<41:43,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: SymBa: Symbolic Backward Chaining for Multi-step Natural Language Reasoning\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  50%|█████████████████████████████▋                             | 1669/3312 [43:15<40:53,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Few shot clinical entity recognition in three languages: Masked language models outperform LLM prompting\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  50%|█████████████████████████████▋                             | 1670/3312 [43:17<41:04,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Chain-of-Specificity: An Iteratively Refining Method for Eliciting Knowledge from Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  50%|█████████████████████████████▊                             | 1671/3312 [43:18<40:41,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Advancing Large Language Models to Capture Varied Speaking Styles and Respond Properly in Spoken Conversations\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  50%|█████████████████████████████▊                             | 1672/3312 [43:20<39:39,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Me LLaMA: Foundation Large Language Models for Medical Applications\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  51%|█████████████████████████████▊                             | 1673/3312 [43:21<39:13,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: An LLM Maturity Model for Reliable and Transparent Text-to-Query\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  51%|█████████████████████████████▊                             | 1674/3312 [43:22<39:15,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: MuLan: Multimodal-LLM Agent for Progressive Multi-Object Diffusion\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  51%|█████████████████████████████▊                             | 1675/3312 [43:24<39:41,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Can Large Language Models be Used to Provide Psychological Counselling? An Analysis of GPT-4-Generated Responses Using Role-play Dialogues\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  51%|█████████████████████████████▊                             | 1676/3312 [43:25<39:23,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Modality-Aware Integration with Large Language Models for Knowledge-based Visual Question Answering\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  51%|█████████████████████████████▊                             | 1677/3312 [43:27<41:01,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Are Large Language Models Rational Investors?\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  51%|█████████████████████████████▉                             | 1678/3312 [43:29<40:58,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Thermometer: Towards Universal Calibration for Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  51%|█████████████████████████████▉                             | 1679/3312 [43:30<42:12,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: SQL-CRAFT: Text-to-SQL through Interactive Refinement and Enhanced Reasoning\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  51%|█████████████████████████████▉                             | 1680/3312 [43:32<42:18,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: FormulaQA: A Question Answering Dataset for Formula-Based Numerical Reasoning\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  51%|█████████████████████████████▉                             | 1681/3312 [43:33<42:04,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: The FinBen: An Holistic Financial Benchmark for Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  51%|█████████████████████████████▉                             | 1682/3312 [43:35<41:21,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: CHATATC: Large Language Model-Driven Conversational Agents for Supporting Strategic Air Traffic Flow Management\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  51%|█████████████████████████████▉                             | 1683/3312 [43:36<41:49,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Bias in Language Models: Beyond Trick Tests and Toward RUTEd Evaluation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  51%|█████████████████████████████▉                             | 1684/3312 [43:38<41:24,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Multimodal Fusion of EHR in Structures and Semantics: Integrating Clinical Records and Notes with Hypergraph and LLM\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  51%|██████████████████████████████                             | 1685/3312 [43:39<40:22,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Standardize: Aligning Language Models with Expert-Defined Standards for Content Generation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  51%|██████████████████████████████                             | 1686/3312 [43:41<39:27,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Detecting misinformation through Framing Theory: the Frame Element-based Model\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  51%|██████████████████████████████                             | 1687/3312 [43:42<39:50,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: GenAudit: Fixing Factual Errors in Language Model Outputs with Evidence\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  51%|██████████████████████████████                             | 1688/3312 [43:43<39:05,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Confidence Matters: Revisiting Intrinsic Self-Correction Capabilities of Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  51%|██████████████████████████████                             | 1689/3312 [43:45<39:11,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: TrustScore: Reference-Free Evaluation of LLM Response Trustworthiness\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  51%|██████████████████████████████                             | 1690/3312 [43:46<39:09,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Your Vision-Language Model Itself Is a Strong Filter: Towards High-Quality Instruction Tuning with Data Selection\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  51%|██████████████████████████████                             | 1691/3312 [43:48<40:38,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Artifacts or Abduction: How Do LLMs Answer Multiple-Choice Questions Without the Question?\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  51%|██████████████████████████████▏                            | 1692/3312 [43:50<42:15,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Sequoia: Scalable, Robust, and Hardware-aware Speculative Decoding\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  51%|██████████████████████████████▏                            | 1693/3312 [43:51<41:07,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: AnaloBench: Benchmarking the Identification of Abstract and Long-context Analogies\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  51%|██████████████████████████████▏                            | 1694/3312 [43:53<41:19,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: A Critical Evaluation of AI Feedback for Aligning Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  51%|██████████████████████████████▏                            | 1695/3312 [43:54<40:12,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: DeepCode AI Fix: Fixing Security Vulnerabilities with Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  51%|██████████████████████████████▏                            | 1696/3312 [43:56<39:41,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Graph-Based Retriever Captures the Long Tail of Biomedical Knowledge\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  51%|██████████████████████████████▏                            | 1697/3312 [43:57<39:05,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: GTBench: Uncovering the Strategic Reasoning Limitations of LLMs via Game-Theoretic Evaluations\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  51%|██████████████████████████████▏                            | 1698/3312 [43:59<40:03,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Emulated Disalignment: Safety Alignment for Large Language Models May Backfire!\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  51%|██████████████████████████████▎                            | 1699/3312 [44:00<41:26,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Robust CLIP: Unsupervised Adversarial Fine-Tuning of Vision Embeddings for Robust Large Vision-Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  51%|██████████████████████████████▎                            | 1700/3312 [44:02<40:12,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Query-Based Adversarial Prompt Generation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  51%|██████████████████████████████▎                            | 1701/3312 [44:03<39:37,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LLM Agents for Psychology: A Study on Gamified Assessments\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  51%|██████████████████████████████▎                            | 1702/3312 [44:05<40:32,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Large Language Model for Mental Health: A Systematic Review\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  51%|██████████████████████████████▎                            | 1703/3312 [44:06<41:29,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ARKS: Active Retrieval in Knowledge Soup for Code Generation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  51%|██████████████████████████████▎                            | 1704/3312 [44:08<40:05,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Is Open-Source There Yet? A Comparative Study on Commercial and Open-Source LLMs in Their Ability to Label Chest X-Ray Reports\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  51%|██████████████████████████████▎                            | 1705/3312 [44:09<40:15,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Adaptive Skeleton Graph Decoding\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  52%|██████████████████████████████▍                            | 1706/3312 [44:11<42:00,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: WorldCoder, a Model-Based LLM Agent: Building World Models by Writing Code and Interacting with the Environment\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  52%|██████████████████████████████▍                            | 1707/3312 [44:13<43:30,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Tables as Images? Exploring the Strengths and Limitations of LLMs on Multimodal Representations of Tabular Data\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  52%|██████████████████████████████▍                            | 1708/3312 [44:14<44:23,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: High-quality Data-to-Text Generation for Severely Under-Resourced Languages with Out-of-the-box Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  52%|██████████████████████████████▍                            | 1709/3312 [44:16<46:18,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Uncertainty quantification in fine-tuned LLMs using LoRA ensembles\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  52%|██████████████████████████████▍                            | 1710/3312 [44:18<43:40,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: NEO-BENCH: Evaluating Robustness of Large Language Models with Neologisms\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  52%|██████████████████████████████▍                            | 1711/3312 [44:19<42:23,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Open3DSG: Open-Vocabulary 3D Scene Graphs from Point Clouds with Queryable Objects and Open-Set Relationships\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  52%|██████████████████████████████▍                            | 1712/3312 [44:21<40:55,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Shallow Synthesis of Knowledge in GPT-Generated Texts: A Case Study in Automatic Related Work Composition\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  52%|██████████████████████████████▌                            | 1713/3312 [44:22<39:57,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Same Task, More Tokens: the Impact of Input Length on the Reasoning Performance of Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  52%|██████████████████████████████▌                            | 1714/3312 [44:24<40:19,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: CovRL: Fuzzing JavaScript Engines with Coverage-Guided Reinforcement Learning for LLM-based Mutation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  52%|██████████████████████████████▌                            | 1715/3312 [44:25<39:52,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Reformatted Alignment\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  52%|██████████████████████████████▌                            | 1716/3312 [44:26<39:02,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Polarization of Autonomous Generative AI Agents Under Echo Chambers\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  52%|██████████████████████████████▌                            | 1717/3312 [44:28<38:40,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Enhancing Multilingual Capabilities of Large Language Models through Self-Distillation from Resource-Rich Languages\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  52%|██████████████████████████████▌                            | 1718/3312 [44:29<38:44,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Browse and Concentrate: Comprehending Multimodal Content via prior-LLM Context Fusion\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  52%|██████████████████████████████▌                            | 1719/3312 [44:31<38:17,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: A Chinese Dataset for Evaluating the Safeguards in Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  52%|██████████████████████████████▋                            | 1720/3312 [44:32<38:45,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Stick to your Role! Stability of Personal Values Expressed in Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  52%|██████████████████████████████▋                            | 1721/3312 [44:34<38:57,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Mafin: Enhancing Black-Box Embeddings with Model Augmented Fine-Tuning\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  52%|██████████████████████████████▋                            | 1722/3312 [44:35<40:17,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: BIDER: Bridging Knowledge Inconsistency for Efficient Retrieval-Augmented LLMs via Key Supporting Evidence\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  52%|██████████████████████████████▋                            | 1723/3312 [44:37<39:38,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Transformer-based Causal Language Models Perform Clustering\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  52%|██████████████████████████████▋                            | 1724/3312 [44:38<39:19,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Your Large Language Model is Secretly a Fairness Proponent and You Should Prompt it Like One\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  52%|██████████████████████████████▋                            | 1725/3312 [44:40<38:57,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Purifying Large Language Models by Ensembling a Small Language Model\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  52%|██████████████████████████████▋                            | 1726/3312 [44:41<40:32,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: End-to-end multilingual fact-checking at scale\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  52%|██████████████████████████████▊                            | 1727/3312 [44:43<39:57,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Meta Ranking: Less Capable Language Models are Capable for Single Response Judgement\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  52%|██████████████████████████████▊                            | 1728/3312 [44:44<39:28,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Do Large Language Models Understand Logic or Just Mimick Context?\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  52%|██████████████████████████████▊                            | 1729/3312 [44:46<39:12,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Can LLMs Compute with Reasons?\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  52%|██████████████████████████████▊                            | 1730/3312 [44:47<38:46,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LVCHAT: Facilitating Long Video Comprehension\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  52%|██████████████████████████████▊                            | 1731/3312 [44:49<38:55,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: EmoBench: Evaluating the Emotional Intelligence of Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  52%|██████████████████████████████▊                            | 1732/3312 [44:50<40:42,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: WKVQuant: Quantizing Weight and Key/Value Cache for Large Language Models Gains More\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  52%|██████████████████████████████▊                            | 1733/3312 [44:52<39:47,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: All Language Models Large and Small\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  52%|██████████████████████████████▉                            | 1734/3312 [44:53<39:06,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Are LLM-based Evaluators Confusing NLG Quality Criteria?\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  52%|██████████████████████████████▉                            | 1735/3312 [44:55<39:02,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Model Tailor: Mitigating Catastrophic Forgetting in Multi-modal Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  52%|██████████████████████████████▉                            | 1736/3312 [44:56<39:01,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Self-AMPLIFY: Improving Small Language Models with Self Post Hoc Explanations\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  52%|██████████████████████████████▉                            | 1737/3312 [44:58<42:07,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Towards Cross-Tokenizer Distillation: the Universal Logit Distillation Loss for LLMs\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  52%|██████████████████████████████▉                            | 1738/3312 [45:00<41:31,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Acquiring Clean Language Models from Backdoor Poisoned Datasets by Downscaling Frequency Space\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  53%|██████████████████████████████▉                            | 1739/3312 [45:01<42:02,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Speech Translation with Speech Foundation Models and Large Language Models: What is There and What is Missing?\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  53%|██████████████████████████████▉                            | 1740/3312 [45:03<41:17,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Evaluation of ChatGPT's Smart Contract Auditing Capabilities Based on Chain of Thought\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  53%|███████████████████████████████                            | 1741/3312 [45:05<44:10,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Distilling Large Language Models for Text-Attributed Graph Learning\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  53%|███████████████████████████████                            | 1742/3312 [45:07<47:53,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: EBFT: Effective and Block-Wise Fine-Tuning for Sparse LLMs\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  53%|███████████████████████████████                            | 1743/3312 [45:08<45:31,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Remember This Event That Year? Assessing Temporal Information and Reasoning in Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  53%|███████████████████████████████                            | 1744/3312 [45:10<44:22,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Structure Guided Large Language Model for SQL Generation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  53%|███████████████████████████████                            | 1745/3312 [45:12<47:23,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: DB-LLM: Accurate Dual-Binarization for Efficient LLMs\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  53%|███████████████████████████████                            | 1746/3312 [45:14<45:08,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Automatic Evaluation for Mental Health Counseling using LLMs\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  53%|███████████████████████████████                            | 1747/3312 [45:15<43:05,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LEMMA: Towards LVLM-Enhanced Multimodal Misinformation Detection with External Knowledge Augmentation\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  53%|███████████████████████████████▏                           | 1748/3312 [45:17<44:21,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Comprehensive Cognitive LLM Agent for Smartphone GUI Automation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  53%|███████████████████████████████▏                           | 1749/3312 [45:18<42:38,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: MRKE: The Multi-hop Reasoning Evaluation of LLMs by Knowledge Edition\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  53%|███████████████████████████████▏                           | 1750/3312 [45:20<41:11,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Direct Large Language Model Alignment Through Self-Rewarding Contrastive Prompt Distillation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  53%|███████████████████████████████▏                           | 1751/3312 [45:21<40:10,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Learning to Edit: Aligning LLMs with Knowledge Editing\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  53%|███████████████████████████████▏                           | 1752/3312 [45:23<39:38,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: SoLA: Solver-Layer Adaption of LLM for Better Logic Reasoning\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  53%|███████████████████████████████▏                           | 1753/3312 [45:24<38:48,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Investigating Multi-Hop Factual Shortcuts in Knowledge Editing of Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  53%|███████████████████████████████▏                           | 1754/3312 [45:26<38:12,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: SIBO: A Simple Booster for Parameter-Efficient Fine-Tuning\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  53%|███████████████████████████████▎                           | 1755/3312 [45:27<37:42,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Have Seen Me Before? Automating Dataset Updates Towards Reliable and Timely Evaluation\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  53%|███████████████████████████████▎                           | 1756/3312 [45:28<37:38,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Discerning and Resolving Knowledge Conflicts through Adaptive Decoding with Contextual Information-Entropy Constraint\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  53%|███████████████████████████████▎                           | 1757/3312 [45:30<38:22,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ROSE Doesn't Do That: Boosting the Safety of Instruction-Tuned Large Language Models with Reverse Prompt Contrastive Decoding\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  53%|███████████████████████████████▎                           | 1758/3312 [45:32<39:05,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: RJUA-MedDQA: A Multimodal Benchmark for Medical Document Question Answering and Clinical Reasoning\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  53%|███████████████████████████████▎                           | 1759/3312 [45:33<38:06,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: The Colorful Future of LLMs: Evaluating and Improving LLMs as Emotional Supporters for Queer Youth\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  53%|███████████████████████████████▎                           | 1760/3312 [45:34<37:48,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: NOTE: Notable generation Of patient Text summaries through Efficient approach based on direct preference optimization\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  53%|███████████████████████████████▎                           | 1761/3312 [45:36<38:57,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LoRA Training in the NTK Regime has No Spurious Local Minima\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  53%|███████████████████████████████▍                           | 1762/3312 [45:38<39:02,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Modularized Networks for Few-shot Hateful Meme Detection\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  53%|███████████████████████████████▍                           | 1763/3312 [45:39<39:23,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: UniST: A Prompt-Empowered Universal Model for Urban Spatio-Temporal Prediction\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  53%|███████████████████████████████▍                           | 1764/3312 [45:41<38:51,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Ask Optimal Questions: Aligning Large Language Models with Retriever's Preference in Conversational Search\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  53%|███████████████████████████████▍                           | 1765/3312 [45:42<38:03,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Microstructures and Accuracy of Graph Recall by Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  53%|███████████████████████████████▍                           | 1766/3312 [45:44<38:33,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Head-wise Shareable Attention for Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  53%|███████████████████████████████▍                           | 1767/3312 [45:45<37:50,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: HU at SemEval-2024 Task 8A: Can Contrastive Learning Learn Embeddings to Detect Machine-Generated Text?\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  53%|███████████████████████████████▍                           | 1768/3312 [45:46<37:04,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: FIPO: Free-form Instruction-oriented Prompt Optimization with Preference Dataset and Modular Fine-tuning Schema\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  53%|███████████████████████████████▌                           | 1769/3312 [45:48<36:50,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LLM as Prompter: Low-resource Inductive Reasoning on Arbitrary Knowledge Graphs\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  53%|███████████████████████████████▌                           | 1770/3312 [45:49<36:39,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: What Evidence Do Language Models Find Convincing?\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  53%|███████████████████████████████▌                           | 1771/3312 [45:51<37:05,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ChatGPT Based Data Augmentation for Improved Parameter-Efficient Debiasing of LLMs\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  54%|███████████████████████████████▌                           | 1772/3312 [45:52<38:09,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Large Language Models for Stemming: Promises, Pitfalls and Failures\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  54%|███████████████████████████████▌                           | 1773/3312 [45:54<37:25,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: MARS: Meaning-Aware Response Scoring for Uncertainty Estimation in Generative LLMs\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  54%|███████████████████████████████▌                           | 1774/3312 [45:55<36:44,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: SPML: A DSL for Defending Language Models Against Prompt Attacks\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  54%|███████████████████████████████▌                           | 1775/3312 [45:57<39:54,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ArtPrompt: ASCII Art-based Jailbreak Attacks against Aligned LLMs\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  54%|███████████████████████████████▋                           | 1776/3312 [45:58<39:22,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: RFBES at SemEval-2024 Task 8: Investigating Syntactic and Semantic Features for Distinguishing AI-Generated and Human-Written Texts\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  54%|███████████████████████████████▋                           | 1777/3312 [46:00<38:08,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: In-Context Learning Demonstration Selection via Influence Analysis\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  54%|███████████████████████████████▋                           | 1778/3312 [46:01<37:14,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Language Models are Homer Simpson! Safety Re-Alignment of Fine-tuned Language Models through Task Arithmetic\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  54%|███████████████████████████████▋                           | 1779/3312 [46:03<39:08,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Utilizing BERT for Information Retrieval: Survey, Applications, Resources, and Challenges\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  54%|███████████████████████████████▋                           | 1780/3312 [46:04<38:50,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Solving Data-centric Tasks using Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  54%|███████████████████████████████▋                           | 1781/3312 [46:06<38:39,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: How Susceptible are Large Language Models to Ideological Manipulation?\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  54%|███████████████████████████████▋                           | 1782/3312 [46:07<37:48,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Shaping Human-AI Collaboration: Varied Scaffolding Levels in Co-writing with Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  54%|███████████████████████████████▊                           | 1783/3312 [46:09<39:10,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Modelling Political Coalition Negotiations Using LLM-based Agents\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  54%|███████████████████████████████▊                           | 1784/3312 [46:10<39:15,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: MORL-Prompt: An Empirical Analysis of Multi-Objective Reinforcement Learning for Discrete Prompt Optimization\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  54%|███████████████████████████████▊                           | 1785/3312 [46:12<38:21,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: GNNavi: Navigating the Information Flow in Large Language Models by Graph Neural Network\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  54%|███████████████████████████████▊                           | 1786/3312 [46:13<38:33,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Search Engines Post-ChatGPT: How Generative Artificial Intelligence Could Make Search Less Reliable\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  54%|███████████████████████████████▊                           | 1787/3312 [46:15<41:18,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Can ChatGPT Support Developers? An Empirical Evaluation of Large Language Models for Code Generation\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  54%|███████████████████████████████▊                           | 1788/3312 [46:17<39:54,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Why Lift so Heavy? Slimming Large Language Models by Cutting Off the Layers\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  54%|███████████████████████████████▊                           | 1789/3312 [46:18<38:19,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Vision-Flan: Scaling Human-Labeled Tasks in Visual Instruction Tuning\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  54%|███████████████████████████████▉                           | 1790/3312 [46:20<39:00,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: One Prompt To Rule Them All: LLMs for Opinion Summary Evaluation\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  54%|███████████████████████████████▉                           | 1791/3312 [46:21<38:09,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: A Multi-Aspect Framework for Counter Narrative Evaluation using Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  54%|███████████████████████████████▉                           | 1792/3312 [46:23<37:55,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Autocorrect for Estonian texts: final report from project EKTB25\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  54%|███████████████████████████████▉                           | 1793/3312 [46:24<38:06,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Learning From Failure: Integrating Negative Examples when Fine-tuning Large Language Models as Agents\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  54%|███████████████████████████████▉                           | 1794/3312 [46:26<38:17,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Stealthy Attack on Large Language Model based Recommendation\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  54%|███████████████████████████████▉                           | 1795/3312 [46:27<38:27,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Towards Versatile Graph Learning Approach: from the Perspective of Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  54%|███████████████████████████████▉                           | 1796/3312 [46:29<37:35,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Stumbling Blocks: Stress Testing the Robustness of Machine-Generated Text Detectors Under Attacks\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  54%|████████████████████████████████                           | 1797/3312 [46:30<37:54,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Self-seeding and Multi-intent Self-instructing LLMs for Generating Intent-aware Information-Seeking dialogs\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  54%|████████████████████████████████                           | 1798/3312 [46:31<37:07,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: On the Roles of LLMs in Planning: Embedding LLMs into Planning Graphs\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  54%|████████████████████████████████                           | 1799/3312 [46:33<37:06,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: SpeCrawler: Generating OpenAPI Specifications from API Documentation Using Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  54%|████████████████████████████████                           | 1800/3312 [46:34<37:06,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Decoding News Narratives: A Critical Analysis of Large Language Models in Framing Bias Detection\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  54%|████████████████████████████████                           | 1801/3312 [46:36<37:45,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Multi-Task Inference: Can Large Language Models Follow Multiple Instructions at Once?\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  54%|████████████████████████████████                           | 1802/3312 [46:37<37:35,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Revisiting Zeroth-Order Optimization for Memory-Efficient LLM Fine-Tuning: A Benchmark\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  54%|████████████████████████████████                           | 1803/3312 [46:39<39:19,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: BESA: Pruning Large Language Models with Blockwise Parameter-Efficient Sparsity Allocation\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  54%|████████████████████████████████▏                          | 1804/3312 [46:41<39:40,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Ain't Misbehavin' -- Using LLMs to Generate Expressive Robot Behavior in Conversations with the Tabletop Robot Haru\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  54%|████████████████████████████████▏                          | 1805/3312 [46:42<39:06,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LongAgent: Scaling Language Models to 128k Context through Multi-Agent Collaboration\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  55%|████████████████████████████████▏                          | 1806/3312 [46:44<38:00,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: KMMLU: Measuring Massive Multitask Language Understanding in Korean\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  55%|████████████████████████████████▏                          | 1807/3312 [46:45<37:57,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ModelGPT: Unleashing LLM's Capabilities for Tailored Model Generation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  55%|████████████████████████████████▏                          | 1808/3312 [46:47<38:54,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Deciphering the Impact of Pretraining Data on Large Language Models through Machine Unlearning\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  55%|████████████████████████████████▏                          | 1809/3312 [46:49<40:51,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Ploutos: Towards interpretable stock movement prediction with financial large language model\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  55%|████████████████████████████████▏                          | 1810/3312 [46:50<40:06,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Chain-of-Instructions: Compositional Instruction Tuning on Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  55%|████████████████████████████████▎                          | 1811/3312 [46:52<38:31,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Efficient Multimodal Learning from Data-centric Perspective\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  55%|████████████████████████████████▎                          | 1812/3312 [46:54<41:03,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Large Language Model-driven Meta-structure Discovery in Heterogeneous Information Network\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  55%|████████████████████████████████▎                          | 1813/3312 [46:55<38:48,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Knowledge-to-SQL: Enhancing SQL Generation with Data Expert LLM\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  55%|████████████████████████████████▎                          | 1814/3312 [46:56<37:34,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: From Prejudice to Parity: A New Approach to Debiasing Large Language Model Word Embeddings\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  55%|████████████████████████████████▎                          | 1815/3312 [46:58<40:14,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Federated Fine-tuning of Large Language Models under Heterogeneous Language Tasks and Client Resources\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  55%|████████████████████████████████▎                          | 1816/3312 [47:00<40:20,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: What's the Plan? Evaluating and Developing Planning-Aware Techniques for LLMs\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  55%|████████████████████████████████▎                          | 1817/3312 [47:01<40:30,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: MIKE: A New Benchmark for Fine-grained Multimodal Entity Knowledge Editing\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  55%|████████████████████████████████▍                          | 1818/3312 [47:03<41:11,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ChatDiet: Empowering Personalized Nutrition-Oriented Food Recommender Chatbots through an LLM-Augmented Framework\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  55%|████████████████████████████████▍                          | 1819/3312 [47:05<39:54,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: scInterpreter: Training Large Language Models to Interpret scRNA-seq Data for Cell Type Annotation\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  55%|████████████████████████████████▍                          | 1820/3312 [47:06<40:17,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: When Do LLMs Need Retrieval Augmentation? Mitigating LLMs' Overconfidence Helps Retrieval Augmentation\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  55%|████████████████████████████████▍                          | 1821/3312 [47:08<39:09,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: FactPICO: Factuality Evaluation for Plain Language Summarization of Medical Evidence\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  55%|████████████████████████████████▍                          | 1822/3312 [47:09<37:47,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LoRA-Flow: Dynamic LoRA Fusion for Large Language Models in Generative Tasks\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  55%|████████████████████████████████▍                          | 1823/3312 [47:11<36:41,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: MatPlotAgent: Method and Evaluation for LLM-Based Agentic Scientific Data Visualization\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  55%|████████████████████████████████▍                          | 1824/3312 [47:12<37:39,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: AutoPRM: Automating Procedural Supervision for Multi-Step Reasoning via Controllable Question Decomposition\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  55%|████████████████████████████████▌                          | 1825/3312 [47:14<39:48,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: SciAgent: Tool-augmented Language Models for Scientific Reasoning\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  55%|████████████████████████████████▌                          | 1826/3312 [47:15<38:03,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: In-Context Example Ordering Guided by Label Distributions\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  55%|████████████████████████████████▌                          | 1827/3312 [47:17<39:57,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Benchmark Self-Evolving: A Multi-Agent Framework for Dynamic LLM Evaluation\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  55%|████████████████████████████████▌                          | 1828/3312 [47:19<38:33,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Can LLMs Reason with Rules? Logic Scaffolding for Stress-Testing and Improving LLMs\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  55%|████████████████████████████████▌                          | 1829/3312 [47:20<39:01,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: InfuserKI: Enhancing Large Language Models with Knowledge Graphs via Infuser-Guided Knowledge Integration\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  55%|████████████████████████████████▌                          | 1830/3312 [47:22<38:37,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Perils of Self-Feedback: Self-Bias Amplifies in Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  55%|████████████████████████████████▌                          | 1831/3312 [47:23<38:30,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Momentor: Advancing Video Large Language Model with Fine-Grained Temporal Reasoning\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  55%|████████████████████████████████▋                          | 1832/3312 [47:25<37:30,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Can Deception Detection Go Deeper? Dataset, Evaluation, and Benchmark for Deception Reasoning\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  55%|████████████████████████████████▋                          | 1833/3312 [47:26<36:38,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: EventRL: Enhancing Event Extraction with Outcome Supervision for Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  55%|████████████████████████████████▋                          | 1834/3312 [47:28<36:46,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Rethinking the Roles of Large Language Models in Chinese Grammatical Error Correction\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  55%|████████████████████████████████▋                          | 1835/3312 [47:29<36:25,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LoRETTA: Low-Rank Economic Tensor-Train Adaptation for Ultra-Low-Parameter Fine-Tuning of Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  55%|████████████████████████████████▋                          | 1836/3312 [47:30<35:31,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Aligning Modalities in Vision Large Language Models via Preference Fine-tuning\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  55%|████████████████████████████████▋                          | 1837/3312 [47:32<35:02,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Multi-dimensional Evaluation of Empathetic Dialog Responses\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  55%|████████████████████████████████▋                          | 1838/3312 [47:33<34:33,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Don't Go To Extremes: Revealing the Excessive Sensitivity and Calibration Limitations of LLMs in Implicit Hate Speech Detection\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  56%|████████████████████████████████▊                          | 1839/3312 [47:35<34:27,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Reasoning before Comparison: LLM-Enhanced Semantic Similarity Metrics for Domain Specialized Text Analysis\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  56%|████████████████████████████████▊                          | 1840/3312 [47:36<35:40,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: CliqueParcel: An Approach For Batching LLM Prompts That Jointly Optimizes Efficiency And Faithfulness\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  56%|████████████████████████████████▊                          | 1841/3312 [47:38<35:32,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Training Language Model Agents without Modifying Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  56%|████████████████████████████████▊                          | 1842/3312 [47:39<35:11,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Understanding the Impact of Long-Term Memory on Self-Disclosure with Large Language Model-Driven Chatbots for Public Health Intervention\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  56%|████████████████████████████████▊                          | 1843/3312 [47:40<35:21,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Tasks That Language Models Don't Learn\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  56%|████████████████████████████████▊                          | 1844/3312 [47:42<34:51,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: PhaseEvo: Towards Unified In-Context Prompt Optimization for Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  56%|████████████████████████████████▊                          | 1845/3312 [47:43<34:36,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: EVEDIT: Event-based Knowledge Editing with Deductive Editing Boundaries\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  56%|████████████████████████████████▉                          | 1846/3312 [47:45<36:18,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Dissecting Human and LLM Preferences\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  56%|████████████████████████████████▉                          | 1847/3312 [47:47<38:57,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: OneBit: Towards Extremely Low-bit Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  56%|████████████████████████████████▉                          | 1848/3312 [47:48<37:10,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Puzzle Solving using Reasoning of Large Language Models: A Survey\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  56%|████████████████████████████████▉                          | 1849/3312 [47:49<36:06,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Can Large Multimodal Models Uncover Deep Semantics Behind Images?\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  56%|████████████████████████████████▉                          | 1850/3312 [47:51<36:57,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Multi-Perspective Consistency Enhances Confidence Estimation in Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  56%|████████████████████████████████▉                          | 1851/3312 [47:53<42:20,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: MoRAL: MoE Augmented LoRA for LLMs' Lifelong Learning\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  56%|████████████████████████████████▉                          | 1852/3312 [47:55<40:15,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: C-ICL: Contrastive In-context Learning for Information Extraction\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  56%|█████████████████████████████████                          | 1853/3312 [47:56<38:51,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Aligning Large Language Models by On-Policy Self-Judgment\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  56%|█████████████████████████████████                          | 1854/3312 [47:58<38:50,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LLM can Achieve Self-Regulation via Hyperparameter Aware Generation\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  56%|█████████████████████████████████                          | 1855/3312 [47:59<37:46,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Can Large Language Models perform Relation-based Argument Mining?\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  56%|█████████████████████████████████                          | 1856/3312 [48:01<36:55,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: When LLMs Meets Acoustic Landmarks: An Efficient Approach to Integrate Speech into Large Language Models for Depression Detection\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  56%|█████████████████████████████████                          | 1857/3312 [48:02<35:58,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Controlled Text Generation for Large Language Model with Dynamic Attribute Graphs\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  56%|█████████████████████████████████                          | 1858/3312 [48:04<35:44,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Asclepius: A Spectrum Evaluation Benchmark for Medical Multi-Modal Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  56%|█████████████████████████████████                          | 1859/3312 [48:05<35:28,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Watch Out for Your Agents! Investigating Backdoor Threats to LLM-Based Agents\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  56%|█████████████████████████████████▏                         | 1860/3312 [48:06<34:48,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Direct Evaluation of Chain-of-Thought in Multi-hop Reasoning with Knowledge Graphs\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  56%|█████████████████████████████████▏                         | 1861/3312 [48:08<34:53,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Evaluating LLMs' Mathematical Reasoning in Financial Document Question Answering\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  56%|█████████████████████████████████▏                         | 1862/3312 [48:09<34:37,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: I Learn Better If You Speak My Language: Enhancing Large Language Model Fine-Tuning with Style-Aligned Response Adjustments\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  56%|█████████████████████████████████▏                         | 1863/3312 [48:11<35:14,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Disclosure and Mitigation of Gender Bias in LLMs\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  56%|█████████████████████████████████▏                         | 1864/3312 [48:12<35:12,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LaCo: Large Language Model Pruning via Layer Collapse\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  56%|█████████████████████████████████▏                         | 1865/3312 [48:14<35:11,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: KnowTuning: Knowledge-aware Fine-tuning for Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  56%|█████████████████████████████████▏                         | 1866/3312 [48:15<35:30,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: M4GT-Bench: Evaluation Benchmark for Black-Box Machine-Generated Text Detection\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  56%|█████████████████████████████████▎                         | 1867/3312 [48:17<37:56,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Token-Ensemble Text Generation: On Attacking the Automatic AI-Generated Text Detection\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  56%|█████████████████████████████████▎                         | 1868/3312 [48:19<39:03,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: GenDec: A robust generative Question-decomposition method for Multi-hop reasoning\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  56%|█████████████████████████████████▎                         | 1869/3312 [48:20<37:57,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: KG-Agent: An Efficient Autonomous Agent Framework for Complex Reasoning over Knowledge Graph\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  56%|█████████████████████████████████▎                         | 1870/3312 [48:22<38:36,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: PANDA (Pedantic ANswer-correctness Determination and Adjudication):Improving Automatic Evaluation for Question Answering and Text Generation\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  56%|█████████████████████████████████▎                         | 1871/3312 [48:23<37:38,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Grasping the Essentials: Tailoring Large Language Models for Zero-Shot Relation Extraction\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  57%|█████████████████████████████████▎                         | 1872/3312 [48:25<37:23,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Boosting of Thoughts: Trial-and-Error Problem Solving with Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  57%|█████████████████████████████████▎                         | 1873/3312 [48:26<36:40,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Contrastive Instruction Tuning\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  57%|█████████████████████████████████▍                         | 1874/3312 [48:28<35:38,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: TuneTables: Context Optimization for Scalable Prior-Data Fitted Networks\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  57%|█████████████████████████████████▍                         | 1875/3312 [48:29<35:53,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Orca-Math: Unlocking the potential of SLMs in Grade School Math\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  57%|█████████████████████████████████▍                         | 1876/3312 [48:31<38:30,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: BlendFilter: Advancing Retrieval-Augmented Large Language Models via Query Generation Blending and Knowledge Filtering\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  57%|█████████████████████████████████▍                         | 1877/3312 [48:33<39:07,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Born With a Silver Spoon? Investigating Socioeconomic Bias in Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  57%|█████████████████████████████████▍                         | 1878/3312 [48:34<38:24,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Navigating the Dual Facets: A Comprehensive Evaluation of Sequential Memory Editing in Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  57%|█████████████████████████████████▍                         | 1879/3312 [48:36<37:14,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: When LLMs Meet Cunning Questions: A Fallacy Understanding Benchmark for Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  57%|█████████████████████████████████▍                         | 1880/3312 [48:37<37:34,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Word Embeddings Revisited: Do LLMs Offer Something New?\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  57%|█████████████████████████████████▌                         | 1881/3312 [48:39<37:18,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: VQAttack: Transferable Adversarial Attacks on Visual Question Answering via Pre-trained Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  57%|█████████████████████████████████▌                         | 1882/3312 [48:41<38:35,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: AFaCTA: Assisting the Annotation of Factual Claim Detection with Reliable LLM Annotators\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  57%|█████████████████████████████████▌                         | 1883/3312 [48:42<37:14,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Bridging Causal Discovery and Large Language Models: A Comprehensive Survey of Integrative Approaches and Future Directions\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  57%|█████████████████████████████████▌                         | 1884/3312 [48:44<37:49,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Persona-DB: Efficient Large Language Model Personalization for Response Prediction with Collaborative Data Refinement\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  57%|█████████████████████████████████▌                         | 1885/3312 [48:45<36:07,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Large Language Models Fall Short: Understanding Complex Relationships in Detective Narratives\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  57%|█████████████████████████████████▌                         | 1886/3312 [48:47<37:41,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Retrieval-Augmented Generation: Is Dense Passage Retrieval Retrieving?\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  57%|█████████████████████████████████▌                         | 1887/3312 [48:49<43:01,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: PAT-Questions: A Self-Updating Benchmark for Present-Anchored Temporal Question-Answering\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  57%|█████████████████████████████████▋                         | 1888/3312 [48:51<40:03,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: PaLM2-VAdapter: Progressively Aligned Language Model Makes a Strong Vision-language Adapter\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  57%|█████████████████████████████████▋                         | 1889/3312 [48:52<40:16,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: RLVF: Learning from Verbal Feedback without Overgeneralization\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  57%|█████████████████████████████████▋                         | 1890/3312 [48:54<38:10,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Proving membership in LLM pretraining data via data watermarks\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  57%|█████████████████████████████████▋                         | 1891/3312 [48:55<37:13,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Instruction Diversity Drives Generalization To Unseen Tasks\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  57%|█████████████████████████████████▋                         | 1892/3312 [48:57<38:57,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: When is Tree Search Useful for LLM Planning? It Depends on the Discriminator\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  57%|█████████████████████████████████▋                         | 1893/3312 [48:59<37:52,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Multi-modal preference alignment remedies regression of visual instruction tuning on language model\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  57%|█████████████████████████████████▋                         | 1894/3312 [49:00<36:21,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Exploring Value Biases: How LLMs Deviate Towards the Ideal\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  57%|█████████████████████████████████▊                         | 1895/3312 [49:02<37:08,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: EcoRank: Budget-Constrained Text Re-ranking Using Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  57%|█████████████████████████████████▊                         | 1896/3312 [49:03<37:34,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Time Series Forecasting with LLMs: Understanding and Enhancing Model Capabilities\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  57%|█████████████████████████████████▊                         | 1897/3312 [49:05<36:39,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: RAG-Driver: Generalisable Driving Explanations with Retrieval-Augmented In-Context Learning in Multi-Modal Large Language Model\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  57%|█████████████████████████████████▊                         | 1898/3312 [49:06<35:44,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Quantifying the Persona Effect in LLM Simulations\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  57%|█████████████████████████████████▊                         | 1899/3312 [49:08<35:11,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Generative Cross-Modal Retrieval: Memorizing Images in Multimodal Language Models for Retrieval and Beyond\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  57%|█████████████████████████████████▊                         | 1900/3312 [49:09<35:27,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: In Search of Needles in a 11M Haystack: Recurrent Memory Finds What LLMs Miss\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  57%|█████████████████████████████████▊                         | 1901/3312 [49:11<35:18,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: EdgeQAT: Entropy and Distribution Guided Quantization-Aware Training for the Acceleration of Lightweight LLMs on the Edge\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  57%|█████████████████████████████████▉                         | 1902/3312 [49:12<34:33,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: A Condensed Transition Graph Framework for Zero-shot Link Prediction with Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  57%|█████████████████████████████████▉                         | 1903/3312 [49:14<35:45,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: AutoGPT+P: Affordance-based Task Planning with Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  57%|█████████████████████████████████▉                         | 1904/3312 [49:16<40:02,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: How Reliable Are Automatic Evaluation Methods for Instruction-Tuned LLMs?\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  58%|█████████████████████████████████▉                         | 1905/3312 [49:17<38:49,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ToolSword: Unveiling Safety Issues of Large Language Models in Tool Learning Across Three Stages\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  58%|█████████████████████████████████▉                         | 1906/3312 [49:19<36:51,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: GenRES: Rethinking Evaluation for Generative Relation Extraction in the Era of Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  58%|█████████████████████████████████▉                         | 1907/3312 [49:20<35:25,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Let's Learn Step by Step: Enhancing In-Context Learning Ability with Curriculum Learning\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  58%|█████████████████████████████████▉                         | 1908/3312 [49:22<35:15,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Assessing the Reasoning Abilities of ChatGPT in the Context of Claim Verification\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  58%|██████████████████████████████████                         | 1909/3312 [49:23<36:15,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: A Novel BERT-based Classifier to Detect Political Leaning of YouTube Videos based on their Titles\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  58%|██████████████████████████████████                         | 1910/3312 [49:25<36:26,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: An Empirical Study on Cross-lingual Vocabulary Adaptation for Efficient Generative LLM Inference\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  58%|██████████████████████████████████                         | 1911/3312 [49:26<35:19,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: AutoSAT: Automatically Optimize SAT Solvers via Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  58%|██████████████████████████████████                         | 1912/3312 [49:28<35:10,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Multi-Cultural Commonsense Knowledge Distillation\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  58%|██████████████████████████████████                         | 1913/3312 [49:29<34:55,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Opening the Black Box of Large Language Models: Two Views on Holistic Interpretability\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  58%|██████████████████████████████████                         | 1914/3312 [49:31<34:07,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LongHeads: Multi-Head Attention is Secretly a Long Context Processor\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  58%|██████████████████████████████████                         | 1915/3312 [49:32<34:03,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: German Text Simplification: Finetuning Large Language Models with Semi-Synthetic Data\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  58%|██████████████████████████████████▏                        | 1916/3312 [49:33<33:33,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Decomposition for Enhancing Attention: Improving LLM-based Text-to-SQL through Workflow Paradigm\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  58%|██████████████████████████████████▏                        | 1917/3312 [49:35<33:30,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: OpenFMNav: Towards Open-Set Zero-Shot Object Navigation via Vision-Language Foundation Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  58%|██████████████████████████████████▏                        | 1918/3312 [49:36<34:03,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Humans or LLMs as the Judge? A Study on Judgement Biases\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  58%|██████████████████████████████████▏                        | 1919/3312 [49:38<35:04,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Improving Demonstration Diversity by Human-Free Fusing for Text-to-SQL\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  58%|██████████████████████████████████▏                        | 1920/3312 [49:39<34:05,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Network Formation and Dynamics Among Multi-LLMs\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  58%|██████████████████████████████████▏                        | 1921/3312 [49:41<35:42,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Enhancing Numerical Reasoning with the Guidance of Reliable Reasoning Processes\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  58%|██████████████████████████████████▏                        | 1922/3312 [49:43<35:23,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: AbsInstruct: Eliciting Abstraction Ability from LLMs through Explanation Tuning with Plausibility Estimation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  58%|██████████████████████████████████▎                        | 1923/3312 [49:44<34:57,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Can Separators Improve Chain-of-Thought Prompting?\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  58%|██████████████████████████████████▎                        | 1924/3312 [49:45<34:16,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: BitDistiller: Unleashing the Potential of Sub-4-Bit LLMs via Self-Distillation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  58%|██████████████████████████████████▎                        | 1925/3312 [49:47<34:35,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Enhancing Role-playing Systems through Aggressive Queries: Evaluation and Improvement\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  58%|██████████████████████████████████▎                        | 1926/3312 [49:48<34:28,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Can LLMs Speak For Diverse People? Tuning LLMs via Debate to Generate Controllable Controversial Statements\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  58%|██████████████████████████████████▎                        | 1927/3312 [49:50<34:33,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Retrieve Only When It Needs: Adaptive Retrieval Augmentation for Hallucination Mitigation in Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  58%|██████████████████████████████████▎                        | 1928/3312 [49:52<35:24,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Jailbreaking Proprietary Large Language Models using Word Substitution Cipher\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  58%|██████████████████████████████████▎                        | 1929/3312 [49:53<35:19,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Efficiency at Scale: Investigating the Performance of Diminutive Language Models in Clinical Tasks\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  58%|██████████████████████████████████▍                        | 1930/3312 [49:54<34:15,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Do Llamas Work in English? On the Latent Language of Multilingual Transformers\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  58%|██████████████████████████████████▍                        | 1931/3312 [49:56<33:30,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Threads of Subtlety: Detecting Machine-Generated Texts Through Discourse Motifs\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  58%|██████████████████████████████████▍                        | 1932/3312 [49:57<33:29,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LinkNER: Linking Local Named Entity Recognition Models to Large Language Models using Uncertainty\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  58%|██████████████████████████████████▍                        | 1933/3312 [49:59<33:42,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LLMs in the Heart of Differential Testing: A Case Study on a Medical Rule Engine\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  58%|██████████████████████████████████▍                        | 1934/3312 [50:00<33:37,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: InSaAF: Incorporating Safety through Accuracy and Fairness | Are LLMs ready for the Indian Legal Domain?\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  58%|██████████████████████████████████▍                        | 1935/3312 [50:02<33:36,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: SPAR: Personalized Content-Based Recommendation via Long Engagement Attention\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  58%|██████████████████████████████████▍                        | 1936/3312 [50:03<34:54,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Disordered-DABS: A Benchmark for Dynamic Aspect-Based Summarization in Disordered Texts\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  58%|██████████████████████████████████▌                        | 1937/3312 [50:05<34:07,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Conversational SimulMT: Efficient Simultaneous Translation with Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  59%|██████████████████████████████████▌                        | 1938/3312 [50:06<33:58,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Properties and Challenges of LLM-Generated Explanations\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  59%|██████████████████████████████████▌                        | 1939/3312 [50:08<34:27,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Can We Verify Step by Step for Incorrect Answer Detection?\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  59%|██████████████████████████████████▌                        | 1940/3312 [50:09<33:34,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Zero-shot sampling of adversarial entities in biomedical question answering\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  59%|██████████████████████████████████▌                        | 1941/3312 [50:11<34:23,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LLM Comparator: Visual Analytics for Side-by-Side Evaluation of Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  59%|██████████████████████████████████▌                        | 1942/3312 [50:12<34:15,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Any-Precision LLM: Low-Cost Deployment of Multiple, Different-Sized LLMs\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  59%|██████████████████████████████████▌                        | 1943/3312 [50:14<35:01,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Provably Sample Efficient RLHF via Active Preference Optimization\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  59%|██████████████████████████████████▋                        | 1944/3312 [50:15<34:17,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Comparing Hallucination Detection Metrics for Multilingual Generation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  59%|██████████████████████████████████▋                        | 1945/3312 [50:17<36:30,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Unsupervised LLM Adaptation for Question Answering\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  59%|██████████████████████████████████▋                        | 1946/3312 [50:19<35:05,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Large Language Models as Zero-shot Dialogue State Tracker through Function Calling\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  59%|██████████████████████████████████▋                        | 1947/3312 [50:20<34:24,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: QDyLoRA: Quantized Dynamic Low-Rank Adaptation for Efficient Large Language Model Tuning\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  59%|██████████████████████████████████▋                        | 1948/3312 [50:21<33:47,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: WilKE: Wise-Layer Knowledge Editor for Lifelong Knowledge Editing\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  59%|██████████████████████████████████▋                        | 1949/3312 [50:23<33:09,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Steering Conversational Large Language Models for Long Emotional Support Conversations\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  59%|██████████████████████████████████▋                        | 1950/3312 [50:24<33:32,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: I Am Not Them: Fluid Identities and Persistent Out-group Bias in Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  59%|██████████████████████████████████▊                        | 1951/3312 [50:26<33:02,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Smaller Language Models are capable of selecting Instruction-Tuning Training Data for Larger Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  59%|██████████████████████████████████▊                        | 1952/3312 [50:27<33:21,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: DELL: Generating Reactions and Explanations for LLM-Based Misinformation Detection\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  59%|██████████████████████████████████▊                        | 1953/3312 [50:29<32:43,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Measuring and Reducing LLM Hallucination without Gold-Standard Answers via Expertise-Weighting\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  59%|██████████████████████████████████▊                        | 1954/3312 [50:30<33:23,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Understanding Survey Paper Taxonomy about Large Language Models via Graph Representation Learning\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  59%|██████████████████████████████████▊                        | 1955/3312 [50:32<33:19,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Chain of Logic: Rule-Based Reasoning with Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  59%|██████████████████████████████████▊                        | 1956/3312 [50:33<33:13,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: DataDreamer: A Tool for Synthetic Data Generation and Reproducible LLM Workflows\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  59%|██████████████████████████████████▊                        | 1957/3312 [50:35<34:28,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: BioMistral: A Collection of Open-Source Pretrained Large Language Models for Medical Domains\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  59%|██████████████████████████████████▉                        | 1958/3312 [50:36<34:51,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Can we Soft Prompt LLMs for Graph Learning Tasks?\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  59%|██████████████████████████████████▉                        | 1959/3312 [50:38<33:56,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Prompt-Based Bias Calibration for Better Zero/Few-Shot Learning of Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  59%|██████████████████████████████████▉                        | 1960/3312 [50:39<34:29,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Large Language Models for Forecasting and Anomaly Detection: A Systematic Literature Review\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  59%|██████████████████████████████████▉                        | 1961/3312 [50:41<35:54,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: On the Safety Concerns of Deploying LLMs/VLMs in Robotics: Highlighting the Risks and Vulnerabilities\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  59%|██████████████████████████████████▉                        | 1962/3312 [50:43<34:52,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: SportsMetrics: Blending Text and Numerical Data to Understand Information Fusion in LLMs\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  59%|██████████████████████████████████▉                        | 1963/3312 [50:44<33:59,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: How to Discern Important Urgent News?\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  59%|██████████████████████████████████▉                        | 1964/3312 [50:46<34:19,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LAVE: LLM-Powered Agent Assistance and Language Augmentation for Video Editing\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  59%|███████████████████████████████████                        | 1965/3312 [50:47<33:55,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Self-Play Fine-Tuning of Diffusion Models for Text-to-Image Generation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  59%|███████████████████████████████████                        | 1966/3312 [50:49<35:50,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: A StrongREJECT for Empty Jailbreaks\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  59%|███████████████████████████████████                        | 1967/3312 [50:50<34:38,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Chain-of-Thought Reasoning Without Prompting\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  59%|███████████████████████████████████                        | 1968/3312 [50:52<33:44,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: A Trembling House of Cards? Mapping Adversarial Attacks against Language Agents\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  59%|███████████████████████████████████                        | 1969/3312 [50:53<33:08,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: BitDelta: Your Fine-Tune May Only Be Worth One Bit\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  59%|███████████████████████████████████                        | 1970/3312 [50:55<33:04,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Uncertainty Quantification for In-Context Learning of Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  60%|███████████████████████████████████                        | 1971/3312 [50:56<33:08,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Language Models with Conformal Factuality Guarantees\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  60%|███████████████████████████████████▏                       | 1972/3312 [50:57<32:29,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: OpenMathInstruct-1: A 1.8 Million Math Instruction Tuning Dataset\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  60%|███████████████████████████████████▏                       | 1973/3312 [50:59<33:13,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Generative AI and Process Systems Engineering: The Next Frontier\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  60%|███████████████████████████████████▏                       | 1974/3312 [51:00<32:39,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: OptiMUS: Scalable Optimization Modeling with (MI)LP Solvers and Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  60%|███████████████████████████████████▏                       | 1975/3312 [51:02<32:10,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Knowledge-Infused LLM-Powered Conversational Health Agent: A Case Study for Diabetes Patients\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  60%|███████████████████████████████████▏                       | 1976/3312 [51:03<32:46,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: TOAD: Task-Oriented Automatic Dialogs with Diverse Response Styles\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  60%|███████████████████████████████████▏                       | 1977/3312 [51:05<32:14,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Selective Reflection-Tuning: Student-Selected Data Recycling for LLM Instruction-Tuning\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  60%|███████████████████████████████████▏                       | 1978/3312 [51:06<31:50,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Towards Reducing Diagnostic Errors with Interpretable Risk Prediction\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  60%|███████████████████████████████████▎                       | 1979/3312 [51:08<32:59,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Quantized Embedding Vectors for Controllable Diffusion Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  60%|███████████████████████████████████▎                       | 1980/3312 [51:10<34:48,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: GeoEval: Benchmark for Evaluating LLMs and Multi-Modal Models on Geometry Problem-Solving\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  60%|███████████████████████████████████▎                       | 1981/3312 [51:12<38:58,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Fine-tuning Large Language Model (LLM) Artificial Intelligence Chatbots in Ophthalmology and LLM-based evaluation using GPT-4\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  60%|███████████████████████████████████▎                       | 1982/3312 [51:13<37:39,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Both Matter: Enhancing the Emotional Intelligence of Large Language Models without Compromising the General Intelligence\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  60%|███████████████████████████████████▎                       | 1983/3312 [51:15<35:56,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Towards Safer Large Language Models through Machine Unlearning\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  60%|███████████████████████████████████▎                       | 1984/3312 [51:16<35:02,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Unmemorization in Large Language Models via Self-Distillation and Deliberate Imagination\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  60%|███████████████████████████████████▎                       | 1985/3312 [51:18<35:21,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: SwissNYF: Tool Grounded LLM Agents for Black Box Setting\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  60%|███████████████████████████████████▍                       | 1986/3312 [51:19<34:09,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: RS-DPO: A Hybrid Rejection Sampling and Direct Preference Optimization Method for Alignment of Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  60%|███████████████████████████████████▍                       | 1987/3312 [51:21<33:39,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Self-Augmented In-Context Learning for Unsupervised Word Translation\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  60%|███████████████████████████████████▍                       | 1988/3312 [51:22<34:00,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LLMs as Bridges: Reformulating Grounded Multimodal Named Entity Recognition\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  60%|███████████████████████████████████▍                       | 1989/3312 [51:24<33:07,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Case Study: Testing Model Capabilities in Some Reasoning Tasks\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  60%|███████████████████████████████████▍                       | 1990/3312 [51:25<32:23,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Crafting a Good Prompt or Providing Exemplary Dialogues? A Study of In-Context Learning for Persona-based Dialogue Generation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  60%|███████████████████████████████████▍                       | 1991/3312 [51:27<31:49,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Generative AI in the Construction Industry: A State-of-the-art Analysis\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  60%|███████████████████████████████████▍                       | 1992/3312 [51:28<34:13,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Enhancing Large Language Models with Pseudo- and Multisource- Knowledge Graphs for Open-ended Question Answering\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  60%|███████████████████████████████████▌                       | 1993/3312 [51:30<33:17,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: DE-COP: Detecting Copyrighted Content in Language Models Training Data\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  60%|███████████████████████████████████▌                       | 1994/3312 [51:31<33:43,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Inadequacies of Large Language Model Benchmarks in the Era of Generative Artificial Intelligence\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  60%|███████████████████████████████████▌                       | 1995/3312 [51:33<33:16,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Camouflage is all you need: Evaluating and Enhancing Language Model Robustness Against Camouflage Adversarial Attacks\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  60%|███████████████████████████████████▌                       | 1996/3312 [51:34<33:17,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: MuChin: A Chinese Colloquial Description Benchmark for Evaluating Language Models in the Field of Music\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  60%|███████████████████████████████████▌                       | 1997/3312 [51:37<38:55,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LAPDoc: Layout-Aware Prompting for Documents\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  60%|███████████████████████████████████▌                       | 1998/3312 [51:38<37:16,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: EFUF: Efficient Fine-grained Unlearning Framework for Mitigating Hallucinations in Multimodal Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 1998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  60%|███████████████████████████████████▌                       | 1999/3312 [51:40<35:19,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: NutePrune: Efficient Progressive Pruning with Numerous Teachers for Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 1999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  60%|███████████████████████████████████▋                       | 2000/3312 [51:41<33:57,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Aligning Crowd Feedback via Distributional Preference Reward Modeling\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  60%|███████████████████████████████████▋                       | 2001/3312 [51:43<33:45,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Grounding Language Model with Chunking-Free In-Context Retrieval\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  60%|███████████████████████████████████▋                       | 2002/3312 [51:44<32:52,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Efficient Language Adaptive Pre-training: Extending State-of-the-Art Large Language Models for Polish\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  60%|███████████████████████████████████▋                       | 2003/3312 [51:46<33:17,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Model Compression and Efficient Inference for Large Language Models: A Survey\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  61%|███████████████████████████████████▋                       | 2004/3312 [51:47<32:59,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: AI Hospital: Interactive Evaluation and Collaboration of LLMs as Intern Doctors for Clinical Diagnosis\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  61%|███████████████████████████████████▋                       | 2005/3312 [51:49<33:29,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Toward a Team of AI-made Scientists for Scientific Discovery from Gene Expression Data\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  61%|███████████████████████████████████▋                       | 2006/3312 [51:50<32:37,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Do LLMs Know about Hallucination? An Empirical Investigation of LLM's Hidden States\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  61%|███████████████████████████████████▊                       | 2007/3312 [51:52<33:38,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: AbuseGPT: Abuse of Generative AI ChatBots to Create Smishing Campaigns\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  61%|███████████████████████████████████▊                       | 2008/3312 [51:53<33:44,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: A Human-Inspired Reading Agent with Gist Memory of Very Long Contexts\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  61%|███████████████████████████████████▊                       | 2009/3312 [51:55<33:49,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Best Arm Identification for Prompt Learning under a Limited Budget\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  61%|███████████████████████████████████▊                       | 2010/3312 [51:56<34:18,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: PAL: Proxy-Guided Black-Box Attack on Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  61%|███████████████████████████████████▊                       | 2011/3312 [51:58<34:19,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: How to Train Data-Efficient LLMs\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  61%|███████████████████████████████████▊                       | 2012/3312 [52:00<36:02,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: CodeMind: A Framework to Challenge Large Language Models for Code Reasoning\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  61%|███████████████████████████████████▊                       | 2013/3312 [52:01<34:54,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: The Butterfly Effect of Model Editing: Few Edits Can Trigger Large Language Models Collapse\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  61%|███████████████████████████████████▉                       | 2014/3312 [52:03<34:03,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ProtChatGPT: Towards Understanding Proteins with Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  61%|███████████████████████████████████▉                       | 2015/3312 [52:04<33:37,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Answer is All You Need: Instruction-following Text Embedding via Answering the Question\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  61%|███████████████████████████████████▉                       | 2016/3312 [52:06<33:09,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LLM-Enhanced User-Item Interactions: Leveraging Edge Information for Optimized Recommendations\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  61%|███████████████████████████████████▉                       | 2017/3312 [52:07<33:00,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Probabilistic Reasoning in Generative Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  61%|███████████████████████████████████▉                       | 2018/3312 [52:09<33:30,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Emerging Opportunities of Using Large Language Models for Translation Between Drug Molecules and Indications\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  61%|███████████████████████████████████▉                       | 2019/3312 [52:11<33:21,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Large Language Model-Based Interpretable Machine Learning Control in Building Energy Systems\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  61%|███████████████████████████████████▉                       | 2020/3312 [52:12<33:32,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Rationality Report Cards: Assessing the Economic Rationality of Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  61%|████████████████████████████████████                       | 2021/3312 [52:14<35:11,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: How Secure Are Large Language Models (LLMs) for Navigation in Urban Environments?\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  61%|████████████████████████████████████                       | 2022/3312 [52:15<33:42,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Arrange, Inpaint, and Refine: Steerable Long-term Music Audio Generation and Editing via Content-based Controls\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  61%|████████████████████████████████████                       | 2023/3312 [52:17<33:13,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: AQA-Bench: An Interactive Benchmark for Evaluating LLMs' Sequential Reasoning Ability\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  61%|████████████████████████████████████                       | 2024/3312 [52:18<32:24,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Reinforcement Learning from Human Feedback with Active Queries\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  61%|████████████████████████████████████                       | 2025/3312 [52:20<32:34,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Get More with LESS: Synthesizing Recurrence with KV Cache Compression for Efficient LLM Inference\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  61%|████████████████████████████████████                       | 2026/3312 [52:22<34:08,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LlaSMol: Advancing Large Language Models for Chemistry with a Large-Scale, Comprehensive, High-Quality Instruction Tuning Dataset\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  61%|████████████████████████████████████                       | 2027/3312 [52:23<35:15,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: HGOT: Hierarchical Graph of Thoughts for Retrieval-Augmented In-Context Learning in Factuality Evaluation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  61%|████████████████████████████████████▏                      | 2028/3312 [52:25<33:42,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Massively Multi-Cultural Knowledge Acquisition & LM Benchmarking\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  61%|████████████████████████████████████▏                      | 2029/3312 [52:26<33:37,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Copyright Traps for Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  61%|████████████████████████████████████▏                      | 2030/3312 [52:28<32:54,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: HiRE: High Recall Approximate Top-$k$ Estimation for Efficient LLM Inference\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  61%|████████████████████████████████████▏                      | 2031/3312 [52:29<32:36,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Developing a Framework for Auditing Large Language Models Using Human-in-the-Loop\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  61%|████████████████████████████████████▏                      | 2032/3312 [52:31<32:01,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: AuditLLM: A Tool for Auditing Large Language Models Using Multiprobe Approach\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  61%|████████████████████████████████████▏                      | 2033/3312 [52:32<31:56,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ICDPO: Effectively Borrowing Alignment Capability of Others via In-context Direct Preference Optimization\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  61%|████████████████████████████████████▏                      | 2034/3312 [52:34<32:06,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Trained Without My Consent: Detecting Code Inclusion In Language Models Trained on Code\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  61%|████████████████████████████████████▎                      | 2035/3312 [52:36<33:54,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Attacks, Defenses and Evaluations for LLM Conversation Safety: A Survey\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  61%|████████████████████████████████████▎                      | 2036/3312 [52:37<33:27,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Leveraging Large Language Models for Enhanced NLP Task Performance through Knowledge Distillation and Optimized Training Strategies\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  62%|████████████████████████████████████▎                      | 2037/3312 [52:39<37:29,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Personalized Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  62%|████████████████████████████████████▎                      | 2038/3312 [52:41<36:50,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Self-Alignment for Factuality: Mitigating Hallucinations in LLMs via Self-Evaluation\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  62%|████████████████████████████████████▎                      | 2039/3312 [52:42<34:38,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: SyntaxShap: Syntax-aware Explainability Method for Text Generation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  62%|████████████████████████████████████▎                      | 2040/3312 [52:44<37:35,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Scaling the Authoring of AutoTutors with Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  62%|████████████████████████████████████▎                      | 2041/3312 [52:46<36:01,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Ten Words Only Still Help: Improving Black-Box AI-Generated Text Detection via Proxy-Guided Efficient Re-Sampling\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  62%|████████████████████████████████████▍                      | 2042/3312 [52:47<34:31,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: (Ir)rationality and Cognitive Biases in Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  62%|████████████████████████████████████▍                      | 2043/3312 [52:49<33:45,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Rapid Adoption, Hidden Risks: The Dual Impact of Large Language Model Customization\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  62%|████████████████████████████████████▍                      | 2044/3312 [52:51<37:06,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Leveraging the Context through Multi-Round Interactions for Jailbreaking Attacks\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  62%|████████████████████████████████████▍                      | 2045/3312 [52:53<34:51,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Attacking Large Language Models with Projected Gradient Descent\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  62%|████████████████████████████████████▍                      | 2046/3312 [52:54<34:38,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Into the Unknown: Self-Learning Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  62%|████████████████████████████████████▍                      | 2047/3312 [52:56<33:37,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Exploring the Adversarial Capabilities of Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  62%|████████████████████████████████████▍                      | 2048/3312 [52:57<32:37,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: MPIrigen: MPI Code Generation through Domain-Specific Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  62%|████████████████████████████████████▌                      | 2049/3312 [52:59<36:48,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Play Guessing Game with LLM: Indirect Jailbreak Attack with Implicit Clues\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  62%|████████████████████████████████████▌                      | 2050/3312 [53:01<34:34,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Soft Prompt Threats: Attacking Safety Alignment and Unlearning in Open-Source LLMs through the Embedding Space\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  62%|████████████████████████████████████▌                      | 2051/3312 [53:02<35:22,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: L3GO: Language Agents with Chain-of-3D-Thoughts for Generating Unconventional Objects\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  62%|████████████████████████████████████▌                      | 2052/3312 [53:04<34:11,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: FGeo-TP: A Language Model-Enhanced Solver for Geometry Problems\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  62%|████████████████████████████████████▌                      | 2053/3312 [53:05<33:23,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: SLEB: Streamlining LLMs through Redundancy Verification and Elimination of Transformer Blocks\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  62%|████████████████████████████████████▌                      | 2054/3312 [53:07<32:34,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Towards better Human-Agent Alignment: Assessing Task Utility in LLM-Powered Applications\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  62%|████████████████████████████████████▌                      | 2055/3312 [53:08<31:55,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Multi-Query Focused Disaster Summarization via Instruction-Based Prompting\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  62%|████████████████████████████████████▋                      | 2056/3312 [53:10<31:11,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: SafeDecoding: Defending against Jailbreak Attacks via Safety-Aware Decoding\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  62%|████████████████████████████████████▋                      | 2057/3312 [53:11<31:18,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: GrounDial: Human-norm Grounded Safe Dialog Response Generation\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  62%|████████████████████████████████████▋                      | 2058/3312 [53:13<31:32,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Generalization in Healthcare AI: Evaluation of a Clinical Large Language Model\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  62%|████████████████████████████████████▋                      | 2059/3312 [53:14<30:49,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Open-Vocabulary Segmentation with Unpaired Mask-Text Supervision\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  62%|████████████████████████████████████▋                      | 2060/3312 [53:16<30:20,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: MUSTARD: Mastering Uniform Synthesis of Theorem and Proof Data\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  62%|████████████████████████████████████▋                      | 2061/3312 [53:17<30:22,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Using Counterfactual Tasks to Evaluate the Generality of Analogical Reasoning in Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  62%|████████████████████████████████████▋                      | 2062/3312 [53:19<30:40,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Premise Order Matters in Reasoning with Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  62%|████████████████████████████████████▊                      | 2063/3312 [53:20<30:11,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: MaxMin-RLHF: Towards Equitable Alignment of Large Language Models with Diverse Human Preferences\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  62%|████████████████████████████████████▊                      | 2064/3312 [53:22<30:40,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Tree-Based Hard Attention with Self-Motivation for Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  62%|████████████████████████████████████▊                      | 2065/3312 [53:23<30:10,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Large Language Model with Graph Convolution for Recommendation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  62%|████████████████████████████████████▊                      | 2066/3312 [53:24<30:29,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: GhostWriter: Augmenting Collaborative Human-AI Writing Experiences Through Personalization and Agency\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  62%|████████████████████████████████████▊                      | 2067/3312 [53:26<31:18,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: eCeLLM: Generalizing Large Language Models for E-commerce from Large-scale, High-quality Instruction Data\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  62%|████████████████████████████████████▊                      | 2068/3312 [53:28<31:38,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Combining Insights From Multiple Large Language Models Improves Diagnostic Accuracy\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  62%|████████████████████████████████████▊                      | 2069/3312 [53:29<32:43,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ChatGPT vs LLaMA: Impact, Reliability, and Challenges in Stack Overflow Discussions\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  62%|████████████████████████████████████▉                      | 2070/3312 [53:31<32:07,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Rethinking Machine Unlearning for Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  63%|████████████████████████████████████▉                      | 2071/3312 [53:32<31:23,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: GLoRe: When, Where, and How to Improve LLM Reasoning via Global and Local Refinements\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  63%|████████████████████████████████████▉                      | 2072/3312 [53:34<31:42,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Measuring and Controlling Instruction (In)Stability in Language Model Dialogs\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  63%|████████████████████████████████████▉                      | 2073/3312 [53:35<31:49,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: JAMDEC: Unsupervised Authorship Obfuscation using Constrained Decoding over Small Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  63%|████████████████████████████████████▉                      | 2074/3312 [53:37<31:11,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LLM-driven Imitation of Subrational Behavior : Illusion or Reality?\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  63%|████████████████████████████████████▉                      | 2075/3312 [53:38<30:47,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Mitigating Object Hallucination in Large Vision-Language Models via Classifier-Free Guidance\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  63%|████████████████████████████████████▉                      | 2076/3312 [53:40<31:31,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: COLD-Attack: Jailbreaking LLMs with Stealthiness and Controllability\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  63%|████████████████████████████████████▉                      | 2077/3312 [53:41<30:59,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Human Curriculum Effects Emerge with In-Context Learning in Neural Networks\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  63%|█████████████████████████████████████                      | 2078/3312 [53:43<30:38,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Improving Generalization in Semantic Parsing by Increasing Natural Language Variation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  63%|█████████████████████████████████████                      | 2079/3312 [53:44<30:48,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: The Last JITAI? The Unreasonable Effectiveness of Large Language Models in Issuing Just-in-Time Adaptive Interventions: Fostering Physical Activity in a Prospective Cardiac Rehabilitation Setting\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  63%|█████████████████████████████████████                      | 2080/3312 [53:46<31:09,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: PIN: Positional Insert Unlocks Object Localisation Abilities in VLMs\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  63%|█████████████████████████████████████                      | 2081/3312 [53:47<31:14,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Tandem Transformers for Inference Efficient LLMs\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  63%|█████████████████████████████████████                      | 2082/3312 [53:49<31:23,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: SemRel2024: A Collection of Semantic Textual Relatedness Datasets for 14 Languages\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  63%|█████████████████████████████████████                      | 2083/3312 [53:50<31:25,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Knowledge Editing on Black-box Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  63%|█████████████████████████████████████                      | 2084/3312 [53:52<31:31,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: PRompt Optimization in Multi-Step Tasks (PROMST): Integrating Human Feedback and Preference Alignment\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  63%|█████████████████████████████████████▏                     | 2085/3312 [53:54<31:27,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Test-Time Backdoor Attacks on Multimodal Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  63%|█████████████████████████████████████▏                     | 2086/3312 [53:55<31:05,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Agent Smith: A Single Image Can Jailbreak One Million Multimodal LLM Agents Exponentially Fast\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  63%|█████████████████████████████████████▏                     | 2087/3312 [53:57<30:53,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Auditing Counterfire: Evaluating Advanced Counterargument Generation with Evidence and Style\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  63%|█████████████████████████████████████▏                     | 2088/3312 [53:58<30:18,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: The Application of ChatGPT in Responding to Questions Related to the Boston Bowel Preparation Scale\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  63%|█████████████████████████████████████▏                     | 2089/3312 [54:00<31:25,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Lying Blindly: Bypassing ChatGPT's Safeguards to Generate Hard-to-Detect Disinformation Claims at Scale\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  63%|█████████████████████████████████████▏                     | 2090/3312 [54:01<31:22,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Large Language Models as Minecraft Agents\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  63%|█████████████████████████████████████▏                     | 2091/3312 [54:03<31:17,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Punctuation Restoration Improves Structure Understanding without Supervision\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  63%|█████████████████████████████████████▎                     | 2092/3312 [54:04<30:54,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Unsupervised Evaluation of Code LLMs with Round-Trip Correctness\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  63%|█████████████████████████████████████▎                     | 2093/3312 [54:06<31:40,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Evaluating the Data Model Robustness of Text-to-SQL Systems Based on Real User Queries\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  63%|█████████████████████████████████████▎                     | 2094/3312 [54:07<31:01,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Visually Dehallucinative Instruction Generation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  63%|█████████████████████████████████████▎                     | 2095/3312 [54:09<30:51,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Eliciting Personality Traits in Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  63%|█████████████████████████████████████▎                     | 2096/3312 [54:10<30:03,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Prompted Contextual Vectors for Spear-Phishing Detection\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  63%|█████████████████████████████████████▎                     | 2097/3312 [54:12<30:10,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ChatCell: Facilitating Single-Cell Analysis with Natural Language\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  63%|█████████████████████████████████████▎                     | 2098/3312 [54:13<30:10,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Towards Faithful and Robust LLM Specialists for Evidence-Based Question-Answering\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  63%|█████████████████████████████████████▍                     | 2099/3312 [54:15<30:13,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: A Survey of Table Reasoning with Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  63%|█████████████████████████████████████▍                     | 2100/3312 [54:16<29:40,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: BERT4FCA: A Method for Bipartite Link Prediction using Formal Concept Analysis and BERT\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  63%|█████████████████████████████████████▍                     | 2101/3312 [54:18<29:17,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Privacy-Preserving Language Model Inference with Instance Obfuscation\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  63%|█████████████████████████████████████▍                     | 2102/3312 [54:19<29:42,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Improving Black-box Robustness with In-Context Rewriting\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  63%|█████████████████████████████████████▍                     | 2103/3312 [54:21<29:48,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: BBox-Adapter: Lightweight Adapting for Black-Box Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  64%|█████████████████████████████████████▍                     | 2104/3312 [54:22<30:03,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LLaGA: Large Language and Graph Assistant\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  64%|█████████████████████████████████████▍                     | 2105/3312 [54:24<33:35,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: On Limitations of the Transformer Architecture\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  64%|█████████████████████████████████████▌                     | 2106/3312 [54:26<32:16,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Verified Multi-Step Synthesis using Large Language Models and Monte Carlo Tree Search\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  64%|█████████████████████████████████████▌                     | 2107/3312 [54:27<33:36,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: On the Resurgence of Recurrent Models for Long Sequences -- Survey and Research Opportunities in the Transformer Era\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  64%|█████████████████████████████████████▌                     | 2108/3312 [54:29<33:03,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: On the Self-Verification Limitations of Large Language Models on Reasoning and Planning Tasks\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  64%|█████████████████████████████████████▌                     | 2109/3312 [54:31<32:51,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Addressing cognitive bias in medical language models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  64%|█████████████████████████████████████▌                     | 2110/3312 [54:32<31:33,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Relative Preference Optimization: Enhancing LLM Alignment through Contrasting Responses across Identical and Diverse Prompts\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  64%|█████████████████████████████████████▌                     | 2111/3312 [54:34<31:00,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Investigating the Impact of Data Contamination of Large Language Models in Text-to-SQL Translation\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  64%|█████████████████████████████████████▌                     | 2112/3312 [54:35<30:11,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Grounding Data Science Code Generation with Input-Output Specifications\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  64%|█████████████████████████████████████▋                     | 2113/3312 [54:36<30:08,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Beyond LLMs: Advancing the Landscape of Complex Reasoning\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  64%|█████████████████████████████████████▋                     | 2114/3312 [54:38<30:02,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Why and When LLM-Based Assistants Can Go Wrong: Investigating the Effectiveness of Prompt-Based Interactions for Software Help-Seeking\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  64%|█████████████████████████████████████▋                     | 2115/3312 [54:40<30:24,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Lumos : Empowering Multimodal LLMs with Scene Text Recognition\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  64%|█████████████████████████████████████▋                     | 2116/3312 [54:41<29:41,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Refined Direct Preference Optimization with Synthetic Data for Behavioral Alignment of LLMs\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  64%|█████████████████████████████████████▋                     | 2117/3312 [54:42<29:34,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Suppressing Pink Elephants with Direct Principle Feedback\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  64%|█████████████████████████████████████▋                     | 2118/3312 [54:44<29:01,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: WildfireGPT: Tailored Large Language Model for Wildfire Analysis\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  64%|█████████████████████████████████████▋                     | 2119/3312 [54:45<29:16,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Policy Improvement using Language Feedback Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  64%|█████████████████████████████████████▊                     | 2120/3312 [54:47<30:03,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: PoisonedRAG: Knowledge Poisoning Attacks to Retrieval-Augmented Generation of Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  64%|█████████████████████████████████████▊                     | 2121/3312 [54:48<29:13,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: AI-Augmented Predictions: LLM Assistants Improve Human Forecasting Accuracy\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  64%|█████████████████████████████████████▊                     | 2122/3312 [54:50<28:45,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Lissard: Long and Simple Sequential Reasoning Datasets\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  64%|█████████████████████████████████████▊                     | 2123/3312 [54:51<29:15,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Mercury: An Efficiency Benchmark for LLM Code Synthesis\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  64%|█████████████████████████████████████▊                     | 2124/3312 [54:53<28:51,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Do Membership Inference Attacks Work on Large Language Models?\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  64%|█████████████████████████████████████▊                     | 2125/3312 [54:54<30:14,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Differentially Private Zeroth-Order Methods for Scalable Large Language Model Finetuning\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  64%|█████████████████████████████████████▊                     | 2126/3312 [54:56<31:27,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Retrieval-Augmented Thought Process as Sequential Decision Making\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  64%|█████████████████████████████████████▉                     | 2127/3312 [54:58<30:18,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: TELLER: A Trustworthy Framework for Explainable, Generalizable and Controllable Fake News Detection\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  64%|█████████████████████████████████████▉                     | 2128/3312 [54:59<30:06,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Quantitative knowledge retrieval from large language models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  64%|█████████████████████████████████████▉                     | 2129/3312 [55:00<29:41,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: AIR-Bench: Benchmarking Large Audio-Language Models via Generative Comprehension\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  64%|█████████████████████████████████████▉                     | 2130/3312 [55:02<29:12,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: CyberMetric: A Benchmark Dataset for Evaluating Large Language Models Knowledge in Cybersecurity\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  64%|█████████████████████████████████████▉                     | 2131/3312 [55:03<29:31,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Large Language Models \"Ad Referendum\": How Good Are They at Machine Translation in the Legal Domain?\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  64%|█████████████████████████████████████▉                     | 2132/3312 [55:05<29:20,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: The Sound of Healthcare: Improving Medical Transcription ASR Accuracy with Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  64%|█████████████████████████████████████▉                     | 2133/3312 [55:06<28:59,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Detecting the Clinical Features of Difficult-to-Treat Depression using Synthetic Data from Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  64%|██████████████████████████████████████                     | 2134/3312 [55:08<30:11,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: G-Retriever: Retrieval-Augmented Generation for Textual Graph Understanding and Question Answering\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  64%|██████████████████████████████████████                     | 2135/3312 [55:09<29:07,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Anchor-based Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  64%|██████████████████████████████████████                     | 2136/3312 [55:11<29:11,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Step-On-Feet Tuning: Scaling Self-Alignment of LLMs via Bootstrapping\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  65%|██████████████████████████████████████                     | 2137/3312 [55:12<29:04,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: BreakGPT: A Large Language Model with Multi-stage Structure for Financial Breakout Detection\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  65%|██████████████████████████████████████                     | 2138/3312 [55:14<28:42,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Secret Collusion Among Generative AI Agents\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  65%|██████████████████████████████████████                     | 2139/3312 [55:15<29:03,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: T-RAG: Lessons from the LLM Trenches\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  65%|██████████████████████████████████████                     | 2140/3312 [55:17<28:30,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Food Recommendation as Language Processing (F-RLP): A Personalized and Contextual Paradigm\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  65%|██████████████████████████████████████▏                    | 2141/3312 [55:18<29:02,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Pushing The Limit of LLM Capacity for Text Classification\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  65%|██████████████████████████████████████▏                    | 2142/3312 [55:20<29:09,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Game Agent Driven by Free-Form Text Command: Using LLM-based Code Generation and Behavior Branch\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  65%|██████████████████████████████████████▏                    | 2143/3312 [55:21<29:00,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Benchmarking and Building Long-Context Retrieval Models with LoCo and M2-BERT\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  65%|██████████████████████████████████████▏                    | 2144/3312 [55:23<31:17,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Large Language Models are Few-shot Generators: Proposing Hybrid Prompt Algorithm To Generate Webshell Escape Samples\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  65%|██████████████████████████████████████▏                    | 2145/3312 [55:25<30:07,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Dólares or Dollars? Unraveling the Bilingual Prowess of Financial LLMs Between Spanish and English\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  65%|██████████████████████████████████████▏                    | 2146/3312 [55:26<29:33,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Can LLMs Produce Faithful Explanations For Fact-checking? Towards Faithful Explainable Fact-Checking via Multi-Agent Debate\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  65%|██████████████████████████████████████▏                    | 2147/3312 [55:28<29:49,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Exploring Perceptual Limitation of Multimodal Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  65%|██████████████████████████████████████▎                    | 2148/3312 [55:29<29:08,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Assessing Generalization for Subpopulation Representative Modeling via In-Context Learning\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  65%|██████████████████████████████████████▎                    | 2149/3312 [55:30<28:34,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Differentially Private Training of Mixture of Experts Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  65%|██████████████████████████████████████▎                    | 2150/3312 [55:32<28:36,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Summing Up the Facts: Additive Mechanisms Behind Factual Recall in LLMs\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  65%|██████████████████████████████████████▎                    | 2151/3312 [55:34<29:45,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ODIN: Disentangled Reward Mitigates Hacking in RLHF\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  65%|██████████████████████████████████████▎                    | 2152/3312 [55:35<28:55,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: A Theoretical Analysis of Nash Learning from Human Feedback under General KL-Regularized Preference\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  65%|██████████████████████████████████████▎                    | 2153/3312 [55:37<29:44,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: How do Large Language Models Navigate Conflicts between Honesty and Helpfulness?\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  65%|██████████████████████████████████████▎                    | 2154/3312 [55:38<28:45,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: TransGPT: Multi-modal Generative Pre-trained Transformer for Transportation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  65%|██████████████████████████████████████▍                    | 2155/3312 [55:40<31:39,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Beware of Words: Evaluating the Lexical Richness of Conversational Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  65%|██████████████████████████████████████▍                    | 2156/3312 [55:41<30:14,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Synergizing Spatial Optimization with Large Language Models for Open-Domain Urban Itinerary Planning\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  65%|██████████████████████████████████████▍                    | 2157/3312 [55:43<30:51,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: GraphTranslator: Aligning Graph Model to Large Language Model for Open-ended Tasks\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  65%|██████████████████████████████████████▍                    | 2158/3312 [55:45<30:22,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Prompt Perturbation in Retrieval-Augmented Generation based Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  65%|██████████████████████████████████████▍                    | 2159/3312 [55:46<30:32,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Large-Language-Model Empowered Dose Volume Histogram Prediction for Intensity Modulated Radiotherapy\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  65%|██████████████████████████████████████▍                    | 2160/3312 [55:48<29:50,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Social Evolution of Published Text and The Emergence of Artificial Intelligence Through Large Language Models and The Problem of Toxicity and Bias\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  65%|██████████████████████████████████████▍                    | 2161/3312 [55:49<29:24,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Effort and Size Estimation in Software Projects with Large Language Model-based Intelligent Interfaces\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  65%|██████████████████████████████████████▌                    | 2162/3312 [55:51<29:36,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Natural Language Reinforcement Learning\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  65%|██████████████████████████████████████▌                    | 2163/3312 [55:53<31:31,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Graph Descriptive Order Improves Reasoning with Large Language Model\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  65%|██████████████████████████████████████▌                    | 2164/3312 [55:55<32:58,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Using Large Language Models for Student-Code Guided Test Case Generation in Computer Science Education\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  65%|██████████████████████████████████████▌                    | 2165/3312 [55:56<31:31,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Exploring the Impact of Large Language Models on Recommender Systems: An Extensive Review\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  65%|██████████████████████████████████████▌                    | 2166/3312 [55:58<31:58,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: A Tale of Tails: Model Collapse as a Change of Scaling Laws\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  65%|██████████████████████████████████████▌                    | 2167/3312 [55:59<32:07,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Fiddler: CPU-GPU Orchestration for Fast Inference of Mixture-of-Experts Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  65%|██████████████████████████████████████▌                    | 2168/3312 [56:01<30:31,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Gemini Goes to Med School: Exploring the Capabilities of Multimodal Large Language Models on Medical Challenge Problems & Hallucinations\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  65%|██████████████████████████████████████▋                    | 2169/3312 [56:03<31:05,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: REALM: RAG-Driven Enhancement of Multimodal Electronic Health Records Analysis via Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  66%|██████████████████████████████████████▋                    | 2170/3312 [56:04<29:55,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: DAEDRA: A language model for predicting outcomes in passive pharmacovigilance reporting\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  66%|██████████████████████████████████████▋                    | 2171/3312 [56:05<29:20,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: A Thorough Examination of Decoding Methods in the Era of LLMs\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  66%|██████████████████████████████████████▋                    | 2172/3312 [56:07<29:00,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Whispers in the Machine: Confidentiality in LLM-integrated Systems\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  66%|██████████████████████████████████████▋                    | 2173/3312 [56:08<28:29,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Generating Chain-of-Thoughts with a Direct Pairwise-Comparison Approach to Searching for the Most Promising Intermediate Thought\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  66%|██████████████████████████████████████▋                    | 2174/3312 [56:10<27:51,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Can LLMs Recognize Toxicity? Structured Toxicity Investigation Framework and Semantic-Based Metric\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  66%|██████████████████████████████████████▋                    | 2175/3312 [56:11<29:16,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: UrbanKGent: A Unified Large Language Model Agent Framework for Urban Knowledge Graph Construction\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  66%|██████████████████████████████████████▊                    | 2176/3312 [56:13<31:26,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: History, Development, and Principles of Large Language Models-An Introductory Survey\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  66%|██████████████████████████████████████▊                    | 2177/3312 [56:15<30:20,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ChemLLM: A Chemical Large Language Model\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  66%|██████████████████████████████████████▊                    | 2178/3312 [56:16<29:24,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Forecasting Events in Soccer Matches Through Language\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  66%|██████████████████████████████████████▊                    | 2179/3312 [56:18<28:21,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: The Unreasonable Effectiveness of Eccentric Automatic Prompts\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  66%|██████████████████████████████████████▊                    | 2180/3312 [56:19<27:53,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Estimating Player Performance in Different Contexts Using Fine-tuned Large Events Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  66%|██████████████████████████████████████▊                    | 2181/3312 [56:21<28:00,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Is it safe to cross? Interpretable Risk Assessment with GPT-4V for Safety-Aware Street Crossing\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  66%|██████████████████████████████████████▊                    | 2182/3312 [56:22<27:27,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Debating with More Persuasive LLMs Leads to More Truthful Answers\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  66%|██████████████████████████████████████▉                    | 2183/3312 [56:23<27:21,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: GLaM: Fine-Tuning Large Language Models for Domain Knowledge Graph Alignment via Neighborhood Partitioning and Generative Subgraph Encoding\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  66%|██████████████████████████████████████▉                    | 2184/3312 [56:25<26:48,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: EntGPT: Linking Generative Large Language Models with Knowledge Bases\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  66%|██████████████████████████████████████▉                    | 2185/3312 [56:26<27:07,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: NICE: To Optimize In-Context Examples or Not?\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  66%|██████████████████████████████████████▉                    | 2186/3312 [56:28<27:14,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Feedback Loops With Language Models Drive In-Context Reward Hacking\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  66%|██████████████████████████████████████▉                    | 2187/3312 [56:29<27:26,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Understanding the Effects of Iterative Prompting on Truthfulness\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  66%|██████████████████████████████████████▉                    | 2188/3312 [56:31<27:30,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: If Turing played piano with an artificial partner\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  66%|██████████████████████████████████████▉                    | 2189/3312 [56:32<27:24,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: TIC: Translate-Infer-Compile for accurate 'text to plan' using LLMs and logical intermediate representations\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  66%|███████████████████████████████████████                    | 2190/3312 [56:34<26:53,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: On the Out-Of-Distribution Generalization of Multimodal Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  66%|███████████████████████████████████████                    | 2191/3312 [56:35<27:14,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Understanding the Weakness of Large Language Model Agents within a Complex Android Environment\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  66%|███████████████████████████████████████                    | 2192/3312 [56:36<26:47,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: G-SciEdBERT: A Contextualized LLM for Science Assessment Tasks in German\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  66%|███████████████████████████████████████                    | 2193/3312 [56:38<26:41,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: The Quantified Boolean Bayesian Network: Theory and Experiments with a Logical Graphical Model\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  66%|███████████████████████████████████████                    | 2194/3312 [56:39<27:23,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Calibrating Long-form Generations from Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  66%|███████████████████████████████████████                    | 2195/3312 [56:41<27:44,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Introspective Planning: Guiding Language-Enabled Agents to Refine Their Own Uncertainty\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  66%|███████████████████████████████████████                    | 2196/3312 [56:43<29:18,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Large Language Models for Captioning and Retrieving Remote Sensing Images\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  66%|███████████████████████████████████████▏                   | 2197/3312 [56:44<29:04,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: V-STaR: Training Verifiers for Self-Taught Reasoners\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  66%|███████████████████████████████████████▏                   | 2198/3312 [56:46<28:43,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: CoSearchAgent: A Lightweight Collaborative Search Agent with Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  66%|███████████████████████████████████████▏                   | 2199/3312 [56:47<28:12,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: RareBench: Can LLMs Serve as Rare Diseases Specialists?\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  66%|███████████████████████████████████████▏                   | 2200/3312 [56:49<28:16,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ExaRanker-Open: Synthetic Explanation for IR using Open-Source LLMs\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  66%|███████████████████████████████████████▏                   | 2201/3312 [56:50<27:56,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: InternLM-Math: Open Math Large Language Models Toward Verifiable Reasoning\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  66%|███████████████████████████████████████▏                   | 2202/3312 [56:52<28:15,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Zero-shot Explainable Mental Health Analysis on Social Media by Incorporating Mental Scales\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  67%|███████████████████████████████████████▏                   | 2203/3312 [56:53<27:51,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LLaVA-Docent: Instruction Tuning with Multimodal Large Language Model to Support Art Appreciation Education\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  67%|███████████████████████████████████████▎                   | 2204/3312 [56:55<28:52,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: On the Efficacy of Eviction Policy for Key-Value Constrained Generative Language Model Inference\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  67%|███████████████████████████████████████▎                   | 2205/3312 [56:56<27:56,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Studious Bob Fight Back Against Jailbreaking via Prompt Adversarial Tuning\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  67%|███████████████████████████████████████▎                   | 2206/3312 [56:58<28:26,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Entropy-Regularized Token-Level Policy Optimization for Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  67%|███████████████████████████████████████▎                   | 2207/3312 [57:00<29:13,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Exploring Interaction Patterns for Debugging: Enhancing Conversational Capabilities of AI-assistants\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  67%|███████████████████████████████████████▎                   | 2208/3312 [57:01<28:02,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ResumeFlow: An LLM-facilitated Pipeline for Personalized Resume Generation and Refinement\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  67%|███████████████████████████████████████▎                   | 2209/3312 [57:03<28:32,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: The Generative AI Paradox on Evaluation: What It Can Solve, It May Not Evaluate\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  67%|███████████████████████████████████████▎                   | 2210/3312 [57:04<28:03,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Large Language Models: A Survey\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  67%|███████████████████████████████████████▍                   | 2211/3312 [57:06<28:42,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: CultureLLM: Incorporating Cultural Differences into Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  67%|███████████████████████████████████████▍                   | 2212/3312 [57:07<28:22,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Learn To be Efficient: Build Structured Sparsity in Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  67%|███████████████████████████████████████▍                   | 2213/3312 [57:09<28:12,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Exploring Group and Symmetry Principles in Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  67%|███████████████████████████████████████▍                   | 2214/3312 [57:10<27:17,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ContPhy: Continuum Physical Concept Learning and Reasoning from Videos\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  67%|███████████████████████████████████████▍                   | 2215/3312 [57:12<27:20,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ViGoR: Improving Visual Grounding of Large Vision Language Models with Fine-Grained Reward Modeling\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  67%|███████████████████████████████████████▍                   | 2216/3312 [57:13<28:41,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LLMs for Coding and Robotics Education\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  67%|███████████████████████████████████████▍                   | 2217/3312 [57:15<28:08,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: SubGen: Token Generation in Sublinear Time and Memory\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  67%|███████████████████████████████████████▌                   | 2218/3312 [57:17<29:17,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Large Language Model Augmented Exercise Retrieval for Personalized Language Learning\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  67%|███████████████████████████████████████▌                   | 2219/3312 [57:18<28:27,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: OpenToM: A Comprehensive Benchmark for Evaluating Theory-of-Mind Reasoning Capabilities of Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  67%|███████████████████████████████████████▌                   | 2220/3312 [57:20<28:53,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: A Prompt Response to the Demand for Automatic Gender-Neutral Translation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  67%|███████████████████████████████████████▌                   | 2221/3312 [57:22<29:37,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Exploring Visual Culture Awareness in GPT-4V: A Comprehensive Probing\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  67%|███████████████████████████████████████▌                   | 2222/3312 [57:23<28:55,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LLMs Among Us: Generative AI Participating in Digital Discourse\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  67%|███████████████████████████████████████▌                   | 2223/3312 [57:25<28:24,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: WebLINX: Real-World Website Navigation with Multi-Turn Dialogue\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  67%|███████████████████████████████████████▌                   | 2224/3312 [57:26<28:04,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: On the Convergence of Zeroth-Order Federated Tuning for Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  67%|███████████████████████████████████████▋                   | 2225/3312 [57:28<27:22,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Efficient Stagewise Pretraining via Progressive Subnetworks\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  67%|███████████████████████████████████████▋                   | 2226/3312 [57:29<26:47,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: FACT-GPT: Fact-Checking Augmentation via Claim Matching with LLMs\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  67%|███████████████████████████████████████▋                   | 2227/3312 [57:30<26:49,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Large Language Model Meets Graph Neural Network in Knowledge Distillation\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  67%|███████████████████████████████████████▋                   | 2228/3312 [57:32<26:50,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: CREMA: Multimodal Compositional Video Reasoning via Efficient Modular Adaptation and Fusion\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  67%|███████████████████████████████████████▋                   | 2229/3312 [57:33<26:34,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Generative Echo Chamber? Effects of LLM-Powered Search Systems on Diverse Information Seeking\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  67%|███████████████████████████████████████▋                   | 2230/3312 [57:35<26:55,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: EmojiCrypt: Prompt Encryption for Secure Communication with Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  67%|███████████████████████████████████████▋                   | 2231/3312 [57:36<27:17,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: How Well Can LLMs Negotiate? NegotiationArena Platform and Analysis\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  67%|███████████████████████████████████████▊                   | 2232/3312 [57:38<26:47,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Is it Possible to Edit Large Language Models Robustly?\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  67%|███████████████████████████████████████▊                   | 2233/3312 [57:39<27:09,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Training Large Language Models for Reasoning through Reverse Curriculum Reinforcement Learning\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  67%|███████████████████████████████████████▊                   | 2234/3312 [57:41<26:45,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Limits of Transformer Language Models on Learning Algorithmic Compositions\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  67%|███████████████████████████████████████▊                   | 2235/3312 [57:42<26:20,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Text-to-Code Generation with Modality-relative Pre-training\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  68%|███████████████████████████████████████▊                   | 2236/3312 [57:44<27:53,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Examining Gender and Racial Bias in Large Vision-Language Models Using a Novel Dataset of Parallel Images\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  68%|███████████████████████████████████████▊                   | 2237/3312 [57:46<29:25,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: TimeArena: Shaping Efficient Multitasking Language Agents in a Time-Aware Simulation\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  68%|███████████████████████████████████████▊                   | 2238/3312 [57:48<30:38,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: In-Context Learning Can Re-learn Forbidden Tasks\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  68%|███████████████████████████████████████▉                   | 2239/3312 [57:49<29:01,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Unified Speech-Text Pretraining for Spoken Dialog Modeling\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  68%|███████████████████████████████████████▉                   | 2240/3312 [57:51<28:03,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Self-Alignment of Large Language Models via Monopolylogue-based Social Scene Simulation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  68%|███████████████████████████████████████▉                   | 2241/3312 [57:52<27:33,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Comprehensive Assessment of Jailbreak Attacks Against LLMs\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  68%|███████████████████████████████████████▉                   | 2242/3312 [57:54<26:59,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Rocks Coding, Not Development--A Human-Centric, Experimental Evaluation of LLM-Supported SE Tasks\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  68%|███████████████████████████████████████▉                   | 2243/3312 [57:55<26:09,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Anfinsen Goes Neural: a Graphical Model for Conditional Antibody Design\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  68%|███████████████████████████████████████▉                   | 2244/3312 [57:57<27:44,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: The Impact of AI Tool on Engineering at ANZ Bank An Emperical Study on GitHub Copilot within Coporate Environment\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  68%|███████████████████████████████████████▉                   | 2245/3312 [57:58<26:51,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Merging Facts, Crafting Fallacies: Evaluating the Contradictory Nature of Aggregated Factual Claims in Long-Form Generations\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  68%|████████████████████████████████████████                   | 2246/3312 [58:00<27:17,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Efficient Models for the Detection of Hate, Abuse and Profanity\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  68%|████████████████████████████████████████                   | 2247/3312 [58:01<27:15,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: AttnLRP: Attention-Aware Layer-wise Relevance Propagation for Transformers\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  68%|████████████████████████████████████████                   | 2248/3312 [58:03<26:28,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Benchmarking Large Language Models on Communicative Medical Coaching: a Novel System and Dataset\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  68%|████████████████████████████████████████                   | 2249/3312 [58:04<25:56,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Can ChatGPT evaluate research quality?\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  68%|████████████████████████████████████████                   | 2250/3312 [58:05<25:32,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Question Aware Vision Transformer for Multimodal Reasoning\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  68%|████████████████████████████████████████                   | 2251/3312 [58:07<28:12,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Rapid Optimization for Jailbreaking LLMs via Subconscious Exploitation and Echopraxia\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  68%|████████████████████████████████████████                   | 2252/3312 [58:09<27:13,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: It's Never Too Late: Fusing Acoustic Information into Large Language Models for Automatic Speech Recognition\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  68%|████████████████████████████████████████▏                  | 2253/3312 [58:11<28:22,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Large Language Models for Psycholinguistic Plausibility Pretesting\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  68%|████████████████████████████████████████▏                  | 2254/3312 [58:12<27:19,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Accurate LoRA-Finetuning Quantization of LLMs via Information Retention\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  68%|████████████████████████████████████████▏                  | 2255/3312 [58:13<27:13,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Do Large Code Models Understand Programming Concepts? A Black-box Approach\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  68%|████████████████████████████████████████▏                  | 2256/3312 [58:15<27:09,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: GPT-4 Generated Narratives of Life Events using a Structured Narrative Prompt: A Validation Study\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  68%|████████████████████████████████████████▏                  | 2257/3312 [58:17<27:09,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Everybody Prune Now: Structured Pruning of LLMs with only Forward Passes\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  68%|████████████████████████████████████████▏                  | 2258/3312 [58:18<26:21,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: In-Context Principle Learning from Mistakes\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  68%|████████████████████████████████████████▏                  | 2259/3312 [58:20<26:46,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Enhancing Zero-shot Counting via Language-guided Exemplar Learning\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  68%|████████████████████████████████████████▎                  | 2260/3312 [58:21<26:42,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: CIC: A framework for Culturally-aware Image Captioning\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  68%|████████████████████████████████████████▎                  | 2261/3312 [58:23<26:53,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Prompting with Divide-and-Conquer Program Makes Large Language Models Discerning to Hallucination and Deception\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  68%|████████████████████████████████████████▎                  | 2262/3312 [58:24<26:45,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Scaling Up LLM Reviews for Google Ads Content Moderation\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  68%|████████████████████████████████████████▎                  | 2263/3312 [58:26<26:05,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Using text embedding models and vector databases as text classifiers with the example of medical data\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  68%|████████████████████████████████████████▎                  | 2264/3312 [58:27<26:16,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Are LLMs Ready for Real-World Materials Discovery?\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  68%|████████████████████████████████████████▎                  | 2265/3312 [58:29<26:04,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: $λ$-ECLIPSE: Multi-Concept Personalized Text-to-Image Diffusion Models by Leveraging CLIP Latent Space\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  68%|████████████████████████████████████████▎                  | 2266/3312 [58:30<26:49,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: InCoRo: In-Context Learning for Robotics Control with Feedback Loops\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  68%|████████████████████████████████████████▍                  | 2267/3312 [58:32<28:15,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Opening the AI black box: program synthesis via mechanistic interpretability\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  68%|████████████████████████████████████████▍                  | 2268/3312 [58:33<27:07,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Hydragen: High-Throughput LLM Inference with Shared Prefixes\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  69%|████████████████████████████████████████▍                  | 2269/3312 [58:35<26:09,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Language-Based Augmentation to Address Shortcut Learning in Object Goal Navigation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  69%|████████████████████████████████████████▍                  | 2270/3312 [58:36<25:28,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Assessing the Brittleness of Safety Alignment via Pruning and Low-Rank Modifications\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  69%|████████████████████████████████████████▍                  | 2271/3312 [58:38<26:35,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: SALAD-Bench: A Hierarchical and Comprehensive Safety Benchmark for Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  69%|████████████████████████████████████████▍                  | 2272/3312 [58:40<27:17,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: A Sober Look at LLMs for Material Discovery: Are They Actually Good for Bayesian Optimization Over Molecules?\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  69%|████████████████████████████████████████▍                  | 2273/3312 [58:41<26:17,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Pedagogical Alignment of Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  69%|████████████████████████████████████████▌                  | 2274/3312 [58:43<26:51,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: An Enhanced Prompt-Based LLM Reasoning Scheme via Knowledge Graph-Integrated Collaboration\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  69%|████████████████████████████████████████▌                  | 2275/3312 [58:44<26:01,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ChatScratch: An AI-Augmented System Toward Autonomous Visual Programming Learning for Children Aged 6-12\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  69%|████████████████████████████████████████▌                  | 2276/3312 [58:46<26:49,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Reconfidencing LLMs from the Grouping Loss Perspective\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  69%|████████████████████████████████████████▌                  | 2277/3312 [58:47<26:27,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Chatbots in Knowledge-Intensive Contexts: Comparing Intent and LLM-Based Systems\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  69%|████████████████████████████████████████▌                  | 2278/3312 [58:49<26:29,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Prompting Implicit Discourse Relation Annotation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  69%|████████████████████████████████████████▌                  | 2279/3312 [58:50<26:10,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: L4Q: Parameter Efficient Quantization-Aware Training on Large Language Models via LoRA-wise LSQ\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  69%|████████████████████████████████████████▌                  | 2280/3312 [58:52<26:02,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Detecting Generated Native Ads in Conversational Search\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  69%|████████████████████████████████████████▋                  | 2281/3312 [58:53<25:16,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Guiding LLMs The Right Way: Fast, Non-Invasive Constrained Generation\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  69%|████████████████████████████████████████▋                  | 2282/3312 [58:55<25:30,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Long Is More for Alignment: A Simple but Tough-to-Beat Baseline for Instruction Fine-Tuning\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  69%|████████████████████████████████████████▋                  | 2283/3312 [58:56<25:15,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Direct Language Model Alignment from Online AI Feedback\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  69%|████████████████████████████████████████▋                  | 2284/3312 [58:57<25:29,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: MLLM-as-a-Judge: Assessing Multimodal LLM-as-a-Judge with Vision-Language Benchmark\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  69%|████████████████████████████████████████▋                  | 2285/3312 [58:59<25:25,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: A Hypothesis-Driven Framework for the Analysis of Self-Rationalising Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  69%|████████████████████████████████████████▋                  | 2286/3312 [59:00<24:41,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ApiQ: Finetuning of 2-Bit Quantized Large Language Model\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  69%|████████████████████████████████████████▋                  | 2287/3312 [59:02<25:00,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Large Language Models As Faithful Explainers\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  69%|████████████████████████████████████████▊                  | 2288/3312 [59:03<24:40,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LEVI: Generalizable Fine-tuning via Layer-wise Ensemble of Different Views\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  69%|████████████████████████████████████████▊                  | 2289/3312 [59:05<24:28,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: The Future of Cognitive Strategy-enhanced Persuasive Dialogue Agents: New Perspectives and Trends\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  69%|████████████████████████████████████████▊                  | 2290/3312 [59:07<28:10,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: SPARQL Generation: an analysis on fine-tuning OpenLLaMA for Question Answering over a Life Science Knowledge Graph\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  69%|████████████████████████████████████████▊                  | 2291/3312 [59:08<27:52,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: MEMORYLLM: Towards Self-Updatable Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  69%|████████████████████████████████████████▊                  | 2292/3312 [59:10<27:18,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: CataractBot: An LLM-Powered Expert-in-the-Loop Chatbot for Cataract Patients\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  69%|████████████████████████████████████████▊                  | 2293/3312 [59:11<26:15,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: InfLLM: Unveiling the Intrinsic Capacity of LLMs for Understanding Extremely Long Sequences with Training-Free Memory\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  69%|████████████████████████████████████████▊                  | 2294/3312 [59:13<25:53,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: TinyLLM: Learning a Small Student from Multiple Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  69%|████████████████████████████████████████▉                  | 2295/3312 [59:14<25:41,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Faithfulness vs. Plausibility: On the (Un)Reliability of Explanations from Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  69%|████████████████████████████████████████▉                  | 2296/3312 [59:16<24:50,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Improving Cross-Domain Low-Resource Text Generation through LLM Post-Editing: A Programmer-Interpreter Approach\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  69%|████████████████████████████████████████▉                  | 2297/3312 [59:17<24:32,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Alirector: Alignment-Enhanced Chinese Grammatical Error Corrector\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  69%|████████████████████████████████████████▉                  | 2298/3312 [59:19<25:26,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: The Role of LLMs in Sustainable Smart Cities: Applications, Challenges, and Future Directions\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  69%|████████████████████████████████████████▉                  | 2299/3312 [59:20<25:46,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Can Large Language Model Agents Simulate Human Trust Behaviors?\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  69%|████████████████████████████████████████▉                  | 2300/3312 [59:22<25:09,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: An Artificial Intelligence (AI) workflow for catalyst design and optimization\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  69%|████████████████████████████████████████▉                  | 2301/3312 [59:23<25:19,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: RA-Rec: An Efficient ID Representation Alignment Framework for LLM-based Recommendation\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  70%|█████████████████████████████████████████                  | 2302/3312 [59:25<24:41,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Online Cascade Learning for Efficient Inference over Streams\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  70%|█████████████████████████████████████████                  | 2303/3312 [59:26<24:38,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: The Fine-Grained Complexity of Gradient Computation for Training Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  70%|█████████████████████████████████████████                  | 2304/3312 [59:28<24:50,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Grandmaster-Level Chess Without Search\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  70%|█████████████████████████████████████████                  | 2305/3312 [59:29<24:18,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: De-amplifying Bias from Differential Privacy in Language Model Fine-tuning\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  70%|█████████████████████████████████████████                  | 2306/3312 [59:31<24:45,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Unmasking the Shadows of AI: Investigating Deceptive Capabilities in Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  70%|█████████████████████████████████████████                  | 2307/3312 [59:32<24:32,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Detecting Mode Collapse in Language Models via Narration\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  70%|█████████████████████████████████████████                  | 2308/3312 [59:33<24:29,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Structured Entity Extraction Using Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  70%|█████████████████████████████████████████▏                 | 2309/3312 [59:35<24:27,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Chatbot Meets Pipeline: Augment Large Language Model with Definite Finite Automaton\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  70%|█████████████████████████████████████████▏                 | 2310/3312 [59:37<26:00,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Democratizing Large Language Models via Personalized Parameter-Efficient Fine-tuning\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  70%|█████████████████████████████████████████▏                 | 2311/3312 [59:38<26:58,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Fine-Tuned Language Models Generate Stable Inorganic Materials as Text\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  70%|█████████████████████████████████████████▏                 | 2312/3312 [59:40<26:52,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Monitoring the evolution of antisemitic discourse on extremist social media using BERT\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  70%|█████████████████████████████████████████▏                 | 2313/3312 [59:42<26:24,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: The World of Generative AI: Deepfakes and Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  70%|█████████████████████████████████████████▏                 | 2314/3312 [59:43<25:21,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Tag-LLM: Repurposing General-Purpose LLMs for Specialized Domains\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  70%|█████████████████████████████████████████▏                 | 2315/3312 [59:44<24:37,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: The Hedgehog & the Porcupine: Expressive Linear Attentions with Softmax Mimicry\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  70%|█████████████████████████████████████████▎                 | 2316/3312 [59:46<25:28,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LESS: Selecting Influential Data for Targeted Instruction Tuning\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  70%|█████████████████████████████████████████▎                 | 2317/3312 [59:47<24:50,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Training Language Models to Generate Text with Citations via Fine-grained Rewards\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  70%|█████████████████████████████████████████▎                 | 2318/3312 [59:49<24:37,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: HarmBench: A Standardized Evaluation Framework for Automated Red Teaming and Robust Refusal\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  70%|█████████████████████████████████████████▎                 | 2319/3312 [59:50<24:23,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Prioritizing Safeguarding Over Autonomy: Risks of LLM Agents for Science\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  70%|█████████████████████████████████████████▎                 | 2320/3312 [59:52<23:55,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Can Generative Agents Predict Emotion?\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  70%|█████████████████████████████████████████▎                 | 2321/3312 [59:53<24:05,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Scaling Laws for Downstream Task Performance of Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  70%|█████████████████████████████████████████▎                 | 2322/3312 [59:55<24:50,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Harnessing the Plug-and-Play Controller by Prompting\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  70%|█████████████████████████████████████████▍                 | 2323/3312 [59:56<24:38,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Multi-line AI-assisted Code Authoring\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  70%|█████████████████████████████████████████▍                 | 2324/3312 [59:58<25:12,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Advancing Legal Reasoning: The Integration of AI to Navigate Complexities and Biases in Global Jurisprudence with Semi-Automated Arbitration Processes (SAAPs)\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  70%|█████████████████████████████████████████▍                 | 2325/3312 [59:59<24:32,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Scientific Language Modeling: A Quantitative Review of Large Language Models in Molecular Science\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  70%|████████████████████████████████████████                 | 2326/3312 [1:00:01<25:57,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Measuring Implicit Bias in Explicitly Unbiased Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  70%|████████████████████████████████████████                 | 2327/3312 [1:00:02<24:56,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: The Use of a Large Language Model for Cyberbullying Detection\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  70%|████████████████████████████████████████                 | 2328/3312 [1:00:04<25:00,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Provably learning a multi-head attention layer\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  70%|████████████████████████████████████████                 | 2329/3312 [1:00:06<26:26,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Systematic Biases in LLM Simulations of Debates\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  70%|████████████████████████████████████████                 | 2330/3312 [1:00:08<27:02,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LLM Agents can Autonomously Hack Websites\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  70%|████████████████████████████████████████                 | 2331/3312 [1:00:09<25:42,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Understanding the Effect of Noise in LLM Training Data with Algorithmic Chains of Thought\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  70%|████████████████████████████████████████▏                | 2332/3312 [1:00:10<24:47,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Enhancing Retrieval Processes for Language Generation with Augmented Queries\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  70%|████████████████████████████████████████▏                | 2333/3312 [1:00:12<24:10,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LV-Eval: A Balanced Long-Context Benchmark with 5 Length Levels Up to 256K\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  70%|████████████████████████████████████████▏                | 2334/3312 [1:00:13<23:36,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Discovery of the Hidden World with Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  71%|████████████████████████████████████████▏                | 2335/3312 [1:00:15<26:10,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Leak, Cheat, Repeat: Data Contamination and Evaluation Malpractices in Closed-Source LLMs\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  71%|████████████████████████████████████████▏                | 2336/3312 [1:00:16<25:30,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Large Language Models to Enhance Bayesian Optimization\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  71%|████████████████████████████████████████▏                | 2337/3312 [1:00:18<25:43,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Can Large Language Models Detect Rumors on Social Media?\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  71%|████████████████████████████████████████▏                | 2338/3312 [1:00:20<25:30,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Embedding Large Language Models into Extended Reality: Opportunities and Challenges for Inclusion, Engagement, and Privacy\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  71%|████████████████████████████████████████▎                | 2339/3312 [1:00:21<25:45,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: DistiLLM: Towards Streamlined Distillation for Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  71%|████████████████████████████████████████▎                | 2340/3312 [1:00:23<25:24,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Beyond Lines and Circles: Unveiling the Geometric Reasoning Gap in Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  71%|████████████████████████████████████████▎                | 2341/3312 [1:00:24<24:54,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ANLS* -- A Universal Document Processing Metric for Generative Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  71%|████████████████████████████████████████▎                | 2342/3312 [1:00:26<24:47,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: BiLLM: Pushing the Limit of Post-Training Quantization for LLMs\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  71%|████████████████████████████████████████▎                | 2343/3312 [1:00:27<24:07,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Rethinking Skill Extraction in the Job Market Domain using Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  71%|████████████████████████████████████████▎                | 2344/3312 [1:00:29<24:08,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: RevOrder: A Novel Method for Enhanced Arithmetic in Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  71%|████████████████████████████████████████▎                | 2345/3312 [1:00:30<23:33,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ReLU$^2$ Wins: Discovering Efficient Activation Functions for Sparse LLMs\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  71%|████████████████████████████████████████▍                | 2346/3312 [1:00:32<23:31,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Exploring Low-Resource Medical Image Classification with Weakly Supervised Prompt Learning\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  71%|████████████████████████████████████████▍                | 2347/3312 [1:00:33<23:22,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: MolTC: Towards Molecular Relational Modeling In Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  71%|████████████████████████████████████████▍                | 2348/3312 [1:00:34<23:27,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Large Language Models As MOOCs Graders\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  71%|████████████████████████████████████████▍                | 2349/3312 [1:00:36<23:44,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: The Instinctive Bias: Spurious Images lead to Hallucination in MLLMs\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  71%|████████████████████████████████████████▍                | 2350/3312 [1:00:37<23:21,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: INSIDE: LLMs' Internal States Retain the Power of Hallucination Detection\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  71%|████████████████████████████████████████▍                | 2351/3312 [1:00:39<23:04,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Similarity-based Neighbor Selection for Graph LLMs\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  71%|████████████████████████████████████████▍                | 2352/3312 [1:00:41<25:05,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Automatic Robotic Development through Collaborative Framework by Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  71%|████████████████████████████████████████▍                | 2353/3312 [1:00:42<24:27,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Personalized Language Modeling from Personalized Human Feedback\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  71%|████████████████████████████████████████▌                | 2354/3312 [1:00:44<23:49,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Large Language Models as an Indirect Reasoner: Contrapositive and Contradiction for Automated Reasoning\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  71%|████████████████████████████████████████▌                | 2355/3312 [1:00:45<24:41,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Limits of Large Language Models in Debating Humans\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  71%|████████████████████████████████████████▌                | 2356/3312 [1:00:47<23:55,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Learning to Generate Explainable Stock Predictions using Self-Reflective Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  71%|████████████████████████████████████████▌                | 2357/3312 [1:00:48<23:57,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Sentiment-enhanced Graph-based Sarcasm Explanation in Dialogue\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  71%|████████████████████████████████████████▌                | 2358/3312 [1:00:50<23:32,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Enhancing LLM-Based Coding Tools through Native Integration of IDE-Derived Static Context\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  71%|████████████████████████████████████████▌                | 2359/3312 [1:00:51<23:05,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Partially Recentralization Softmax Loss for Vision-Language Models Robustness\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  71%|████████████████████████████████████████▌                | 2360/3312 [1:00:52<23:26,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Self-Discover: Large Language Models Self-Compose Reasoning Structures\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  71%|████████████████████████████████████████▋                | 2361/3312 [1:00:55<26:42,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Improving Contextual Congruence Across Modalities for Effective Multimodal Marketing using Knowledge-infused Learning\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  71%|████████████████████████████████████████▋                | 2362/3312 [1:00:56<26:18,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Distinguishing the Knowable from the Unknowable with Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  71%|████████████████████████████████████████▋                | 2363/3312 [1:00:58<25:31,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Evaluating the Factuality of Zero-shot Summarizers Across Varied Domains\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  71%|████████████████████████████████████████▋                | 2364/3312 [1:00:59<24:41,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Neural networks for abstraction and reasoning: Towards broad generalization in machines\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  71%|████████████████████████████████████████▋                | 2365/3312 [1:01:01<24:11,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Beyond Text: Improving LLM's Decision Making for Robot Navigation via Vocal Cues\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  71%|████████████████████████████████████████▋                | 2366/3312 [1:01:02<25:08,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: A Systematic Survey of Prompt Engineering in Large Language Models: Techniques and Applications\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  71%|████████████████████████████████████████▋                | 2367/3312 [1:01:04<24:15,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Arabic Synonym BERT-based Adversarial Examples for Text Classification\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  71%|████████████████████████████████████████▊                | 2368/3312 [1:01:05<23:59,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Nevermind: Instruction Override and Moderation in Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  72%|████████████████████████████████████████▊                | 2369/3312 [1:01:07<25:52,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  72%|████████████████████████████████████████▊                | 2370/3312 [1:01:09<26:22,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: GUARD: Role-playing to Generate Natural-language Jailbreakings to Test Guideline Adherence of Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  72%|████████████████████████████████████████▊                | 2371/3312 [1:01:10<24:57,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Make Every Move Count: LLM-based High-Quality RTL Code Generation Using MCTS\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  72%|████████████████████████████████████████▊                | 2372/3312 [1:01:12<24:28,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Deal, or no deal (or who knows)? Forecasting Uncertainty in Conversations using Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  72%|████████████████████████████████████████▊                | 2373/3312 [1:01:13<23:40,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: A Framework for Partially Observed Reward-States in RLHF\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  72%|████████████████████████████████████████▊                | 2374/3312 [1:01:15<23:01,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: MobilityGPT: Enhanced Human Mobility Modeling with a GPT model\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  72%|████████████████████████████████████████▊                | 2375/3312 [1:01:16<22:29,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: English Prompts are Better for NLI-based Zero-Shot Emotion Classification than Target-Language Prompts\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  72%|████████████████████████████████████████▉                | 2376/3312 [1:01:18<23:05,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Unified Hallucination Detection for Multimodal Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  72%|████████████████████████████████████████▉                | 2377/3312 [1:01:19<23:10,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LB-KBQA: Large-language-model and BERT based Knowledge-Based Question and Answering System\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  72%|████████████████████████████████████████▉                | 2378/3312 [1:01:21<23:00,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Empowering Time Series Analysis with Large Language Models: A Survey\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  72%|████████████████████████████████████████▉                | 2379/3312 [1:01:22<22:35,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: C-RAG: Certified Generation Risks for Retrieval-Augmented Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  72%|████████████████████████████████████████▉                | 2380/3312 [1:01:23<22:18,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: CIDAR: Culturally Relevant Instruction Dataset For Arabic\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  72%|████████████████████████████████████████▉                | 2381/3312 [1:01:25<22:39,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: The Matrix: A Bayesian learning model for LLMs\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  72%|████████████████████████████████████████▉                | 2382/3312 [1:01:26<22:44,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: MULTI: Multimodal Understanding Leaderboard with Text and Images\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  72%|█████████████████████████████████████████                | 2383/3312 [1:01:28<22:22,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Homograph Attacks on Maghreb Sentiment Analyzers\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  72%|█████████████████████████████████████████                | 2384/3312 [1:01:29<22:57,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Video-LaVIT: Unified Video-Language Pre-training with Decoupled Visual-Motional Tokenization\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  72%|█████████████████████████████████████████                | 2385/3312 [1:01:31<22:35,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Constrained Decoding for Cross-lingual Label Projection\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  72%|█████████████████████████████████████████                | 2386/3312 [1:01:32<22:10,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Evaluation of ChatGPT Usability as A Code Generation Tool\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  72%|█████████████████████████████████████████                | 2387/3312 [1:01:34<22:19,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Best Practices for Text Annotation with Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  72%|█████████████████████████████████████████                | 2388/3312 [1:01:35<22:33,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Intent-based Prompt Calibration: Enhancing prompt optimization with synthetic boundary cases\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  72%|█████████████████████████████████████████                | 2389/3312 [1:01:37<23:20,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Enhancing the Stability of LLM-based Speech Generation Systems through Self-Supervised Representations\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  72%|█████████████████████████████████████████▏               | 2390/3312 [1:01:38<23:45,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: UniMem: Towards a Unified View of Long-Context Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  72%|█████████████████████████████████████████▏               | 2391/3312 [1:01:40<23:36,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Conversation Reconstruction Attack Against GPT Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  72%|█████████████████████████████████████████▏               | 2392/3312 [1:01:41<23:55,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Unsupervised semantic segmentation of high-resolution UAV imagery for road scene parsing\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  72%|█████████████████████████████████████████▏               | 2393/3312 [1:01:43<23:20,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Enhancing Textbook Question Answering Task with Large Language Models and Retrieval Augmented Generation\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  72%|█████████████████████████████████████████▏               | 2394/3312 [1:01:45<23:53,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LLM Agents in Interaction: Measuring Personality Consistency and Linguistic Alignment in Interacting Populations of Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  72%|█████████████████████████████████████████▏               | 2395/3312 [1:01:46<25:16,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Shortened LLaMA: A Simple Depth Pruning for Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  72%|█████████████████████████████████████████▏               | 2396/3312 [1:01:48<24:08,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Evading Data Contamination Detection for Language Models is (too) Easy\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  72%|█████████████████████████████████████████▎               | 2397/3312 [1:01:49<23:28,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Graph-enhanced Large Language Models in Asynchronous Plan Reasoning\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  72%|█████████████████████████████████████████▎               | 2398/3312 [1:01:51<23:29,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Large Language Model Distilling Medication Recommendation Model\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  72%|█████████████████████████████████████████▎               | 2399/3312 [1:01:52<22:49,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: KS-Lottery: Finding Certified Lottery Tickets for Multilingual Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  72%|█████████████████████████████████████████▎               | 2400/3312 [1:01:54<22:35,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Rethinking Optimization and Architecture for Tiny Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  72%|█████████████████████████████████████████▎               | 2401/3312 [1:01:55<23:46,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: List-aware Reranking-Truncation Joint Model for Search and Retrieval-augmented Generation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  73%|█████████████████████████████████████████▎               | 2402/3312 [1:01:57<23:02,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: DeAL: Decoding-time Alignment for Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  73%|█████████████████████████████████████████▎               | 2403/3312 [1:01:58<22:27,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Illuminate: A novel approach for depression detection with explainable analysis and proactive therapy using prompt engineering\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  73%|█████████████████████████████████████████▎               | 2404/3312 [1:02:00<22:06,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: KIVI: A Tuning-Free Asymmetric 2bit Quantization for KV Cache\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  73%|█████████████████████████████████████████▍               | 2405/3312 [1:02:01<22:21,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Understanding the planning of LLM agents: A survey\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  73%|█████████████████████████████████████████▍               | 2406/3312 [1:02:03<22:22,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Adversarial Text Purification: A Large Language Model Approach for Defense\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  73%|█████████████████████████████████████████▍               | 2407/3312 [1:02:04<22:22,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Large Language Models are Geographically Biased\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  73%|█████████████████████████████████████████▍               | 2408/3312 [1:02:06<22:34,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Open-Universe Indoor Scene Generation using LLM Program Synthesis and Uncurated Object Databases\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  73%|█████████████████████████████████████████▍               | 2409/3312 [1:02:07<22:09,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: RACER: An LLM-powered Methodology for Scalable Analysis of Semi-structured Mental Health Interviews\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  73%|█████████████████████████████████████████▍               | 2410/3312 [1:02:08<21:49,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Recursive Chain-of-Feedback Prevents Performance Degradation from Redundant Prompting\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  73%|█████████████████████████████████████████▍               | 2411/3312 [1:02:10<22:17,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Zero-Shot Clinical Trial Patient Matching with LLMs\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  73%|█████████████████████████████████████████▌               | 2412/3312 [1:02:11<22:13,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LLM-Enhanced Data Management\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  73%|█████████████████████████████████████████▌               | 2413/3312 [1:02:13<22:23,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Can Large Language Models Learn Independent Causal Mechanisms?\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  73%|█████████████████████████████████████████▌               | 2414/3312 [1:02:15<22:50,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Predicting Machine Translation Performance on Low-Resource Languages: The Role of Domain Similarity\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  73%|█████████████████████████████████████████▌               | 2415/3312 [1:02:16<22:42,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: UniTSyn: A Large-Scale Dataset Capable of Enhancing the Prowess of Large Language Models for Program Testing\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  73%|█████████████████████████████████████████▌               | 2416/3312 [1:02:18<23:02,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: PuzzleBench: Can LLMs Solve Challenging First-Order Combinatorial Reasoning Problems?\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  73%|█████████████████████████████████████████▌               | 2417/3312 [1:02:19<22:50,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: A Truly Joint Neural Architecture for Segmentation and Parsing\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  73%|█████████████████████████████████████████▌               | 2418/3312 [1:02:21<23:18,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: DefInt: A Default-interventionist Framework for Efficient Reasoning with Hybrid Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  73%|█████████████████████████████████████████▋               | 2419/3312 [1:02:22<23:16,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Enhancing Robustness in Biomedical NLI Models: A Probing Approach for Clinical Trials\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  73%|█████████████████████████████████████████▋               | 2420/3312 [1:02:24<23:08,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Are Large Language Models Table-based Fact-Checkers?\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  73%|█████████████████████████████████████████▋               | 2421/3312 [1:02:25<22:49,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Knowledge Generation for Zero-shot Knowledge-based VQA\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  73%|█████████████████████████████████████████▋               | 2422/3312 [1:02:27<22:22,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: CompeteSMoE -- Effective Training of Sparse Mixture of Experts via Competition\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  73%|█████████████████████████████████████████▋               | 2423/3312 [1:02:28<21:46,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Conversational Crowdsensing: A Parallel Intelligence Powered Novel Sensing Approach\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  73%|█████████████████████████████████████████▋               | 2424/3312 [1:02:30<22:07,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: GeReA: Question-Aware Prompt Captions for Knowledge-based Visual Question Answering\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  73%|█████████████████████████████████████████▋               | 2425/3312 [1:02:31<21:51,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Navigating the Peril of Generated Alternative Facts: A ChatGPT-4 Fabricated Omega Variant Case as a Cautionary Tale in Medical Misinformation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  73%|█████████████████████████████████████████▊               | 2426/3312 [1:02:33<21:43,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: BRAIn: Bayesian Reward-conditioned Amortized Inference for natural language generation from feedback\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  73%|█████████████████████████████████████████▊               | 2427/3312 [1:02:34<21:35,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: A Graph is Worth $K$ Words: Euclideanizing Graph using Pure Transformer\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  73%|█████████████████████████████████████████▊               | 2428/3312 [1:02:36<21:13,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: FoldToken: Learning Protein Language via Vector Quantization and Beyond\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  73%|█████████████████████████████████████████▊               | 2429/3312 [1:02:37<21:02,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Breaking MLPerf Training: A Case Study on Optimizing BERT\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  73%|█████████████████████████████████████████▊               | 2430/3312 [1:02:38<20:55,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LQER: Low-Rank Quantization Error Reconstruction for LLMs\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  73%|█████████████████████████████████████████▊               | 2431/3312 [1:02:40<21:07,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Factuality of Large Language Models in the Year 2024\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  73%|█████████████████████████████████████████▊               | 2432/3312 [1:02:41<21:20,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Aligner: Achieving Efficient Alignment through Weak-to-Strong Correction\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  73%|█████████████████████████████████████████▊               | 2433/3312 [1:02:43<22:44,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: GLaPE: Gold Label-agnostic Prompt Evaluation and Optimization for Large Language Model\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  73%|█████████████████████████████████████████▉               | 2434/3312 [1:02:45<22:06,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: DeLLMa: A Framework for Decision Making Under Uncertainty with Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  74%|█████████████████████████████████████████▉               | 2435/3312 [1:02:46<23:17,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: KICGPT: Large Language Model with Knowledge in Context for Knowledge Graph Completion\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  74%|█████████████████████████████████████████▉               | 2436/3312 [1:02:48<22:45,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Solution-oriented Agent-based Models Generation with Verifier-assisted Iterative In-context Learning\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  74%|█████████████████████████████████████████▉               | 2437/3312 [1:02:49<22:23,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Evaluating Large Language Models in Analysing Classroom Dialogue\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  74%|█████████████████████████████████████████▉               | 2438/3312 [1:02:51<24:48,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: AutoTimes: Autoregressive Time Series Forecasters via Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  74%|█████████████████████████████████████████▉               | 2439/3312 [1:02:53<24:10,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Timer: Transformers for Time Series Analysis at Scale\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  74%|█████████████████████████████████████████▉               | 2440/3312 [1:02:55<23:48,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Advancing Graph Representation Learning with Large Language Models: A Comprehensive Survey of Techniques\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  74%|██████████████████████████████████████████               | 2441/3312 [1:02:56<22:45,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Large Language Model Adaptation for Networking\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  74%|██████████████████████████████████████████               | 2442/3312 [1:02:57<22:44,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Enhance Reasoning for Large Language Models in the Game Werewolf\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  74%|██████████████████████████████████████████               | 2443/3312 [1:02:59<22:25,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: A Survey of Large Language Models in Finance (FinLLMs)\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  74%|██████████████████████████████████████████               | 2444/3312 [1:03:01<22:37,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Selecting Large Language Model to Fine-tune via Rectified Scaling Law\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  74%|██████████████████████████████████████████               | 2445/3312 [1:03:02<23:18,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Jailbreaking Attack against Multimodal Large Language Model\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  74%|██████████████████████████████████████████               | 2446/3312 [1:03:04<23:01,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Large Language Model for Table Processing: A Survey\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  74%|██████████████████████████████████████████               | 2447/3312 [1:03:06<23:32,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: SynthDST: Synthetic Data is All You Need for Few-Shot Dialog State Tracking\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  74%|██████████████████████████████████████████▏              | 2448/3312 [1:03:07<23:49,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Frequency Explains the Inverse Correlation of Large Language Models' Size, Training Data Amount, and Surprisal's Fit to Reading Times\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  74%|██████████████████████████████████████████▏              | 2449/3312 [1:03:09<23:08,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Beyond the Limits: A Survey of Techniques to Extend the Context Length in Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  74%|██████████████████████████████████████████▏              | 2450/3312 [1:03:11<23:59,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Language Writ Large: LLMs, ChatGPT, Grounding, Meaning and Understanding\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  74%|██████████████████████████████████████████▏              | 2451/3312 [1:03:12<23:18,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Safety Fine-Tuning at (Almost) No Cost: A Baseline for Vision Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  74%|██████████████████████████████████████████▏              | 2452/3312 [1:03:14<22:59,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: GPT-4V as Traffic Assistant: An In-depth Look at Vision Language Model on Complex Traffic Events\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  74%|██████████████████████████████████████████▏              | 2453/3312 [1:03:15<23:51,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Vi(E)va LLM! A Conceptual Stack for Evaluating and Interpreting Generative AI-based Visualizations\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  74%|██████████████████████████████████████████▏              | 2454/3312 [1:03:17<23:37,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Analyzing Sentiment Polarity Reduction in News Presentation through Contextual Perturbation and Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  74%|██████████████████████████████████████████▎              | 2455/3312 [1:03:19<22:47,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Do Moral Judgment and Reasoning Capability of LLMs Change with Language? A Study using the Multilingual Defining Issues Test\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  74%|██████████████████████████████████████████▎              | 2456/3312 [1:03:20<22:11,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Rendering Graphs for Graph Reasoning in Multimodal Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  74%|██████████████████████████████████████████▎              | 2457/3312 [1:03:22<23:49,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Are Large Language Models Good Prompt Optimizers?\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  74%|██████████████████████████████████████████▎              | 2458/3312 [1:03:23<22:52,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Break the Sequential Dependency of LLM Inference Using Lookahead Decoding\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  74%|██████████████████████████████████████████▎              | 2459/3312 [1:03:25<23:01,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Affordable Generative Agents\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  74%|██████████████████████████████████████████▎              | 2460/3312 [1:03:27<22:27,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Panacea: Pareto Alignment via Preference Adaptation for LLMs\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  74%|██████████████████████████████████████████▎              | 2461/3312 [1:03:28<22:04,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: A Closer Look at the Limitations of Instruction Tuning\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  74%|██████████████████████████████████████████▎              | 2462/3312 [1:03:30<21:42,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: How well do LLMs cite relevant medical references? An evaluation framework and analyses\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  74%|██████████████████████████████████████████▍              | 2463/3312 [1:03:31<22:22,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: PresAIse, A Prescriptive AI Solution for Enterprises\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  74%|██████████████████████████████████████████▍              | 2464/3312 [1:03:33<21:57,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Human-Centered Privacy Research in the Age of Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  74%|██████████████████████████████████████████▍              | 2465/3312 [1:03:34<21:13,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Self-Debiasing Large Language Models: Zero-Shot Recognition and Reduction of Stereotypes\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  74%|██████████████████████████████████████████▍              | 2466/3312 [1:03:36<21:27,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: SOCIALITE-LLAMA: An Instruction-Tuned Model for Social Scientific Tasks\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  74%|██████████████████████████████████████████▍              | 2467/3312 [1:03:37<21:06,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: A Survey on Context-Aware Multi-Agent Systems: Techniques, Challenges and Future Directions\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  75%|██████████████████████████████████████████▍              | 2468/3312 [1:03:39<22:19,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: MasonPerplexity at Multimodal Hate Speech Event Detection 2024: Hate Speech and Target Detection Using Transformer Ensembles\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  75%|██████████████████████████████████████████▍              | 2469/3312 [1:03:41<23:33,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Large Language Model Agent for Hyper-Parameter Optimization\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  75%|██████████████████████████████████████████▌              | 2470/3312 [1:03:42<22:27,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: The RL/LLM Taxonomy Tree: Reviewing Synergies Between Reinforcement Learning and Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  75%|██████████████████████████████████████████▌              | 2471/3312 [1:03:44<24:35,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Leveraging Large Language Models for Structure Learning in Prompted Weak Supervision\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  75%|██████████████████████████████████████████▌              | 2472/3312 [1:03:46<23:37,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: What Will My Model Forget? Forecasting Forgotten Examples in Language Model Refinement\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  75%|██████████████████████████████████████████▌              | 2473/3312 [1:03:47<22:50,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: (A)I Am Not a Lawyer, But...: Engaging Legal Experts towards Responsible LLM Policies for Legal Advice\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  75%|██████████████████████████████████████████▌              | 2474/3312 [1:03:49<21:45,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Cross-modality debiasing: using language to mitigate sub-population shifts in imaging\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  75%|██████████████████████████████████████████▌              | 2475/3312 [1:03:51<22:49,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Peer-review-in-LLMs: Automatic Evaluation Method for LLMs in Open-environment\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  75%|██████████████████████████████████████████▌              | 2476/3312 [1:03:53<24:03,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: TravelPlanner: A Benchmark for Real-World Planning with Language Agents\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  75%|██████████████████████████████████████████▋              | 2477/3312 [1:03:54<22:43,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Stochastic Two Points Method for Deep Model Zeroth-order Optimization\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  75%|██████████████████████████████████████████▋              | 2478/3312 [1:03:56<23:23,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: MAGDi: Structured Distillation of Multi-Agent Interaction Graphs Improves Reasoning in Smaller Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  75%|██████████████████████████████████████████▋              | 2479/3312 [1:03:57<22:14,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: KB-Plugin: A Plug-and-play Framework for Large Language Models to Induce Programs over Low-resourced Knowledge Bases\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  75%|██████████████████████████████████████████▋              | 2480/3312 [1:03:59<22:06,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Style Vectors for Steering Generative Large Language Model\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  75%|██████████████████████████████████████████▋              | 2481/3312 [1:04:00<22:06,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Leveraging Large Language Models for Analyzing Blood Pressure Variations Across Biological Sex from Scientific Literature\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  75%|██████████████████████████████████████████▋              | 2482/3312 [1:04:02<21:44,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Foundation Model Sherpas: Guiding Foundation Models through Knowledge and Reasoning\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  75%|██████████████████████████████████████████▋              | 2483/3312 [1:04:03<21:59,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: TrustAgent: Towards Safe and Trustworthy LLM-based Agents through Agent Constitution\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  75%|██████████████████████████████████████████▊              | 2484/3312 [1:04:05<21:43,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Building Guardrails for Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  75%|██████████████████████████████████████████▊              | 2485/3312 [1:04:06<21:01,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Ecologically rational meta-learned inference explains human category learning\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  75%|██████████████████████████████████████████▊              | 2486/3312 [1:04:08<20:31,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Homogenization Effects of Large Language Models on Human Creative Ideation\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  75%|██████████████████████████████████████████▊              | 2487/3312 [1:04:09<20:43,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: An Empirical Analysis of Diversity in Argument Summarization\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  75%|██████████████████████████████████████████▊              | 2488/3312 [1:04:11<20:32,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Decoding Speculative Decoding\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  75%|██████████████████████████████████████████▊              | 2489/3312 [1:04:12<20:33,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: K-Level Reasoning with Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  75%|██████████████████████████████████████████▊              | 2490/3312 [1:04:14<20:53,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: A Comparative Analysis of Conversational Large Language Models in Knowledge-Based Text Generation\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  75%|██████████████████████████████████████████▊              | 2491/3312 [1:04:15<20:52,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: AMOR: A Recipe for Building Adaptable Modular Knowledge Agents Through Process Feedback\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  75%|██████████████████████████████████████████▉              | 2492/3312 [1:04:17<20:38,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Integrating Large Language Models in Causal Discovery: A Statistical Causal Approach\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  75%|██████████████████████████████████████████▉              | 2493/3312 [1:04:18<20:03,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LLMs Can't Plan, But Can Help Planning in LLM-Modulo Frameworks\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  75%|██████████████████████████████████████████▉              | 2494/3312 [1:04:20<20:11,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Distilling LLMs' Decomposition Abilities into Compact Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  75%|██████████████████████████████████████████▉              | 2495/3312 [1:04:22<21:00,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: StepCoder: Improve Code Generation with Reinforcement Learning from Compiler Feedback\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  75%|██████████████████████████████████████████▉              | 2496/3312 [1:04:23<20:46,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LLM-based NLG Evaluation: Current Status and Challenges\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  75%|██████████████████████████████████████████▉              | 2497/3312 [1:04:25<20:44,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Continual Learning for Large Language Models: A Survey\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  75%|██████████████████████████████████████████▉              | 2498/3312 [1:04:26<20:56,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: A Survey on Large Language Model Hallucination via a Creativity Perspective\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  75%|███████████████████████████████████████████              | 2499/3312 [1:04:28<22:06,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Beyond the Answers: Reviewing the Rationality of Multiple Choice Question Answering for the Evaluation of Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  75%|███████████████████████████████████████████              | 2500/3312 [1:04:29<21:10,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Preference-free Alignment Learning with Regularized Relevance Reward\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  76%|███████████████████████████████████████████              | 2501/3312 [1:04:31<20:41,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Training-time Neuron Alignment through Permutation Subspace for Improving Linear Mode Connectivity and Model Fusion\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  76%|███████████████████████████████████████████              | 2502/3312 [1:04:32<21:18,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: KTO: Model Alignment as Prospect Theoretic Optimization\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  76%|███████████████████████████████████████████              | 2503/3312 [1:04:34<20:33,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Can MLLMs Perform Text-to-Image In-Context Learning?\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  76%|███████████████████████████████████████████              | 2504/3312 [1:04:35<20:45,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Exploring the Limitations of Graph Reasoning in Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  76%|███████████████████████████████████████████              | 2505/3312 [1:04:37<20:04,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: The Human and the Mechanical: logos, truthfulness, and ChatGPT\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  76%|███████████████████████████████████████████▏             | 2506/3312 [1:04:39<20:58,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Efficient Causal Graph Discovery Using Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  76%|███████████████████████████████████████████▏             | 2507/3312 [1:04:40<20:34,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Large Language Models for Time Series: A Survey\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  76%|███████████████████████████████████████████▏             | 2508/3312 [1:04:42<20:36,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Towards a Unified Language Model for Knowledge-Intensive Tasks Utilizing External Corpus\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  76%|███████████████████████████████████████████▏             | 2509/3312 [1:04:43<20:15,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Efficient Prompt Caching via Embedding Similarity\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  76%|███████████████████████████████████████████▏             | 2510/3312 [1:04:45<20:02,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Faster and Lighter LLMs: A Survey on Current Challenges and Way Forward\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  76%|███████████████████████████████████████████▏             | 2511/3312 [1:04:46<19:36,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LLM-Detector: Improving AI-Generated Chinese Text Detection with Open-Source LLM Instruction Tuning\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  76%|███████████████████████████████████████████▏             | 2512/3312 [1:04:48<21:20,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: CABINET: Content Relevance based Noise Reduction for Table Question Answering\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  76%|███████████████████████████████████████████▏             | 2513/3312 [1:04:49<21:08,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ReEvo: Large Language Models as Hyper-Heuristics with Reflective Evolution\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  76%|███████████████████████████████████████████▎             | 2514/3312 [1:04:51<21:11,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: A Multi-Agent Conversational Recommender System\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  76%|███████████████████████████████████████████▎             | 2515/3312 [1:04:53<21:34,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: PokeLLMon: A Human-Parity Agent for Pokemon Battles with Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  76%|███████████████████████████████████████████▎             | 2516/3312 [1:04:54<20:58,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: DTS-SQL: Decomposed Text-to-SQL with Small Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  76%|███████████████████████████████████████████▎             | 2517/3312 [1:04:56<20:19,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Vaccine: Perturbation-aware Alignment for Large Language Model\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  76%|███████████████████████████████████████████▎             | 2518/3312 [1:04:57<19:36,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Reasoning Capacity in Multi-Agent Systems: Limitations, Challenges and Human-Centered Solutions\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  76%|███████████████████████████████████████████▎             | 2519/3312 [1:04:59<20:09,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: The Political Preferences of LLMs\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  76%|███████████████████████████████████████████▎             | 2520/3312 [1:05:00<20:13,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LitLLM: A Toolkit for Scientific Literature Review\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  76%|███████████████████████████████████████████▍             | 2521/3312 [1:05:02<20:06,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Character-based Outfit Generation with Vision-augmented Style Extraction via LLMs\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  76%|███████████████████████████████████████████▍             | 2522/3312 [1:05:03<20:33,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Specialized Language Models with Cheap Inference from Limited Domain Data\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  76%|███████████████████████████████████████████▍             | 2523/3312 [1:05:05<20:48,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Chameleon: Foundation Models for Fairness-aware Multi-modal Data Augmentation to Enhance Coverage of Minorities\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  76%|███████████████████████████████████████████▍             | 2524/3312 [1:05:06<20:27,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Evaluation Methodology for Large Language Models for Multilingual Document Question and Answer\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  76%|███████████████████████████████████████████▍             | 2525/3312 [1:05:08<20:02,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Plan-Grounded Large Language Models for Dual Goal Conversational Settings\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  76%|███████████████████████████████████████████▍             | 2526/3312 [1:05:09<19:58,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Generation, Distillation and Evaluation of Motivational Interviewing-Style Reflections with a Foundational Language Model\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  76%|███████████████████████████████████████████▍             | 2527/3312 [1:05:11<19:39,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: IMUGPT 2.0: Language-Based Cross Modality Transfer for Sensor-Based Human Activity Recognition\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  76%|███████████████████████████████████████████▌             | 2528/3312 [1:05:13<20:23,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: COA-GPT: Generative Pre-trained Transformers for Accelerated Course of Action Development in Military Operations\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  76%|███████████████████████████████████████████▌             | 2529/3312 [1:05:14<20:04,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Getting the most out of your tokenizer for pre-training and domain adaptation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  76%|███████████████████████████████████████████▌             | 2530/3312 [1:05:15<19:45,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Repeat After Me: Transformers are Better than State Space Models at Copying\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  76%|███████████████████████████████████████████▌             | 2531/3312 [1:05:17<19:19,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Executable Code Actions Elicit Better LLM Agents\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  76%|███████████████████████████████████████████▌             | 2532/3312 [1:05:18<19:05,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: HR-MultiWOZ: A Task Oriented Dialogue (TOD) Dataset for HR LLM Agent\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  76%|███████████████████████████████████████████▌             | 2533/3312 [1:05:20<19:41,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: When Benchmarks are Targets: Revealing the Sensitivity of Large Language Model Leaderboards\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  77%|███████████████████████████████████████████▌             | 2534/3312 [1:05:21<19:21,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Evaluating Large Language Models for Generalization and Robustness via Data Compression\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  77%|███████████████████████████████████████████▋             | 2535/3312 [1:05:23<20:00,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Can Large Language Models Understand Context?\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  77%|███████████████████████████████████████████▋             | 2536/3312 [1:05:25<20:32,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Tiny Titans: Can Smaller Large Language Models Punch Above Their Weight in the Real World for Meeting Summarization?\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  77%|███████████████████████████████████████████▋             | 2537/3312 [1:05:26<20:52,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Formal-LLM: Integrating Formal Language and Natural Language for Controllable LLM-based Agents\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  77%|███████████████████████████████████████████▋             | 2538/3312 [1:05:28<20:02,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LLMs learn governing principles of dynamical systems, revealing an in-context neural scaling law\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  77%|███████████████████████████████████████████▋             | 2539/3312 [1:05:29<20:05,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Dense Reward for Free in Reinforcement Learning from Human Feedback\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  77%|███████████████████████████████████████████▋             | 2540/3312 [1:05:31<19:31,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Unlearnable Algorithms for In-context Learning\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  77%|███████████████████████████████████████████▋             | 2541/3312 [1:05:32<19:36,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Health-LLM: Personalized Retrieval-Augmented Disease Prediction System\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  77%|███████████████████████████████████████████▋             | 2542/3312 [1:05:34<19:28,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Enhancing Ethical Explanations of Large Language Models through Iterative Symbolic Refinement\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  77%|███████████████████████████████████████████▊             | 2543/3312 [1:05:35<19:14,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Transforming and Combining Rewards for Aligning Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  77%|███████████████████████████████████████████▊             | 2544/3312 [1:05:37<18:58,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Intent Assurance using LLMs guided by Intent Drift\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  77%|███████████████████████████████████████████▊             | 2545/3312 [1:05:38<18:48,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Ocassionally Secure: A Comparative Analysis of Code Generation Assistants\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  77%|███████████████████████████████████████████▊             | 2546/3312 [1:05:40<18:30,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Learning Planning-based Reasoning by Trajectories Collection and Process Reward Synthesizing\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  77%|███████████████████████████████████████████▊             | 2547/3312 [1:05:41<18:52,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Vision-LLMs Can Fool Themselves with Self-Generated Typographic Attacks\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  77%|███████████████████████████████████████████▊             | 2548/3312 [1:05:43<18:40,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Actor Identification in Discourse: A Challenge for LLMs?\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  77%|███████████████████████████████████████████▊             | 2549/3312 [1:05:44<18:44,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Superfiltering: Weak-to-Strong Data Filtering for Fast Instruction-Tuning\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  77%|███████████████████████████████████████████▉             | 2550/3312 [1:05:46<18:45,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: EE-Tuning: An Economical yet Scalable Solution for Tuning Early-Exit Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  77%|███████████████████████████████████████████▉             | 2551/3312 [1:05:47<19:17,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: SA-MDKIF: A Scalable and Adaptable Medical Domain Knowledge Injection Framework for Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  77%|███████████████████████████████████████████▉             | 2552/3312 [1:05:49<19:29,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: From PARIS to LE-PARIS: Toward Patent Response Automation with Recommender Systems and Collaborative Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  77%|███████████████████████████████████████████▉             | 2553/3312 [1:05:50<19:30,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Prompt-Time Symbolic Knowledge Capture with Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  77%|███████████████████████████████████████████▉             | 2554/3312 [1:05:52<19:29,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Hidding the Ghostwriters: An Adversarial Evaluation of AI-Generated Student Essay Detection\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  77%|███████████████████████████████████████████▉             | 2555/3312 [1:05:53<19:22,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Investigating Bias Representations in Llama 2 Chat via Activation Steering\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  77%|███████████████████████████████████████████▉             | 2556/3312 [1:05:55<19:24,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: What Does the Bot Say? Opportunities and Risks of Large Language Models in Social Media Bot Detection\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  77%|████████████████████████████████████████████             | 2557/3312 [1:05:57<19:34,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Don't Hallucinate, Abstain: Identifying LLM Knowledge Gaps via Multi-LLM Collaboration\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  77%|████████████████████████████████████████████             | 2558/3312 [1:05:58<19:15,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Safety of Multimodal Large Language Models on Images and Text\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  77%|████████████████████████████████████████████             | 2559/3312 [1:06:00<19:11,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Large Language Models Based Fuzzing Techniques: A Survey\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  77%|████████████████████████████████████████████             | 2560/3312 [1:06:01<19:57,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: IndiVec: An Exploration of Leveraging Large Language Models for Media Bias Detection with Fine-Grained Bias Indicators\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  77%|████████████████████████████████████████████             | 2561/3312 [1:06:03<19:09,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Redefining \"Hallucination\" in LLMs: Towards a psychology-informed framework for mitigating misinformation\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  77%|████████████████████████████████████████████             | 2562/3312 [1:06:04<19:03,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Multimodal Embodied Interactive Agent for Cafe Scene\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  77%|████████████████████████████████████████████             | 2563/3312 [1:06:06<20:06,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: PAP-REC: Personalized Automatic Prompt for Recommendation Language Model\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  77%|████████████████████████████████████████████▏            | 2564/3312 [1:06:07<19:25,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: HiQA: A Hierarchical Contextual Augmentation RAG for Massive Documents QA\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  77%|████████████████████████████████████████████▏            | 2565/3312 [1:06:09<19:03,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Does DetectGPT Fully Utilize Perturbation? Bridge Selective Perturbation to Fine-tuned Contrastive Learning Detector would be Better\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  77%|████████████████████████████████████████████▏            | 2566/3312 [1:06:10<18:43,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Computational Experiments Meet Large Language Model Based Agents: A Survey and Perspective\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  78%|████████████████████████████████████████████▏            | 2567/3312 [1:06:12<18:19,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Towards scalable robotic intervention of children with Autism Spectrum Disorder using LLMs\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  78%|████████████████████████████████████████████▏            | 2568/3312 [1:06:13<18:17,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Efficient Non-Parametric Uncertainty Quantification for Black-Box Large Language Models and Decision Planning\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  78%|████████████████████████████████████████████▏            | 2569/3312 [1:06:15<18:13,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Exploring the limits of decoder-only models trained on public speech recognition corpora\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  78%|████████████████████████████████████████████▏            | 2570/3312 [1:06:16<19:10,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: De-identification is not always enough\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  78%|████████████████████████████████████████████▏            | 2571/3312 [1:06:18<18:49,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Multimodal Clinical Pseudo-notes for Emergency Department Prediction Tasks using Multiple Embedding Model for EHR (MEME)\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  78%|████████████████████████████████████████████▎            | 2572/3312 [1:06:19<18:17,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Dolma: an Open Corpus of Three Trillion Tokens for Language Model Pretraining Research\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  78%|████████████████████████████████████████████▎            | 2573/3312 [1:06:21<18:15,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Large Language Models for Mathematical Reasoning: Progresses and Challenges\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  78%|████████████████████████████████████████████▎            | 2574/3312 [1:06:22<18:40,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: An Early Categorization of Prompt Injection Attacks on Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  78%|████████████████████████████████████████████▎            | 2575/3312 [1:06:24<18:30,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Comparing Template-based and Template-free Language Model Probing\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  78%|████████████████████████████████████████████▎            | 2576/3312 [1:06:26<20:15,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: KVQuant: Towards 10 Million Context Length LLM Inference with KV Cache Quantization\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  78%|████████████████████████████████████████████▎            | 2577/3312 [1:06:27<19:33,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Do Language Models Exhibit the Same Cognitive Biases in Problem Solving as Human Learners?\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  78%|████████████████████████████████████████████▎            | 2578/3312 [1:06:29<19:09,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LongAlign: A Recipe for Long Context Alignment of Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  78%|████████████████████████████████████████████▍            | 2579/3312 [1:06:30<19:02,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Code-Aware Prompting: A study of Coverage Guided Test Generation in Regression Setting using LLM\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  78%|████████████████████████████████████████████▍            | 2580/3312 [1:06:32<19:12,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: SpeechComposer: Unifying Multiple Speech Tasks with Prompt Composition\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  78%|████████████████████████████████████████████▍            | 2581/3312 [1:06:33<18:42,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ConSmax: Hardware-Friendly Alternative Softmax with Learnable Parameters\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  78%|████████████████████████████████████████████▍            | 2582/3312 [1:06:35<19:48,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Supporting Anticipatory Governance using LLMs: Evaluating and Aligning Large Language Models with the News Media to Anticipate the Negative Impacts of AI\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  78%|████████████████████████████████████████████▍            | 2583/3312 [1:06:37<19:14,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: On Prompt-Driven Safeguarding for Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  78%|████████████████████████████████████████████▍            | 2584/3312 [1:06:38<18:55,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: EEG-GPT: Exploring Capabilities of Large Language Models for EEG Classification and Interpretation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  78%|████████████████████████████████████████████▍            | 2585/3312 [1:06:40<18:19,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Enhancing Multimodal Large Language Models with Vision Detection Models: An Empirical Study\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  78%|████████████████████████████████████████████▌            | 2586/3312 [1:06:41<18:52,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: GUMsley: Evaluating Entity Salience in Summarization for 12 English Genres\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  78%|████████████████████████████████████████████▌            | 2587/3312 [1:06:43<18:43,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Employing Label Models on ChatGPT Answers Improves Legal Text Entailment Performance\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  78%|████████████████████████████████████████████▌            | 2588/3312 [1:06:44<18:41,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LLM Voting: Human Choices and AI Collective Decision Making\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  78%|████████████████████████████████████████████▌            | 2589/3312 [1:06:46<18:24,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: I Think, Therefore I am: Benchmarking Awareness of Large Language Models Using AwareBench\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  78%|████████████████████████████████████████████▌            | 2590/3312 [1:06:47<17:54,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Proximity QA: Unleashing the Power of Multi-Modal Large Language Models for Spatial Proximity Analysis\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  78%|████████████████████████████████████████████▌            | 2591/3312 [1:06:49<17:41,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Probing Language Models' Gesture Understanding for Enhanced Human-AI Interaction\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  78%|████████████████████████████████████████████▌            | 2592/3312 [1:06:50<17:53,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Uncertainty-Aware Explainable Recommendation with Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  78%|████████████████████████████████████████████▋            | 2593/3312 [1:06:52<17:41,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Global-Liar: Factuality of LLMs over Time and Geographic Regions\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  78%|████████████████████████████████████████████▋            | 2594/3312 [1:06:53<18:31,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: SWEA: Changing Factual Knowledge in Large Language Models via Subject Word Embedding Altering\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  78%|████████████████████████████████████████████▋            | 2595/3312 [1:06:55<18:17,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ChIRAAG: ChatGPT Informed Rapid and Automated Assertion Generation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  78%|████████████████████████████████████████████▋            | 2596/3312 [1:06:56<17:52,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: SwarmBrain: Embodied agent for real-time strategy game StarCraft II via large language models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  78%|████████████████████████████████████████████▋            | 2597/3312 [1:06:58<17:36,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Enhancing Large Language Model with Decomposed Reasoning for Emotion Cause Pair Extraction\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  78%|████████████████████████████████████████████▋            | 2598/3312 [1:06:59<17:22,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: WSC+: Enhancing The Winograd Schema Challenge Using Tree-of-Experts\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  78%|████████████████████████████████████████████▋            | 2599/3312 [1:07:01<17:37,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Mitigating the Problem of Strong Priors in LMs with Context Extrapolation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  79%|████████████████████████████████████████████▋            | 2600/3312 [1:07:02<17:47,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Deductive Beam Search: Decoding Deducible Rationale for Chain-of-Thought Reasoning\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  79%|████████████████████████████████████████████▊            | 2601/3312 [1:07:04<18:22,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Navigating the OverKill in Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  79%|████████████████████████████████████████████▊            | 2602/3312 [1:07:06<19:10,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Neighboring Perturbations of Knowledge Editing on Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  79%|████████████████████████████████████████████▊            | 2603/3312 [1:07:07<18:22,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Assertion Detection Large Language Model In-context Learning LoRA Fine-tuning\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  79%|████████████████████████████████████████████▊            | 2604/3312 [1:07:09<18:43,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Good at captioning, bad at counting: Benchmarking GPT-4V on Earth observation data\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  79%|████████████████████████████████████████████▊            | 2605/3312 [1:07:10<19:11,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Arrows of Time for Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  79%|████████████████████████████████████████████▊            | 2606/3312 [1:07:12<18:57,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: When Large Language Models Meet Vector Databases: A Survey\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  79%|████████████████████████████████████████████▊            | 2607/3312 [1:07:13<18:14,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Towards Visual Syntactical Understanding\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  79%|████████████████████████████████████████████▉            | 2608/3312 [1:07:15<18:31,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Detecting mental disorder on social media: a ChatGPT-augmented explainable approach\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  79%|████████████████████████████████████████████▉            | 2609/3312 [1:07:17<18:15,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Efficient Tool Use with Chain-of-Abstraction Reasoning\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  79%|████████████████████████████████████████████▉            | 2610/3312 [1:07:18<17:44,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: A Preliminary Study on Using Large Language Models in Software Pentesting\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  79%|████████████████████████████████████████████▉            | 2611/3312 [1:07:20<17:55,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Can Large Language Models Replace Economic Choice Prediction Labs?\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  79%|████████████████████████████████████████████▉            | 2612/3312 [1:07:21<17:48,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: EvoMerge: Neuroevolution for Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  79%|████████████████████████████████████████████▉            | 2613/3312 [1:07:22<17:22,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Customizing Language Model Responses with Contrastive In-Context Learning\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  79%|████████████████████████████████████████████▉            | 2614/3312 [1:07:24<17:12,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Infini-gram: Scaling Unbounded n-gram Language Models to a Trillion Tokens\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  79%|█████████████████████████████████████████████            | 2615/3312 [1:07:25<17:11,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Robust Prompt Optimization for Defending Language Models Against Jailbreaking Attacks\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  79%|█████████████████████████████████████████████            | 2616/3312 [1:07:27<17:03,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Weak-to-Strong Jailbreaking on Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  79%|█████████████████████████████████████████████            | 2617/3312 [1:07:28<17:08,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LLaMP: Large Language Model Made Powerful for High-fidelity Materials Knowledge Retrieval and Distillation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  79%|█████████████████████████████████████████████            | 2618/3312 [1:07:30<17:11,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: MouSi: Poly-Visual-Expert Vision-Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  79%|█████████████████████████████████████████████            | 2619/3312 [1:07:31<16:55,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Rethinking Interpretability in the Era of Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  79%|█████████████████████████████████████████████            | 2620/3312 [1:07:33<17:36,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Single Word Change is All You Need: Designing Attacks and Defenses for Text Classifiers\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  79%|█████████████████████████████████████████████            | 2621/3312 [1:07:35<17:45,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Transfer Learning for Text Diffusion Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  79%|█████████████████████████████████████████████▏           | 2622/3312 [1:07:36<18:00,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Conditional and Modal Reasoning in Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  79%|█████████████████████████████████████████████▏           | 2623/3312 [1:07:38<18:00,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Planning, Creation, Usage: Benchmarking LLMs for Comprehensive Tool Utilization in Real-World Complex Scenarios\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  79%|█████████████████████████████████████████████▏           | 2624/3312 [1:07:39<17:39,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Large Language Model Evaluation via Matrix Entropy\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  79%|█████████████████████████████████████████████▏           | 2625/3312 [1:07:41<17:28,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Reproducibility, energy efficiency and performance of pseudorandom number generators in machine learning: a comparative study of python, numpy, tensorflow, and pytorch implementations\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  79%|█████████████████████████████████████████████▏           | 2626/3312 [1:07:43<20:49,  1.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: StrokeNUWA: Tokenizing Strokes for Vector Graphic Synthesis\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  79%|█████████████████████████████████████████████▏           | 2627/3312 [1:07:45<19:23,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: SemScore: Automated Evaluation of Instruction-Tuned LLMs based on Semantic Textual Similarity\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  79%|█████████████████████████████████████████████▏           | 2628/3312 [1:07:46<19:01,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: GPT4Battery: An LLM-driven Framework for Adaptive State of Health Estimation of Raw Li-ion Batteries\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  79%|█████████████████████████████████████████████▏           | 2629/3312 [1:07:48<18:08,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: CRUD-RAG: A Comprehensive Chinese Benchmark for Retrieval-Augmented Generation of Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  79%|█████████████████████████████████████████████▎           | 2630/3312 [1:07:49<18:38,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Finetuning Large Language Models for Vulnerability Detection\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  79%|█████████████████████████████████████████████▎           | 2631/3312 [1:07:51<18:08,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: QACP: An Annotated Question Answering Dataset for Assisting Chinese Python Programming Learners\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  79%|█████████████████████████████████████████████▎           | 2632/3312 [1:07:53<18:13,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Two Heads Are Better Than One: Integrating Knowledge from Knowledge Graphs and Large Language Models for Entity Alignment\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  79%|█████████████████████████████████████████████▎           | 2633/3312 [1:07:54<17:26,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Aalap: AI Assistant for Legal & Paralegal Functions in India\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  80%|█████████████████████████████████████████████▎           | 2634/3312 [1:07:55<17:26,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: EarthGPT: A Universal Multi-modal Large Language Model for Multi-sensor Image Comprehension in Remote Sensing Domain\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  80%|█████████████████████████████████████████████▎           | 2635/3312 [1:07:57<18:28,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Detecting LLM-Assisted Writing in Scientific Communication: Are We There Yet?\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  80%|█████████████████████████████████████████████▎           | 2636/3312 [1:07:59<18:47,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Performance Assessment of ChatGPT vs Bard in Detecting Alzheimer's Dementia\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  80%|█████████████████████████████████████████████▍           | 2637/3312 [1:08:01<18:17,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Can Large Language Models be Trusted for Evaluation? Scalable Meta-Evaluation of LLMs as Evaluators via Agent Debate\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  80%|█████████████████████████████████████████████▍           | 2638/3312 [1:08:02<17:26,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: PACE: A Pragmatic Agent for Enhancing Communication Efficiency Using Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  80%|█████████████████████████████████████████████▍           | 2639/3312 [1:08:04<17:26,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: A Cross-Language Investigation into Jailbreak Attacks in Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  80%|█████████████████████████████████████████████▍           | 2640/3312 [1:08:05<16:53,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: SwapNet: Efficient Swapping for DNN Inference on Edge AI Devices Beyond the Memory Budget\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  80%|█████████████████████████████████████████████▍           | 2641/3312 [1:08:06<16:52,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: MT-Eval: A Multi-Turn Capabilities Evaluation Benchmark for Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  80%|█████████████████████████████████████████████▍           | 2642/3312 [1:08:08<17:06,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Security and Privacy Challenges of Large Language Models: A Survey\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  80%|█████████████████████████████████████████████▍           | 2643/3312 [1:08:10<17:27,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Recent Advances in Hate Speech Moderation: Multimodality and the Role of Large Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  80%|█████████████████████████████████████████████▌           | 2644/3312 [1:08:11<17:40,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: T3: Transparent Tracking & Triggering for Fine-grained Overlap of Compute & Collectives\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  80%|█████████████████████████████████████████████▌           | 2645/3312 [1:08:13<17:20,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Gradient-Based Language Model Red Teaming\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  80%|█████████████████████████████████████████████▌           | 2646/3312 [1:08:14<17:39,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Incoherent Probability Judgments in Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  80%|█████████████████████████████████████████████▌           | 2647/3312 [1:08:16<17:49,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: TeenyTinyLlama: open-source tiny language models trained in Brazilian Portuguese\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  80%|█████████████████████████████████████████████▌           | 2648/3312 [1:08:18<17:36,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Breaking Free Transformer Models: Task-specific Context Attribution Promises Improved Generalizability Without Fine-tuning Pre-trained LLMs\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  80%|█████████████████████████████████████████████▌           | 2649/3312 [1:08:19<18:18,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Large Multi-Modal Models (LMMs) as Universal Foundation Models for AI-Native Wireless Systems\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  80%|█████████████████████████████████████████████▌           | 2650/3312 [1:08:21<17:46,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Leveraging Professional Radiologists' Expertise to Enhance LLMs' Evaluation for Radiology Reports\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  80%|█████████████████████████████████████████████▌           | 2651/3312 [1:08:22<17:12,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LLMs as On-demand Customizable Service\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  80%|█████████████████████████████████████████████▋           | 2652/3312 [1:08:24<16:58,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Diverse, but Divisive: LLMs Can Exaggerate Gender Differences in Opinion Related to Harms of Misinformation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  80%|█████████████████████████████████████████████▋           | 2653/3312 [1:08:25<16:31,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: SelectLLM: Can LLMs Select Important Instructions to Annotate?\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  80%|█████████████████████████████████████████████▋           | 2654/3312 [1:08:27<16:54,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: InfoLossQA: Characterizing and Recovering Information Loss in Text Simplification\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  80%|█████████████████████████████████████████████▋           | 2655/3312 [1:08:28<16:40,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ReGAL: Refactoring Programs to Discover Generalizable Abstractions\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  80%|█████████████████████████████████████████████▋           | 2656/3312 [1:08:30<16:48,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Scaling Sparse Fine-Tuning to Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  80%|█████████████████████████████████████████████▋           | 2657/3312 [1:08:31<16:26,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  80%|█████████████████████████████████████████████▋           | 2658/3312 [1:08:33<16:29,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: TQCompressor: improving tensor decomposition methods in neural networks via permutations\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  80%|█████████████████████████████████████████████▊           | 2659/3312 [1:08:35<16:50,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: PathMMU: A Massive Multimodal Expert-Level Benchmark for Understanding and Reasoning in Pathology\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  80%|█████████████████████████████████████████████▊           | 2660/3312 [1:08:36<16:52,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Tradeoffs Between Alignment and Helpfulness in Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  80%|█████████████████████████████████████████████▊           | 2661/3312 [1:08:38<16:44,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Machine Translation Meta Evaluation through Translation Accuracy Challenge Sets\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  80%|█████████████████████████████████████████████▊           | 2662/3312 [1:08:39<16:31,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: The Reasoning Under Uncertainty Trap: A Structural AI Risk\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  80%|█████████████████████████████████████████████▊           | 2663/3312 [1:08:41<16:34,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Security Code Review by LLMs: A Deep Dive into Responses\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  80%|█████████████████████████████████████████████▊           | 2664/3312 [1:08:42<16:18,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Towards Optimizing the Costs of LLM Usage\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  80%|█████████████████████████████████████████████▊           | 2665/3312 [1:08:44<16:21,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Compensatory Biases Under Cognitive Load: Reducing Selection Bias in Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  80%|█████████████████████████████████████████████▉           | 2666/3312 [1:08:45<16:36,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Combining Hierachical VAEs with LLMs for clinically meaningful timeline summarisation in social media\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  81%|█████████████████████████████████████████████▉           | 2667/3312 [1:08:47<16:06,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LLM4Vuln: A Unified Evaluation Framework for Decoupling and Enhancing LLMs' Vulnerability Reasoning\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  81%|█████████████████████████████████████████████▉           | 2668/3312 [1:08:48<16:36,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: \"You tell me\": A Dataset of GPT-4-Based Behaviour Change Support Conversations\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  81%|█████████████████████████████████████████████▉           | 2669/3312 [1:08:50<16:06,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LLaVA-MoLE: Sparse Mixture of LoRA Experts for Mitigating Data Conflicts in Instruction Finetuning MLLMs\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  81%|█████████████████████████████████████████████▉           | 2670/3312 [1:08:51<16:17,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: OpenMoE: An Early Effort on Open Mixture-of-Experts Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  81%|█████████████████████████████████████████████▉           | 2671/3312 [1:08:53<16:07,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Prompt4Vis: Prompting Large Language Models with Example Mining and Schema Filtering for Tabular Data Visualization\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  81%|█████████████████████████████████████████████▉           | 2672/3312 [1:08:54<16:02,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Credit Risk Meets Large Language Models: Building a Risk Indicator from Loan Descriptions in P2P Lending\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  81%|██████████████████████████████████████████████           | 2673/3312 [1:08:56<16:06,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Assistive Large Language Model Agents for Socially-Aware Negotiation Dialogues\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  81%|██████████████████████████████████████████████           | 2674/3312 [1:08:57<15:34,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Response Generation for Cognitive Behavioral Therapy with Large Language Models: Comparative Study with Socratic Questioning\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  81%|██████████████████████████████████████████████           | 2675/3312 [1:08:59<15:34,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: VIALM: A Survey and Benchmark of Visually Impaired Assistance with Large Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  81%|██████████████████████████████████████████████           | 2676/3312 [1:09:00<15:35,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: E-EVAL: A Comprehensive Chinese K-12 Education Evaluation Benchmark for Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  81%|██████████████████████████████████████████████           | 2677/3312 [1:09:02<15:18,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Overcoming the Pitfalls of Vision-Language Model Finetuning for OOD Generalization\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  81%|██████████████████████████████████████████████           | 2678/3312 [1:09:03<15:26,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Development and Testing of Retrieval Augmented Generation in Large Language Models -- A Case Study Report\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  81%|██████████████████████████████████████████████           | 2679/3312 [1:09:05<16:10,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Corrective Retrieval Augmented Generation\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  81%|██████████████████████████████████████████████           | 2680/3312 [1:09:06<16:32,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: UnMASKed: Quantifying Gender Biases in Masked Language Models through Linguistically Informed Job Market Prompts\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  81%|██████████████████████████████████████████████▏          | 2681/3312 [1:09:08<16:41,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ACCESS: Prompt Engineering for Automated Web Accessibility Violation Corrections\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  81%|██████████████████████████████████████████████▏          | 2682/3312 [1:09:10<16:38,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Fine-Tuned Large Language Models for Symptom Recognition from Spanish Clinical Text\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  81%|██████████████████████████████████████████████▏          | 2683/3312 [1:09:12<17:59,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LLM4SecHW: Leveraging Domain Specific Large Language Model for Hardware Debugging\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  81%|██████████████████████████████████████████████▏          | 2684/3312 [1:09:13<16:56,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: RE-GAINS & EnCHANT: Intelligent Tool Manipulation Systems For Enhanced Query Responses\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  81%|██████████████████████████████████████████████▏          | 2685/3312 [1:09:14<16:22,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Identifying and Improving Disability Bias in GAI-Based Resume Screening\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  81%|██████████████████████████████████████████████▏          | 2686/3312 [1:09:16<16:40,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Divide and Conquer: Language Models can Plan and Self-Correct for Compositional Text-to-Image Generation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  81%|██████████████████████████████████████████████▏          | 2687/3312 [1:09:18<16:04,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: YODA: Teacher-Student Progressive Learning for Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  81%|██████████████████████████████████████████████▎          | 2688/3312 [1:09:19<15:48,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LLsM: Generative Linguistic Steganography with Large Language Model\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  81%|██████████████████████████████████████████████▎          | 2689/3312 [1:09:21<16:07,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: PRE: A Peer Review Based Large Language Model Evaluator\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  81%|██████████████████████████████████████████████▎          | 2690/3312 [1:09:23<17:06,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Evaluating LLM -- Generated Multimodal Diagnosis from Medical Images and Symptom Analysis\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  81%|██████████████████████████████████████████████▎          | 2691/3312 [1:09:24<17:32,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Contextualization Distillation from Large Language Model for Knowledge Graph Completion\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  81%|██████████████████████████████████████████████▎          | 2692/3312 [1:09:26<16:46,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Evaluating Gender Bias in Large Language Models via Chain-of-Thought Prompting\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  81%|██████████████████████████████████████████████▎          | 2693/3312 [1:09:27<16:48,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Efficient Tuning and Inference for Large Language Models on Textual Graphs\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  81%|██████████████████████████████████████████████▎          | 2694/3312 [1:09:29<16:16,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Hardware Phi-1.5B: A Large Language Model Encodes Hardware Domain Specific Knowledge\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  81%|██████████████████████████████████████████████▍          | 2695/3312 [1:09:30<15:42,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Prompting Diverse Ideas: Increasing AI Idea Variance\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  81%|██████████████████████████████████████████████▍          | 2696/3312 [1:09:32<15:35,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Do We Need Language-Specific Fact-Checking Models? The Case of Chinese\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  81%|██████████████████████████████████████████████▍          | 2697/3312 [1:09:33<15:39,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Baichuan2-Sum: Instruction Finetune Baichuan2-7B Model for Dialogue Summarization\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  81%|██████████████████████████████████████████████▍          | 2698/3312 [1:09:35<15:35,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ProtAgents: Protein discovery via large language model multi-agent collaborations combining physics and machine learning\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  81%|██████████████████████████████████████████████▍          | 2699/3312 [1:09:36<15:13,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: To Burst or Not to Burst: Generating and Quantifying Improbable Text\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  82%|██████████████████████████████████████████████▍          | 2700/3312 [1:09:38<15:00,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: DataFrame QA: A Universal LLM Framework on DataFrame Question Answering Without Data Exposure\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  82%|██████████████████████████████████████████████▍          | 2701/3312 [1:09:39<14:49,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Learning to Trust Your Feelings: Leveraging Self-awareness in LLMs for Hallucination Mitigation\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  82%|██████████████████████████████████████████████▌          | 2702/3312 [1:09:41<15:16,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: AI Does Not Alter Perceptions of Text Messages\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  82%|██████████████████████████████████████████████▌          | 2703/3312 [1:09:42<15:01,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: A Survey on Data Augmentation in Large Model Era\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  82%|██████████████████████████████████████████████▌          | 2704/3312 [1:09:44<14:47,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: MultiHop-RAG: Benchmarking Retrieval-Augmented Generation for Multi-Hop Queries\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  82%|██████████████████████████████████████████████▌          | 2705/3312 [1:09:45<15:20,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: A RAG-based Question Answering System Proposal for Understanding Islam: MufassirQAS LLM\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  82%|██████████████████████████████████████████████▌          | 2706/3312 [1:09:47<15:10,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: A Comprehensive Survey of Compression Algorithms for Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  82%|██████████████████████████████████████████████▌          | 2707/3312 [1:09:48<15:26,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Fortifying Ethical Boundaries in AI: Advanced Strategies for Enhancing Security in Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  82%|██████████████████████████████████████████████▌          | 2708/3312 [1:09:50<15:43,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: L-AutoDA: Leveraging Large Language Models for Automated Decision-based Adversarial Attacks\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  82%|██████████████████████████████████████████████▌          | 2709/3312 [1:09:51<15:25,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Equipping Language Models with Tool Use Capability for Tabular Data Analysis in Finance\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  82%|██████████████████████████████████████████████▋          | 2710/3312 [1:09:53<15:24,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: An Empirical Study on Large Language Models in Accuracy and Robustness under Chinese Industrial Scenarios\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  82%|██████████████████████████████████████████████▋          | 2711/3312 [1:09:54<15:01,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Improving Medical Reasoning through Retrieval and Self-Reflection with Retrieval-Augmented Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  82%|██████████████████████████████████████████████▋          | 2712/3312 [1:09:56<14:40,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Enhancing Large Language Model Performance To Answer Questions and Extract Information More Accurately\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  82%|██████████████████████████████████████████████▋          | 2713/3312 [1:09:57<14:22,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Scalable Qualitative Coding with LLMs: Chain-of-Thought Reasoning Matches Human Performance in Some Hermeneutic Tasks\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  82%|██████████████████████████████████████████████▋          | 2714/3312 [1:09:59<14:26,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: EAGLE: Speculative Sampling Requires Rethinking Feature Uncertainty\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  82%|██████████████████████████████████████████████▋          | 2715/3312 [1:10:00<14:41,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: From GPT-4 to Gemini and Beyond: Assessing the Landscape of MLLMs on Generalizability, Trustworthiness and Causality through Four Modalities\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  82%|██████████████████████████████████████████████▋          | 2716/3312 [1:10:02<14:39,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: PROXYQA: An Alternative Framework for Evaluating Long-Form Text Generation with Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  82%|██████████████████████████████████████████████▊          | 2717/3312 [1:10:03<14:17,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Measuring Moral Inconsistencies in Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  82%|██████████████████████████████████████████████▊          | 2718/3312 [1:10:04<14:25,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: On the generalization capacity of neural networks during generic multimodal reasoning\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  82%|██████████████████████████████████████████████▊          | 2719/3312 [1:10:06<14:31,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: SliceGPT: Compress Large Language Models by Deleting Rows and Columns\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  82%|██████████████████████████████████████████████▊          | 2720/3312 [1:10:08<14:50,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Airavata: Introducing Hindi Instruction-tuned LLM\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  82%|██████████████████████████████████████████████▊          | 2721/3312 [1:10:09<15:41,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Do LLMs Dream of Ontologies?\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  82%|██████████████████████████████████████████████▊          | 2722/3312 [1:10:11<15:40,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: The Power of Noise: Redefining Retrieval for RAG Systems\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  82%|██████████████████████████████████████████████▊          | 2723/3312 [1:10:12<15:25,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: F-Eval: Asssessing Fundamental Abilities with Refined Evaluation Methods\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  82%|██████████████████████████████████████████████▉          | 2724/3312 [1:10:14<14:58,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Evaluation of LLM Chatbots for OSINT-based Cyber Threat Awareness\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  82%|██████████████████████████████████████████████▉          | 2725/3312 [1:10:15<14:44,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ChemDFM: Dialogue Foundation Model for Chemistry\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  82%|██████████████████████████████████████████████▉          | 2726/3312 [1:10:17<14:31,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Large Language Model Adaptation for Financial Sentiment Analysis\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  82%|██████████████████████████████████████████████▉          | 2727/3312 [1:10:18<14:53,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Large Language Model Guided Knowledge Distillation for Time Series Anomaly Detection\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  82%|██████████████████████████████████████████████▉          | 2728/3312 [1:10:20<15:06,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Under the Surface: Tracking the Artifactuality of LLM-Generated Data\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  82%|██████████████████████████████████████████████▉          | 2729/3312 [1:10:21<14:41,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: MaLLaM -- Malaysia Large Language Model\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  82%|██████████████████████████████████████████████▉          | 2730/3312 [1:10:23<14:42,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Scientific Large Language Models: A Survey on Biological & Chemical Domains\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  82%|███████████████████████████████████████████████          | 2731/3312 [1:10:24<14:37,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Benchmarking Large Language Models in Complex Question Answering Attribution using Knowledge Graphs\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  82%|███████████████████████████████████████████████          | 2732/3312 [1:10:26<14:16,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: An Empirical Investigation of Domain Adaptation Ability for Chinese Spelling Check Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  83%|███████████████████████████████████████████████          | 2733/3312 [1:10:27<13:58,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Query of CC: Unearthing Large Scale Domain-Specific Knowledge from Public Corpora\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  83%|███████████████████████████████████████████████          | 2734/3312 [1:10:29<14:00,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Enhancing Diagnostic Accuracy through Multi-Agent Conversations: Using Large Language Models to Mitigate Cognitive Bias\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  83%|███████████████████████████████████████████████          | 2735/3312 [1:10:30<14:30,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ChatGPT vs Gemini vs LLaMA on Multilingual Sentiment Analysis\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  83%|███████████████████████████████████████████████          | 2736/3312 [1:10:32<14:10,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Language Modelling Approaches to Adaptive Machine Translation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  83%|███████████████████████████████████████████████          | 2737/3312 [1:10:33<14:12,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Looking Right is Sometimes Right: Investigating the Capabilities of Decoder-only LLMs for Sequence Labeling\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  83%|███████████████████████████████████████████████          | 2738/3312 [1:10:35<14:09,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Relative Value Biases in Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  83%|███████████████████████████████████████████████▏         | 2739/3312 [1:10:36<14:38,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Empathy and the Right to Be an Exception: What LLMs Can and Cannot Do\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  83%|███████████████████████████████████████████████▏         | 2740/3312 [1:10:38<14:27,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Prompting Large Language Models for Zero-Shot Clinical Prediction with Structured Longitudinal Electronic Health Record Data\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  83%|███████████████████████████████████████████████▏         | 2741/3312 [1:10:39<14:11,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: K-QA: A Real-World Medical Q&A Benchmark\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  83%|███████████████████████████████████████████████▏         | 2742/3312 [1:10:41<14:50,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LongHealth: A Question Answering Benchmark with Long Clinical Documents\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  83%|███████████████████████████████████████████████▏         | 2743/3312 [1:10:43<14:50,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Wordflow: Social Prompt Engineering for Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  83%|███████████████████████████████████████████████▏         | 2744/3312 [1:10:44<14:23,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: The Typing Cure: Experiences with Large Language Model Chatbots for Mental Health Support\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  83%|███████████████████████████████████████████████▏         | 2745/3312 [1:10:45<14:04,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ServerlessLLM: Locality-Enhanced Serverless Inference for Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  83%|███████████████████████████████████████████████▎         | 2746/3312 [1:10:47<14:19,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LLM on FHIR -- Demystifying Health Records\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  83%|███████████████████████████████████████████████▎         | 2747/3312 [1:10:48<14:07,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Demystifying Chains, Trees, and Graphs of Thoughts\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  83%|███████████████████████████████████████████████▎         | 2748/3312 [1:10:50<14:07,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: RomanSetu: Efficiently unlocking multilingual capabilities of Large Language Models models via Romanization\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  83%|███████████████████████████████████████████████▎         | 2749/3312 [1:10:51<13:57,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ZS4C: Zero-Shot Synthesis of Compilable Code for Incomplete Code Snippets using ChatGPT\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  83%|███████████████████████████████████████████████▎         | 2750/3312 [1:10:53<13:59,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Transformers and Cortical Waves: Encoders for Pulling In Context Across Time\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  83%|███████████████████████████████████████████████▎         | 2751/3312 [1:10:55<14:16,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Improving Natural Language Capability of Code Large Language Model\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  83%|███████████████████████████████████████████████▎         | 2752/3312 [1:10:56<14:18,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: How Can Large Language Models Understand Spatial-Temporal Data?\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  83%|███████████████████████████████████████████████▍         | 2753/3312 [1:10:58<14:38,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Copilot Refinement: Addressing Code Smells in Copilot-Generated Python Code\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  83%|███████████████████████████████████████████████▍         | 2754/3312 [1:11:01<18:47,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: BayesPrompt: Prompting Large-Scale Pre-Trained Language Models on Few-shot Inference via Debiased Domain Abstraction\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  83%|███████████████████████████████████████████████▍         | 2755/3312 [1:11:02<17:09,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: True Knowledge Comes from Practice: Aligning LLMs with Embodied Environments via Reinforcement Learning\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  83%|███████████████████████████████████████████████▍         | 2756/3312 [1:11:04<16:18,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: When Geoscience Meets Generative AI and Large Language Models: Foundations, Trends, and Future Challenges\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  83%|███████████████████████████████████████████████▍         | 2757/3312 [1:11:05<15:41,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: FP6-LLM: Efficiently Serving Large Language Models Through FP6-Centric Algorithm-System Co-Design\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  83%|███████████████████████████████████████████████▍         | 2758/3312 [1:11:07<14:57,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: CompactifAI: Extreme Compression of Large Language Models using Quantum-Inspired Tensor Networks\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  83%|███████████████████████████████████████████████▍         | 2759/3312 [1:11:08<14:40,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Towards Goal-oriented Large Language Model Prompting: A Survey\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  83%|███████████████████████████████████████████████▌         | 2760/3312 [1:11:10<14:18,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Towards Uncertainty-Aware Language Agent\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  83%|███████████████████████████████████████████████▌         | 2761/3312 [1:11:11<14:02,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: CMMU: A Benchmark for Chinese Multi-modal Multi-type Question Understanding and Reasoning\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  83%|███████████████████████████████████████████████▌         | 2762/3312 [1:11:13<14:01,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ConstraintChecker: A Plugin for Large Language Models to Reason on Commonsense Knowledge Bases\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  83%|███████████████████████████████████████████████▌         | 2763/3312 [1:11:14<13:42,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Towards Consistent Natural-Language Explanations via Explanation-Consistency Finetuning\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  83%|███████████████████████████████████████████████▌         | 2764/3312 [1:11:16<13:46,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: BootPIG: Bootstrapping Zero-shot Personalized Image Generation Capabilities in Pretrained Diffusion Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  83%|███████████████████████████████████████████████▌         | 2765/3312 [1:11:17<14:02,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Adaptive Text Watermark for Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  84%|███████████████████████████████████████████████▌         | 2766/3312 [1:11:19<14:03,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LocMoE: A Low-overhead MoE for Large Language Model Training\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  84%|███████████████████████████████████████████████▌         | 2767/3312 [1:11:20<13:39,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: WebVoyager: Building an End-to-End Web Agent with Large Multimodal Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  84%|███████████████████████████████████████████████▋         | 2768/3312 [1:11:22<13:21,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: A Survey of Deep Learning and Foundation Models for Time Series Forecasting\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  84%|███████████████████████████████████████████████▋         | 2769/3312 [1:11:23<13:05,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Hierarchical Continual Reinforcement Learning via Large Language Model\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  84%|███████████████████████████████████████████████▋         | 2770/3312 [1:11:25<13:13,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: MULTIVERSE: Exposing Large Language Model Alignment Problems in Diverse Worlds\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  84%|███████████████████████████████████████████████▋         | 2771/3312 [1:11:26<13:04,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: A comparative study of zero-shot inference with large language models and supervised modeling in breast cancer pathology classification\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  84%|███████████████████████████████████████████████▋         | 2772/3312 [1:11:27<12:49,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Beyond Behaviorist Representational Harms: A Plan for Measurement and Mitigation\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  84%|███████████████████████████████████████████████▋         | 2773/3312 [1:11:29<13:10,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Unmasking and Quantifying Racial Bias of Large Language Models in Medical Report Generation\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  84%|███████████████████████████████████████████████▋         | 2774/3312 [1:11:30<13:03,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: TPD: Enhancing Student Language Model Reasoning via Principle Discovery and Guidance\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  84%|███████████████████████████████████████████████▊         | 2775/3312 [1:11:32<12:53,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Democratizing Fine-grained Visual Recognition with Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  84%|███████████████████████████████████████████████▊         | 2776/3312 [1:11:33<13:07,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: The Calibration Gap between Model and Human Confidence in Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  84%|███████████████████████████████████████████████▊         | 2777/3312 [1:11:35<13:22,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Automated Root Causing of Cloud Incidents using In-Context Learning with GPT-4\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  84%|███████████████████████████████████████████████▊         | 2778/3312 [1:11:36<13:05,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Investigating the Efficacy of Large Language Models for Code Clone Detection\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  84%|███████████████████████████████████████████████▊         | 2779/3312 [1:11:38<13:14,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: VisualWebArena: Evaluating Multimodal Agents on Realistic Visual Web Tasks\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  84%|███████████████████████████████████████████████▊         | 2780/3312 [1:11:39<13:08,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Consistency Guided Knowledge Retrieval and Denoising in LLMs for Zero-shot Document-level Relation Triplet Extraction\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  84%|███████████████████████████████████████████████▊         | 2781/3312 [1:11:41<13:01,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Evaluation of General Large Language Models in Contextually Assessing Semantic Concepts Extracted from Adult Critical Care Electronic Health Record Notes\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  84%|███████████████████████████████████████████████▉         | 2782/3312 [1:11:42<12:48,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: SpeechGPT-Gen: Scaling Chain-of-Information Speech Generation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  84%|███████████████████████████████████████████████▉         | 2783/3312 [1:11:44<13:07,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Can GPT-3.5 Generate and Code Discharge Summaries?\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  84%|███████████████████████████████████████████████▉         | 2784/3312 [1:11:45<13:51,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Research about the Ability of LLM in the Tamper-Detection Area\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  84%|███████████████████████████████████████████████▉         | 2785/3312 [1:11:47<13:54,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: How AI Ideas Affect the Creativity, Diversity, and Evolution of Human Ideas: Evidence From a Large, Dynamic Experiment\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  84%|███████████████████████████████████████████████▉         | 2786/3312 [1:11:49<14:02,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Clue-Guided Path Exploration: An Efficient Knowledge Base Question-Answering Framework with Low Computational Resource Consumption\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  84%|███████████████████████████████████████████████▉         | 2787/3312 [1:11:51<14:39,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Large language model empowered participatory urban planning\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  84%|███████████████████████████████████████████████▉         | 2788/3312 [1:11:53<15:39,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: APT-Pipe: A Prompt-Tuning Tool for Social Data Annotation using ChatGPT\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  84%|███████████████████████████████████████████████▉         | 2789/3312 [1:11:54<15:19,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ConTextual: Evaluating Context-Sensitive Text-Rich Visual Reasoning in Large Multimodal Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  84%|████████████████████████████████████████████████         | 2790/3312 [1:11:56<14:25,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Towards Explainable Harmful Meme Detection through Multimodal Debate between Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  84%|████████████████████████████████████████████████         | 2791/3312 [1:11:57<13:49,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Can AI Assistants Know What They Don't Know?\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  84%|████████████████████████████████████████████████         | 2792/3312 [1:11:59<13:33,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: UniMS-RAG: A Unified Multi-source Retrieval-Augmented Generation for Personalized Dialogue Systems\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  84%|████████████████████████████████████████████████         | 2793/3312 [1:12:00<13:28,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: From Random to Informed Data Selection: A Diversity-Based Approach to Optimize Human Annotation and Few-Shot Learning\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  84%|████████████████████████████████████████████████         | 2794/3312 [1:12:02<12:58,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LPNL: Scalable Link Prediction with Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  84%|████████████████████████████████████████████████         | 2795/3312 [1:12:03<13:12,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: TAT-LLM: A Specialized Language Model for Discrete Reasoning over Tabular and Textual Data\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  84%|████████████████████████████████████████████████         | 2796/3312 [1:12:05<12:59,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ULTRA: Unleash LLMs' Potential for Event Argument Extraction through Hierarchical Modeling and Pair-wise Refinement\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  84%|████████████████████████████████████████████████▏        | 2797/3312 [1:12:06<12:52,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: MLLMReID: Multimodal Large Language Model-based Person Re-identification\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  84%|████████████████████████████████████████████████▏        | 2798/3312 [1:12:08<12:56,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: AgentBoard: An Analytical Evaluation Board of Multi-turn LLM Agents\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  85%|████████████████████████████████████████████████▏        | 2799/3312 [1:12:09<12:39,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: CFMatch: Aligning Automated Answer Equivalence Evaluation with Expert Judgments For Open-Domain Question Answering\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  85%|████████████████████████████████████████████████▏        | 2800/3312 [1:12:10<12:27,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ARGS: Alignment as Reward-Guided Search\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  85%|████████████████████████████████████████████████▏        | 2801/3312 [1:12:12<12:15,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: The Language Barrier: Dissecting Safety Challenges of LLMs in Multilingual Contexts\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  85%|████████████████████████████████████████████████▏        | 2802/3312 [1:12:13<12:31,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Quality of Answers of Generative Large Language Models vs Peer Patients for Interpreting Lab Test Results for Lay Patients: Evaluation Study\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  85%|████████████████████████████████████████████████▏        | 2803/3312 [1:12:15<12:43,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: XAI for All: Can Large Language Models Simplify Explainable AI?\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  85%|████████████████████████████████████████████████▎        | 2804/3312 [1:12:16<12:28,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Towards Trustable Language Models: Investigating Information Quality of Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  85%|████████████████████████████████████████████████▎        | 2805/3312 [1:12:18<12:26,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: HAZARD Challenge: Embodied Decision Making in Dynamically Changing Environments\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  85%|████████████████████████████████████████████████▎        | 2806/3312 [1:12:20<13:19,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Raidar: geneRative AI Detection viA Rewriting\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  85%|████████████████████████████████████████████████▎        | 2807/3312 [1:12:21<13:25,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: AutoRT: Embodied Foundation Models for Large Scale Orchestration of Robotic Agents\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  85%|████████████████████████████████████████████████▎        | 2808/3312 [1:12:23<13:09,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Chatterbox: Robust Transport for LLM Token Streaming under Unstable Network\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  85%|████████████████████████████████████████████████▎        | 2809/3312 [1:12:24<13:12,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Transformer-Based Models Are Not Yet Perfect At Learning to Emulate Structural Recursion\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  85%|████████████████████████████████████████████████▎        | 2810/3312 [1:12:26<12:49,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Red Teaming Visual Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  85%|████████████████████████████████████████████████▍        | 2811/3312 [1:12:27<12:36,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: From Understanding to Utilization: A Survey on Explainability for Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  85%|████████████████████████████████████████████████▍        | 2812/3312 [1:12:29<12:46,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: How well can large language models explain business processes?\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  85%|████████████████████████████████████████████████▍        | 2813/3312 [1:12:31<13:29,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Benchmarking LLMs via Uncertainty Quantification\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  85%|████████████████████████████████████████████████▍        | 2814/3312 [1:12:32<12:58,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Multilingual and Fully Non-Autoregressive ASR with Large Language Model Fusion: A Comprehensive Study\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  85%|████████████████████████████████████████████████▍        | 2815/3312 [1:12:34<14:45,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Evaluation of large language models for assessing code maintainability\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  85%|████████████████████████████████████████████████▍        | 2816/3312 [1:12:36<14:32,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Generating Zero-shot Abstractive Explanations for Rumour Verification\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  85%|████████████████████████████████████████████████▍        | 2817/3312 [1:12:38<13:57,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ChatGraph: Chat with Your Graphs\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  85%|████████████████████████████████████████████████▍        | 2818/3312 [1:12:39<13:36,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Context Matters: Pushing the Boundaries of Open-Ended Answer Generation with Graph-Structured Knowledge Context\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  85%|████████████████████████████████████████████████▌        | 2819/3312 [1:12:41<13:22,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Knowledge Distillation from Language-Oriented to Emergent Communication for Multi-Agent Remote Control\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  85%|████████████████████████████████████████████████▌        | 2820/3312 [1:12:42<12:58,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Revolutionizing Retrieval-Augmented Generation with Enhanced PDF Structure Recognition\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  85%|████████████████████████████████████████████████▌        | 2821/3312 [1:12:44<13:03,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: SLANG: New Concept Comprehension of Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  85%|████████████████████████████████████████████████▌        | 2822/3312 [1:12:46<14:00,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Automated Fact-Checking of Climate Change Claims with Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  85%|████████████████████████████████████████████████▌        | 2823/3312 [1:12:47<13:35,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Can Large Language Models Write Parallel Code?\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  85%|████████████████████████████████████████████████▌        | 2824/3312 [1:12:49<12:59,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: BiTA: Bi-Directional Tuning for Lossless Acceleration in Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  85%|████████████████████████████████████████████████▌        | 2825/3312 [1:12:51<13:40,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Assessing and Understanding Creativity in Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  85%|████████████████████████████████████████████████▋        | 2826/3312 [1:12:52<13:05,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Large Language Models are Superpositions of All Characters: Attaining Arbitrary Role-play via Self-Alignment\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  85%|████████████████████████████████████████████████▋        | 2827/3312 [1:12:54<12:42,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Zero Shot Open-ended Video Inference\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  85%|████████████████████████████████████████████████▋        | 2828/3312 [1:12:55<12:48,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Towards Socially and Morally Aware RL agent: Reward Design With LLM\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  85%|████████████████████████████████████████████████▋        | 2829/3312 [1:12:57<12:51,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: The Neglected Tails of Vision-Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  85%|████████████████████████████████████████████████▋        | 2830/3312 [1:12:58<12:36,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Analyzing the Effectiveness of Large Language Models on Text-to-SQL Synthesis\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  85%|████████████████████████████████████████████████▋        | 2831/3312 [1:13:00<12:24,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Fine-tuning Large Language Models for Multigenerator, Multidomain, and Multilingual Machine-Generated Text Detection\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  86%|████████████████████████████████████████████████▋        | 2832/3312 [1:13:01<12:00,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: GRATH: Gradual Self-Truthifying for Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  86%|████████████████████████████████████████████████▊        | 2833/3312 [1:13:03<12:10,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Less Could Be Better: Parameter-efficient Fine-tuning Advances Medical Vision Foundation Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  86%|████████████████████████████████████████████████▊        | 2834/3312 [1:13:05<12:40,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: CheXagent: Towards a Foundation Model for Chest X-Ray Interpretation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  86%|████████████████████████████████████████████████▊        | 2835/3312 [1:13:06<12:38,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: APT: Adaptive Pruning and Tuning Pretrained Language Models for Efficient Training and Inference\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  86%|████████████████████████████████████████████████▊        | 2836/3312 [1:13:08<12:10,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Text Embedding Inversion Security for Multilingual Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  86%|████████████████████████████████████████████████▊        | 2837/3312 [1:13:09<11:53,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: WARM: On the Benefits of Weight Averaged Reward Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  86%|████████████████████████████████████████████████▊        | 2838/3312 [1:13:11<11:56,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: The Ethics of Interaction: Mitigating Security Threats in LLMs\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  86%|████████████████████████████████████████████████▊        | 2839/3312 [1:13:12<12:10,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: The Curious Case of Nonverbal Abstract Reasoning with Multi-Modal Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  86%|████████████████████████████████████████████████▉        | 2840/3312 [1:13:14<11:50,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: An Empirical Study of In-context Learning in LLMs for Machine Translation\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  86%|████████████████████████████████████████████████▉        | 2841/3312 [1:13:15<11:55,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Temporal Blind Spots in Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  86%|████████████████████████████████████████████████▉        | 2842/3312 [1:13:17<12:14,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Spotting LLMs With Binoculars: Zero-Shot Detection of Machine-Generated Text\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  86%|████████████████████████████████████████████████▉        | 2843/3312 [1:13:18<12:05,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LLM-based policy generation for intent-based management of applications\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  86%|████████████████████████████████████████████████▉        | 2844/3312 [1:13:20<11:38,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: \"Which LLM should I use?\": Evaluating LLMs for tasks performed by Undergraduate Computer Science Students\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  86%|████████████████████████████████████████████████▉        | 2845/3312 [1:13:21<11:38,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Detecting Multimedia Generated by Large AI Models: A Survey\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  86%|████████████████████████████████████████████████▉        | 2846/3312 [1:13:23<11:55,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: CMMMU: A Chinese Massive Multi-discipline Multimodal Understanding Benchmark\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  86%|████████████████████████████████████████████████▉        | 2847/3312 [1:13:25<12:35,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Blinded by Generated Contexts: How Language Models Merge Generated and Retrieved Contexts for Open-Domain QA?\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  86%|█████████████████████████████████████████████████        | 2848/3312 [1:13:26<12:19,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Multimodal Deep Learning of Word-of-Mouth Text and Demographics to Predict Customer Rating: Handling Consumer Heterogeneity in Marketing\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  86%|█████████████████████████████████████████████████        | 2849/3312 [1:13:28<12:39,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: PsySafe: A Comprehensive Framework for Psychological-based Attack, Defense, and Evaluation of Multi-agent System Safety\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  86%|█████████████████████████████████████████████████        | 2850/3312 [1:13:30<12:23,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Distilling Mathematical Reasoning Capabilities into Small Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  86%|█████████████████████████████████████████████████        | 2851/3312 [1:13:31<12:09,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: AI for social science and social science of AI: A Survey\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  86%|█████████████████████████████████████████████████        | 2852/3312 [1:13:33<11:49,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Hallucination is Inevitable: An Innate Limitation of Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  86%|█████████████████████████████████████████████████        | 2853/3312 [1:13:34<12:02,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Speak It Out: Solving Symbol-Related Problems with Symbol-to-Language Conversion for Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  86%|█████████████████████████████████████████████████        | 2854/3312 [1:13:36<11:44,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Mastering Text-to-Image Diffusion: Recaptioning, Planning, and Generating with Multimodal LLMs\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  86%|█████████████████████████████████████████████████▏       | 2855/3312 [1:13:37<11:24,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Emojis Decoded: Leveraging ChatGPT for Enhanced Understanding in Social Media Communications\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  86%|█████████████████████████████████████████████████▏       | 2856/3312 [1:13:39<11:23,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Revolutionizing Finance with LLMs: An Overview of Applications and Insights\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  86%|█████████████████████████████████████████████████▏       | 2857/3312 [1:13:40<11:54,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Large Language Model based Multi-Agents: A Survey of Progress and Challenges\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  86%|█████████████████████████████████████████████████▏       | 2858/3312 [1:13:42<11:26,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Enhancing Recommendation Diversity by Re-ranking with Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  86%|█████████████████████████████████████████████████▏       | 2859/3312 [1:13:43<11:09,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: CheX-GPT: Harnessing Large Language Models for Enhanced Chest X-ray Report Labeling\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  86%|█████████████████████████████████████████████████▏       | 2860/3312 [1:13:44<11:01,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Integration of Large Language Models in Control of EHD Pumps for Precise Color Synthesis\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  86%|█████████████████████████████████████████████████▏       | 2861/3312 [1:13:46<10:54,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Training microrobots to swim by a large language model\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  86%|█████████████████████████████████████████████████▎       | 2862/3312 [1:13:47<11:06,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Over-Reasoning and Redundant Calculation of Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  86%|█████████████████████████████████████████████████▎       | 2863/3312 [1:13:49<10:55,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Instructional Fingerprinting of Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  86%|█████████████████████████████████████████████████▎       | 2864/3312 [1:13:51<11:38,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: General Flow as Foundation Affordance for Scalable Robot Learning\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  87%|█████████████████████████████████████████████████▎       | 2865/3312 [1:13:52<11:58,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LLMRA: Multi-modal Large Language Model based Restoration Assistant\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  87%|█████████████████████████████████████████████████▎       | 2866/3312 [1:13:54<11:43,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: MedLM: Exploring Language Models for Medical Question Answering Systems\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  87%|█████████████████████████████████████████████████▎       | 2867/3312 [1:13:55<11:40,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Using Large Language Model for End-to-End Chinese ASR and NER\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  87%|█████████████████████████████████████████████████▎       | 2868/3312 [1:13:57<11:23,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Confidence Preservation Property in Knowledge Distillation Abstractions\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  87%|█████████████████████████████████████████████████▍       | 2869/3312 [1:13:59<11:32,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ProLex: A Benchmark for Language Proficiency-oriented Lexical Substitution\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  87%|█████████████████████████████████████████████████▍       | 2870/3312 [1:14:00<11:41,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Prompting Large Vision-Language Models for Compositional Reasoning\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  87%|█████████████████████████████████████████████████▍       | 2871/3312 [1:14:02<11:30,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Identifying and Analyzing Task-Encoding Tokens in Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  87%|█████████████████████████████████████████████████▍       | 2872/3312 [1:14:03<11:22,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: CodeAid: Evaluating a Classroom Deployment of an LLM-based Programming Assistant that Balances Student and Educator Needs\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  87%|█████████████████████████████████████████████████▍       | 2873/3312 [1:14:05<11:04,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Prompt-RAG: Pioneering Vector Embedding-Free Retrieval-Augmented Generation in Niche Domains, Exemplified by Korean Medicine\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  87%|█████████████████████████████████████████████████▍       | 2874/3312 [1:14:06<11:18,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: InferAligner: Inference-Time Alignment for Harmlessness through Cross-Model Guidance\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  87%|█████████████████████████████████████████████████▍       | 2875/3312 [1:14:08<11:29,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: How the Advent of Ubiquitous Large Language Models both Stymie and Turbocharge Dynamic Adversarial Question Generation\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  87%|█████████████████████████████████████████████████▍       | 2876/3312 [1:14:09<11:02,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Inducing High Energy-Latency of Large Vision-Language Models with Verbose Images\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  87%|█████████████████████████████████████████████████▌       | 2877/3312 [1:14:11<10:44,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: BadChain: Backdoor Chain-of-Thought Prompting for Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  87%|█████████████████████████████████████████████████▌       | 2878/3312 [1:14:12<10:50,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Evaluating and Enhancing Large Language Models Performance in Domain-specific Medicine: Osteoarthritis Management with DocOA\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  87%|█████████████████████████████████████████████████▌       | 2879/3312 [1:14:14<10:58,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Mining experimental data from Materials Science literature with Large Language Models: an evaluation study\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  87%|█████████████████████████████████████████████████▌       | 2880/3312 [1:14:15<11:00,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: FAIR Enough: How Can We Develop and Assess a FAIR-Compliant Dataset for Large Language Models' Training?\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  87%|█████████████████████████████████████████████████▌       | 2881/3312 [1:14:17<10:51,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Reinforcement learning for question answering in programming domain using public community scoring as a human feedback\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  87%|█████████████████████████████████████████████████▌       | 2882/3312 [1:14:18<10:50,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Pruning for Protection: Increasing Jailbreak Resistance in Aligned LLMs Without Fine-Tuning\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  87%|█████████████████████████████████████████████████▌       | 2883/3312 [1:14:20<10:52,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Using LLMs to discover emerging coded antisemitic hate-speech in extremist social media\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  87%|█████████████████████████████████████████████████▋       | 2884/3312 [1:14:21<10:50,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Quantifying Similarity: Text-Mining Approaches to Evaluate ChatGPT and Google Bard Content in Relation to BioMedical Literature\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  87%|█████████████████████████████████████████████████▋       | 2885/3312 [1:14:23<10:56,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Medusa: Simple LLM Inference Acceleration Framework with Multiple Decoding Heads\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  87%|█████████████████████████████████████████████████▋       | 2886/3312 [1:14:24<10:51,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Knowledge Verification to Nip Hallucination in the Bud\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  87%|█████████████████████████████████████████████████▋       | 2887/3312 [1:14:26<10:30,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Interactions with Prompt Problems: A New Way to Teach Programming with Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  87%|█████████████████████████████████████████████████▋       | 2888/3312 [1:14:28<11:21,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: FinLLMs: A Framework for Financial Reasoning Dataset Generation with Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  87%|█████████████████████████████████████████████████▋       | 2889/3312 [1:14:29<10:58,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Dynamic Q&A of Clinical Documents with Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  87%|█████████████████████████████████████████████████▋       | 2890/3312 [1:14:31<10:44,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: MLLM-Tool: A Multimodal Large Language Model For Tool Agent Learning\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  87%|█████████████████████████████████████████████████▊       | 2891/3312 [1:14:32<10:36,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Sowing the Wind, Reaping the Whirlwind: The Impact of Editing Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  87%|█████████████████████████████████████████████████▊       | 2892/3312 [1:14:34<10:20,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: PHOENIX: Open-Source Language Adaption for Direct Preference Optimization\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  87%|█████████████████████████████████████████████████▊       | 2893/3312 [1:14:35<10:48,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Progressive Distillation Based on Masked Generation Feature Method for Knowledge Graph Completion\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  87%|█████████████████████████████████████████████████▊       | 2894/3312 [1:14:37<10:43,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: SocraSynth: Multi-LLM Reasoning with Conditional Statistics\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  87%|█████████████████████████████████████████████████▊       | 2895/3312 [1:14:38<10:59,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Mementos: A Comprehensive Benchmark for Multimodal Large Language Model Reasoning over Image Sequences\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  87%|█████████████████████████████████████████████████▊       | 2896/3312 [1:14:40<10:49,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Cross-lingual Editing in Multilingual Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  87%|█████████████████████████████████████████████████▊       | 2897/3312 [1:14:41<10:37,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: A match made in consistency heaven: when large language models meet evolutionary algorithms\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  88%|█████████████████████████████████████████████████▉       | 2898/3312 [1:14:43<11:16,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: AI Revolution on Chat Bot: Evidence from a Randomized Controlled Experiment\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  88%|█████████████████████████████████████████████████▉       | 2899/3312 [1:14:45<10:53,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: FinSQL: Model-Agnostic LLMs-based Text-to-SQL Framework for Financial Analysis\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  88%|█████████████████████████████████████████████████▉       | 2900/3312 [1:14:47<11:17,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Knowledge Fusion of Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  88%|█████████████████████████████████████████████████▉       | 2901/3312 [1:14:48<11:18,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Named Entity Recognition Under Domain Shift via Metric Learning for Life Sciences\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  88%|█████████████████████████████████████████████████▉       | 2902/3312 [1:14:50<11:17,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: DeepEdit: Knowledge Editing as Decoding with Constraints\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  88%|█████████████████████████████████████████████████▉       | 2903/3312 [1:14:52<11:51,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Critical Data Size of Language Models from a Grokking Perspective\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  88%|█████████████████████████████████████████████████▉       | 2904/3312 [1:14:53<11:07,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Large Language Models are Efficient Learners of Noise-Robust Speech Recognition\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  88%|█████████████████████████████████████████████████▉       | 2905/3312 [1:14:55<10:52,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Can A Cognitive Architecture Fundamentally Enhance LLMs? Or Vice Versa?\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  88%|██████████████████████████████████████████████████       | 2906/3312 [1:14:56<10:30,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Can Large Language Model Summarizers Adapt to Diverse Scientific Communication Goals?\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  88%|██████████████████████████████████████████████████       | 2907/3312 [1:14:58<10:10,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Using LLM such as ChatGPT for Designing and Implementing a RISC Processor: Execution,Challenges and Limitations\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  88%|██████████████████████████████████████████████████       | 2908/3312 [1:14:59<09:57,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Excuse me, sir? Your language model is leaking (information)\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  88%|██████████████████████████████████████████████████       | 2909/3312 [1:15:01<10:57,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Towards Language-Driven Video Inpainting via Multimodal Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  88%|██████████████████████████████████████████████████       | 2910/3312 [1:15:02<10:40,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LangProp: A code optimization framework using Language Models applied to driving\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  88%|██████████████████████████████████████████████████       | 2911/3312 [1:15:04<10:34,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Beyond Reference-Based Metrics: Analyzing Behaviors of Open LLMs on Data-to-Text Generation\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  88%|██████████████████████████████████████████████████       | 2912/3312 [1:15:06<11:41,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Spatial-Temporal Large Language Model for Traffic Prediction\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  88%|██████████████████████████████████████████████████▏      | 2913/3312 [1:15:09<13:15,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Code Prompting Elicits Conditional Reasoning Abilities in Text+Code LLMs\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  88%|██████████████████████████████████████████████████▏      | 2914/3312 [1:15:10<12:29,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: DiffusionGPT: LLM-Driven Text-to-Image Generation System\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  88%|██████████████████████████████████████████████████▏      | 2915/3312 [1:15:12<11:29,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Self-Rewarding Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  88%|██████████████████████████████████████████████████▏      | 2916/3312 [1:15:13<11:03,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: R-Judge: Benchmarking Safety Risk Awareness for LLM Agents\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  88%|██████████████████████████████████████████████████▏      | 2917/3312 [1:15:15<10:37,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Gender Bias in Machine Translation and The Era of Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  88%|██████████████████████████████████████████████████▏      | 2918/3312 [1:15:16<10:19,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Advancing Large Multi-modal Models with Explicit Chain-of-Reasoning and Visual Question Generation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  88%|██████████████████████████████████████████████████▏      | 2919/3312 [1:15:18<10:09,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: WorldDreamer: Towards General World Models for Video Generation via Predicting Masked Tokens\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  88%|██████████████████████████████████████████████████▎      | 2920/3312 [1:15:19<09:49,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Sketch-Guided Constrained Decoding for Boosting Blackbox Large Language Models without Logit Access\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  88%|██████████████████████████████████████████████████▎      | 2921/3312 [1:15:21<10:17,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: When Neural Code Completion Models Size up the Situation: Attaining Cheaper and Faster Completion through Dynamic Model Inference\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  88%|██████████████████████████████████████████████████▎      | 2922/3312 [1:15:22<10:23,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Veagle: Advancements in Multimodal Representation Learning\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  88%|██████████████████████████████████████████████████▎      | 2923/3312 [1:15:24<10:09,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: A Survey on Hardware Accelerators for Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  88%|██████████████████████████████████████████████████▎      | 2924/3312 [1:15:26<10:07,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Evolutionary Multi-Objective Optimization of Large Language Model Prompts for Balancing Sentiments\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  88%|██████████████████████████████████████████████████▎      | 2925/3312 [1:15:27<10:01,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Temporal Insight Enhancement: Mitigating Temporal Hallucination in Multimodal Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  88%|██████████████████████████████████████████████████▎      | 2926/3312 [1:15:29<09:55,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: All in How You Ask for It: Simple Black-Box Method for Jailbreak Attacks\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  88%|██████████████████████████████████████████████████▎      | 2927/3312 [1:15:30<09:51,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: A Fast, Performant, Secure Distributed Training Framework For Large Language Model\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  88%|██████████████████████████████████████████████████▍      | 2928/3312 [1:15:32<09:32,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Leveraging Biases in Large Language Models: \"bias-kNN'' for Effective Few-Shot Learning\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  88%|██████████████████████████████████████████████████▍      | 2929/3312 [1:15:33<09:37,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: A Comparative Study on Annotation Quality of Crowdsourcing and LLM via Label Aggregation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  88%|██████████████████████████████████████████████████▍      | 2930/3312 [1:15:35<09:31,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Large Language Model Lateral Spear Phishing: A Comparative Study in Large-Scale Organizational Settings\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  88%|██████████████████████████████████████████████████▍      | 2931/3312 [1:15:36<09:18,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: SkyEyeGPT: Unifying Remote Sensing Vision-Language Tasks via Instruction Tuning with Large Language Model\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  89%|██████████████████████████████████████████████████▍      | 2932/3312 [1:15:38<09:34,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Impact of Large Language Model Assistance on Patients Reading Clinical Notes: A Mixed-Methods Study\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  89%|██████████████████████████████████████████████████▍      | 2933/3312 [1:15:39<09:50,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Learning Shortcuts: On the Misleading Promise of NLU in Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  89%|██████████████████████████████████████████████████▍      | 2934/3312 [1:15:41<09:31,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Aligning Large Language Models with Counterfactual DPO\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  89%|██████████████████████████████████████████████████▌      | 2935/3312 [1:15:42<09:36,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Improving Classification Performance With Human Feedback: Label a few, we label the rest\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  89%|██████████████████████████████████████████████████▌      | 2936/3312 [1:15:44<09:36,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Vlogger: Make Your Dream A Vlog\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  89%|██████████████████████████████████████████████████▌      | 2937/3312 [1:15:45<09:50,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Deciphering Textual Authenticity: A Generalized Strategy through the Lens of Large Language Semantics for Detecting Human vs. Machine-Generated Text\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  89%|██████████████████████████████████████████████████▌      | 2938/3312 [1:15:47<09:43,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Caught in the Quicksand of Reasoning, Far from AGI Summit: Evaluating LLMs' Mathematical and Coding Competency through Ontology-guided Interventions\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  89%|██████████████████████████████████████████████████▌      | 2939/3312 [1:15:48<09:41,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Efficient slot labelling\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  89%|██████████████████████████████████████████████████▌      | 2940/3312 [1:15:50<09:28,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Large Language Models Are Neurosymbolic Reasoners\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  89%|██████████████████████████████████████████████████▌      | 2941/3312 [1:15:51<09:27,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Beyond Anti-Forgetting: Multimodal Continual Instruction Tuning with Positive Forward Transfer\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  89%|██████████████████████████████████████████████████▋      | 2942/3312 [1:15:53<09:25,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Fine-tuning Strategies for Domain Specific Question Answering under Low Annotation Budget Constraints\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  89%|██████████████████████████████████████████████████▋      | 2943/3312 [1:15:54<09:13,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Bridging Research and Readers: A Multi-Modal Automated Academic Papers Interpretation System\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  89%|██████████████████████████████████████████████████▋      | 2944/3312 [1:15:56<10:04,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Remote Sensing ChatGPT: Solving Remote Sensing Tasks with ChatGPT and Visual Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  89%|██████████████████████████████████████████████████▋      | 2945/3312 [1:15:58<09:48,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: What makes for a 'good' social actor? Using respect as a lens to evaluate interactions with language agents\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  89%|██████████████████████████████████████████████████▋      | 2946/3312 [1:16:00<10:05,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: GPT in Sheep's Clothing: The Risk of Customized GPTs\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  89%|██████████████████████████████████████████████████▋      | 2947/3312 [1:16:01<09:50,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Code Simulation Challenges for Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  89%|██████████████████████████████████████████████████▋      | 2948/3312 [1:16:03<09:32,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LLMs for Relational Reasoning: How Far are We?\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  89%|██████████████████████████████████████████████████▊      | 2949/3312 [1:16:04<09:45,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Augmenting Math Word Problems via Iterative Question Composing\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  89%|██████████████████████████████████████████████████▊      | 2950/3312 [1:16:06<09:36,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: AttackEval: How to Evaluate the Effectiveness of Jailbreak Attacking on Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  89%|██████████████████████████████████████████████████▊      | 2951/3312 [1:16:08<09:39,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: COCO is \"ALL'' You Need for Visual Instruction Fine-tuning\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  89%|██████████████████████████████████████████████████▊      | 2952/3312 [1:16:09<09:28,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ReFT: Reasoning with Reinforced Fine-Tuning\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  89%|██████████████████████████████████████████████████▊      | 2953/3312 [1:16:11<09:41,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: AiGen-FoodReview: A Multimodal Dataset of Machine-Generated Restaurant Reviews and Images on Social Media\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  89%|██████████████████████████████████████████████████▊      | 2954/3312 [1:16:12<09:24,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Segment Anything Model Can Not Segment Anything: Assessing AI Foundation Model's Generalizability in Permafrost Mapping\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  89%|██████████████████████████████████████████████████▊      | 2955/3312 [1:16:14<09:23,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: HuixiangDou: Overcoming Group Chat Scenarios with LLM-based Technical Assistance\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  89%|██████████████████████████████████████████████████▊      | 2956/3312 [1:16:15<09:20,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: MMToM-QA: Multimodal Theory of Mind Question Answering\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  89%|██████████████████████████████████████████████████▉      | 2957/3312 [1:16:17<09:11,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Tuning Language Models by Proxy\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  89%|██████████████████████████████████████████████████▉      | 2958/3312 [1:16:18<09:09,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Scalable Pre-training of Large Autoregressive Image Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  89%|██████████████████████████████████████████████████▉      | 2959/3312 [1:16:20<09:02,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Supporting Student Decisions on Learning Recommendations: An LLM-Based Chatbot with Knowledge Graph Contextualization for Conversational Explainability and Mentoring\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  89%|██████████████████████████████████████████████████▉      | 2960/3312 [1:16:22<09:16,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: EmoLLMs: A Series of Emotional Large Language Models and Annotation Tools for Comprehensive Affective Analysis\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  89%|██████████████████████████████████████████████████▉      | 2961/3312 [1:16:23<09:07,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  89%|██████████████████████████████████████████████████▉      | 2962/3312 [1:16:25<09:11,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: The Effect of Group Status on the Variability of Group Representations in LLM-generated Text\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  89%|██████████████████████████████████████████████████▉      | 2963/3312 [1:16:26<09:15,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Contrastive Perplexity for Controlled Generation: An Application in Detoxifying Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  89%|███████████████████████████████████████████████████      | 2964/3312 [1:16:28<08:57,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Machine Translation with Large Language Models: Prompt Engineering for Persian, English, and Russian Directions\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  90%|███████████████████████████████████████████████████      | 2965/3312 [1:16:29<09:04,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Ask the experts: sourcing high-quality datasets for nutritional counselling through Human-AI collaboration\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  90%|███████████████████████████████████████████████████      | 2966/3312 [1:16:31<09:13,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Contrastive Preference Optimization: Pushing the Boundaries of LLM Performance in Machine Translation\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  90%|███████████████████████████████████████████████████      | 2967/3312 [1:16:33<09:05,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: RAG vs Fine-tuning: Pipelines, Tradeoffs, and a Case Study on Agriculture\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  90%|███████████████████████████████████████████████████      | 2968/3312 [1:16:34<08:54,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Hidden Flaws Behind Expert-Level Accuracy of GPT-4 Vision in Medicine\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  90%|███████████████████████████████████████████████████      | 2969/3312 [1:16:37<10:22,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Into the crossfire: evaluating the use of a language model to crowdsource gun violence reports\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  90%|███████████████████████████████████████████████████      | 2970/3312 [1:16:38<09:41,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: DoraemonGPT: Toward Understanding Dynamic Scenes with Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  90%|███████████████████████████████████████████████████▏     | 2971/3312 [1:16:40<09:35,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Exploiting Inter-Layer Expert Affinity for Accelerating Mixture-of-Experts Model Inference\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  90%|███████████████████████████████████████████████████▏     | 2972/3312 [1:16:41<09:14,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Few-Shot Learning for Chronic Disease Management: Leveraging Large Language Models and Multi-Prompt Engineering with Medical Knowledge Injection\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  90%|███████████████████████████████████████████████████▏     | 2973/3312 [1:16:43<08:54,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Hallucination Detection and Hallucination Mitigation: An Investigation\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  90%|███████████████████████████████████████████████████▏     | 2974/3312 [1:16:44<09:08,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Salute the Classic: Revisiting Challenges of Machine Translation in the Age of Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  90%|███████████████████████████████████████████████████▏     | 2975/3312 [1:16:46<08:43,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: RoTBench: A Multi-Level Benchmark for Evaluating the Robustness of Large Language Models in Tool Learning\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  90%|███████████████████████████████████████████████████▏     | 2976/3312 [1:16:47<08:40,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Application of LLM Agents in Recruitment: A Novel Framework for Resume Screening\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  90%|███████████████████████████████████████████████████▏     | 2977/3312 [1:16:49<08:34,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: AesBench: An Expert Benchmark for Multimodal Large Language Models on Image Aesthetics Perception\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  90%|███████████████████████████████████████████████████▎     | 2978/3312 [1:16:50<08:41,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Large Language Models are Null-Shot Learners\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  90%|███████████████████████████████████████████████████▎     | 2979/3312 [1:16:52<08:41,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LoMA: Lossless Compressed Memory Attention\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  90%|███████████████████████████████████████████████████▎     | 2980/3312 [1:16:54<08:36,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Human vs. LMMs: Exploring the Discrepancy in Emoji Interpretation and Usage in Digital Communication\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  90%|███████████████████████████████████████████████████▎     | 2981/3312 [1:16:55<08:16,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Generative Multi-Modal Knowledge Retrieval with Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  90%|███████████████████████████████████████████████████▎     | 2982/3312 [1:16:57<08:30,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: MARIO: MAth Reasoning with code Interpreter Output -- A Reproducible Pipeline\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  90%|███████████████████████████████████████████████████▎     | 2983/3312 [1:16:58<08:32,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: PRewrite: Prompt Rewriting with Reinforcement Learning\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  90%|███████████████████████████████████████████████████▎     | 2984/3312 [1:17:00<08:39,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LLMs for Test Input Generation for Semantic Caches\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  90%|███████████████████████████████████████████████████▎     | 2985/3312 [1:17:01<08:31,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: A Survey of Resource-efficient LLM and Multimodal Foundation Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  90%|███████████████████████████████████████████████████▍     | 2986/3312 [1:17:03<09:03,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: A Study on Training and Developing Large Language Models for Behavior Tree Generation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  90%|███████████████████████████████████████████████████▍     | 2987/3312 [1:17:05<09:05,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Enhancing Document-level Translation of Large Language Model via Translation Mixed-instructions\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  90%|███████████████████████████████████████████████████▍     | 2988/3312 [1:17:06<08:42,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Enhancing Robustness of LLM-Synthetic Text Detectors for Academic Writing: A Comprehensive Analysis\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  90%|███████████████████████████████████████████████████▍     | 2989/3312 [1:17:08<08:31,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: A Novel Approach for Automatic Program Repair using Round-Trip Translation with Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  90%|███████████████████████████████████████████████████▍     | 2990/3312 [1:17:09<08:28,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Leveraging External Knowledge Resources to Enable Domain-Specific Comprehension\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  90%|███████████████████████████████████████████████████▍     | 2991/3312 [1:17:11<08:07,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: A Study on Large Language Models' Limitations in Multiple-Choice Question Answering\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  90%|███████████████████████████████████████████████████▍     | 2992/3312 [1:17:13<08:28,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: SciGLM: Training Scientific Language Models with Self-Reflective Instruction Annotation and Tuning\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  90%|███████████████████████████████████████████████████▌     | 2993/3312 [1:17:14<08:09,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Are self-explanations from Large Language Models faithful?\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  90%|███████████████████████████████████████████████████▌     | 2994/3312 [1:17:16<08:27,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: The Pitfalls of Defining Hallucination\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  90%|███████████████████████████████████████████████████▌     | 2995/3312 [1:17:17<08:07,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: The Chronicles of RAG: The Retriever, the Chunk and the Generator\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  90%|███████████████████████████████████████████████████▌     | 2996/3312 [1:17:19<08:00,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: The What, Why, and How of Context Length Extension Techniques in Large Language Models -- A Detailed Survey\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 2996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  90%|███████████████████████████████████████████████████▌     | 2997/3312 [1:17:20<08:09,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: JumpCoder: Go Beyond Autoregressive Coder via Online Modification\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  91%|███████████████████████████████████████████████████▌     | 2998/3312 [1:17:22<08:13,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Consolidating Trees of Robotic Plans Generated Using Large Language Models to Improve Reliability\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  91%|███████████████████████████████████████████████████▌     | 2999/3312 [1:17:23<08:17,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Authorship Obfuscation in Multilingual Machine-Generated Text Detection\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 2999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  91%|███████████████████████████████████████████████████▋     | 3000/3312 [1:17:25<07:55,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Unlocking Efficiency in Large Language Model Inference: A Comprehensive Survey of Speculative Decoding\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  91%|███████████████████████████████████████████████████▋     | 3001/3312 [1:17:27<08:16,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Question Translation Training for Better Multilingual Reasoning\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  91%|███████████████████████████████████████████████████▋     | 3002/3312 [1:17:28<08:08,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Consolidating Strategies for Countering Hate Speech Using Persuasive Dialogues\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  91%|███████████████████████████████████████████████████▋     | 3003/3312 [1:17:30<08:12,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Flexibly Scaling Large Language Models Contexts Through Extensible Tokenization\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  91%|███████████████████████████████████████████████████▋     | 3004/3312 [1:17:31<08:17,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: When Large Language Model Agents Meet 6G Networks: Perception, Grounding, and Alignment\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  91%|███████████████████████████████████████████████████▋     | 3005/3312 [1:17:33<08:08,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Assistant, Parrot, or Colonizing Loudspeaker? ChatGPT Metaphors for Developing Critical AI Literacies\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  91%|███████████████████████████████████████████████████▋     | 3006/3312 [1:17:34<07:48,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Prompting open-source and commercial language models for grammatical error correction of English learner text\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  91%|███████████████████████████████████████████████████▊     | 3007/3312 [1:17:36<07:40,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Signed-Prompt: A New Approach to Prevent Prompt Injection Attacks Against LLM-Integrated Applications\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  91%|███████████████████████████████████████████████████▊     | 3008/3312 [1:17:37<07:48,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: MAPLE: Multilingual Evaluation of Parameter Efficient Finetuning of Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  91%|███████████████████████████████████████████████████▊     | 3009/3312 [1:17:39<07:34,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: MM-SAP: A Comprehensive Benchmark for Assessing Self-Awareness of Multimodal Large Language Models in Perception\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  91%|███████████████████████████████████████████████████▊     | 3010/3312 [1:17:40<07:34,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Editing Arbitrary Propositions in LLMs without Subject Labels\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  91%|███████████████████████████████████████████████████▊     | 3011/3312 [1:17:43<08:33,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: TP-Aware Dequantization\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  91%|███████████████████████████████████████████████████▊     | 3012/3312 [1:17:44<08:10,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Survey of Natural Language Processing for Education: Taxonomy, Systematic Review, and Future Trends\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  91%|███████████████████████████████████████████████████▊     | 3013/3312 [1:17:45<07:49,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Model Editing at Scale leads to Gradual and Catastrophic Forgetting\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  91%|███████████████████████████████████████████████████▊     | 3014/3312 [1:17:47<07:45,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Stability Analysis of ChatGPT-based Sentiment Analysis in AI Quality Assurance\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  91%|███████████████████████████████████████████████████▉     | 3015/3312 [1:17:48<07:32,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Beyond Sparse Rewards: Enhancing Reinforcement Learning with Language Model Critique in Text Generation\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  91%|███████████████████████████████████████████████████▉     | 3016/3312 [1:17:50<07:30,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Active Learning for NLP with Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  91%|███████████████████████████████████████████████████▉     | 3017/3312 [1:17:51<07:21,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Generative AI in EU Law: Liability, Privacy, Intellectual Property, and Cybersecurity\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  91%|███████████████████████████████████████████████████▉     | 3018/3312 [1:17:53<07:35,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Small LLMs Are Weak Tool Learners: A Multi-LLM Agent\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  91%|███████████████████████████████████████████████████▉     | 3019/3312 [1:17:55<07:33,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Harnessing Large Language Models Over Transformer Models for Detecting Bengali Depressive Social Media Text: A Comprehensive Study\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  91%|███████████████████████████████████████████████████▉     | 3020/3312 [1:17:56<07:36,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Small Language Model Can Self-correct\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  91%|███████████████████████████████████████████████████▉     | 3021/3312 [1:17:58<07:34,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: CANDLE: Iterative Conceptualization and Instantiation Distillation from Large Language Models for Commonsense Reasoning\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  91%|████████████████████████████████████████████████████     | 3022/3312 [1:17:59<07:18,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Improving Domain Adaptation through Extended-Text Reading Comprehension\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  91%|████████████████████████████████████████████████████     | 3023/3312 [1:18:01<07:21,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Distilling Event Sequence Knowledge From Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  91%|████████████████████████████████████████████████████     | 3024/3312 [1:18:02<07:11,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Inroads to a Structured Data Natural Language Bijection and the role of LLM annotation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  91%|████████████████████████████████████████████████████     | 3025/3312 [1:18:04<07:21,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: A Survey on Statistical Theory of Deep Learning: Approximation, Training Dynamics, and Generative Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  91%|████████████████████████████████████████████████████     | 3026/3312 [1:18:06<07:37,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Reinforcement Learning from LLM Feedback to Counteract Goal Misgeneralization\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  91%|████████████████████████████████████████████████████     | 3027/3312 [1:18:07<07:38,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Quantized Side Tuning: Fast and Memory-Efficient Tuning of Quantized Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  91%|████████████████████████████████████████████████████     | 3028/3312 [1:18:09<07:31,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Assessing Large Language Models in Mechanical Engineering Education: A Study on Mechanics-Focused Conceptual Understanding\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  91%|████████████████████████████████████████████████████▏    | 3029/3312 [1:18:10<07:17,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Open Models, Closed Minds? On Agents Capabilities in Mimicking Human Personalities through Open Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  91%|████████████████████████████████████████████████████▏    | 3030/3312 [1:18:12<07:06,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Combining Confidence Elicitation and Sample-based Methods for Uncertainty Quantification in Misinformation Mitigation\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  92%|████████████████████████████████████████████████████▏    | 3031/3312 [1:18:13<07:16,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Leveraging Large Language Models for NLG Evaluation: A Survey\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  92%|████████████████████████████████████████████████████▏    | 3032/3312 [1:18:15<07:23,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Evolving Code with A Large Language Model\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  92%|████████████████████████████████████████████████████▏    | 3033/3312 [1:18:16<07:08,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: PUB: A Pragmatics Understanding Benchmark for Assessing LLMs' Pragmatics Capabilities\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  92%|████████████████████████████████████████████████████▏    | 3034/3312 [1:18:18<07:04,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: xCoT: Cross-lingual Instruction Tuning for Cross-lingual Chain-of-Thought Reasoning\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  92%|████████████████████████████████████████████████████▏    | 3035/3312 [1:18:20<07:39,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Code Security Vulnerability Repair Using Reinforcement Learning with Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  92%|████████████████████████████████████████████████████▎    | 3036/3312 [1:18:21<07:17,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Knowledge Distillation for Closed-Source Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  92%|████████████████████████████████████████████████████▎    | 3037/3312 [1:18:23<07:13,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Extending LLMs' Context Window with 100 Samples\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  92%|████████████████████████████████████████████████████▎    | 3038/3312 [1:18:24<07:11,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: NHANES-GCP: Leveraging the Google Cloud Platform and BigQuery ML for reproducible machine learning with data from the National Health and Nutrition Examination Survey\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  92%|████████████████████████████████████████████████████▎    | 3039/3312 [1:18:26<07:32,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: CHAMP: A Competition-level Dataset for Fine-Grained Analyses of LLMs' Mathematical Reasoning Capabilities\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  92%|████████████████████████████████████████████████████▎    | 3040/3312 [1:18:28<07:15,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: E^2-LLM: Efficient and Extreme Length Extension of Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  92%|████████████████████████████████████████████████████▎    | 3041/3312 [1:18:29<07:04,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Parameter-Efficient Detoxification with Contrastive Decoding\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  92%|████████████████████████████████████████████████████▎    | 3042/3312 [1:18:31<07:05,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Knowledge-Centric Templatic Views of Documents\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  92%|████████████████████████████████████████████████████▎    | 3043/3312 [1:18:32<06:48,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Comparing GPT-4 and Open-Source Language Models in Misinformation Mitigation\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  92%|████████████████████████████████████████████████████▍    | 3044/3312 [1:18:34<06:38,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: DocFinQA: A Long-Context Financial Reasoning Dataset\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  92%|████████████████████████████████████████████████████▍    | 3045/3312 [1:18:35<06:44,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Promptly Predicting Structures: The Return of Inference\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  92%|████████████████████████████████████████████████████▍    | 3046/3312 [1:18:37<06:59,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Health-LLM: Large Language Models for Health Prediction via Wearable Sensor Data\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  92%|████████████████████████████████████████████████████▍    | 3047/3312 [1:18:38<06:46,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Fine-grained Hallucination Detection and Editing for Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  92%|████████████████████████████████████████████████████▍    | 3048/3312 [1:18:40<06:40,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Large Language Models Can Learn Temporal Reasoning\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  92%|████████████████████████████████████████████████████▍    | 3049/3312 [1:18:41<06:40,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: APAR: LLMs Can Do Auto-Parallel Auto-Regressive Decoding\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  92%|████████████████████████████████████████████████████▍    | 3050/3312 [1:18:43<07:17,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: MAPO: Advancing Multilingual Reasoning through Multilingual Alignment-as-Preference Optimization\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  92%|████████████████████████████████████████████████████▌    | 3051/3312 [1:18:45<06:56,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LLM-Assisted Crisis Management: Building Advanced LLM Platforms for Effective Emergency Response and Public Collaboration\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  92%|████████████████████████████████████████████████████▌    | 3052/3312 [1:18:46<06:55,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Structsum Generation for Faster Text Comprehension\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  92%|████████████████████████████████████████████████████▌    | 3053/3312 [1:18:48<06:38,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Zero-Shot RTL Code Generation with Attention Sink Augmented Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  92%|████████████████████████████████████████████████████▌    | 3054/3312 [1:18:49<06:31,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Few-Shot Detection of Machine-Generated Text using Style Representations\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  92%|████████████████████████████████████████████████████▌    | 3055/3312 [1:18:51<06:21,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Multi-Candidate Speculative Decoding\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  92%|████████████████████████████████████████████████████▌    | 3056/3312 [1:18:52<06:17,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: An Experimental Design Framework for Label-Efficient Supervised Finetuning of Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  92%|████████████████████████████████████████████████████▌    | 3057/3312 [1:18:54<06:23,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Don't Rank, Combine! Combining Machine Translation Hypotheses Using Quality Estimation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  92%|████████████████████████████████████████████████████▋    | 3058/3312 [1:18:55<06:26,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Enhancing Emotional Generation Capability of Large Language Models via Emotional Chain-of-Thought\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  92%|████████████████████████████████████████████████████▋    | 3059/3312 [1:18:57<07:19,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LLMRS: Unlocking Potentials of LLM-Based Recommender Systems for Software Purchase\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  92%|████████████████████████████████████████████████████▋    | 3060/3312 [1:18:59<07:04,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: How Johnny Can Persuade LLMs to Jailbreak Them: Rethinking Persuasion to Challenge AI Safety by Humanizing LLMs\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  92%|████████████████████████████████████████████████████▋    | 3061/3312 [1:19:01<06:57,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Effects of diversity incentives on sample diversity and downstream model performance in LLM-based text augmentation\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  92%|████████████████████████████████████████████████████▋    | 3062/3312 [1:19:02<06:39,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: OOP: Object-Oriented Programming Evaluation Benchmark for Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  92%|████████████████████████████████████████████████████▋    | 3063/3312 [1:19:04<06:30,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Mutual Enhancement of Large Language and Reinforcement Learning Models through Bi-Directional Feedback Mechanisms: A Case Study\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  93%|████████████████████████████████████████████████████▋    | 3064/3312 [1:19:05<06:42,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Lost in the Source Language: How Large Language Models Evaluate the Quality of Machine Translation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  93%|████████████████████████████████████████████████████▋    | 3065/3312 [1:19:08<07:47,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Intention Analysis Makes LLMs A Good Jailbreak Defender\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  93%|████████████████████████████████████████████████████▊    | 3066/3312 [1:19:09<07:08,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: A systematic review of geospatial location embedding approaches in large language models: A path to spatial AI systems\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  93%|████████████████████████████████████████████████████▊    | 3067/3312 [1:19:11<06:56,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: INTERS: Unlocking the Power of Large Language Models in Search with Instruction Tuning\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  93%|████████████████████████████████████████████████████▊    | 3068/3312 [1:19:12<06:42,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ML-On-Rails: Safeguarding Machine Learning Models in Software Systems A Case Study\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  93%|████████████████████████████████████████████████████▊    | 3069/3312 [1:19:14<07:00,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: AntEval: Evaluation of Social Interaction Competencies in LLM-Driven Agents\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  93%|████████████████████████████████████████████████████▊    | 3070/3312 [1:19:16<06:47,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: An investigation of structures responsible for gender bias in BERT and DistilBERT\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  93%|████████████████████████████████████████████████████▊    | 3071/3312 [1:19:17<06:35,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: A Survey on the Applications of Frontier AI, Foundation Models, and Large Language Models to Intelligent Transportation Systems\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  93%|████████████████████████████████████████████████████▊    | 3072/3312 [1:19:19<06:25,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Cross-Attention Watermarking of Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  93%|████████████████████████████████████████████████████▉    | 3073/3312 [1:19:21<07:01,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Batch-ICL: Effective, Efficient, and Order-Agnostic In-Context Learning\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  93%|████████████████████████████████████████████████████▉    | 3074/3312 [1:19:23<06:41,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Adapting Large Language Models for Document-Level Machine Translation\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  93%|████████████████████████████████████████████████████▉    | 3075/3312 [1:19:24<06:53,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Between Lines of Code: Unraveling the Distinct Patterns of Machine and Human Programmers\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  93%|████████████████████████████████████████████████████▉    | 3076/3312 [1:19:26<06:36,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: 3D-PreMise: Can Large Language Models Generate 3D Shapes with Sharp Features and Parametric Control?\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  93%|████████████████████████████████████████████████████▉    | 3077/3312 [1:19:27<06:14,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Mission: Impossible Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  93%|████████████████████████████████████████████████████▉    | 3078/3312 [1:19:29<06:09,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: AboutMe: Using Self-Descriptions in Webpages to Document the Effects of English Pretraining Data Filters\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  93%|████████████████████████████████████████████████████▉    | 3079/3312 [1:19:30<05:53,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: DevEval: Evaluating Code Generation in Practical Software Projects\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  93%|█████████████████████████████████████████████████████    | 3080/3312 [1:19:32<05:47,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Generalizing Visual Question Answering from Synthetic to Human-Written Questions via a Chain of QA with a Large Language Model\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  93%|█████████████████████████████████████████████████████    | 3081/3312 [1:19:33<05:58,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Zero-shot Generative Large Language Models for Systematic Review Screening Automation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  93%|█████████████████████████████████████████████████████    | 3082/3312 [1:19:36<07:03,  1.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Open the Pandora's Box of LLMs: Jailbreaking LLMs through Representation Engineering\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  93%|█████████████████████████████████████████████████████    | 3083/3312 [1:19:37<06:39,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Misconfidence-based Demonstration Selection for LLM In-Context Learning\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  93%|█████████████████████████████████████████████████████    | 3084/3312 [1:19:39<06:59,  1.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Uncertainty Awareness of Large Language Models Under Code Distribution Shifts: A Benchmark Study\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  93%|█████████████████████████████████████████████████████    | 3085/3312 [1:19:41<06:37,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Eyes Wide Shut? Exploring the Visual Shortcomings of Multimodal LLMs\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  93%|█████████████████████████████████████████████████████    | 3086/3312 [1:19:43<06:38,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: TOFU: A Task of Fictitious Unlearning for LLMs\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  93%|█████████████████████████████████████████████████████▏   | 3087/3312 [1:19:45<06:35,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Extreme Compression of Large Language Models via Additive Quantization\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  93%|█████████████████████████████████████████████████████▏   | 3088/3312 [1:19:46<06:15,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Transformers are Multi-State RNNs\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  93%|█████████████████████████████████████████████████████▏   | 3089/3312 [1:19:48<06:11,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: A Closer Look at AUROC and AUPRC under Class Imbalance\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  93%|█████████████████████████████████████████████████████▏   | 3090/3312 [1:19:49<06:07,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Autocompletion of Chief Complaints in the Electronic Health Records using Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  93%|█████████████████████████████████████████████████████▏   | 3091/3312 [1:19:51<06:21,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: An Exploratory Assessment of LLM's Potential Toward Flight Trajectory Reconstruction Analysis\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  93%|█████████████████████████████████████████████████████▏   | 3092/3312 [1:19:53<06:04,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Improving Large Language Models via Fine-grained Reinforcement Learning with Minimum Editing Constraint\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  93%|█████████████████████████████████████████████████████▏   | 3093/3312 [1:19:54<06:02,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Secrets of RLHF in Large Language Models Part II: Reward Modeling\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  93%|█████████████████████████████████████████████████████▏   | 3094/3312 [1:19:56<05:51,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Chain of History: Learning and Forecasting with LLMs for Temporal Knowledge Graph Completion\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  93%|█████████████████████████████████████████████████████▎   | 3095/3312 [1:19:58<05:56,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: GroundingGPT:Language Enhanced Multi-modal Grounding Model\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  93%|█████████████████████████████████████████████████████▎   | 3096/3312 [1:19:59<05:47,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: DeepSeekMoE: Towards Ultimate Expert Specialization in Mixture-of-Experts Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  94%|█████████████████████████████████████████████████████▎   | 3097/3312 [1:20:01<05:41,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Investigating Data Contamination for Pre-training Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  94%|█████████████████████████████████████████████████████▎   | 3098/3312 [1:20:02<05:30,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: When ChatGPT is gone: Creativity reverts and homogeneity persists\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  94%|█████████████████████████████████████████████████████▎   | 3099/3312 [1:20:03<05:19,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Combating Adversarial Attacks with Multi-Agent Debate\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  94%|█████████████████████████████████████████████████████▎   | 3100/3312 [1:20:05<05:16,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: EASYTOOL: Enhancing LLM-based Agents with Concise Tool Instruction\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  94%|█████████████████████████████████████████████████████▎   | 3101/3312 [1:20:06<05:10,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LLM-as-a-Coauthor: Can Mixed Human-Written and Machine-Generated Text Be Detected?\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  94%|█████████████████████████████████████████████████████▍   | 3102/3312 [1:20:08<05:03,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Universal Vulnerabilities in Large Language Models: Backdoor Attacks for In-context Learning\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  94%|█████████████████████████████████████████████████████▍   | 3103/3312 [1:20:09<05:12,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Mutation-based Consistency Testing for Evaluating the Code Understanding Capability of LLMs\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  94%|█████████████████████████████████████████████████████▍   | 3104/3312 [1:20:11<05:33,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: SH2: Self-Highlighted Hesitation Helps You Decode More Truthfully\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  94%|█████████████████████████████████████████████████████▍   | 3105/3312 [1:20:13<05:25,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: EpilepsyLLM: Domain-Specific Large Language Model Fine-tuned with Epilepsy Medical Knowledge\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  94%|█████████████████████████████████████████████████████▍   | 3106/3312 [1:20:14<05:28,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Towards Boosting Many-to-Many Multilingual Machine Translation with Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  94%|█████████████████████████████████████████████████████▍   | 3107/3312 [1:20:16<05:23,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Seven Failure Points When Engineering a Retrieval Augmented Generation System\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  94%|█████████████████████████████████████████████████████▍   | 3108/3312 [1:20:17<05:20,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Hallucination Benchmark in Medical Visual Question Answering\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  94%|█████████████████████████████████████████████████████▌   | 3109/3312 [1:20:20<06:45,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Tuning LLMs with Contrastive Alignment Instructions for Machine Translation in Unseen, Low-resource Languages\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  94%|█████████████████████████████████████████████████████▌   | 3110/3312 [1:20:22<06:15,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Evidence to Generate (E2G): A Single-agent Two-step Prompting for Context Grounded and Retrieval Augmented Reasoning\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  94%|█████████████████████████████████████████████████████▌   | 3111/3312 [1:20:24<05:54,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Risk Taxonomy, Mitigation, and Assessment Benchmarks of Large Language Model Systems\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  94%|█████████████████████████████████████████████████████▌   | 3112/3312 [1:20:25<05:31,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Probing Structured Semantics Understanding and Generation of Language Models via Question Answering\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  94%|█████████████████████████████████████████████████████▌   | 3113/3312 [1:20:26<05:18,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: A Shocking Amount of the Web is Machine Translated: Insights from Multi-Way Parallelism\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  94%|█████████████████████████████████████████████████████▌   | 3114/3312 [1:20:28<05:07,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Zero Resource Cross-Lingual Part Of Speech Tagging\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  94%|█████████████████████████████████████████████████████▌   | 3115/3312 [1:20:29<05:11,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: CAT-LLM: Prompting Large Language Models with Text Style Definition for Chinese Article-style Transfer\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  94%|█████████████████████████████████████████████████████▋   | 3116/3312 [1:20:31<05:08,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Video Anomaly Detection and Explanation via Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  94%|█████████████████████████████████████████████████████▋   | 3117/3312 [1:20:33<05:04,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Towards Conversational Diagnostic AI\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  94%|█████████████████████████████████████████████████████▋   | 3118/3312 [1:20:34<04:55,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: On Detecting Cherry-picking in News Coverage Using Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  94%|█████████████████████████████████████████████████████▋   | 3119/3312 [1:20:35<04:45,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: The Benefits of a Concise Chain of Thought on Problem-Solving in Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  94%|█████████████████████████████████████████████████████▋   | 3120/3312 [1:20:37<04:45,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Scaling Laws for Forgetting When Fine-Tuning Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  94%|█████████████████████████████████████████████████████▋   | 3121/3312 [1:20:38<04:47,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: REBUS: A Robust Evaluation Benchmark of Understanding Symbols\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  94%|█████████████████████████████████████████████████████▋   | 3122/3312 [1:20:40<04:47,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: POMP: Probability-driven Meta-graph Prompter for LLMs in Low-resource Unsupervised Neural Machine Translation\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  94%|█████████████████████████████████████████████████████▋   | 3123/3312 [1:20:41<04:44,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Sleeper Agents: Training Deceptive LLMs that Persist Through Safety Training\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  94%|█████████████████████████████████████████████████████▊   | 3124/3312 [1:20:43<04:53,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: TrustLLM: Trustworthiness in Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  94%|█████████████████████████████████████████████████████▊   | 3125/3312 [1:20:45<04:47,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: An EcoSage Assistant: Towards Building A Multimodal Plant Care Dialogue Assistant\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  94%|█████████████████████████████████████████████████████▊   | 3126/3312 [1:20:46<04:40,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: InfiAgent-DABench: Evaluating Agents on Data Analysis Tasks\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  94%|█████████████████████████████████████████████████████▊   | 3127/3312 [1:20:47<04:32,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: AugSumm: towards generalizable speech summarization using synthetic labels from large language model\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  94%|█████████████████████████████████████████████████████▊   | 3128/3312 [1:20:49<04:32,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Leveraging Print Debugging to Improve Code Generation in Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  94%|█████████████████████████████████████████████████████▊   | 3129/3312 [1:20:51<05:07,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Theory of Mind abilities of Large Language Models in Human-Robot Interaction : An Illusion?\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  95%|█████████████████████████████████████████████████████▊   | 3130/3312 [1:20:53<04:52,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: I am a Strange Dataset: Metalinguistic Tests for Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  95%|█████████████████████████████████████████████████████▉   | 3131/3312 [1:20:54<04:54,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: INACIA: Integrating Large Language Models in Brazilian Audit Courts: Opportunities and Challenges\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  95%|█████████████████████████████████████████████████████▉   | 3132/3312 [1:20:56<04:42,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Exploring the Reasoning Abilities of Multimodal Large Language Models (MLLMs): A Comprehensive Survey on Emerging Trends in Multimodal Reasoning\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  95%|█████████████████████████████████████████████████████▉   | 3133/3312 [1:20:57<04:38,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Pre-trained Large Language Models for Financial Sentiment Analysis\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  95%|█████████████████████████████████████████████████████▉   | 3134/3312 [1:20:59<04:33,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Knowledge Sharing in Manufacturing using Large Language Models: User Evaluation and Model Benchmarking\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  95%|█████████████████████████████████████████████████████▉   | 3135/3312 [1:21:00<04:26,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Monte Carlo Tree Search for Recipe Generation using GPT-2\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  95%|█████████████████████████████████████████████████████▉   | 3136/3312 [1:21:02<04:18,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Machine Teaching for Building Modular AI Agents based on Zero-shot Learners\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  95%|█████████████████████████████████████████████████████▉   | 3137/3312 [1:21:03<04:17,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: DCR: Divide-and-Conquer Reasoning for Multi-choice Question Answering with LLMs\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  95%|██████████████████████████████████████████████████████   | 3138/3312 [1:21:04<04:18,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ChatGPT, Let us Chat Sign Language: Experiments, Architectural Elements, Challenges and Research Directions\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  95%|██████████████████████████████████████████████████████   | 3139/3312 [1:21:06<04:26,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Aligning Translation-Specific Understanding to General Understanding in Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  95%|██████████████████████████████████████████████████████   | 3140/3312 [1:21:08<04:19,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Bootstrapping LLM-based Task-Oriented Dialogue Agents via Self-Talk\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  95%|██████████████████████████████████████████████████████   | 3141/3312 [1:21:09<04:15,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Personal LLM Agents: Insights and Survey about the Capability, Efficiency and Security\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  95%|██████████████████████████████████████████████████████   | 3142/3312 [1:21:11<04:20,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Graph-of-Thought: Utilizing Large Language Models to Solve Complex and Dynamic Business Problems\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  95%|██████████████████████████████████████████████████████   | 3143/3312 [1:21:13<04:50,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: The Impact of Reasoning Step Length on Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  95%|██████████████████████████████████████████████████████   | 3144/3312 [1:21:15<04:49,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ANGO: A Next-Level Evaluation Benchmark For Generation-Oriented Language Models In Chinese Domain\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  95%|██████████████████████████████████████████████████████▏  | 3145/3312 [1:21:16<04:40,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Reinforcement Learning for Optimizing RAG for Domain Chatbots\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  95%|██████████████████████████████████████████████████████▏  | 3146/3312 [1:21:18<04:47,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Multi-User Chat Assistant (MUCA): a Framework Using LLMs to Facilitate Group Conversations\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  95%|██████████████████████████████████████████████████████▏  | 3147/3312 [1:21:19<04:34,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Attendre: Wait To Attend By Retrieval With Evicted Queries in Memory-Based Transformers for Long Context Processing\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  95%|██████████████████████████████████████████████████████▏  | 3148/3312 [1:21:21<04:27,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Are Language Models More Like Libraries or Like Librarians? Bibliotechnism, the Novel Reference Problem, and the Attitudes of LLMs\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  95%|██████████████████████████████████████████████████████▏  | 3149/3312 [1:21:22<04:15,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Entity Recognition from Colloquial Text\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  95%|██████████████████████████████████████████████████████▏  | 3150/3312 [1:21:24<04:06,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Arabic Text Diacritization In The Age Of Transfer Learning: Token Classification Is All You Need\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  95%|██████████████████████████████████████████████████████▏  | 3151/3312 [1:21:25<04:05,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Model Editing Can Hurt General Abilities of Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  95%|██████████████████████████████████████████████████████▏  | 3152/3312 [1:21:27<04:18,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Narrowing the Knowledge Evaluation Gap: Open-Domain Question Answering with Multi-Granularity Answers\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  95%|██████████████████████████████████████████████████████▎  | 3153/3312 [1:21:29<04:17,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: RoSA: Accurate Parameter-Efficient Fine-Tuning via Robust Adaptation\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  95%|██████████████████████████████████████████████████████▎  | 3154/3312 [1:21:31<04:16,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Lightning Attention-2: A Free Lunch for Handling Unlimited Sequence Lengths in Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  95%|██████████████████████████████████████████████████████▎  | 3155/3312 [1:21:32<04:17,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: DebugBench: Evaluating Debugging Capability of Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  95%|██████████████████████████████████████████████████████▎  | 3156/3312 [1:21:34<04:08,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Agent Alignment in Evolving Social Norms\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  95%|██████████████████████████████████████████████████████▎  | 3157/3312 [1:21:35<04:02,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Language Detection for Transliterated Content\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  95%|██████████████████████████████████████████████████████▎  | 3158/3312 [1:21:37<04:17,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Metacognition is all you need? Using Introspection in Generative Agents to Improve Goal-directed Behavior\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  95%|██████████████████████████████████████████████████████▎  | 3159/3312 [1:21:38<04:03,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Informed AI Regulation: Comparing the Ethical Frameworks of Leading LLM Chatbots Using an Ethics-Based Audit to Assess Moral Reasoning and Normative Values\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  95%|██████████████████████████████████████████████████████▍  | 3160/3312 [1:21:40<03:55,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: An Assessment on Comprehending Mental Health through Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  95%|██████████████████████████████████████████████████████▍  | 3161/3312 [1:21:42<04:01,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Evaluating Language Model Agency through Negotiations\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  95%|██████████████████████████████████████████████████████▍  | 3162/3312 [1:21:43<03:55,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: MERA: A Comprehensive LLM Evaluation in Russian\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  96%|██████████████████████████████████████████████████████▍  | 3163/3312 [1:21:45<04:05,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Rewriting the Code: A Simple Method for Large Language Model Augmented Code Search\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  96%|██████████████████████████████████████████████████████▍  | 3164/3312 [1:21:47<04:17,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Fighting Fire with Fire: Adversarial Prompting to Generate a Misinformation Detection Dataset\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  96%|██████████████████████████████████████████████████████▍  | 3165/3312 [1:21:49<04:10,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: TransportationGames: Benchmarking Transportation Knowledge of (Multimodal) Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  96%|██████████████████████████████████████████████████████▍  | 3166/3312 [1:21:50<03:56,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Chain-of-Table: Evolving Tables in the Reasoning Chain for Table Understanding\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  96%|██████████████████████████████████████████████████████▌  | 3167/3312 [1:21:51<03:46,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: DeepSpeed-FastGen: High-throughput Text Generation for LLMs via MII and DeepSpeed-Inference\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  96%|██████████████████████████████████████████████████████▌  | 3168/3312 [1:21:53<03:42,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Uni3D-LLM: Unifying Point Cloud Perception, Generation and Editing with Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  96%|██████████████████████████████████████████████████████▌  | 3169/3312 [1:21:54<03:34,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Improving the Robustness of Knowledge-Grounded Dialogue via Contrastive Learning\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  96%|██████████████████████████████████████████████████████▌  | 3170/3312 [1:21:56<03:30,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Private Fine-tuning of Large Language Models with Zeroth-order Optimization\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  96%|██████████████████████████████████████████████████████▌  | 3171/3312 [1:21:57<03:34,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Large Language Models for Robotics: Opportunities, Challenges, and Perspectives\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  96%|██████████████████████████████████████████████████████▌  | 3172/3312 [1:21:59<03:30,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Know Your Needs Better: Towards Structured Understanding of Marketer Demands with Analogical Reasoning Augmented LLMs\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  96%|██████████████████████████████████████████████████████▌  | 3173/3312 [1:22:00<03:28,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LLM4PLC: Harnessing Large Language Models for Verifiable Programming of PLCs in Industrial Control Systems\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  96%|██████████████████████████████████████████████████████▋  | 3174/3312 [1:22:02<03:32,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: MARG: Multi-Agent Review Generation for Scientific Papers\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  96%|██████████████████████████████████████████████████████▋  | 3175/3312 [1:22:04<03:34,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Distortions in Judged Spatial Relations in Large Language Models: The Dawn of Natural Language Geographic Data?\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  96%|██████████████████████████████████████████████████████▋  | 3176/3312 [1:22:05<03:28,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: FunnyNet-W: Multimodal Learning of Funny Moments in Videos in the Wild\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  96%|██████████████████████████████████████████████████████▋  | 3177/3312 [1:22:07<03:27,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: AI and Generative AI for Research Discovery and Summarization\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  96%|██████████████████████████████████████████████████████▋  | 3178/3312 [1:22:08<03:20,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Unveiling Bias in Fairness Evaluations of Large Language Models: A Critical Literature Review of Music and Movie Recommendation Systems\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  96%|██████████████████████████████████████████████████████▋  | 3179/3312 [1:22:10<03:21,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: FFSplit: Split Feed-Forward Network For Optimizing Accuracy-Efficiency Trade-off in Language Model Inference\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  96%|██████████████████████████████████████████████████████▋  | 3180/3312 [1:22:11<03:24,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Large language models in bioinformatics: applications and perspectives\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  96%|██████████████████████████████████████████████████████▋  | 3181/3312 [1:22:13<03:18,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: IDoFew: Intermediate Training Using Dual-Clustering in Language Models for Few Labels Text Classification\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  96%|██████████████████████████████████████████████████████▊  | 3182/3312 [1:22:14<03:29,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Advancing Spatial Reasoning in Large Language Models: An In-Depth Evaluation and Enhancement Using the StepGame Benchmark\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  96%|██████████████████████████████████████████████████████▊  | 3183/3312 [1:22:16<03:29,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Tiny Time Mixers (TTMs): Fast Pre-trained Models for Enhanced Zero/Few-Shot Forecasting of Multivariate Time Series\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  96%|██████████████████████████████████████████████████████▊  | 3184/3312 [1:22:18<03:20,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: TextMachina: Seamless Generation of Machine-Generated Text Datasets\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  96%|██████████████████████████████████████████████████████▊  | 3185/3312 [1:22:19<03:25,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: SpeechAgents: Human-Communication Simulation with Multi-Modal Multi-Agent Systems\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  96%|██████████████████████████████████████████████████████▊  | 3186/3312 [1:22:21<03:17,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Chain of LoRA: Efficient Fine-tuning of Language Models via Residual Learning\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  96%|██████████████████████████████████████████████████████▊  | 3187/3312 [1:22:22<03:11,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: FlightLLM: Efficient Large Language Model Inference with a Complete Mapping Flow on FPGAs\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  96%|██████████████████████████████████████████████████████▊  | 3188/3312 [1:22:24<03:06,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: PythonSaga: Redefining the Benchmark to Evaluate Code Generating LLM\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  96%|██████████████████████████████████████████████████████▉  | 3189/3312 [1:22:25<03:01,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Aligned with LLM: a new multi-modal training paradigm for encoding fMRI activity in visual cortex\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  96%|██████████████████████████████████████████████████████▉  | 3190/3312 [1:22:27<03:01,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: TeleChat Technical Report\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  96%|██████████████████████████████████████████████████████▉  | 3191/3312 [1:22:28<02:59,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Enhanced Automated Code Vulnerability Repair using Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  96%|██████████████████████████████████████████████████████▉  | 3192/3312 [1:22:30<03:03,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Language Models Understand Numbers, at Least Partially\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  96%|██████████████████████████████████████████████████████▉  | 3193/3312 [1:22:31<02:57,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: The Butterfly Effect of Altering Prompts: How Small Changes and Jailbreaks Affect Large Language Model Performance\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  96%|██████████████████████████████████████████████████████▉  | 3194/3312 [1:22:33<02:58,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Assessing AI Detectors in Identifying AI-Generated Code: Implications for Education\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  96%|██████████████████████████████████████████████████████▉  | 3195/3312 [1:22:34<02:58,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LightHouse: A Survey of AGI Hallucination\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  96%|███████████████████████████████████████████████████████  | 3196/3312 [1:22:36<02:52,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: An Exploratory Study on Automatic Identification of Assumptions in the Development of Deep Learning Frameworks\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  97%|███████████████████████████████████████████████████████  | 3197/3312 [1:22:37<02:48,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Why Solving Multi-agent Path Finding with Large Language Model has not Succeeded Yet\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  97%|███████████████████████████████████████████████████████  | 3198/3312 [1:22:38<02:45,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Using Zero-shot Prompting in the Automatic Creation and Expansion of Topic Taxonomies for Tagging Retail Banking Transactions\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  97%|███████████████████████████████████████████████████████  | 3199/3312 [1:22:40<02:42,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ChatGPT for Conversational Recommendation: Refining Recommendations by Reprompting with Feedback\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  97%|███████████████████████████████████████████████████████  | 3200/3312 [1:22:41<02:39,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: InFoBench: Evaluating Instruction Following Ability in Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  97%|███████████████████████████████████████████████████████  | 3201/3312 [1:22:43<02:43,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: CharPoet: A Chinese Classical Poetry Generation System Based on Token-free LLM\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  97%|███████████████████████████████████████████████████████  | 3202/3312 [1:22:44<02:42,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: DiarizationLM: Speaker Diarization Post-Processing with Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  97%|███████████████████████████████████████████████████████  | 3203/3312 [1:22:46<02:52,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Maintaining Journalistic Integrity in the Digital Age: A Comprehensive NLP Framework for Evaluating Online News Content\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  97%|███████████████████████████████████████████████████████▏ | 3204/3312 [1:22:49<03:19,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Soaring from 4K to 400K: Extending LLM's Context with Activation Beacon\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  97%|███████████████████████████████████████████████████████▏ | 3205/3312 [1:22:50<03:06,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Exploring Large Language Model based Intelligent Agents: Definitions, Methods, and Prospects\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  97%|███████████████████████████████████████████████████████▏ | 3206/3312 [1:22:51<02:54,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: On Leveraging Large Language Models for Enhancing Entity Resolution\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  97%|███████████████████████████████████████████████████████▏ | 3207/3312 [1:22:53<02:47,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: The Stronger the Diffusion Model, the Easier the Backdoor: Data Poisoning to Induce Copyright Breaches Without Adjusting Finetuning Pipeline\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  97%|███████████████████████████████████████████████████████▏ | 3208/3312 [1:22:55<02:44,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: GRAM: Global Reasoning for Multi-Page VQA\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  97%|███████████████████████████████████████████████████████▏ | 3209/3312 [1:22:56<02:44,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Escalation Risks from Language Models in Military and Diplomatic Decision-Making\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  97%|███████████████████████████████████████████████████████▏ | 3210/3312 [1:22:58<02:46,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Empirical Study of Large Language Models as Automated Essay Scoring Tools in English Composition__Taking TOEFL Independent Writing Task for Example\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  97%|███████████████████████████████████████████████████████▎ | 3211/3312 [1:22:59<02:37,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LLMs for Robotic Object Disambiguation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  97%|███████████████████████████████████████████████████████▎ | 3212/3312 [1:23:01<02:35,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LLM-Powered Code Vulnerability Repair with Reinforcement Learning and Semantic Reward\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  97%|███████████████████████████████████████████████████████▎ | 3213/3312 [1:23:02<02:31,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: An Investigation of Large Language Models for Real-World Hate Speech Detection\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  97%|███████████████████████████████████████████████████████▎ | 3214/3312 [1:23:04<02:30,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: PIXAR: Auto-Regressive Language Modeling in Pixel Space\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  97%|███████████████████████████████████████████████████████▎ | 3215/3312 [1:23:05<02:25,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Malla: Demystifying Real-world Large Language Model Integrated Malicious Services\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  97%|███████████████████████████████████████████████████████▎ | 3216/3312 [1:23:07<02:23,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Reflections on Inductive Thematic Saturation as a potential metric for measuring the validity of an inductive Thematic Analysis with LLMs\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  97%|███████████████████████████████████████████████████████▎ | 3217/3312 [1:23:08<02:27,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Using Large Language Models to Assess Tutors' Performance in Reacting to Students Making Math Errors\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  97%|███████████████████████████████████████████████████████▍ | 3218/3312 [1:23:10<02:22,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Human-Instruction-Free LLM Self-Alignment with Limited Samples\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  97%|███████████████████████████████████████████████████████▍ | 3219/3312 [1:23:12<02:40,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: The Dawn After the Dark: An Empirical Study on Factuality Hallucination in Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  97%|███████████████████████████████████████████████████████▍ | 3220/3312 [1:23:13<02:30,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: 3DMIT: 3D Multi-modal Instruction Tuning for Scene Understanding\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  97%|███████████████████████████████████████████████████████▍ | 3221/3312 [1:23:15<02:22,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: δ-CAUSAL: Exploring Defeasibility in Causal Reasoning\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  97%|███████████████████████████████████████████████████████▍ | 3222/3312 [1:23:16<02:16,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: A Joint-Reasoning based Disease Q&A System\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  97%|███████████████████████████████████████████████████████▍ | 3223/3312 [1:23:18<02:27,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Quartet Logic: A Four-Step Reasoning (QLFR) framework for advancing Short Text Classification\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  97%|███████████████████████████████████████████████████████▍ | 3224/3312 [1:23:20<02:19,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Examining Forgetting in Continual Pre-training of Aligned Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  97%|███████████████████████████████████████████████████████▌ | 3225/3312 [1:23:21<02:14,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Incorporating Visual Experts to Resolve the Information Loss in Multimodal Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  97%|███████████████████████████████████████████████████████▌ | 3226/3312 [1:23:23<02:17,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: DeepSeek LLM: Scaling Open-Source Language Models with Longtermism\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  97%|███████████████████████████████████████████████████████▌ | 3227/3312 [1:23:24<02:12,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Towards ASR Robust Spoken Language Understanding Through In-Context Learning With Word Confusion Networks\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  97%|███████████████████████████████████████████████████████▌ | 3228/3312 [1:23:26<02:09,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Introducing Bode: A Fine-Tuned Large Language Model for Portuguese Prompt-Based Task\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  97%|███████████████████████████████████████████████████████▌ | 3229/3312 [1:23:27<02:07,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: MLLM-Protector: Ensuring MLLM's Safety without Hurting Performance\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  98%|███████████████████████████████████████████████████████▌ | 3230/3312 [1:23:29<02:05,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: AFSPP: Agent Framework for Shaping Preference and Personality with Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  98%|███████████████████████████████████████████████████████▌ | 3231/3312 [1:23:30<02:04,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Generative Large Language Models are autonomous practitioners of evidence-based medicine\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  98%|███████████████████████████████████████████████████████▌ | 3232/3312 [1:23:32<02:09,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Pheme: Efficient and Conversational Speech Generation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  98%|███████████████████████████████████████████████████████▋ | 3233/3312 [1:23:34<02:08,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: From LLM to Conversational Agent: A Memory Enhanced Architecture with Fine-Tuning of Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  98%|███████████████████████████████████████████████████████▋ | 3234/3312 [1:23:35<02:05,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Detection and Classification of Diabetic Retinopathy using Deep Learning Algorithms for Segmentation to Facilitate Referral Recommendation for Test and Treatment Prediction\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  98%|███████████████████████████████████████████████████████▋ | 3235/3312 [1:23:38<02:15,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Parameter-Efficient Sparsity Crafting from Dense to Mixture-of-Experts for Instruction Tuning on General Tasks\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  98%|███████████████████████████████████████████████████████▋ | 3236/3312 [1:23:39<02:11,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: XUAT-Copilot: Multi-Agent Collaborative System for Automated User Acceptance Testing with Large Language Model\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  98%|███████████████████████████████████████████████████████▋ | 3237/3312 [1:23:41<02:09,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: VoroNav: Voronoi-based Zero-shot Object Navigation with Large Language Model\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  98%|███████████████████████████████████████████████████████▋ | 3238/3312 [1:23:43<02:10,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LMaaS: Exploring Pricing Strategy of Large Model as a Service for Communication\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  98%|███████████████████████████████████████████████████████▋ | 3239/3312 [1:23:44<02:00,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: AST-T5: Structure-Aware Pretraining for Code Generation and Understanding\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  98%|███████████████████████████████████████████████████████▊ | 3240/3312 [1:23:46<01:53,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: CoCoT: Contrastive Chain-of-Thought Prompting for Large Multimodal Models with Multiple Image Inputs\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  98%|███████████████████████████████████████████████████████▊ | 3241/3312 [1:23:47<01:47,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Large Language Models for Social Networks: Applications, Challenges, and Solutions\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  98%|███████████████████████████████████████████████████████▊ | 3242/3312 [1:23:48<01:44,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Vulnerabilities Unveiled: Adversarially Attacking a Multimodal Vision Language Model for Pathology Imaging\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  98%|███████████████████████████████████████████████████████▊ | 3243/3312 [1:23:50<01:41,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Learning to Prompt with Text Only Supervision for Vision-Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  98%|███████████████████████████████████████████████████████▊ | 3244/3312 [1:23:51<01:39,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: SPEER: Sentence-Level Planning of Long Clinical Summaries via Embedded Entity Retrieval\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  98%|███████████████████████████████████████████████████████▊ | 3245/3312 [1:23:53<01:42,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Are LLMs Robust for Spoken Dialogues?\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  98%|███████████████████████████████████████████████████████▊ | 3246/3312 [1:23:55<01:41,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: PokerGPT: An End-to-End Lightweight Solver for Multi-Player Texas Hold'em via Large Language Model\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  98%|███████████████████████████████████████████████████████▉ | 3247/3312 [1:23:56<01:39,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: DIALIGHT: Lightweight Multilingual Development and Evaluation of Task-Oriented Dialogue Systems with Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  98%|███████████████████████████████████████████████████████▉ | 3248/3312 [1:23:58<01:38,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: A Dataset and Benchmark for Copyright Protection from Text-to-Image Diffusion Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  98%|███████████████████████████████████████████████████████▉ | 3249/3312 [1:23:59<01:34,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Exploring Boundary of GPT-4V on Marine Analysis: A Preliminary Case Study\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  98%|███████████████████████████████████████████████████████▉ | 3250/3312 [1:24:01<01:35,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Improved Zero-Shot Classification by Adapting VLMs with Text Descriptions\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  98%|███████████████████████████████████████████████████████▉ | 3251/3312 [1:24:02<01:34,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: DCR-Consistency: Divide-Conquer-Reasoning for Consistency Evaluation and Improvement of Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  98%|███████████████████████████████████████████████████████▉ | 3252/3312 [1:24:04<01:34,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Using LLM to select the right SQL Query from candidates\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  98%|███████████████████████████████████████████████████████▉ | 3253/3312 [1:24:05<01:31,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Blending Is All You Need: Cheaper, Better Alternative to Trillion-Parameters LLM\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  98%|████████████████████████████████████████████████████████ | 3254/3312 [1:24:07<01:27,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Re-evaluating the Memory-balanced Pipeline Parallelism: BPipe\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  98%|████████████████████████████████████████████████████████ | 3255/3312 [1:24:08<01:24,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ICE-GRT: Instruction Context Enhancement by Generative Reinforcement based Transformers\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  98%|████████████████████████████████████████████████████████ | 3256/3312 [1:24:10<01:26,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: An Example of Evolutionary Computation + Large Language Model Beating Human: Design of Efficient Guided Local Search\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  98%|████████████████████████████████████████████████████████ | 3257/3312 [1:24:11<01:24,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: MobileAgent: enhancing mobile control via human-machine interaction and SOP integration\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  98%|████████████████████████████████████████████████████████ | 3258/3312 [1:24:13<01:22,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Text2MDT: Extracting Medical Decision Trees from Medical Texts\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  98%|████████████████████████████████████████████████████████ | 3259/3312 [1:24:14<01:21,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Self-Contrast: Better Reflection Through Inconsistent Solving Perspectives\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  98%|████████████████████████████████████████████████████████ | 3260/3312 [1:24:16<01:21,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Revisiting Zero-Shot Abstractive Summarization in the Era of Large Language Models from the Perspective of Position Bias\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  98%|████████████████████████████████████████████████████████ | 3261/3312 [1:24:18<01:18,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Towards Truly Zero-shot Compositional Visual Reasoning with LLMs as Programmers\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  98%|████████████████████████████████████████████████████████▏| 3262/3312 [1:24:19<01:16,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Generalist embedding models are better at short-context clinical semantic search than specialized embedding models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  99%|████████████████████████████████████████████████████████▏| 3263/3312 [1:24:20<01:12,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: A Vision Check-up for Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  99%|████████████████████████████████████████████████████████▏| 3264/3312 [1:24:22<01:11,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Multilingual Instruction Tuning With Just a Pinch of Multilinguality\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  99%|████████████████████████████████████████████████████████▏| 3265/3312 [1:24:23<01:09,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Physio: An LLM-Based Physiotherapy Advisor\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  99%|████████████████████████████████████████████████████████▏| 3266/3312 [1:24:25<01:08,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Large Language Models Relearn Removed Concepts\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  99%|████████████████████████████████████████████████████████▏| 3267/3312 [1:24:27<01:09,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Navigating Uncertainty: Optimizing API Dependency for Hallucination Reduction in Closed-Book Question Answering\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  99%|████████████████████████████████████████████████████████▏| 3268/3312 [1:24:28<01:08,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Cross-target Stance Detection by Exploiting Target Analytical Perspectives\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  99%|████████████████████████████████████████████████████████▎| 3269/3312 [1:24:30<01:05,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: WordArt Designer API: User-Driven Artistic Typography Synthesis with Large Language Models on ModelScope\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  99%|████████████████████████████████████████████████████████▎| 3270/3312 [1:24:31<01:05,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Predicting challenge moments from students' discourse: A comparison of GPT-4 to two traditional natural language processing approaches\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  99%|████████████████████████████████████████████████████████▎| 3271/3312 [1:24:33<01:03,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: GPT-4V(ision) is a Generalist Web Agent, if Grounded\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  99%|████████████████████████████████████████████████████████▎| 3272/3312 [1:24:34<01:03,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: PLLaMa: An Open-source Large Language Model for Plant Science\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  99%|████████████████████████████████████████████████████████▎| 3273/3312 [1:24:36<01:02,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: GOAT-Bench: Safety Insights to Large Multimodal Models through Meme-Based Social Abuse\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  99%|████████████████████████████████████████████████████████▎| 3274/3312 [1:24:37<00:58,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Exploring the Frontiers of LLMs in Psychological Applications: A Comprehensive Review\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  99%|████████████████████████████████████████████████████████▎| 3275/3312 [1:24:39<00:59,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Question-Answering Based Summarization of Electronic Health Records using Retrieval Augmented Generation\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  99%|████████████████████████████████████████████████████████▍| 3276/3312 [1:24:41<00:57,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Quantifying the Uniqueness of Donald Trump in Presidential Discourse\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  99%|████████████████████████████████████████████████████████▍| 3277/3312 [1:24:42<00:54,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: TREC iKAT 2023: The Interactive Knowledge Assistance Track Overview\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  99%|████████████████████████████████████████████████████████▍| 3278/3312 [1:24:44<00:51,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LLM Maybe LongLM: Self-Extend LLM Context Window Without Tuning\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  99%|████████████████████████████████████████████████████████▍| 3279/3312 [1:24:45<00:50,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  99%|████████████████████████████████████████████████████████▍| 3280/3312 [1:24:47<00:49,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Large Legal Fictions: Profiling Legal Hallucinations in Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  99%|████████████████████████████████████████████████████████▍| 3281/3312 [1:24:48<00:47,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: A Comprehensive Study of Knowledge Editing for Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  99%|████████████████████████████████████████████████████████▍| 3282/3312 [1:24:50<00:47,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: CharacterEval: A Chinese Benchmark for Role-Playing Conversational Agent Evaluation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  99%|████████████████████████████████████████████████████████▌| 3283/3312 [1:24:51<00:44,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LLbezpeky: Leveraging Large Language Models for Vulnerability Detection\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  99%|████████████████████████████████████████████████████████▌| 3284/3312 [1:24:53<00:42,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Fairness Certification for Natural Language Processing and Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  99%|████████████████████████████████████████████████████████▌| 3285/3312 [1:24:56<00:51,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: VideoDrafter: Content-Consistent Multi-Scene Video Generation with LLM\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  99%|████████████████████████████████████████████████████████▌| 3286/3312 [1:24:58<00:49,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Zero-Shot Position Debiasing for Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  99%|████████████████████████████████████████████████████████▌| 3287/3312 [1:25:00<00:49,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Uncertainty Resolution in Misinformation Detection\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  99%|████████████████████████████████████████████████████████▌| 3288/3312 [1:25:01<00:45,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: BEV-CLIP: Multi-modal BEV Retrieval Methodology for Complex Scene in Autonomous Driving\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  99%|████████████████████████████████████████████████████████▌| 3289/3312 [1:25:05<00:55,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LLaMA Beyond English: An Empirical Study on Language Capability Transfer\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  99%|████████████████████████████████████████████████████████▌| 3290/3312 [1:25:10<01:10,  3.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Cheetah: Natural Language Generation for 517 African Languages\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  99%|████████████████████████████████████████████████████████▋| 3291/3312 [1:25:12<00:56,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Auffusion: Leveraging the Power of Diffusion and Large Language Models for Text-to-Audio Generation\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  99%|████████████████████████████████████████████████████████▋| 3292/3312 [1:25:13<00:46,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Evaluating Large Language Models on the GMAT: Implications for the Future of Business Education\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  99%|████████████████████████████████████████████████████████▋| 3293/3312 [1:25:15<00:40,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Holistic Autonomous Driving Understanding by Bird's-Eye-View Injected Multi-Modal Large Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  99%|████████████████████████████████████████████████████████▋| 3294/3312 [1:25:16<00:34,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Detection of Machine-Generated Text: Literature Survey\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers:  99%|████████████████████████████████████████████████████████▋| 3295/3312 [1:25:18<00:30,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Fast and Optimal Weight Update for Pruned Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers: 100%|████████████████████████████████████████████████████████▋| 3296/3312 [1:25:19<00:26,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: COSMO: COntrastive Streamlined MultimOdal Model with Interleaved Pre-Training\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers: 100%|████████████████████████████████████████████████████████▋| 3297/3312 [1:25:20<00:24,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Taking the Next Step with Generative Artificial Intelligence: The Transformative Role of Multimodal Large Language Models in Science Education\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers: 100%|████████████████████████████████████████████████████████▊| 3298/3312 [1:25:22<00:22,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Large Language Models in Mental Health Care: a Scoping Review\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers: 100%|████████████████████████████████████████████████████████▊| 3299/3312 [1:25:24<00:20,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: A Computational Framework for Behavioral Assessment of LLM Therapists\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers: 100%|████████████████████████████████████████████████████████▊| 3300/3312 [1:25:25<00:18,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: SecFormer: Towards Fast and Accurate Privacy-Preserving Inference for Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers: 100%|████████████████████████████████████████████████████████▊| 3301/3312 [1:25:27<00:17,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Astraios: Parameter-Efficient Instruction Tuning Code Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers: 100%|████████████████████████████████████████████████████████▊| 3302/3312 [1:25:28<00:16,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: The Earth is Flat? Unveiling Factual Errors in Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers: 100%|████████████████████████████████████████████████████████▊| 3303/3312 [1:25:30<00:14,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: A & B == B & A: Triggering Logical Reasoning Failures in Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers: 100%|████████████████████████████████████████████████████████▊| 3304/3312 [1:25:32<00:13,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ToolEyes: Fine-Grained Evaluation for Tool Learning Capabilities of Large Language Models in Real-world Scenarios\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers: 100%|████████████████████████████████████████████████████████▉| 3305/3312 [1:25:33<00:11,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Large Language Models aren't all that you need\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers: 100%|████████████████████████████████████████████████████████▉| 3306/3312 [1:25:35<00:09,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Benchmarking Large Language Models on Controllable Generation under Diversified Instructions\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers: 100%|████████████████████████████████████████████████████████▉| 3307/3312 [1:25:36<00:07,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Fine-tuning and Utilization Methods of Domain-specific LLMs\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers: 100%|████████████████████████████████████████████████████████▉| 3308/3312 [1:25:38<00:06,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Digger: Detecting Copyright Content Mis-usage in Large Language Model Training\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers: 100%|████████████████████████████████████████████████████████▉| 3309/3312 [1:25:39<00:04,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Predicting Anti-microbial Resistance using Large Language Models\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers: 100%|████████████████████████████████████████████████████████▉| 3310/3312 [1:25:42<00:03,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: From Prompt Engineering to Prompt Science With Human in the Loop\n",
      "Result: no\n",
      "\n",
      "Progress saved at index: 3310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing papers: 100%|████████████████████████████████████████████████████████▉| 3311/3312 [1:25:44<00:01,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Beyond Efficiency: A Systematic Survey of Resource-Efficient Large Language Models\n",
      "Result: yes\n",
      "\n",
      "Progress saved at index: 3311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing papers: 100%|█████████████████████████████████████████████████████████| 3312/3312 [1:25:45<00:00,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import json\n",
    "import csv\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "openai.api_key = ' ' #my api \n",
    "\n",
    "# Keep track of progress with an index\n",
    "progress_file = 'progress.txt'\n",
    "\n",
    "def evaluate_paper_simple(title, summary):\n",
    "    prompt = f\"\"\"\n",
    "    Can you please tell me if the title or the abstract of the paper explicitly mentions any limitation or challenge that is directly related to Large Language Models (LLM)? Please consider as positive only the limitations of the models and not of other topics mentioned. If it does, please output 'yes', if it does not, please output 'no'.\n",
    "    Please make sure that you answer 'yes' only for the abstracts that talk only about LLMs limitations explicitely. \n",
    "    Title: {title}\n",
    "    Paper: {summary}\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            max_tokens=50,  \n",
    "            n=1,\n",
    "            stop=None,\n",
    "            temperature=0\n",
    "        )\n",
    "        return response.choices[0].message['content'].strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Error during API call: {e}\")\n",
    "        return None\n",
    "\n",
    "def read_papers_from_json(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            papers = json.load(file)\n",
    "        print(f\"Successfully read {len(papers)} papers from the JSON file.\")\n",
    "        return papers\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading JSON file: {e}\")\n",
    "        return []\n",
    "\n",
    "def get_last_processed_index():\n",
    "    if os.path.exists(progress_file):\n",
    "        try:\n",
    "            with open(progress_file, 'r') as file:\n",
    "                return int(file.read().strip())\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading progress file: {e}\")\n",
    "            return -1\n",
    "    return -1\n",
    "\n",
    "def save_progress(index):\n",
    "    try:\n",
    "        with open(progress_file, 'w') as file:\n",
    "            file.write(str(index))\n",
    "        print(f\"Progress saved at index: {index}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving progress: {e}\")\n",
    "\n",
    "file_path = 'data_crawling/arXiv_classification_yes_no_results/arXiv_Jan_March_2024_LLM_Limitations_only.json'\n",
    "csv_file_path = 'LLM_paper_classification/arXiv_classification_yes_no_results/arXiv_Jan_Mar_2024_filtered_results_new.csv'\n",
    "\n",
    "last_index = get_last_processed_index()\n",
    "print(f\"Last processed index: {last_index}\")\n",
    "\n",
    "papers = read_papers_from_json(file_path)\n",
    "\n",
    "if not papers:\n",
    "    print(\"No papers to process. Exiting.\")\n",
    "    exit()\n",
    "\n",
    "if last_index >= len(papers):\n",
    "    last_index = -1\n",
    "\n",
    "with open(csv_file_path, mode='a', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    \n",
    "    if last_index == -1:\n",
    "        writer.writerow(['Title', 'Mentions LLM Limitations'])\n",
    "        print(\"Header written to CSV file.\")\n",
    "\n",
    "    for index, paper in enumerate(tqdm(papers, desc=\"Processing papers\"), start=0):\n",
    "        # Skipping the papers that were already processed\n",
    "        if index <= last_index:\n",
    "            continue\n",
    "\n",
    "        title = paper.get('title', 'No Title')\n",
    "        summary = paper.get('summary', 'No Summary')\n",
    "        try:\n",
    "            evaluation_result = evaluate_paper_simple(title, summary)\n",
    "\n",
    "            if evaluation_result is None:\n",
    "                print(f\"Skipping paper at index {index} due to API call failure.\")\n",
    "                continue\n",
    "\n",
    "            result = 'yes' if 'yes' in evaluation_result.lower() else 'no'\n",
    "\n",
    "            writer.writerow([title, result])\n",
    "            print(f\"Title: {title}\\nResult: {result}\\n\")\n",
    "\n",
    "            save_progress(index)\n",
    "\n",
    "            time.sleep(1)  # Adding a delay to avoid rate limits\n",
    "            \n",
    "        except openai.error.RateLimitError:\n",
    "            print(\"Rate limit exceeded. Waiting before retrying...\")\n",
    "            time.sleep(60)  # Wait for a minute before retrying\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred at index {index}: {e}\")\n",
    "            break\n",
    "\n",
    "print(\"Processing complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fc6ccd",
   "metadata": {},
   "source": [
    "### Calculating the F1-Score for Classification of Papers into Two Groups\n",
    "This Python script calculates the F1 score to evaluate the performance of a model that classifies papers into two groups ('yes' or 'no')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28eec5ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.2' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7403846153846154\n",
      "Precision: 0.6640625\n",
      "Recall: 0.8854166666666666\n",
      "F1 Score: 0.7589285714285714\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "\n",
    "file_path = os.path.expanduser('~/Desktop/model_vs_ground_truth_comparison.xlsx')\n",
    "data = pd.read_excel(file_path)\n",
    "ground_truth = data['GroundTruth_yes/no']\n",
    "model_answer1 = data['Prompt1_Classification_yes/no']\n",
    "\n",
    "valid_indices1 = ground_truth.notna() & model_answer1.notna()\n",
    "ground_truth1 = ground_truth[valid_indices1]\n",
    "model_answer1 = model_answer1[valid_indices1]\n",
    "ground_truth_binary1 = ground_truth1.apply(lambda x: 1 if x.lower() == 'yes' else 0)\n",
    "model_answer_binary1 = model_answer1.apply(lambda x: 1 if x.lower() == 'yes' else 0)\n",
    "\n",
    "f1_prompt1 = f1_score(ground_truth_binary1, model_answer_binary1)\n",
    "precision_prompt1 = precision_score(ground_truth_binary1, model_answer_binary1)\n",
    "recall_prompt1 = recall_score(ground_truth_binary1, model_answer_binary1)\n",
    "accuracy_prompt1 = accuracy_score(ground_truth_binary1, model_answer_binary1)\n",
    "print(f'Accuracy: {accuracy_prompt1}')\n",
    "print(f'Precision: {precision_prompt1}')\n",
    "print(f'Recall: {recall_prompt1}')\n",
    "print(f'F1 Score: {f1_prompt1}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4aba83",
   "metadata": {},
   "source": [
    "#### Filtering Papers: Retaining Only Those Classified as 'Yes' by the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e4233ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.2' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV Columns: Index(['Title', 'Mentions LLM Limitations'], dtype='object')\n",
      "Filtered JSON data saved to arXiv_classification_yes_no_results/arXiv_Jan_March_2024_LLM_Limitations_only.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def filter_papers(csv_path, json_path, output_json_path):\n",
    "    try:\n",
    "        csv_data = pd.read_csv(csv_path, encoding='utf-8') \n",
    "    except UnicodeDecodeError:\n",
    "        csv_data = pd.read_csv(csv_path, encoding='ISO-8859-1')  \n",
    "    print(\"CSV Columns:\", csv_data.columns)\n",
    "    title_column = 'Title'\n",
    "    evaluation_column = 'Mentions LLM Limitations' \n",
    "    filtered_titles = csv_data[csv_data[evaluation_column] == 'yes'][title_column].tolist()\n",
    "\n",
    "    with open(json_path, 'r', encoding='utf-8') as json_file:\n",
    "        json_data = json.load(json_file)\n",
    "    \n",
    "    filtered_json_data = [paper for paper in json_data if paper['title'] in filtered_titles]\n",
    "   \n",
    "    with open(output_json_path, 'w', encoding='utf-8') as output_json_file:\n",
    "        json.dump(filtered_json_data, output_json_file, ensure_ascii=False, indent=4)\n",
    "    \n",
    "    print(f'Filtered JSON data saved to {output_json_path}')\n",
    "\n",
    "csv_path = os.path.expanduser('LLM_paper_classification/arXiv_classification_yes_no_results/arXiv_Jan_Mar_2024_filtered_results_new.csv')\n",
    "json_path = os.path.expanduser('data_crawling/arXiv_data/data_collected_Jan2024-31March2024_filtered.json')\n",
    "output_json_path = os.path.expanduser('LLM_paper_classification/arXiv_classification_yes_no_results/arXiv_Jan_March_2024_LLM_Limitations_only.json')\n",
    "filter_papers(csv_path, json_path, output_json_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2c7f23",
   "metadata": {},
   "source": [
    "#### Filtering papers on the json file by the date "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6eb524d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered data has been saved to arXiv_classification_yes_no_results/arXiv_01Feb_to_31Mar_2024_LLM_limitations_only.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp/ipykernel_13460/3930431511.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['published'] = filtered_df['published'].dt.strftime('%Y-%m-%dT%H:%M:%SZ')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def load_json(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            return json.load(file)\n",
    "    except UnicodeDecodeError:\n",
    "        with open(file_path, 'r', encoding='ISO-8859-1') as file:\n",
    "            return json.load(file)\n",
    "        \n",
    "input_file_path = 'LLM_paper_classification/arXiv_classification_yes_no_results/arXiv_Jan_March_2024_LLM_Limitations_only.json'\n",
    "output_file_path = 'LLM_paper_classification/arXiv_classification_yes_no_results/arXiv_01Feb_to_31Mar_2024_LLM_limitations_only.json'\n",
    "data = load_json(input_file_path)\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df['published'] = pd.to_datetime(df['published'])\n",
    "\n",
    "# Filter the DataFrame for papers published from 1 February to 31 March 2024\n",
    "start_date = '2024-02-01'\n",
    "end_date = '2024-03-31'\n",
    "filtered_df = df[(df['published'] >= start_date) & (df['published'] <= end_date)]\n",
    "filtered_df['published'] = filtered_df['published'].dt.strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "filtered_data = filtered_df.to_dict(orient='records')\n",
    "with open(output_file_path, 'w', encoding='utf-8') as file:\n",
    "    json.dump(filtered_data, file, indent=4)\n",
    "print(f\"Filtered data has been saved to {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376834fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
