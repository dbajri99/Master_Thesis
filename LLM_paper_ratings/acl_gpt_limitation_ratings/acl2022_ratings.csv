Title,Talks about LLMs,Rate,Evidence
AlephBERT: Language Model Pre-training and Evaluation from Sub-Word to Sentence Level,Yes.,1.,"""First, so far, Hebrew resources for training large language models are not of the same magnitude as their English counterparts. Second, most benchmarks available to evaluate progress in Hebrew NLP require morphological boundaries which are not available in the output of standard PLMs."""
GLM: General Language Model Pretraining with Autoregressive Blank Infilling,Yes.,1.,"""We propose a General Language Model (GLM) based on autoregressive blank infilling to address this challenge."""
Towards Comprehensive Patent Approval Predictions:Beyond Traditional Document Classification,No.,1.,The abstract focuses on patent approval predictions and does not mention language models or their limitations.
Answer-level Calibration for Free-form Multiple Choice Question Answering,Yes.,3.,"""it often requires task-specific heuristics such as length normalization, or probability calibration."""
Meta-learning via Language Model In-context Tuning,Yes.,1.,"""Inspired by the recent progress in large language models,"" and ""we fine-tune a pre-trained language model (LM) to predict the target label given the input sequence on a collection of tasks."""
RoCBert: Robust Chinese Bert with Multimodal Contrastive Pretraining,Yes.,3.,"""Large-scale pretrained language models have achieved SOTA results on NLP tasks. However, they have been shown vulnerable to adversarial attacks especially for logographic languages like Chinese."""
Auto-Debias: Debiasing Masked Language Models with Automated Biased Prompts,Yes.,4.,"""Human-like biases and undesired social stereotypes exist in large pretrained language models. Given the wide adoption of these models in real-world applications, mitigating such biases has become an emerging and important task."""
A Closer Look at How Fine-tuning Changes BERT,Yes.,1.,"""Finally, by comparing the representations before and after fine-tuning, we discover that fine-tuning does not introduce arbitrary changes to representations; instead, it adjusts the representations to downstream tasks while largely preserving the original spatial structure of the data points."""
GPT-D: Inducing Dementia-related Linguistic Anomalies by Deliberate Degradation of Artificial Neural Language Models,Yes.,2.,"""questions remain about their ability to generalize beyond the small reference sets that are publicly available for research."""
Distributionally Robust Finetuning BERT for Covariate Drift in Spoken Language Understanding,Yes.,2.,"""Experiments show that a state-of-the-art BERT-based model suffers performance loss under this drift."""
CTRLEval: An Unsupervised Reference-Free Metric for Evaluating Controlled Text Generation,Yes.,1.,"""Experimental results show that our metric has higher correlations with human judgments than other baselines, while obtaining better generalization of evaluating generated texts from different models and with different qualities."""
Are Prompt-based Models Clueless?,Yes.,5.,"""models with a task-specific head require a lot of training data, making them susceptible to learning and exploiting dataset-specific superficial cues that do not generalize to other datasets"" and ""Analyzing few-shot prompt-based models on MNLI, SNLI, HANS, and COPA has revealed that prompt-based models also exploit superficial cues. While the models perform well on instances with superficial cues"
Contextual Representation Learning beyond Masked Language Modeling,Yes.,3.,"""it adopts sampled embeddings as anchors to estimate and inject contextual semantics to representations, which limits the efficiency and effectiveness of MLMs."""
Unsupervised Corpus Aware Language Model Pre-training for Dense Passage Retrieval,Yes.,2.,"""fragility to training data noise and ii) requiring large batches to robustly learn the embedding space."""
Confidence Based Bidirectional Global Context Aware Training Framework for Neural Machine Translation,No.,1.,The abstract discusses neural machine translation (NMT) models and their limitations but does not mention LLMs or their limitations.
TruthfulQA: Measuring How Models Mimic Human Falsehoods,Yes.,5.,"""Models generated many false answers that mimic popular misconceptions and have the potential to deceive humans."" and ""The largest models were generally the least truthful."""
ToxiGen: A Large-Scale Machine-Generated Dataset for Adversarial and Implicit Hate Speech Detection,,,
NumGLUE: A Suite of Fundamental yet Challenging Mathematical Reasoning Tasks,,,
Upstream Mitigation Is Not All You Need: Testing the Bias Transfer Hypothesis in Pre-Trained Language Models,Yes.,4.,"""We investigate the bias transfer hypothesis"
ePiC: Employing Proverbs in Context as a Benchmark for Abstract Language Understanding,Yes.,3.,"""Our experiments show that neural language models struggle on these tasks compared to humans, and these tasks pose multiple learning challenges."""
Bag-of-Words vs. Graph vs. Sequence in Text Classification: Questioning the Necessity of Text-Graphs and the Surprising Strength of a Wide MLP,Yes.,1.,"""Moreover, we fine-tune a sequence-based BERT and a lightweight DistilBERT model, which both outperform all state-of-the-art models."""
Compression of Generative Pre-trained Language Models via Quantization,Yes.,3.,"""Despite various methods to compress BERT or its variants, there are few attempts to compress generative PLMs, and the underlying difficulty remains unclear."" and ""We find that previous quantization methods fail on generative tasks due to the homogeneous word embeddings caused by reduced capacity and the varied distribution of weights."""
KinyaBERT: a Morphology-aware Kinyarwanda Language Model,Yes.,3.,"""the unsupervised sub-word tokenization methods commonly used in these models (e.g., byte-pair encoding - BPE) are sub-optimal at handling morphologically rich languages."" and ""naive sequencing of morphemes into a standard BERT architecture is inefficient at capturing morphological compos"
Flooding-X: Improving BERT’s Resistance to Adversarial Attacks via Loss-Restricted Fine-Tuning,Yes.,1.,"""We experimentally show that our method improves BERT’s resistance to textual adversarial attacks by a large margin, and achieves state-of-the-art robust accuracy on various text classification and GLUE tasks."""
What does the sea say to the shore? A BERT based DST style approach for speaker to dialogue attribution in novels,No.,1.,The abstract does not mention LLMs or any of their limitations.
Probing Simile Knowledge from Pre-trained Language Models,Yes.,1.,"""The knowledge embedded in PLMs may be useful for SI and SG tasks. Nevertheless, there are few works to explore it."""
SHIELD: Defending Textual Neural Networks against Multiple Black-Box Adversarial Attacks with Stochastic Multi-Expert Patcher,Yes.,2.,"""In particular, the state-of-the-art transformer models (e.g., BERT, RoBERTa) require great time and computation resources."""
A Token-level Reference-free Hallucination Detection Benchmark for Free-form Text Generation,Yes.,5.,"""Large pretrained generative models like GPT-3 often suffer from hallucinating non-existent or incorrect content, which undermines their potential merits in real applications."""
Low-Rank Softmax Can Have Unargmaxable Classes in Theory but Rarely in Practice,Yes.,3.,"""In theory, the result is some words may be impossible to be predicted via argmax, irrespective of input features, and empirically, there is evidence this happens in small language models (Demeter et al., 2020)."""
Is GPT-3 Text Indistinguishable from Human Text? Scarecrow: A Framework for Scrutinizing Machine Text,Yes.,4.,"""errors in machine generations become ever subtler and harder to spot,"" and ""the ten error categories of Scarecrow—such as redundancy, commonsense errors, and incoherence."""
Transkimmer: Transformer Learns to Layer-wise Skim,No.,1.,The abstract focuses on improving the computational efficiency of Transformer-based models and does not specifically discuss LLMs or their limitations.
ABC: Attention with Bounded-memory Control,Yes.,3.,"""However, their attention mechanism comes with a quadratic complexity in sequence lengths, making the computational overhead prohibitive, especially for long sequences."""
Cluster & Tune: Boost Cold Start Performance in Text Classification,Yes.,1.,"""the common practice of fine-tuning pre-trained models, such as BERT, for a target classification task, is prone to produce poor performance."""
Exploiting Language Model Prompts Using Similarity Measures: A Case Study on the Word-in-Context Task,Yes.,5.,"""existing prompt-based techniques fail on the semantic distinction task of the Word-in-Context (WiC) dataset. Specifically, none of the existing few-shot approaches (including the in-context learning of GPT-3) can attain a performance that is meaningfully different from the random baseline."""
Softmax Bottleneck Makes Language Models Unable to Represent Multi-mode Word Distributions,Yes.,5.,"""However, we discover that this single hidden state cannot produce all probability distributions regardless of the LM size or training data size because the single hidden state embedding cannot be close to the embeddings of all the possible next words simultaneously when there are other interfering word embeddings between them."""
Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity,,,
Coherence boosting: When your pretrained language model is not paying enough attention,Yes.,5.,"""We demonstrate that large language models have insufficiently learned the effect of distant words on next-token prediction."""
Improving the Generalizability of Depression Detection by Leveraging Clinical Questionnaires,No.,1.,The abstract does not mention LLMs or any form of language models.
Internet-Augmented Dialogue Generation,Yes.,3.,"""Large language models, even though they store an impressive amount of knowledge within their weights, are known to hallucinate facts when generating dialogue; moreover, those facts are frozen in time at the point of model training."""
Text-Free Prosody-Aware Generative Spoken Language Modeling,Yes.,3.,"""Unfortunately, because the units used in GSLM discard most prosodic information, GSLM fails to leverage prosody for better comprehension and does not generate expressive speech."""
P-Tuning: Prompt Tuning Can Be Comparable to Fine-tuning Across Scales and Tasks,Yes.,3.,"""prior work reveals that prompt tuning does not perform well for normal-sized pretrained models. We also find that existing methods of prompt tuning cannot handle hard sequence labeling tasks, indicating a lack of universality."""
Does BERT Know that the IS-A Relation Is Transitive?,,,
Data Contamination: From Memorization to Exploitation,Yes.,5.,"""It is not clear to what extent models exploit the contaminated data for downstream tasks."" and ""Our results highlight the importance of analyzing massive web-scale datasets to verify that progress in NLP is obtained by better language understanding and not better data exploitation."""
Kronecker Decomposition for GPT Compression,Yes.,5.,"""Despite the superior performance of GPT, this overparameterized nature of GPT can be very prohibitive for deploying this model on devices with limited computational power or memory."""
Exploiting Language Model Prompts Using Similarity Measures: A Case Study on the Word-in-Context Task,Yes.,3.,"""existing prompt-based techniques fail on the semantic distinction task of the Word-in-Context (WiC) dataset"" and ""none of the existing few-shot approaches (including the in-context learning of GPT-3) can attain a performance that is meaningfully different from the random baseline."""
"Fire Burns, Sword Cuts: Commonsense Inductive Bias for Exploration in Text-based Games",Yes.,1.,"""We propose CommExpl, an exploration technique that injects external commonsense knowledge, via a pretrained language model (LM), into the agent during training."""
"When classifying grammatical role, BERT doesn’t care about word order... except when it matters",,,
A Recipe for Arbitrary Text Style Transfer with Large Language Models,Yes.,1.,"""In this paper, we leverage large language models (LLMs) to perform zero-shot text style transfer."""
Exploring Cross-lingual Text Detoxification with Large Multilingual Language Models.,Yes.,3.,"""tested state-of-the-art models are not able to perform cross-lingual detoxification and direct fine-tuning on exact language is currently inevitable and motivating the need of further research in this direction."""
Cue-bot: A Conversational Agent for Assistive Technology,Yes.,1.,"""Language model technologies can be very powerful tools in enabling these users to carry out daily communication and social interactions."""
Zero- and Few-Shot NLP with Pretrained Language Models,Yes.,1.,"""our goal is to reveal new research opportunities to the audience, which will hopefully bring us closer to address existing challenges in this domain."""
