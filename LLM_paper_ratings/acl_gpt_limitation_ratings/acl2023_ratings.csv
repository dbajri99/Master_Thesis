Title,Talks about LLMs,Rate,Evidence
ACLM: A Selective-Denoising based Generative Data Augmentation Approach for Low-Resource Complex NER,Yes.,1.,"""In this paper, we present ACLM Attention-map aware keyword selection for Conditional Language Model fine-tuning), a novel data augmentation approach based on conditional generation, to address the data scarcity problem in low-resource complex NER."""
MIL-Decoding: Detoxifying Language Models at Token-Level via Multiple Instance Learning,Yes.,4.,"""Despite advances in large pre-trained neural language models, they are prone to generating toxic language, which brings security risks to their applications."""
Text Adversarial Purification as Defense against Adversarial Attacks,Yes.,1.,"""With the help of language models, we can inject noise by masking input texts and reconstructing the masked texts based on the masked language models."""
Knowledge of cultural moral norms in large language models,Yes.,4.,"""We find that pre-trained English language models predict empirical moral norms across countries worse than the English moral norms reported previously. However, fine-tuning language models on the survey data improves inference across countries at the expense of a less accurate estimate of the English moral norms."""
A Causal Framework to Quantify the Robustness of Mathematical Reasoning with Language Models,Yes.,5.,"""the robustness of these models has also been called into question; recent works have shown that models can rely on shallow patterns in the problem description when generating a solution"" and ""Our analysis shows that robustness does not appear to continuously improve as a function of size."""
Increasing Diversity While Maintaining Accuracy: Text Data Generation with Large Language Models and Human Interventions,Yes.,,
Self-Edit: Fault-Aware Code Editor for Code Generation,Yes.,3.,"""However, with limited sample numbers, LLMs still suffer from poor accuracy."""
Does GPT-3 Grasp Metaphors? Identifying Metaphor Mappings with Generative Language Models,Yes.,3.,"""GPT’s most common error is a hallucinated source domain for which no indicator is present in the sentence. Other common errors include identifying a sequence as literal even though a metaphor is present and predicting the wrong source domain based on specific words in the sequence that are"
ALERT: Adapt Language Models to Reasoning Tasks,Yes.,5.,"""it is unclear whether these models are applying reasoning skills they have learnt during pre-training, or if they are simply memorizing their training corpus at finer granularity,"" and ""we also find that when language models are finetuned they tend to overfit to the prompt template, which hurts the robustness of models causing generalization"
Glot500: Scaling Multilingual Corpora and Language Models to 500 Languages,Yes.,1.,"""The NLP community has mainly focused on scaling Large Language Models (LLMs) vertically, i.e., making them better for about 100 languages."""
Pretrained Bidirectional Distillation for Machine Translation,,,
ThinkSum: Probabilistic reasoning over sets using large language models,Yes.,5.,"""recent studies show that even the more advanced LLMs fail in scenarios that require reasoning over multiple objects or facts and making sequences of logical deductions."""
Synthetic Text Generation with Differential Privacy: A Simple and Practical Recipe,Yes.,1.,"""simply fine-tuning a pretrained generative language model with DP enables the model to generate useful synthetic text with strong privacy protection."""
Cross-Domain Data Augmentation with Domain-Adaptive Language Modeling for Aspect-Based Sentiment Analysis,Yes.,1.,"""we propose a new cross-domain Data Augmentation approach based on Domain-Adaptive Language Modeling named DA2LM"""
Marked Personas: Using Natural Language Prompts to Measure Stereotypes in Language Models,,,
Elaboration-Generating Commonsense Question Answering at Scale,Yes.,2.,"""Yet the cost of working with such models is very high."""
DaMSTF: Domain Adversarial Learning Enhanced Meta Self-Training for Domain Adaptation,Yes.,1.,"""On the cross-domain sentiment classification task, DaMSTF improves the performance of BERT with an average of nearly 4%."""
Do language models have coherent mental models of everyday things?,Yes.,5.,"""we observe that state-of-the-art pre-trained language models (LMs) like GPT-3 and Macaw have fragments of knowledge about these everyday things, but do not have fully coherent 'parts mental models' (54-59% accurate, 19-43% conditional constraint violation)."""
"KALM: Knowledge-Aware Integration of Local, Document, and Global Contexts for Long Document Understanding",Yes.,2.,"""While existing approaches leverage external knowledge, it remains an open question how to jointly incorporate knowledge graphs represented in varying contexts"" and ""incorporating varying contexts can especially benefit long document understanding tasks that leverage pre-trained LMs, typically bounded by the input sequence length."""
Z-ICL: Zero-Shot In-Context Learning with Pseudo-Demonstrations,Yes.,3.,"""performance drops significantly when no demonstrations are available."""
Training-free Neural Architecture Search for RNNs and Transformers,,,
Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning by Large Language Models,Yes.,5.,"""Despite the success of Zero-shot-CoT, it still suffers from three pitfalls"
Symbolic Chain-of-Thought Distillation: Small Models Can Also “Think” Step-by-Step,Yes.,3.,"""benefits appear to emerge only for sufficiently large models (beyond 50B parameters)."""
Towards Understanding Chain-of-Thought Prompting: An Empirical Study of What Matters,Yes.,3.,"""Despite its success, there is still little understanding of what makes CoT prompting effective and which aspects of the demonstrated reasoning steps contribute to its performance."""
Dynamic and Efficient Inference for Text Generation via BERT Family,Yes.,5.,"""they suffer from inefficient inference on computation and memory due to their large-scale parameters and the universal autoregressive decoding paradigm."""
An Invariant Learning Characterization of Controlled Text Generation,Yes.,3.,"""researchers hoping to deploy a large language model to produce non-toxic content may use a toxicity classifier to filter generated text"" and ""the performance of controlled generation may be poor if the distributions of text in response to user prompts differ from the distribution the predictor was trained on."""
HyPe: Better Pre-trained Language Model Fine-tuning with Hidden Representation Perturbation,Yes.,3.,"""there still poses problems when fine-tuning pre-trained language models on downstream tasks, such as over-fitting or representation collapse."""
Decoding Symbolism in Language Models,,,
A Survey on Zero Pronoun Translation,Yes.,3.,"""ZPT is in line with the development trend of large language model"" and ""data limitation causes learning bias in languages and domains"" and ""advanced methods are still far from real-world use"" and ""general-purpose metrics are not reliable on nuances and complexities of ZPT, emphasizing the necessity of targeted metrics."""
Alleviating Over-smoothing for Unsupervised Sentence Representation,Yes.,3.,"""Experimentally, we observe that the over-smoothing problem reduces the capacity of these powerful PLMs, leading to sub-optimal sentence representations."""
Code4Struct: Code Generation for Few-Shot Event Structure Prediction,Yes.,1.,"""Large Language Model (LLM) trained on a mixture of text and code has demonstrated impressive capability in translating natural language (NL) into structured code."""
Entity Tracking in Language Models,Yes.,3.,"""we present a task probing to what extent a language model can infer the final state of an entity given an English description of the initial state and a series of state-changing operations"" and ""pretraining on text corpora alone does not make this capacity surface."""
Faithful Question Answering with Monte-Carlo Planning,Yes.,3.,"""revealing the intermediate reasoning steps that the models faithfully follow remains challenging."""
Analyzing and Reducing the Performance Gap in Cross-Lingual Transfer with Fine-tuning Slow and Fast,Yes.,3.,"""However, there is a clear gap between the performance of the source language and that of the non-source languages."""
Social-Group-Agnostic Bias Mitigation via the Stereotype Content Model,Yes.,4.,"""Existing bias mitigation methods require social-group-specific word pairs (e.g., “man” – “woman”) for each social attribute (e.g., gender), restricting the bias mitigation to only one specified social attribute. Further, this constraint renders such methods impractical and costly for mitigating bias in"
Revisiting the Gold Standard: Grounding Summarization Evaluation with Robust Human Evaluation,Yes.,3.,"""The metrics we benchmarked include recent methods based on large language models (LLMs), GPTScore and G-Eval. Furthermore, our findings have important implications for evaluating LLMs, as we show that LLMs adjusted by human feedback (e.g., GPT-3.5"
FIREBALL: A Dataset of Dungeons and Dragons Actual-Play with Structured Game State Information,Yes.,2.,"""Recent work has shown that large language models (LLMs) that have access to state information can generate higher quality game turns than LLMs that use dialog history alone. However, previous work used game state information that was heuristically created and was not a true gold standard game"
Distilling Script Knowledge from Large Language Models for Constrained Language Planning,Yes.,2.,"""Previous work has exploited language models (LMs) to plan for abstract goals of stereotypical activities (e.g., “make a cake”), but leaves more specific goals with multi-facet constraints understudied (e.g., “make a cake for diabetics”)."""
CELDA: Leveraging Black-box Language Model as Enhanced Classifier without Labels,Yes.,3.,"""Despite their efficacy, they still fall short in comparison to fully supervised counterparts and are generally brittle to slight modifications."""
Explanation-based Finetuning Makes Models More Robust to Spurious Cues,Yes.,5.,"""Large Language Models (LLMs) are so powerful that they sometimes learn correlations between labels and features that are irrelevant to the task, leading to poor generalization on out-of-distribution data."""
"On Second Thought, Let’s Not Think Step by Step! Bias and Toxicity in Zero-Shot Reasoning",Yes.,5.,"""We find that zero-shot CoT reasoning in sensitive domains significantly increases a model’s likelihood to produce harmful or undesirable output,"" and ""Our work suggests that zero-shot CoT should be used with caution on socially important tasks, especially when marginalized groups or sensitive topics are involved."""
Solving Math Word Problems via Cooperative Reasoning induced Language Models,Yes.,3.,"""However, directly applying existing PLMs to MWPs can fail as the generation process lacks sufficient supervision and thus lacks fast adaptivity as humans."""
"Don’t Generate, Discriminate: A Proposal for Grounding Language Models to Real-World Environments",Yes.,3.,"""A key missing capacity of current language models (LMs) is grounding to real-world environments."" and ""It thereby casts the burden of ensuring grammaticality, faithfulness, and controllability all on the LMs."""
Randomized Smoothing with Masked Inference for Adversarially Robust Text Classifications,Yes.,3.,"""Large-scale pre-trained language models have shown outstanding performance in a variety of NLP tasks. However, they are also known to be significantly brittle against specifically crafted adversarial examples, leading to increasing interest in probing the adversarial robustness of NLP systems."""
MetaAdapt: Domain Adaptive Few-Shot Misinformation Detection via Meta Learning,Yes.,1.,"""we perform extensive experiments to compare MetaAdapt with state-of-the-art baselines and large language models (LLMs) such as LLaMA."""
Making Language Models Better Reasoners with Step-Aware Verifier,Yes.,3.,"""Large language models like GPT-3 and PaLM have made impressive progress in this area, but they still face difficulties in reasoning tasks such as GSM8K, a benchmark for arithmetic problems."""
MISGENDERED: Limits of Large Language Models in Understanding Pronouns,Yes.,5.,"""When prompted out-of-the-box, language models perform poorly at correctly predicting neo-pronouns (averaging 7.6% accuracy) and gender-neutral pronouns (averaging 31.0% accuracy). This inability to generalize results from a lack of representation of non-binary pronouns in training data and memorized associations."""
DISCO: Distilling Counterfactuals with Large Language Models,,,
SCOTT: Self-Consistent Chain-of-Thought Distillation,Yes.,4.,"""Even more concerning, there is little guarantee that the generated rationales are consistent with LM’s predictions or faithfully justify the decisions."""
Evaluating Open-Domain Question Answering in the Era of Large Language Models,Yes.,5.,"""The automated models struggle in detecting hallucinations in LLM answers and are thus unable to evaluate LLMs."""
Open-Domain Hierarchical Event Schema Induction by Incremental Prompting and Verification,Yes.,1.,"""we propose to treat event schemas as a form of commonsense knowledge that can be derived from large language models (LLMs)."""
Verify-and-Edit: A Knowledge-Enhanced Chain-of-Thought Framework,Yes.,5.,"""one of its most fatal disadvantages is the lack of factual correctness. Generating unfactual texts not only leads to lower performances but also degrades the trust and validity of their applications."""
Connective Prediction for Implicit Discourse Relation Recognition via Knowledge Distillation,Yes.,1.,"""To address these problems, we propose a novel Connective Prediction via Knowledge Distillation (CP-KD) approach to instruct large-scale pre-trained language models (PLMs) mining the latent correlations between connectives and discourse relations, which is meaningful for IDRR."""
Language model acceptability judgements are not always robust to context,Yes.,5.,"""We find that model judgements are generally robust when placed in randomly sampled linguistic contexts, but are unstable when contexts match the test stimuli in syntactic structure."" and ""This sensitivity to highly specific syntactic features of the context can only be explained by the models’ implicit in-context learning abilities."""
RobuT: A Systematic Study of Table QA Robustness Against Human-Annotated Adversarial Perturbations,Yes.,5.,"""Our results indicate that both state-of-the-art Table QA models and large language models (e.g., GPT-3) with few-shot learning falter in these adversarial sets."""
Learning Non-linguistic Skills without Sacrificing Linguistic Proficiency,Yes.,5.,"""non-linguistic skill injection typically comes at a cost for LLMs"
Multilingual LLMs are Better Cross-lingual In-context Learners with Alignment,Yes.,3.,"""We find that the prevalent mode of selecting random input-label pairs to construct the prompt-context is severely limited in the case of cross-lingual ICL, primarily due to the lack of alignment in the input as well as the output spaces."""
MultiTabQA: Generating Tabular Answers for Multi-Table Question Answering,Yes.,1.,"""Recent advances in tabular question answering (QA) with large language models are constrained in their coverage and only answer questions over a single table."""
Long-Tailed Question Answering in an Open World,Yes.,1.,"""we define Open Long-Tailed QA (OLTQA) as learning from long-tailed distributed data and optimizing performance over seen and unseen QA tasks. We propose an OLTQA model that encourages knowledge sharing between head, tail and unseen tasks, and explicitly mines knowledge from a large pre-trained language model (LM)."""
Parallel Context Windows for Large Language Models,Yes.,5.,"""When applied to processing long text, Large Language Models (LLMs) are limited by their context window."""
Contrastive Learning with Adversarial Examples for Alleviating Pathology of Language Model,Yes.,5.,"""However, these models also suffer from the pathology of overconfidence in the out-of-distribution examples, potentially making the model difficult to interpret and making the interpretation methods fail to provide faithful attributions."""
FutureTOD: Teaching Future Knowledge to Pre-trained Language Model for Task-Oriented Dialogue,Yes.,3.,"""the intrinsical difference of linguistic patterns between general text and task-oriented dialogues makes existing pre-trained language models less useful in practice"" and ""Current dialogue pre-training methods rely on a contrastive framework and face the challenges of both selecting true positives and hard negatives."""
LAMBADA: Backward Chaining for Automated Reasoning in Natural Language,Yes.,3.,"""These techniques search for proofs in the forward direction from axioms to the conclusion, which suffers from a combinatorial explosion of the search space, and thus high failure rates for problems requiring longer chains of reasoning."""
SQuARe: A Large-Scale Dataset of Sensitive Questions and Acceptable Responses Created through Human-Machine Collaboration,Yes.,4.,"""The potential social harms that large language models pose, such as generating offensive content and reinforcing biases, are steeply rising."""
FLamE: Few-shot Learning from Natural Language Explanations,Yes.,3.,"""Yet, recent work by Lampinen et al. has shown limited utility of natural language explanations in improving classification."" and ""human evaluation surprisingly reveals that the majority of generated explanations does not adequately justify classification decisions."""
What social attitudes about gender does BERT encode? Leveraging insights from psycholinguistics,Yes.,3.,"""We find that the language model BERT takes into account factors that shape human lexical choice of such language, but may not weigh those factors in the same way people do."" and ""Such findings illuminate how a language model"
Are Experts Needed? On Human Evaluation of Counselling Reflection Generation,Yes.,1.,"""We also discover that GPT-3 mostly produces coherent and consistent reflections, and we explore changes in evaluation results when the source of synthetic reflections changes to GPT-3 from the less powerful GPT-2."""
When and how to paraphrase for named entity recognition?,Yes.,1.,"""We find that the choice of the paraphraser greatly impacts NER performance, with one of the larger GPT-3 variants exceedingly capable of generating high quality paraphrases, yielding statistically significant improvements in NER performance with increasing paraphrasing strength, while other paraphrasers show more mixed results."""
Are Machine Rationales (Not) Useful to Humans? Measuring and Improving Human Utility of Free-text Rationales,Yes.,4.,"""We observe that human utility of existing rationales is far from satisfactory and expensive to estimate with human studies. Existing metrics like task performance of the LM generating the rationales or similarity between generated and gold rationales are not good indicators of their human utility."""
Multi-Level Knowledge Distillation for Out-of-Distribution Detection in Text,Yes.,1.,"""These approaches either train a language model from scratch or fine-tune a pre-trained language model using ID examples, and then take the perplexity output by the language model as OoD scores."""
ByGPT5: End-to-End Style-conditioned Poetry Generation with Token-free Language Models,Yes.,1.,"""We identify and address lack of training data and mismatching tokenization algorithms as possible limitations of past attempts."""
Matching Pairs: Attributing Fine-Tuned Models to their Pre-Trained Large Language Models,Yes.,3.,"""However, this leads to issues over violation of model licenses, model theft, and copyright infringement. Moreover, recent advances show that generative technology is capable of producing harmful content which exacerbates the problems of accountability within model supply chains."""
Large Language Models Meet NL2Code: A Survey,Yes.,2.,"""In addition, we discuss challenges and opportunities regarding the gap between models and humans."""
DarkBERT: A Language Model for the Dark Side of the Internet,Yes.,1.,"""We describe the steps taken to filter and compile the text data used to train DarkBERT to combat the extreme lexical and structural diversity of the Dark Web that may be detrimental to building a proper representation of the domain."""
Are You Copying My Model? Protecting the Copyright of Large Language Models for EaaS via Backdoor Watermark,Yes.,3.,"""EaaS is vulnerable to model extraction attacks, which can cause significant losses for the owners of LLMs, as training these models is extremely expensive."""
RL4F: Generating Natural Language Feedback with Reinforcement Learning for Repairing Model Outputs,Yes.,4.,"""Despite their unprecedented success, even the largest language models make mistakes,"" and ""this approach does not apply to black-box or limited access models such as ChatGPT, as they cannot be fine-tuned. Moreover, in the era of large general-purpose language agents, fine-tuning"
DIP: Dead code Insertion based Black-box Attack for Programming Language Model,Yes.,3.,"""However, these PL models are vulnerable to adversarial examples that are generated with slight perturbation."""
Data Curation Alone Can Stabilize In-context Learning,Yes.,3.,"""ICL is very sensitive to the choice of training examples"
S2ynRE: Two-stage Self-training with Synthetic data for Low-resource Relation Extraction,Yes.,1.,"""We first leverage the capability of large language models to adapt to the target domain and automatically synthesize large quantities of coherent, realistic training data."""
DSEE: Dually Sparsity-embedded Efficient Tuning of Pre-trained Language Models,Yes.,3.,"""as the pre-trained models grow bigger (e.g., 175B parameters for GPT-3), even the fine-tuning process can be time-consuming and computationally expensive"" and ""the fine-tuned model has the same size as its starting point by default, which is neither sensible due to its more specialized functionality, nor practical since many fine-tuned models will be deployed in"
A New Dataset and Empirical Study for Sentence Simplification in Chinese,Yes.,1.,"""In the end, we explore whether Large Language Models can serve as high-quality Chinese sentence simplification systems by evaluating them on CSS."""
AD-KD: Attribution-Driven Knowledge Distillation for Language Model Compression,Yes.,3.,"""existing knowledge distillation methods suffer from two limitations. First, the student model simply imitates the teacher’s behavior while ignoring the reasoning behind it. Second, these methods usually focus on the transfer of sophisticated model-specific knowledge but overlook data-specific knowledge."""
Targeted Data Generation: Finding and Fixing Model Weaknesses,Yes.,4.,"""state-of-the-art NLP models often fail systematically on specific subgroups of data, resulting in unfair outcomes and eroding user trust."""
On “Scientific Debt” in NLP: A Case for More Rigour in Language Model Pre-Training Research,Yes.,5.,"""current PLM research practices often conflate different possible sources of model improvement, without conducting proper ablation studies and principled comparisons between different models under comparable conditions. These practices (i) leave us ill-equipped to understand which pre-training approaches should be used under what circumstances; (ii) impede reproducibility and credit assignment; and (iii) render it difficult to understand"
Element-aware Summarization with Large Language Models: Expert-aligned Evaluation and Chain-of-Thought Method,Yes.,1.,"""we observe the surprising zero-shot summary ability of LLMs, which addresses the issue of the inconsistent results between human preference and automatic evaluation metrics of LLMs’ zero-shot summaries in prior work."""
The CRINGE Loss: Learning what language not to model,Yes.,3.,"""Growing evidence shows that even with very large amounts of positive training data, issues remain that can be alleviated with relatively small amounts of negative data – examples of what the model should not do."""
"My side, your side and the evidence: Discovering aligned actor groups and the narratives they weave",Yes.,1.,"""With the help of Large Language Models (LLM), we address this task by"
WinoQueer: A Community-in-the-Loop Benchmark for Anti-LGBTQ+ Bias in Large Language Models,Yes.,5.,"""We apply our benchmark to several popular LLMs and find that off-the-shelf models generally do exhibit considerable anti-queer bias."""
Benchmarking Large Language Model Capabilities for Conditional Generation,Yes.,3.,"""Despite their ubiquitous use, the generation quality of language models is rarely evaluated when these models are introduced. Additionally, it is unclear how existing generation tasks–while they can be used to compare systems at a high level–relate to the real world use cases for which people have been adopting them."""
Searching for Needles in a Haystack: On the Role of Incidental Bilingualism in PaLM’s Translation Capability,Yes.,1.,"""We investigate the role of incidental bilingualism—the unintentional consumption of bilingual signals, including translation examples—in explaining the translation capabilities of large language models, taking the Pathways Language Model (PaLM) as a case study."""
I2D2: Inductive Knowledge Distillation with NeuroLogic and Self-Imitation,Yes.,3.,"""Commonsense capabilities of pre-trained language models dramatically improve with scale, leading many to believe that scale is the only winning recipe. But is it?"" and ""can smaller language models (e.g., GPT-2) win over models that are orders of magnitude larger and better (e.g., GPT-3), if powered with novel commonsense distillation algorithms?"""
When Not to Trust Language Models: Investigating Effectiveness of Parametric and Non-Parametric Memories,Yes.,5.,"""Despite their impressive performance on diverse tasks, large language models (LMs) still struggle with tasks requiring rich world knowledge, implying the difficulty of encoding a wealth of world knowledge in their parameters."" and ""We find that LMs struggle with less popular factual knowledge, and that retrieval augmentation helps significantly in these cases."" and ""Scaling, on the other hand, mainly improves memorization of"
SeeGULL: A Stereotype Benchmark with Broad Geo-Cultural Coverage Leveraging Generative Models,,,
Say What You Mean! Large Language Models Speak Too Positively about Negative Commonsense Knowledge,Yes.,5.,"""Our experiments reveal that LLMs frequently fail to generate valid sentences grounded in negative commonsense knowledge,"" and ""statistical shortcuts and negation reporting bias from language modeling pre-training cause this conflict."""
Cognitive Reframing of Negative Thoughts through Human-Language Model Interaction,Yes.,1.,"""Our findings provide key implications for the use of LMs to assist people in overcoming negative thoughts."""
Interleaving Retrieval with Chain-of-Thought Reasoning for Knowledge-Intensive Multi-Step Questions,,,
Improved Instruction Ordering in Recipe-Grounded Conversation,Yes.,3.,"""Analyzing the generated output of the GPT-J model, we reveal that the primary challenge for a recipe-grounded dialog system is how to provide the instructions in the correct order."" and ""we analyze its outputs and find that it also makes mistakes (10.7% of the responses), about half of which are out-of-order"
Token-wise Decomposition of Autoregressive Language Model Hidden States for Analyzing Model Predictions,Yes.,3.,"""the complex computations performed within each layer have made their behavior somewhat opaque"" and ""collocational association and repetitions of the same token largely explain the language models’ predictions on these tasks."""
Language Detoxification with Attribute-Discriminative Latent Space,Yes.,3.,"""Transformer-based Language Models (LMs) have achieved impressive results on natural language understanding tasks, but they can also generate toxic text such as insults, threats, and profanity, limiting their real-world applications."""
Revisiting Token Dropping Strategy in Efficient BERT Pretraining,Yes.,3.,"""Token dropping is prone to a semantic loss problem and falls short in handling semantic-intense tasks."""
Your spouse needs professional help: Determining the Contextual Appropriateness of Messages through Modeling Social Relationships,Yes.,1.,"""we show that large language models can readily incorporate relationship information to accurately identify appropriateness in a given context."""
How Do In-Context Examples Affect Compositional Generalization?,Yes.,5.,"""We find that the compositional generalization performance can be easily affected by the selection of in-context examples,"" and ""two strong limitations are observed"
Measuring Inductive Biases of In-Context Learning with Underspecified Demonstrations,Yes.,3.,"""the generalization behavior of ICL remains poorly understood"" and ""we find that, while many interventions can influence the learner to prefer a particular feature, it can be difficult to overcome strong prior biases."""
Introducing Semantics into Speech Encoders,Yes.,1.,"""Recent studies find existing self-supervised speech encoders contain primarily acoustic rather than semantic information. As a result, pipelined supervised automatic speech recognition (ASR) to large language model (LLM) systems achieve state-of-the-art results on semantic spoken language tasks by utilizing rich semantic representations from the LLM."""
SSD-LM: Semi-autoregressive Simplex-based Diffusion Language Model for Text Generation and Modular Control,Yes.,1.,"""Despite the growing success of diffusion models in continuous-valued domains (e.g., images), similar efforts for discrete domains such as text have yet to match the performance of autoregressive language models."""
"Recall, Expand, and Multi-Candidate Cross-Encode: Fast and Accurate Ultra-Fine Entity Typing",Yes.,1.,"""CE concatenates a mention (and its context) with each type and feeds the pair into a pretrained language model (PLM) to score their relevance."""
"Understanding Factual Errors in Summarization: Errors, Summarizers, Datasets, Error Detectors",Yes.,3.,"""Critically, our analysis shows that much of the recent improvement in the factuality detection space has been on summaries from older (pre-Transformer) models instead of more relevant recent summarization models."""
SLABERT Talk Pretty One Day: Modeling Second Language Acquisition with BERT,Yes.,1.,"""Our findings call for further research using our novel Transformer-based SLA models and we would like to encourage it by releasing our code, data, and models."""
Contrastive Novelty-Augmented Learning: Anticipating Outliers with Large Language Models,Yes.,3.,"""existing models are often overly confident on unseen classes."""
Rethinking the Role of Scale for In-Context Learning: An Interpretability-based Case Study at 66 Billion Scale,Yes.,3.,"""Overall, our study provides several insights that indicate large language models may be under-trained for in-context learning and opens up questions on how to pre-train language models to more effectively perform in-context learning."""
ESCOXLM-R: Multilingual Taxonomy-driven Pre-training for the Job Market Domain,Yes.,1.,"""In this study, we introduce a language model called ESCOXLM-R, based on XLM-R-large, which uses domain-adaptive pre-training on the European Skills, Competences, Qualifications and Occupations (ESCO) taxonomy, covering 27 languages."""
On the Blind Spots of Model-Based Evaluation Metrics for Text Generation,,,
Downstream Datasets Make Surprisingly Good Pretraining Corpora,Yes.,2.,"""These findings are especially relevant in light of concerns about intellectual property and offensive content in web-scale pretraining data."""
Contrastive Decoding: Open-ended Text Generation as Optimization,Yes.,5.,"""maximum probability is a poor decoding objective for open-ended generation, because it produces short and repetitive text. On the other hand, sampling can often produce incoherent text that drifts from the original topics."""
Self-Instruct: Aligning Language Models with Self-Generated Instructions,Yes.,2.,"""they depend heavily on human-written instruction data that is often limited in quantity, diversity, and creativity, therefore hindering the generality of the tuned model."""
CHBias: Bias Evaluation and Mitigation of Chinese Conversational Language Models,Yes.,4.,"""Pretrained conversational agents have been exposed to safety issues, exhibiting a range of stereotypical human biases such as gender bias."" and ""Experimental results show that these Chinese pretrained models are potentially risky for generating texts that contain social biases."""
Mitigating Label Biases for In-context Learning,Yes.,5.,"""domain-label bias restricts LLMs to random-level performance on many tasks regardless of the choice of in-context examples."""
LLM-Blender: Ensembling Large Language Models with Pairwise Ranking and Generative Fusion,Yes.,1.,"""Our framework consists of two modules"
Python Code Generation by Asking Clarification Questions,Yes.,3.,"""While recent pretrained language models demonstrate remarkable performance for this task, these models fail when the given natural language description is under-specified."""
Towards Benchmarking and Improving the Temporal Reasoning Capability of Large Language Models,Yes.,1.,"""we introduce a comprehensive probing dataset TempReason to evaluate the temporal reasoning capability of large language models."""
Large Language Models Are Reasoning Teachers,Yes.,3.,"""prompt-based CoT methods are dependent on very large models such as GPT-3 175B which are prohibitive to deploy at scale."""
Visually-augmented pretrained language models for NLP tasks without images,Yes.,3.,"""they are found lack of visual semantics or commonsense."""
FERMAT: An Alternative to Accuracy for Numerical Reasoning,Yes.,3.,"""While pre-trained language models achieve impressive performance on various NLP benchmarks, they still struggle with tasks that require numerical reasoning."" and ""Recent advances in improving numerical reasoning are mostly achieved using very large language models that contain billions of parameters and are not accessible to everyone."""
On Improving Summarization Factual Consistency from Natural Language Feedback,Yes.,3.,"""fine-tuned language models can leverage our dataset to improve the summary factual consistency, while large language models lack the zero-shot learning ability in our proposed tasks that require controllable text generation."""
From Dogwhistles to Bullhorns: Unveiling Coded Rhetoric with Language Models,Yes.,3.,"""We then assess whether a large language model (GPT-3) can identify dogwhistles and their meanings, and find that GPT-3’s performance varies widely across types of dogwhistles and targeted groups."""
CodeIE: Large Code Generation Models are Better Few-Shot Information Extractors,Yes.,3.,"""it is nontrivial to perform information extraction (IE) tasks with NL-LLMs since the output of the IE task is usually structured and therefore is hard to be converted into plain text."""
Prompting PaLM for Translation: Assessing Strategies and Performance,Yes.,3.,"""find that its performance, while impressive, still lags that of state-of-the-art supervised systems."""
Revisiting Relation Extraction in the era of Large Language Models,Yes.,1.,"""Here we push the limits of this approach, using larger language models (GPT-3 and Flan-T5 large) than considered in prior work and evaluating their performance on standard RE tasks under varying levels of supervision."""
Can Large Language Models Be an Alternative to Human Evaluations?,Yes.,3.,"""We are the first to show the potential of using LLMs to assess the quality of texts and discuss the limitations and ethical considerations of LLM evaluation."""
An Empirical Analysis of Parameter-Efficient Methods for Debiasing Pre-Trained Language Models,,,
XSemPLR: Cross-Lingual Semantic Parsing in Multiple Natural Languages and Meaning Representations,,,
LENS: A Learnable Evaluation Metric for Text Simplification,Yes.,1.,"""Training learnable metrics using modern language models has recently emerged as a promising method for the automatic evaluation of machine translation."""
"RARR: Researching and Revising What Language Models Say, Using Language Models",Yes.,5.,"""However, they sometimes generate unsupported or misleading content. A user cannot easily determine whether their outputs are trustworthy or not, because most LMs do not have any built-in mechanism for attribution to external evidence."""
Ellipsis-Dependent Reasoning: a New Challenge for Large Language Models,Yes.,5.,"""Test results show that the best models perform well on non-elliptical examples but struggle with all but the simplest ellipsis structures."""
Improving Generalization in Language Model-based Text-to-SQL Semantic Parsing: Two Simple Semantic Boundary-based Techniques,Yes.,3.,"""Compositional and domain generalization present significant challenges in semantic parsing, even for state-of-the-art semantic parsers based on pre-trained language models (LMs)."""
Language Models Get a Gender Makeover: Mitigating Gender Bias with Few-Shot Data Interventions,Yes.,4.,"""Societal biases present in pre-trained large language models are a critical issue as these models have been shown to propagate biases in countless downstream applications, rendering them unfair towards specific groups of people."""
Credible without Credit: Domain Experts Assess Generative Language Models,Yes.,3.,"""While we find the results are consistently cohesive and concise, we find that they are mixed in their accuracy. These results raise questions of the role language models should play in general-purpose and expert knowledge seeking."""
MetaVL: Transferring In-Context Learning Ability From Language Models to Vision-Language Models,Yes.,2.,"""However, in the vision-language domain, most large-scale pre-trained vision-language (VL) models do not possess the ability to conduct in-context learning."""
Probing Physical Reasoning with Counter-Commonsense Context,Yes.,5.,"""The results show that while large language models can use prepositions such as 'in' and 'into' in the provided context to infer size relationships, they fail to use verbs and thus make incorrect judgments led by their prior physical commonsense."""
In and Out-of-Domain Text Adversarial Robustness via Label Smoothing,Yes.,1.,"""Recently it has been shown that state-of-the-art NLP models are vulnerable to adversarial attacks, where the predictions of a model can be drastically altered by slight modifications to the input (such as synonym substitutions)."""
LM-CPPF: Paraphrasing-Guided Data Augmentation for Contrastive Prompt-Based Few-Shot Fine-Tuning,Yes.,1.,"""In recent years, there has been significant progress in developing pre-trained language models for NLP. However, these models often struggle when fine-tuned on small datasets."""
Exploring Continual Learning for Code Generation Models,Yes.,3.,"""re-training large-scale language models is computationally expensive"" and ""effective methods like Prompt Pooling (PP) suffer from catastrophic forgetting due to the unstable training of the prompt selection mechanism caused by stark distribution shifts in coding tasks."""
A Better Way to Do Masked Language Model Scoring,,,
ChatGPT for Zero-shot Dialogue State Tracking: A Solution or an Opportunity?,Yes.,3.,"""Despite our findings, we argue that properties inherent to general purpose models limit their ability to replace specialized systems."""
Controllable Mixed-Initiative Dialogue Generation through Prompting,Yes.,2.,"""these supervised generation models are limited by the cost and quality of data annotation."""
Trading Syntax Trees for Wordpieces: Target-oriented Opinion Words Extraction with Wordpieces and Aspect Enhancement,Yes.,3.,"""These methods achieve limited gains with GCNs and have difficulty using BERT wordpieces."""
Do GPTs Produce Less Literal Translations?,Yes.,2.,"""However, there has been relatively little investigation on how such translations differ qualitatively from the translations generated by standard Neural Machine Translation (NMT) models."""
Black-box language model explanation by context length probing,Yes.,2.,"""We apply context length probing to large pre-trained language models and offer some initial analyses and insights, including the potential for studying long-range dependencies."""
Latent Positional Information is in the Self-Attention Variance of Transformer Language Models Without Positional Embeddings,Yes.,1.,"""We further extend this inquiry by demonstrating that a randomly initialized and frozen transformer language model, devoid of positional embeddings, inherently encodes strong positional information through the shrinkage of self-attention variance."""
Towards Adaptive Prefix Tuning for Parameter-Efficient Language Model Fine-tuning,,,
Evaluating pragmatic abilities of image captioners on A3DS,Yes.,1.,"""Evaluating grounded neural language model performance with respect to pragmatic qualities like the trade off between truthfulness, contrastivity and overinformativity of generated utterances remains a challenge in absence of data collected from humans."""
"Summarizing, Simplifying, and Synthesizing Medical Evidence using GPT-3 (with Varying Success)",Yes.,5.,"""We find that while GPT-3 is able to summarize and simplify single biomedical articles faithfully, it struggles to provide accurate aggregations of findings over multiple documents."""
Discourse-Level Representations can Improve Prediction of Degree of Anxiety,Yes.,1.,"""evaluating the utility of discourse-level information in addition to lexical-level large language model embeddings."""
Controlling the Extraction of Memorized Data from Large Language Models via Prompt-Tuning,Yes.,5.,"""Large Language Models (LLMs) are known to memorize significant portions of their training data. Parts of this memorized content have been shown to be extractable by simply querying the model, which poses a privacy risk."""
MultiTool-CoT: GPT-3 Can Use Multiple External Tools with Chain of Thought Prompting,Yes.,1.,"""Large language models (LLMs) have achieved impressive performance on various reasoning tasks."""
S3HQA: A Three-Stage Approach for Multi-hop Text-Table Hybrid Question Answering,Yes.,1.,"""This includes two approaches"
AutoConv: Automatically Generating Information-seeking Conversations with Large Language Models,Yes.,1.,"""we propose AutoConv for synthetic conversation generation, which takes advantage of the few-shot learning ability and generation capacity of large language models (LLM)."""
A Simple and Effective Framework for Strict Zero-Shot Hierarchical Classification,Yes.,5.,"""these benchmarks often do not adequately address the challenges posed in the real-world, such as that of hierarchical classification. ... We observe LLMs are more prone to failure in these cases."""
Revisiting Automated Prompting: Are We Actually Doing Better?,Yes.,3.,"""We find that automated prompting does not consistently outperform simple manual prompting."""
Lingxi: A Diversity-aware Chinese Modern Poetry Generation System,Yes.,1.,"""we propose a novel sampling algorithm that flattens the high likelihood part of the predicted distribution of the language model to emphasize the comparatively low-likelihood words and increase the diversity of generated poetry."""
LIDA: A Tool for Automatic Generation of Grammar-Agnostic Visualizations and Infographics using Large Language Models,Yes.,1.,"""we pose visualization generation as a multi-stage generation problem and argue that well-orchestrated pipelines based on large language models (LLMs) and image generation models (IGMs) are suitable to addressing these tasks."""
Pipeline for modeling causal beliefs from natural language,Yes.,1.,"""We present a causal language analysis pipeline that leverages a Large Language Model to identify causal claims made in natural language documents, and aggregates claims across a corpus to produce a causal claim network."""
OpenICL: An Open-Source Framework for In-context Learning,Yes.,1.,"""In recent years, In-context Learning (ICL) has gained increasing attention and emerged as the new paradigm for large language model (LLM) evaluation."""
Petals: Collaborative Inference and Fine-tuning of Large Models,Yes.,3.,"""offloading is too slow for interactive inference, while APIs are not flexible enough for research that requires access to weights, attention or logits."""
ChatGPT vs Human-authored Text: Insights into Controllable Text Summarization and Sentence Style Transfer,,,
Making the Most Out of the Limited Context Length: Predictive Power Varies with Clinical Note Type and Note Section,Yes.,5.,"""when the context length for a language model predictor is limited, which part of clinical notes should we choose as the input?"""
Data Selection for Fine-tuning Large Language Models Using Transferred Shapley Values,Yes.,2.,"""dataset size and model complexity constraints limit the ability to apply Shapley-based data valuation to fine-tuning large pre-trained language models."""
Moral Mimicry: Large Language Models Produce Moral Rationalizations Tailored to Political Identity,Yes.,2.,"""Large Language Models (LLMs) have demonstrated impressive capabilities in generating fluent text, as well as tendencies to reproduce undesirable social biases."""
Authorship Attribution of Late 19th Century Novels using GAN-BERT,No.,1.,The paper does not discuss LLMs or their limitations.
Semantic Accuracy in Natural Language Generation: A Thesis Proposal,Yes.,2.,"""We propose a novel method for evaluating semantic accuracy and discuss the importance of working towards a unified and objective benchmark for NLG metrics. We also review interpretability approaches which could help us pinpoint the sources of inaccuracies within the models and explore potential mitigation strategies."""
CWSeg: An Efficient and General Approach to Chinese Word Segmentation,Yes.,3.,"""The pre-trained language model (PLM) based segmentation methods have achieved state-of-the-art (SOTA) performance, whereas this paradigm also poses challenges in the deployment. It includes the balance between performance and cost, segmentation ambiguity due to domain diversity and vague words boundary, and multi-grained segmentation."""
MathPrompter: Mathematical Reasoning using Large Language Models,Yes.,5.,"""Large Language Models (LLMs) have limited performance when solving arithmetic reasoning tasks and often provide incorrect answers."" and ""To the best of our knowledge, we are not aware of any LLMs that indicate their level of confidence in their responses which fuels a trust deficit in these models impeding their adoption."""
GKD: A General Knowledge Distillation Framework for Large-scale Pre-trained Language Model,Yes.,3.,"""the deployment of knowledge distillation systems faces great challenges in real-world industrial-strength applications, which require the use of complex distillation methods on even larger-scale PLMs (over 10B), limited by memory on GPUs and the switching of methods."""
KoSBI: A Dataset for Mitigating Social Bias Risks Towards Safer Large Language Model Applications,Yes.,5.,"""Large language models (LLMs) not only learn natural text generation abilities but also social biases against different demographic groups from real-world data. This poses a critical risk when deploying LLM-based applications."" and ""This limitation requires localized social bias datasets to ensure the safe and effective deployment of LLMs."""
The economic trade-offs of large language models: A case study,Yes.,2.,"""However, their efficacy must be balanced with the cost of training and serving them."""
Boosting Transformers and Language Models for Clinical Prediction in Immunotherapy,Yes.,1.,"""The study benchmarks the efficacy of baselines and language models on prognostic prediction across multiple cancer types and investigates the impact of different pretrained language models under few-shot regimes."""
A Static Evaluation of Code Completion by Large Language Models,Yes.,4.,"""Our static analysis reveals that Undefined Name and Unused Variable are the most common errors among others made by language models."""
SaFER: A Robust and Efficient Framework for Fine-tuning BERT-based Classifier with Noisy Labels,,,
"Sharing Encoder Representations across Languages, Domains and Tasks in Large-Scale Spoken Language Understanding",Yes.,2.,"""Larger encoders can improve accuracy for spoken language understanding (SLU) but are challenging to use given the inference latency constraints of online systems (especially on CPU machines)."""
Exploring Zero and Few-shot Techniques for Intent Classification,Yes.,1.,"""zero-shot intent classification using descriptions large language models (LLMs)"" and ""parameter-efficient fine-tuning of instruction-finetuned language models."""
Complex Reasoning in Natural Language,,,
"Everything you need to know about Multilingual LLMs: Towards fair, performant and reliable models for languages of the world",Yes.,4.,"""Responsible AI issues such as fairness, bias and toxicity, linguistic diversity and evaluation in the context of MMLMs, specifically focusing on issues in non-English and low-resource languages."""
Generating Text from Language Models,,,
