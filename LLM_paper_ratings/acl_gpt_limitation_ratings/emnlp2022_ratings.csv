Title,Talks about LLMs,Rate,Evidence
RankGen: Improving Text Generation with Large Ranking Models,Yes.,5,"""modern language models often assign high probabilities to output sequences that are repetitive, incoherent, or irrelevant to the prefix; as such, model-generated text also contains such artifacts."""
"Tomayto, Tomahto. Beyond Token-level Answer Equivalence for Question Answering Evaluation",No.,1,The abstract does not mention LLMs or their limitations. It focuses on the evaluation of QA systems and the shortcomings of token-level equivalence measures.
UnifiedSKG: Unifying and Multi-Tasking Structured Knowledge Grounding with Text-to-Text Language Models,Yes.,3,"""we show that T0, GPT-3, and Codex struggle in zero-shot and few-shot learning for SKG."""
DocInfer: Document-level Natural Language Inference using Optimal Evidence Selection,Yes.,3,"""Our evidence selection mechanism allows it to transcend the input length limitation of modern BERT-like Transformer models while presenting the entire evidence together for inferential reasoning."""
Entity Extraction in Low Resource Domains with Selective Pre-training of Large Language Models,Yes.,3,"""Transformer-based language models trained on large natural language corpora have been very useful in downstream entity extraction tasks. However, they often result in poor performances when applied to domains that are different from those they are pretrained on."""
How Large Language Models are Transforming Machine-Paraphrase Plagiarism,Yes.,2,"""The recent success of large language models for text generation poses a severe threat to academic integrity, as plagiarists can generate realistic paraphrases indistinguishable from original work."""
ELMER: A Non-Autoregressive Pre-trained Language Model for Efficient and Effective Text Generation,,,
Z-LaVI: Zero-Shot Language Solver Fueled by Visual Imagination,Yes.,3,"""However, they generally suffer from reporting bias, the phenomenon describing the lack of explicit commonsense knowledge in written text, e.g., 'an orange is orange'."""
Generative Multi-hop Retrieval,Yes.,3,"""However, such a bi-encoder approach has limitations in multi-hop settings; (1) the reformulated query gets longer as the number of hops increases, which further tightens the embedding bottleneck of the query vector, and (2) it is prone to error propagation."""
Extracted BERT Model Leaks More Information than You Think!,Yes.,3,"""Our extensive experiments reveal that model extraction can cause severe privacy leakage even when victim models are facilitated with state-of-the-art defensive strategies."""
An Empirical Analysis of Memorization in Fine-tuned Autoregressive Language Models,Yes.,5,"""Large language models are shown to present privacy risks through memorization of training data,"" and ""we empirically study memorization of fine-tuning methods using membership inference and extraction attacks, and show that their susceptibility to attacks is very different."""
EvEntS ReaLM: Event Reasoning of Entity States via Language Models,Yes.,5,"""Nominally, Large Language models (LLM) have been exposed to procedural knowledge about how objects interact, yet our benchmarking shows they fail to reason about the world."""
Large language models are few-shot clinical information extractors,Yes.,1,"""large language models, such as InstructGPT (Ouyang et al., 2022), perform well at zero- and few-shot information extraction from clinical text despite not being trained specifically for the clinical domain."""
Are Hard Examples also Harder to Explain? A Study with Human and Model-Generated Explanations,Yes.,3,"""for hard examples, human explanations are significantly better than GPT-3 explanations both in terms of label-supportiveness and generalizability judgements."""
Gradient-based Constrained Sampling from Language Models,Yes.,3,"""Large pretrained language models are successful at generating fluent text but are notoriously hard to controllably sample from."""
Rich Knowledge Sources Bring Complex Knowledge Conflicts: Recalibrating Models to Reflect Conflicting Evidence,Yes.,5,"""we simulate knowledge conflicts (i.e., where parametric knowledge suggests one answer and different passages suggest different answers) and examine model behaviors"" and ""contradictions among knowledge sources affect model confidence only marginally."""
SafeText: A Benchmark for Exploring Physical Safety in Language Models,Yes.,5,"""We find that state-of-the-art large language models are susceptible to the generation of unsafe text and have difficulty rejecting unsafe advice."""
Language Model Decomposition: Quantifying the Dependency and Correlation of Language Models,Yes.,2,"""To further advance SOTA we need more diverse and novel LMs that are less dependent on existing LMs."""
Calibrating Zero-shot Cross-lingual (Un-)structured Predictions,Yes.,3,"""We find that models trained with data from the source language become less calibrated when applied to the target language and that calibration errors increase with intrinsic task difficulty and relative sparsity of training data."""
Fast-R2D2: A Pretrained Recursive Neural Network based on Pruned CKY for Grammar Induction and Text Representation,,,
Memory-assisted prompt editing to improve GPT-3 after deployment,Yes.,5,"""Large LMs such as GPT-3 are powerful, but can commit mistakes that are obvious to humans."""
ROSE: Robust Selective Fine-tuning for Pre-trained Language Models,Yes.,3,"""Even though the large-scale language models have achieved excellent performances, they suffer from various adversarial attacks. A large body of defense methods has been proposed. However, they are still limited due to redundant attack search spaces and the inability to defend against various types of attacks."""
Reproducibility Issues for BERT-based Evaluation Metrics,Yes.,3,"""We find that reproduction of claims and results often fails because of (i) heavy undocumented preprocessing involved in the metrics, (ii) missing code and (iii) reporting weaker results for the baseline metrics."""
Generative Entity Typing with Curriculum Learning,Yes.,3,"""PLMs tend to generate coarse-grained types after fine-tuning upon the entity typing dataset."""
Revisiting Pre-trained Language Models and their Evaluation for Arabic Natural Language Processing,Yes.,2,"""This work addresses two major problems in existing Arabic PLMs that limit the progress of the Arabic NLU and NLG fields."""
Nearest Neighbor Zero-Shot Inference,Yes.,1,"""Retrieval-augmented language models (LMs) use non-parametric memory to substantially outperform their non-retrieval counterparts on perplexity-based evaluations, but it is an open question whether they achieve similar gains in few- and zero-shot end-task accuracy."""
RLPrompt: Optimizing Discrete Text Prompts with Reinforcement Learning,Yes.,2,"""Interestingly, the resulting optimized prompts are often ungrammatical gibberish text; and surprisingly, those gibberish prompts are transferrable between different LMs to retain significant performance, indicating that LM prompting may not follow human language patterns."""
BERTScore is Unfair: On Social Bias in Language Model-Based Metrics for Text Generation,Yes.,4,"""However, it has been demonstrated that PLMs encode a range of stereotypical societal biases, leading to a concern about the fairness of PLMs as metrics."" and ""We demonstrate that popular PLM-based metrics exhibit significantly higher social bias than traditional metrics on 6 sensitive attributes,"
HPT: Hierarchy-aware Prompt Tuning for Hierarchical Text Classification,Yes.,3,"""there exists a huge gap between the classification tasks with sophisticated label hierarchy and the masked language model (MLM) pretraining tasks of PLMs and thus the potential of PLMs cannot be fully tapped."""
Neural Theory-of-Mind? On the Limits of Social Intelligence in Large LMs,Yes.,5,"""We show that one of todayâ€™s largest language models (GPT-3; Brown et al., 2020) lacks this kind of social intelligence out-of-the box,"" and ""Our results show that models struggle substantially at these Theory of Mind tasks,"" and ""we"
Improving Temporal Generalization of Pre-trained Language Models with Lexical Semantic Change,Yes.,5,"""neural language models at scale suffer from poor temporal generalization capability"" and ""language model pre-trained on static data from past years performs worse over time on emerging data."""
Perturbation Augmentation for Fairer NLP,Yes.,4,"""Unwanted and often harmful social biases are becoming ever more salient in NLP research, affecting both models and datasets,"" and ""Lastly, we discuss outstanding questions about how best to evaluate the (un)fairness of large language models."""
"The better your Syntax, the better your Semantics? Probing Pretrained Language Models for the English Comparative Correlative",Yes.,5,"""Our results show that all three investigated PLMs are able to recognise the structure of the CC but fail to use its meaning. While human-like performance of PLMs on many NLP tasks has been alleged, this indicates that PLMs still suffer from substantial shortcomings in central domains of linguistic knowledge."""
Is a Question Decomposition Unit All We Need?,Yes.,2,"""building new LMs may not be an ideal option owing to the cost, time and environmental impact associated with it."""
SLING: Sino Linguistic Evaluation of Large Language Models,Yes.,3,"""Our experiments show that the average accuracy for LMs is far below human performance (69.7% vs. 97.1%),"" and ""we find that most LMs have a strong gender and number (singular/plural) bias, and they perform better on local phenomena than hierarchical ones."""
Differentially Private Language Models for Secure Data Sharing,Yes.,3,"""In practice, these approaches are often dissatisfying in terms of the quality of their output language due to the strong noise required for local differential privacy."""
LittleBird: Efficient Faster & Longer Transformer for Question Answering,Yes.,5,"""But it has a limitation dealing with long inputs due to its attention mechanism."""
PLOG: Table-to-Logic Pretraining for Logical Table-to-Text Generation,,,
Rethinking the Authorship Verification Experimental Setups,No.,1,The abstract does not mention LLMs or any other language models.
Invariant Language Modeling,Yes.,5,"""Yet, they suffer from spurious correlations, poor out-of-domain generalization, and biases."""
InforMask: Unsupervised Informative Masking for Language Model Pretraining,,,
Mutual Information Alleviates Hallucinations in Abstractive Summarization,Yes.,5,"""these models still exhibit the tendency to hallucinate, i.e., output content not supported by the source document."""
Fine-tuned Language Models are Continual Learners,,,
Bernice: A Multilingual Pre-trained Encoder for Twitter,Yes.,1,"""The language of Twitter differs significantly from that of other domains commonly included in large language model training."""
Just Fine-tune Twice: Selective Differential Privacy for Large Language Models,Yes.,3,"""applying differential privacy (DP), a canonical notion with provable privacy guarantees for machine learning models, to those models remains challenging due to the trade-off between model utility and privacy loss."""
Textual Manifold-based Defense Against Natural Language Adversarial Examples,Yes.,3,"""Despite the recent success of large pretrained language models in NLP, they are susceptible to adversarial examples."""
FLUTE: Figurative Language Understanding through Textual Explanations,Yes.,1,"""We show how utilizing GPT-3 in conjunction with human annotators (novices and experts) can aid in scaling up the creation of datasets even for such complex linguistic phenomena as figurative language."""
One size does not fit all: Investigating strategies for differentially-private learning across NLP tasks,Yes.,2,"""stricter privacy guarantees in differentially-private stochastic gradient descent (DP-SGD) generally degrade model performance."""
Tutoring Helps Students Learn Better: Improving Knowledge Distillation for BERT with Tutor Network,Yes.,3,"""typical KD approaches for language models have overlooked the difficulty of training examples, suffering from incorrect teacher prediction transfer and sub-efficient training."""
Multitask Instruction-based Prompting for Fallacy Recognition,Yes.,1,"""we approach these differences across datasets as multiple tasks and show how instruction-based prompting in a multitask setup based on the T5 model improves the results against approaches built for a specific dataset such as T5, BERT or GPT-3."""
Towards Table-to-Text Generation with Pretrained Language Model: A Table Structure Understanding and Text Deliberating Approach,Yes.,3,"""Although remarkable progress on the neural table-to-text methods has been made, the generalization issues hinder the applicability of these models due to the limited source tables."" and ""However, how to effectively bridge the gap between the structured table and the text input by fully leveraging table information to fuel the pretrained model is still not well explored."""
Rainier: Reinforced Knowledge Introspector for Commonsense Question Answering,Yes.,3,"""knowledge retrieved from knowledge bases are incomplete and knowledge generated from language models are inconsistent."""
Few-shot Learning with Multilingual Generative Language Models,Yes.,3,"""their training data is dominated by English, potentially limiting their cross-lingual generalization."""
Active Example Selection for In-Context Learning,Yes.,3,"""We demonstrate that in-context learning performance can be highly unstable across samples of examples, indicating the idiosyncrasies of how language models acquire information."" and ""However, the improvement diminishes on larger GPT-3 models, suggesting emerging capabilities of large language models."""
Evaluating the Impact of Model Scale for Compositional Generalization in Semantic Parsing,Yes.,5,"""Despite their strong performance on many tasks, pre-trained language models have been shown to struggle on out-of-distribution compositional generalization."" and ""Overall, our study highlights limitations of current techniques for effectively leveraging model scale for compositional generalization, while our analysis also suggests promising directions for future work."""
Improving Large-scale Paraphrase Acquisition and Generation,Yes.,1,"""the best pre-trained language model fine-tuned on our dataset achieves the state-of-the-art performance of 84.2 F1 for automatic paraphrase identification."""
Entropy- and Distance-Based Predictors From GPT-2 Attention Patterns Predict Reading Times Over and Above GPT-2 Surprisal,Yes.,1,"""Transformer-based large language models are trained to make predictions about the next word by aggregating representations of previous tokens through their self-attention mechanism."""
"Learning Cross-Task Dependencies for Joint Extraction of Entities, Events, Event Arguments, and Relations",,,
Correcting Diverse Factual Errors in Abstractive Summarization via Post-Editing and Language Model Infilling,Yes.,3,"""Abstractive summarization models often generate inconsistent summaries containing factual errors or hallucinated content."""
Fine-Tuning Pre-trained Transformers into Decaying Fast Weights,Yes.,3,"""Autoregressive Transformers are strong language models but incur O(T) complexity during per-token generation due to the self-attention mechanism."""
Adapting a Language Model While Preserving its General Knowledge,Yes.,3,"""However, existing DA-training methods are in some sense blind as they do not explicitly identify what knowledge in the LM should be preserved and what should be changed by the domain corpus."""
Continual Training of Language Models for Few-Shot Learning,Yes.,1,"""This paper proposes the problem of continually extending an LM by incrementally post-train the LM with a sequence of unlabeled domain corpora to expand its knowledge without forgetting its previous skills."""
Graph-Induced Transformers for Efficient Multi-Hop Question Answering,Yes.,3,"""Previous approaches to MHQA relied on leveraging the graph information along with the pre-trained language model (PLM) encoders. However, this trend exhibits the following drawbacks"
Pneg: Prompt-based Negative Response Generation for Dialogue Response Selection Task,Yes.,1,"""To overcome these limitations, this paper proposes a simple but efficient method for generating adversarial negative responses leveraging a large-scale language model."""
Neighborhood Contrastive Learning for Scientific Document Representations with Citation Embeddings,Yes.,1,"""Furthermore, we demonstrate that it can train (or tune) language models sample-efficiently and that it can be combined with recent training-efficient methods."""
A Systematic Investigation of Commonsense Knowledge in Large Language Models,Yes.,5,"""Our findings highlight the limitations of pre-trained LMs in acquiring commonsense knowledge without task-specific supervision; furthermore, using larger models or few-shot evaluation is insufficient to achieve human-level commonsense performance."""
SEAL: Interactive Tool for Systematic Error Analysis and Labeling,Yes.,5,"""However, many times these models systematically fail on tail data or rare groups not obvious in aggregate evaluation."""
Knowledge Distillation Transfer Sets and their Impact on Downstream NLU Tasks,Yes.,2,"""the generic corpora used to pretrain the teacher and the corpora associated with the downstream target domain are often significantly different, which raises a natural question"
Grafting Pre-trained Models for Multimodal Headline Generation,Yes.,3,"""A major challenge in simply gluing language model and video-language model is the modality balance, which is aimed at combining visual-language complementary abilities."""
QUILL: Query Intent with Large Language Models using Retrieval Augmentation and Multi-stage Distillation,Yes.,3,"""Search queries though pose a unique challenge, given their short-length and lack of nuance or context. Complicated feature engineering efforts do not always lead to downstream improvements as their performance benefits may be offset by increased complexity of knowledge distillation."""
