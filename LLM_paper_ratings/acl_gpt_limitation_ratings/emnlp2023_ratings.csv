Title,Talks about LLMs,Rate,Evidence
IAG: Induction-Augmented Generation Framework for Answering Reasoning Questions,Yes.,2,"""common knowledge bases are inherently constrained by limited coverage and noisy information, making retrieval-based approaches inadequate to answer implicit reasoning questions."""
Primacy Effect of ChatGPT,Yes.,5,"""ChatGPT’s decision is sensitive to the order of labels in the prompt; ChatGPT has a clearly higher chance to select the labels at earlier positions as the answer."""
Evaluating the Rationale Understanding of Critical Reasoning in Logical Reading Comprehension,Yes.,5,"""Experiments on our dataset show that recent large language models (e.g., InstructGPT) struggle to answer the subquestions even if they are able to answer the main questions correctly. We find that the models perform particularly poorly in answering subquestions written for the incorrect options"
Theory of Mind for Multi-Agent Collaboration via Large Language Models,Yes.,5,"""Our results reveal limitations in LLM-based agents’ planning optimization due to systematic failures in managing long-horizon contexts and hallucination about the task state."""
Establishing Trustworthiness: Rethinking Tasks and Model Evaluation,Yes.,2,"""the traditional compartmentalized notion of language tasks is breaking down, followed by an increasing challenge for evaluation and analysis."""
GPTAraEval: A Comprehensive Evaluation of ChatGPT on Arabic NLP,Yes.,5,"""our work adds to a growing body of research underscoring the limitations of ChatGPT."""
Evaluating Object Hallucination in Large Vision-Language Models,,,
Parameter-efficient Tuning for Large Language Model without Calculating Its Gradients,Yes.,3,"""Fine-tuning all parameters of large language models (LLMs) requires significant computational resources and is time-consuming."" and ""However, they can only save approximately 30% of the training memory requirements, due to the problem that gradient computation and backpropagation are still necessary for these methods."""
CompoundPiece: Evaluating and Improving Decompounding Performance of Language Models,Yes.,5,"""We find that LLMs perform poorly, especially on words which are tokenized unfavorably by subword tokenization."""
How to Enhance Causal Discrimination of Utterances: A Case on Affective Reasoning,Yes.,3,"""Almost all existing models, including large language models (LLMs), excel at capturing semantic correlations within utterance embeddings but fall short in determining the specific causal relationships."""
Temporal Knowledge Graph Forecasting Without Knowledge Using In-Context Learning,Yes.,1,"""We observe that naive LLMs perform on par with SOTA models,"" and ""Our analysis also reveals that ICL enables LLMs to learn irregular patterns from the historical context, going beyond frequency and recency biases."""
Knowledge Graph Compression Enhances Diverse Commonsense Generation,Yes.,3,"""the extracted subgraphs may contain loosely related, redundant and irrelevant information, which can introduce noise into the model."" and ""our model achieves better quality-diversity tradeoff than a large language model with 100 times the number of parameters."""
LLM-FP4: 4-Bit Floating-Point Quantized Transformers,Yes.,1,"""We propose LLM-FP4 for quantizing both weights and activations in large language models (LLMs) down to 4-bit floating-point values, in a post-training manner."""
LLM-powered Data Augmentation for Enhanced Cross-lingual Performance,Yes.,3,"""LLMs such as ChatGPT and GPT-4 excel at producing natural and coherent text in most languages, however, they struggle to generate meaningful text in certain languages like Tamil"" and ""ChatGPT falls short in generating plausible alternatives compared to the original dataset."""
Conceptual structure coheres in human cognition but not in large language models,Yes.,5,"""Structures estimated from the LLM behavior, while individually fairly consistent with those estimated from human behavior, depend much more upon the particular task used to generate behavior responses–responses generated by the very same model in the three tasks yield estimates of conceptual structure that cohere less with one another than do human structure"
Towards LLM-driven Dialogue State Tracking,Yes.,5,"""Despite its impressive performance, ChatGPT has significant limitations including its closed-source nature, request restrictions, raising data privacy concerns, and lacking local deployment capabilities."""
We’re Afraid Language Models Aren’t Modeling Ambiguity,Yes.,5,"""We find that the task remains extremely challenging, including for GPT-4, whose generated disambiguations are considered correct only 32% of the time in crowdworker evaluation, compared to 90% for disambiguations in our dataset."""
"Reading Books is Great, But Not if You Are Driving! Visually Grounded Reasoning about Defeasible Commonsense Norms",Yes.,3,"""We find that state-of-the-art model judgments and explanations are not well-aligned with human annotation."""
Enhancing Uncertainty-Based Hallucination Detection with Stronger Focus,Yes.,5,"""However, LLMs are prone to hallucinate untruthful or nonsensical outputs that fail to meet user expectations in many real-world applications."""
Tree of Clarifications: Answering Ambiguous Questions with Retrieval-Augmented Large Language Models,Yes.,1,"""considering multiple dimensions of ambiguity and gathering corresponding knowledge remains a challenge."""
Large Language Models Can Self-Improve,Yes.,3,"""fine-tuning an LLM requires extensive supervision."""
CodeT5+: Open Code Large Language Models for Code Understanding and Generation,Yes.,5,"""However, existing code LLMs have two main limitations. First, they often adopt a specific architecture (encoder-only or decoder-only) or rely on a unified encoder-decoder network for different downstream tasks, lacking the flexibility to operate in the optimal architecture for a specific task. Secondly, they often employ a limited set of pretraining objectives which might not be relevant to some tasks and"
SeqXGPT: Sentence-Level AI-Generated Text Detection,Yes.,2,"""raising concerns about the abuse of LLMs"" and ""Current works only consider document-level AIGT detection."""
QTSumm: Query-Focused Summarization over Tabular Data,,,
Towards Robust Pruning: An Adaptive Knowledge-Retention Pruning Strategy for Language Models,Yes.,3,"""Despite this, existing methods struggle to enhance robustness against adversarial attacks when continually increasing model sparsity."""
Unveiling the Implicit Toxicity in Large Language Models,Yes.,5,"""We show that LLMs can generate diverse implicit toxic outputs that are exceptionally difficult to detect via simply zero-shot prompting,"" and ""Our findings suggest that LLMs pose a significant threat in generating undetectable implicit toxic outputs."""
Is ChatGPT a General-Purpose Natural Language Processing Task Solver?,Yes.,2,"""With extensive empirical studies, we demonstrate both the effectiveness and limitations of the current version of ChatGPT."""
ALCUNA: Large Language Models Meet New Knowledge,Yes.,5,"""We benchmark several LLMs, reveals that their performance in face of new knowledge is not satisfactory, particularly in reasoning between new and internal knowledge."""
Transcending Scaling Laws with 0.1% Extra Compute,Yes.,1,"""Scaling language models improves performance but comes with significant computational costs."""
CoAnnotating: Uncertainty-Guided Work Allocation between Human and Large Language Models for Data Annotation,Yes.,2,"""However, limited work has leveraged LLMs as complementary annotators, nor explored how annotation work is best allocated among humans and LLMs to achieve both quality and cost objectives."""
Robust Prompt Optimization for Large Language Models Against Distribution Shifts,Yes.,5,"""We reveal that these prompt optimization techniques are vulnerable to distribution shifts such as subpopulation shifts, which are common for LLMs in real-world scenarios such as customer reviews analysis."""
Increasing Coverage and Precision of Textual Information in Multilingual Knowledge Graphs,Yes.,3,"""demonstrate that state-of-the-art methods, namely, Machine Translation (MT), Web Search (WS), and Large Language Models (LLMs), struggle with this task."""
Interpreting Embedding Spaces by Conceptualization,Yes.,4,"""One major drawback of this type of representation is their incomprehensibility to humans."" and ""Understanding the embedding space is crucial for several important needs, including the need to debug the embedding method and compare it to alternatives, and the need to detect biases hidden in the model."""
Knowledge-Augmented Language Model Verification,Yes.,5,"""Yet, LMs often generate the factually incorrect responses to the given queries, since their knowledge may be inaccurate, incomplete, and outdated."" and ""the model may fail to retrieve the knowledge relevant to the given query, or the model may not faithfully reflect the retrieved knowledge in the generated text."""
Failures Pave the Way: Enhancing Large Language Models through Tuning-free Rule Accumulation,Yes.,5,"""However, due to their inability to capture relationships among samples, these frozen LLMs inevitably keep repeating similar mistakes."""
Active Instruction Tuning: Improving Cross-Task Generalization by Training on Prompt Sensitive Tasks,Yes.,1,"""Instruction tuning (IT) achieves impressive zero-shot generalization results by training large language models (LLMs) on a massive amount of diverse tasks with instructions."""
“Fifty Shades of Bias”: Normative Ratings of Gender Bias in GPT Generated English Text,Yes.,4,"""With LLMs increasingly gaining human-like fluency in text generation, gaining a nuanced understanding of the biases these systems can generate is imperative."""
ChatGPT to Replace Crowdsourcing of Paraphrases for Intent Classification: Higher Diversity and Comparable Model Robustness,Yes.,1,"""The emergence of generative large language models (LLMs) raises the question"
Democratizing Reasoning Ability: Tailored Learning from Large Language Model,Yes.,3,"""LLMs exhibit impressive emergent abilities in natural language processing, but their democratization is hindered due to huge computation requirements and closed-source nature."""
OpenAsp: A Benchmark for Multi-document Open Aspect-based Summarization,Yes.,1,"""we show that the realistic open-aspect setting realized in OpenAsp poses a challenge for current state-of-the-art summarization models, as well as for large language models."""
Self-Influence Guided Data Reweighting for Language Model Pre-training,Yes.,3,"""Once the pre-training corpus has been assembled, all data samples in the corpus are treated with equal importance during LM pre-training. However, due to varying levels of relevance and quality of data, equal importance to all the data samples may not be the optimal choice."""
TrueTeacher: Learning Factual Consistency Evaluation with Large Language Models,,,
Larger Probes Tell a Different Story: Extending Psycholinguistic Datasets Via In-Context Learning,Yes.,3,"""We evaluate 22 models on the extended datasets, seeing model performance dip 20-57% compared to the original smaller benchmarks."" and ""Finally, we observe that while GPT3 has generated all the examples in ROLE-1500 is only able to solve 24.6% of them during probing."""
MAGNIFICo: Evaluating the In-Context Learning Ability of Large Language Models to Generalize to Novel Interpretations,Yes.,4,"""LLMs have a knowledge cutoff and are costly to finetune repeatedly"" and ""our findings also highlight the need for further improvements, particularly when interpreting unfamiliar words or when composing multiple novel interpretations simultaneously in the same example."""
Generating and Evaluating Tests for K-12 Students with Language Model Simulations: A Case Study on Sentence Reading Efficiency,Yes.,1,"""To generate high-quality parallel tests, we propose to fine-tune large language models (LLMs) to simulate how previous students would have responded to unseen items."""
Counter Turing Test (CT2): AI-Generated Text Detection is Not as Easy as You May Think - Introducing AI Detectability Index (ADI),Yes.,3,"""Our empirical findings unequivocally highlight the fragility of the proposed AGTD methods under scrutiny."""
Instructed Language Models with Retrievers Are Powerful Entity Linkers,Yes.,5,"""the generative nature still makes the generated content suffer from hallucinations, thus unsuitable for entity-centric tasks like entity linking (EL) requiring precise entity predictions over a large knowledge base."" and ""the EL task remains a persistent hurdle for general LLMs."""
Does the Correctness of Factual Knowledge Matter for Factual Knowledge-Enhanced Pre-trained Language Models?,Yes.,5,"""Surprisingly, throughout our experiments, we find that although the knowledge seems to be successfully injected, the correctness of injected knowledge only has a very limited effect on the models’ downstream performance. This finding strongly challenges previous assumptions that the injected factual knowledge is the key for language models to achieve performance improvements on downstream tasks in pretrain-finetune paradigm."""
"The Past, Present and Better Future of Feedback Learning in Large Language Models for Subjective Human Preferences and Values",Yes.,4,"""it is unclear how to collect and incorporate feedback in a way that is efficient, effective and unbiased, especially for highly subjective human preferences and values"" and ""we encourage a better future of feedback learning in LLMs by raising five unresolved conceptual and practical challenges."""
TempTabQA: Temporal Question Answering for Semi-Structured Tables,,,
Task-Level Thinking Steps Help Large Language Models for Challenging Classification Task,Yes.,3,"""the distribution of demonstrations can severely affect the performance, especially for challenging classification tasks."""
G-Eval: NLG Evaluation using Gpt-4 with Better Human Alignment,Yes.,3,"""these LLM-based evaluators still have lower human correspondence than medium-size neural evaluators"" and ""highlight the potential concern of LLM-based evaluators having a bias towards the LLM-generated texts."""
"The Troubling Emergence of Hallucination in Large Language Models - An Extensive Definition, Quantification, and Prescriptive Remediations",Yes.,5,"""the issue of hallucination has parallelly emerged as a by-product, posing significant concerns"" and ""we propose two solution strategies for mitigating hallucinations."""
Improving Summarization with Human Edits,Yes.,1,"""Existing works use human feedback to train large language models (LLMs) in general domain abstractive summarization and have obtained summary quality exceeding traditional likelihood training."""
The Skipped Beat: A Study of Sociopragmatic Understanding in LLMs for 64 Languages,Yes.,5,"""Our comprehensive analysis reveals that existing open-source instruction tuned LLMs still struggle to understand SM across various languages, performing close to a random baseline in some cases. We also find that although ChatGPT outperforms many LLMs, it still falls behind task-specific finetuned models with a gap of 12.19 SPARROW score."""
Understanding the Effect of Model Compression on Social Bias in Large Language Models,Yes.,4,"""Large Language Models (LLMs) trained with self-supervision on vast corpora of web text fit to the social biases of that text. Without intervention, these social biases persist in the model’s predictions in downstream tasks, leading to representational harm."""
BioPlanner: Automatic Evaluation of LLMs on Protocol Planning in Biology,Yes.,,
Cross-lingual Prompting: Improving Zero-shot Chain-of-Thought Reasoning across Languages,Yes.,3,"""Despite the success of zero-shot CoT, the existing zero-shot prompting techniques remain limited to a single language, making it challenging to generalize to other languages and hindering global development."""
FinGPT: Large Generative Models for a Small Language,Yes.,3,"""LLM work tends to focus on languages where nearly unlimited data is available for pretraining."""
"Plan, Verify and Switch: Integrated Reasoning with Diverse X-of-Thoughts",Yes.,1,"""As large language models (LLMs) have shown effectiveness with different prompting methods, such as Chain of Thought, Program of Thought, we find that these methods have formed a great complementarity to each other on math reasoning tasks."""
Critic-Driven Decoding for Mitigating Hallucinations in Data-to-text Generation,Yes.,5,"""Hallucination of text ungrounded in the input is a well-known problem in neural data-to-text generation."""
Can Language Models Laugh at YouTube Short-form Videos?,Yes.,1,"""we develop a zero-shot video-to-text prompting to maximize video humor understanding of large language models (LLMs)."""
API-Bank: A Comprehensive Benchmark for Tool-Augmented LLMs,Yes.,4,"""However, three pivotal questions remain unanswered"
Lion: Adversarial Distillation of Proprietary Large Language Models,,,
Evaluating Large Language Models on Controlled Generation Tasks,Yes.,5,"""large language models struggle at meeting fine-grained hard constraints."""
"DeSIQ: Towards an Unbiased, Challenging Benchmark for Social Intelligence Understanding",Yes.,3,"""Our analysis reveals that Social-IQ contains substantial biases, which can be exploited by a moderately strong language model to learn spurious correlations to achieve perfect performance without being given the context or even the question."""
"Why LLMs Hallucinate, and How to Get (Evidential) Closure: Perceptual, Intensional, and Extensional Learning for Faithful Natural Language Generation",,,
Can LLMs Facilitate Interpretation of Pre-trained Language Models?,Yes.,3,"""Work done to uncover the knowledge encoded within pre-trained language models rely on annotated corpora or human-in-the-loop methods. However, these approaches are limited in terms of scalability and the scope of interpretation."""
Oolong: Investigating What Makes Transfer Learning Hard with Controlled Studies,Yes.,5,"""We find that models can largely recover from syntactic-style shifts, but cannot recover from vocabulary misalignment and embedding matrix re-initialization, even with continued pretraining on 15 million tokens."""
Knowledge Rumination for Pre-trained Language Models,Yes.,3,"""vanilla pre-trained language models (PLMs) lack the capacity to handle knowledge-intensive NLP tasks alone"" and ""PLMs may have already encoded rich knowledge in their pre-trained parameters but fails to fully utilize them when applying to knowledge-intensive tasks."""
Struct-XLM: A Structure Discovery Multilingual Language Model for Enhancing Cross-lingual Transfer through Reinforcement Learning,Yes.,1,"""limited researches utilize it for aligning representation in multilingual pre-trained language models (PLMs)."""
Dancing Between Success and Failure: Edit-level Simplification Evaluation using SALSA,Yes.,3,"""current human evaluation methods fail to provide a clear understanding of systems’ specific strengths and weaknesses"" and ""GPT-3.5 performs more quality edits than humans, but still exhibits frequent errors."""
GPT-RE: In-context Learning for Relation Extraction using Large Language Models,,,
INFORM : Information eNtropy based multi-step reasoning FOR large language Models,Yes.,3,"""the effectiveness of CoT prompts may fluctuate dramatically with different choices of in-context examples. Additionally, manual construction of rationale steps can be time-consuming, presenting challenges for the widespread adoption of CoT prompting."""
Adaptive Gating in Mixture-of-Experts based Language Models,Yes.,2,"""Little is discussed in prior research on the trade-off between computation per token and model performance."""
On the Automatic Generation and Simplification of Children’s Stories,Yes.,3,"""We find that, in spite of the growing capabilities of LLMs, they do not yet possess the ability to limit their vocabulary to levels appropriate for younger age groups."""
The Curious Case of Hallucinatory (Un)answerability: Finding Truths in the Hidden States of Over-Confident Large Language Models,Yes.,5,"""A primary issue arising in this context is the management of (un)answerable queries by LLMs, which often results in hallucinatory behavior due to overconfidence."""
Small Language Models Fine-tuned to Coordinate Larger Language Models improve Complex Reasoning,,,
ReasoningLM: Enabling Structural Subgraph Reasoning in Pre-trained Language Models for Question Answering over Knowledge Graph,Yes.,1,"""Despite the effectiveness, due to the divergence in model architecture, the PLM and GNN are not closely integrated, limiting the knowledge sharing and fine-grained feature interactions."""
Deep Natural Language Feature Learning for Interpretable Prediction,,,
ROBBIE: Robust Bias Evaluation of Large Generative Language Models,Yes.,4,"""we must develop comprehensive enough tools to measure and improve their fairness,"" and ""testing LLMs on more datasets can potentially help us characterize their biases more fully,"" and ""we explore the frequency of demographic terms in common LLM pre-training corpora and how this may relate to model biases."""
Adapting Language Models to Compress Contexts,Yes.,5,"""Transformer-based language models (LMs) are powerful and widely-applicable tools, but their usefulness is constrained by a finite context window and the expensive computational cost of processing long text documents."""
COVID-19 Vaccine Misinformation in Middle Income Countries,Yes.,1,"""we adopt two approaches for developing COVID-19 vaccine misinformation detection models"
Contrastive Learning of Sentence Embeddings from Scratch,Yes.,1,"""we explore utilizing large language models to synthesize the required data samples for contrastive learning."""
DisCo: Distilled Student Models Co-training for Semi-supervised Text Mining,Yes.,3,"""a significant challenge that arises nowadays is how to maintain performance when we use a lightweight model with limited labeled samples."""
Dynosaur: A Dynamic Growth Paradigm for Instruction-Tuning Data Curation,Yes.,1,"""Existing methods either manually annotate or employ LLM (e.g., GPT-series) to generate data for instruction tuning."""
Sparse Low-rank Adaptation of Pre-trained Language Models,Yes.,1,"""Fine-tuning pre-trained large language models in a parameter-efficient manner is widely studied for its effectiveness and efficiency."""
The Art of SOCRATIC QUESTIONING: Recursive Thinking with Large Language Models,Yes.,3,"""CoT heavily relies on the initial decisions, causing errors in early steps to accumulate and impact the final answers."""
MEGA: Multilingual Evaluation of Generative AI,Yes.,3,"""We present a thorough analysis of the performance of models across languages and tasks and discuss challenges in improving the performance of generative LLMs on low-resource languages."""
Large Language Models are Temporal and Causal Reasoners for Video Question Answering,Yes.,5,"""However, such priors often cause suboptimal results on VideoQA by leading the model to over-rely on questions, i.e., linguistic bias, while ignoring visual content. This is also known as ‘ungrounded guesses’ or ‘hallucinations’."""
Prompting Large Language Models with Chain-of-Thought for Few-Shot Knowledge Base Question Generation,Yes.,1,"""The emergence of Large Language Models (LLMs) has shown their impressive generalization ability in few-shot tasks."""
TrojanSQL: SQL Injection against Natural Language Interface to Database,Yes.,4,"""Experimental results demonstrate that both medium-sized models based on fine-tuning and LLM-based parsers using prompting techniques are vulnerable to this type of attack, with attack success rates as high as 99% and 89%, respectively."""
Preserving Privacy Through Dememorization: An Unlearning Technique For Mitigating Memorization Risks In Language Models,Yes.,5,"""LLMs have shown the ability to memorize and reproduce portions of their training data when prompted by adversaries. Prior research has focused on addressing this memorization issue and preventing verbatim replication through techniques like knowledge unlearning and data pre-processing. However, these methods have limitations regarding the number of protected samples, limited privacy types, and potentially lower-quality generative models."""
Meta-Learning Online Adaptation of Language Models,Yes.,5,"""the knowledge in static language models falls out of date, limiting the model’s effective 'shelf life.' While online fine-tuning can reduce this degradation, we find that naively fine-tuning on a stream of documents leads to a low level of information uptake."""
Noisy Exemplars Make Large Language Models More Robust: A Domain-Agnostic Behavioral Analysis,Yes.,5,"""we find that models are more sensitive to certain perturbations such as replacing words with their synonyms."""
Can Large Language Models Capture Dissenting Human Voices?,Yes.,5,"""we show LLMs exhibit limited ability in solving NLI tasks and simultaneously fail to capture human disagreement distribution. The inference and human alignment performances plunge even further on data samples with high human disagreement levels, raising concerns about their natural language understanding (NLU) ability and their representativeness to a larger human population."""
DecoMT: Decomposed Prompting for Machine Translation Between Related Languages using Large Language Models,Yes.,1,The abstract discusses the use of large language models for machine translation but does not mention any explicit limitations of the models.
Well Begun is Half Done: Generator-agnostic Knowledge Pre-Selection for Knowledge-Grounded Dialogue,Yes.,1,"""knowledge selection before generation is a lightweight yet effective way to facilitate LLMs (e.g., ChatGPT) to generate more informative responses."""
Merging Generated and Retrieved Knowledge for Open-Domain QA,Yes.,4,"""retrieving passages from a given source is known to suffer from insufficient knowledge coverage"" and ""LLMs tend to 'hallucinate' content that conflicts with the retrieved knowledge."""
A Cheaper and Better Diffusion Language Model with Soft-Masked Noise,Yes.,3,"""existing diffusion models still have some limitations in modeling discrete data, e.g., languages. For example, the generally used Gaussian noise can not handle the discrete corruption well, and the objectives in continuous spaces fail to be stable for textual data in the diffusion process especially when the dimension is high."""
Cognitive Dissonance: Why Do Language Model Outputs Disagree with Internal Representations of Truthfulness?,Yes.,3,"""Past work has found that these two procedures sometimes disagree, and that probes tend to be more accurate than LM outputs."""
Can We Edit Factual Knowledge by In-Context Learning?,Yes.,3,"""However, the stored knowledge could be false or outdated."""
Ignore This Title and HackAPrompt: Exposing Systemic Vulnerabilities of LLMs Through a Global Prompt Hacking Competition,Yes.,5,"""These deployments are increasingly plagued by prompt injection and jailbreaking (collectively, prompt hacking), in which models are manipulated to ignore their original instructions and instead follow potentially malicious ones."""
Localizing Active Objects from Egocentric Vision with Symbolic World Knowledge,Yes.,1,"""We leverage large language models (LLMs) to extract the aforementioned action-object knowledge."""
Prompting is not a substitute for probability measurements in large language models,Yes.,5,"""Broadly, we find that LLMs’ metalinguistic judgments are inferior to quantities directly derived from representations. Furthermore, consistency gets worse as the prompt query diverges from direct measurements of next-word probabilities."""
LINC: A Neurosymbolic Approach for Logical Reasoning by Combining Language Models with First-Order Logic Provers,Yes.,3,"""While many prompting-based strategies have been proposed to enable Large Language Models (LLMs) to do such reasoning more effectively, they still appear unsatisfactory, often failing in subtle and unpredictable ways."""
LLM-Adapters: An Adapter Family for Parameter-Efficient Fine-Tuning of Large Language Models,Yes.,1,"""The success of large language models (LLMs), like GPT-4 and ChatGPT, has led to the development of numerous cost-effective and accessible alternatives that are created by finetuning open-access LLMs with task-specific data (e.g., ChatDoctor) or"
PromptMix: A Class Boundary Augmentation Method for Large Language Model Distillation,,,
QUDeval: The Evaluation of Questions Under Discussion Discourse Parsing,Yes.,3,"""Using QUDeval, we show that satisfying all constraints of QUD is still challenging for modern LLMs, and that existing evaluation metrics poorly approximate parser quality."""
PRCA: Fitting Black-Box Large Language Models for Retrieval Question Answering via Pluggable Reward-Driven Contextual Adapter,Yes.,2,"""they are typically too large to be fine-tuned with budget constraints while some of them are only accessible via APIs."""
Exploring Chain of Thought Style Prompting for Text-to-SQL,Yes.,3,"""However, its performance on text-to-SQL parsing still has much room for improvement."" and ""using detailed reasoning steps tends to have more error propagation issues."""
Harnessing Black-Box Control to Boost Commonsense in LM’s Generation,Yes.,3,"""a crucial issue persists"
Just Ask for Calibration: Strategies for Eliciting Calibrated Confidence Scores from Language Models Fine-Tuned with Human Feedback,,,
"The Effect of Scaling, Retrieval Augmentation and Form on the Factual Consistency of Language Models",Yes.,5,"""Large Language Models (LLMs) make natural interfaces to factual knowledge, but their usefulness is limited by their tendency to deliver inconsistent answers to semantically equivalent questions."""
Semi-automatic Data Enhancement for Document-Level Relation Extraction with Distant Supervision from Large Language Models,Yes.,3,"""vanilla in-context learning is infeasible for DocRE due to the plenty of predefined fine-grained relation types and the uncontrolled generations of LLMs."""
Dialogue Chain-of-Thought Distillation for Commonsense-aware Conversational Agents,Yes.,3,"""Even for large language models (LLMs), the task of identifying and aggregating key evidence within a single hop presents a substantial challenge."""
C-STS: Conditional Semantic Textual Similarity,,,
HyperRouter: Towards Efficient Training and Inference of Sparse Mixture of Experts,Yes.,5,"""However, this strategy has two key limitations"
"Fine-tuned LLMs Know More, Hallucinate Less with Few-Shot Sequence-to-Sequence Semantic Parsing over Wikidata",Yes.,5,"""While large language models (LLMs) can answer many questions correctly, they can also hallucinate and give wrong answers."""
ZEROTOP: Zero-Shot Task-Oriented Semantic Parsing using Large Language Models,Yes.,3,"""LLMs are generally trained on publicly available text and code and cannot be expected to directly generalize to domain-specific parsing tasks in a zero-shot setting."" and ""We observe that current LLMs fail to detect unanswerable questions; and as a result, cannot handle questions corresponding to missing slots."""
Ditto: A Simple and Efficient Approach to Improve Sentence Embeddings,Yes.,3,"""Our analysis reveals that the sentence embeddings from BERT suffer from a bias towards uninformative words, limiting the performance in semantic textual similarity (STS) tasks."""
INSTRUCTSCORE: Towards Explainable Text Generation Evaluation with Automatic Feedback,Yes.,2,"""Although recent learned metrics show high correlation with human judgement, these metrics do not provide explicit explanation of their verdict, nor associate the scores with defects in the generated text."""
Towards Interpretable Mental Health Analysis with Large Language Models,Yes.,3,"""However, existing relevant studies bear several limitations, including inadequate evaluations, lack of prompting strategies, and ignorance of exploring LLMs for explainability."""
Beyond Factuality: A Comprehensive Evaluation of Large Language Models as Knowledge Generators,Yes.,4,"""community concerns abound regarding the factuality and potential implications of using this uncensored knowledge"" and ""Surprisingly, our study reveals that the factuality of generated knowledge, even if lower, does not significantly hinder downstream tasks."""
Compressing Context to Enhance Inference Efficiency of Large Language Models,Yes.,5,"""However, they face challenges in managing long documents and extended conversations, due to significantly increased computational requirements, both in memory and inference time, and potential context truncation when the input exceeds the LLM’s fixed context length."""
MoT: Memory-of-Thought Enables ChatGPT to Self-Improve,Yes.,3,"""However, fundamentally improving them depends on high-quality datasets or computationally expensive fine-tuning."""
Can You Follow Me? Testing Situational Understanding for ChatGPT,Yes.,5,"""Previous works have identified certain SU limitations in non-chatbot Large Language models (LLMs),"" and ""find that despite the fundamental simplicity of the task, the model’s performance reflects an inability to retain correct environment states across time,"" and ""performance degradation is largely because ChatGPT has non-persistent in-context memory (although it can access the full dialogue history) and it is susceptible to"
"Towards Reliable Misinformation Mitigation: Generalization, Uncertainty, and GPT-4",Yes.,2,"""Next, we explore generalization, revealing that GPT-4 and RoBERTa-large exhibit differences in failure modes."""
HaluEval: A Large-Scale Hallucination Evaluation Benchmark for Large Language Models,Yes.,5,"""Large language models (LLMs), such as ChatGPT, are prone to generate hallucinations, i.e., content that conflicts with the source or cannot be verified by the factual knowledge."" and ""Moreover, existing LLMs face great challenges in recognizing the hallucinations in texts."""
Enabling Large Language Models to Generate Text with Citations,Yes.,5,"""their generated outputs are prone to hallucination"" and ""current systems have considerable room for improvement—For example, on the ELI5 dataset, even the best models lack complete citation support 50% of the time."""
Counting the Bugs in ChatGPT’s Wugs: A Multilingual Investigation into the Morphological Capabilities of a Large Language Model,Yes.,5,"""We find that ChatGPT massively underperforms purpose-built systems, particularly in English. Overall, our results—through the lens of morphology—cast a new light on the linguistic capabilities of ChatGPT, suggesting that claims of human-like language skills are premature and misleading."""
Adapt in Contexts: Retrieval-Augmented Domain Adaptation via In-Context Learning,Yes.,3,"""LLMs are still facing challenges in long-tail knowledge in unseen and unfamiliar domains."""
MAF: Multi-Aspect Feedback for Improving Reasoning in Large Language Models,Yes.,5,"""However, when it comes to natural language reasoning, LMs still face challenges such as hallucination, generating incorrect intermediate reasoning steps, and making mathematical errors."""
Personalized Distillation: Empowering Open-Sourced LLMs with Adaptive Learning for Code Generation,Yes.,1,"""Previous distillation methods usually prompt ChatGPT to generate a set of instructions and answers, for the student model to learn. However, such standard distillation approach neglects the merits and conditions of the student model."""
Do Language Models Have a Common Sense regarding Time? Revisiting Temporal Commonsense Reasoning in the Era of Large Language Models,Yes.,5,"""Our findings reveal a nuanced depiction of the capabilities and limitations of the models within temporal reasoning, offering a comprehensive reference for future research in this pivotal domain."""
Evaluation of African American Language Bias in Natural Language Generation,Yes.,4,"""We present evidence of dialectal bias for six pre-trained LLMs through performance gaps on these tasks."""
EtiCor: Corpus for Analyzing LLMs for Etiquettes,Yes.,2,"""Initial results indicate that LLMs, mostly fail to understand etiquettes from regions from non-Western world."""
An Investigation of LLMs’ Inefficacy in Understanding Converse Relations,Yes.,5,"""The results suggest that LLMs often resort to shortcut learning and still face challenges on our proposed benchmark."""
ZGUL: Zero-shot Generalization to Unseen Languages using Multi-source Ensembling of Language Adapters,Yes.,1,"""Training target LA requires unlabeled data, which may not be readily available for low resource *unseen* languages"
Log-FGAER: Logic-Guided Fine-Grained Address Entity Recognition from Multi-Turn Spoken Dialogue,Yes.,1,"""we provide an ontology-based data augmentation methodology that employs ChatGPT to augment a spoken dialogue dataset with labeled address entities."""
Unified Low-Resource Sequence Labeling by Sample-Aware Dynamic Sparse Finetuning,Yes.,3,"""this requires formatting them into specialized augmented format unknown to the base pretrained language model (PLMs) necessitating finetuning to the target format. This significantly bounds its usefulness in data-limited settings where finetuning large models cannot properly generalize to the target format."""
Benchmarking and Improving Text-to-SQL Generation under Ambiguity,Yes.,3,"""We evaluate several Text-to-SQL systems and decoding algorithms, including those employing state-of-the-art LLMs, and find them to be far from this ideal."""
Prompt-Based Monte-Carlo Tree Search for Goal-oriented Dialogue Policy Planning,Yes.,1,"""GDP-Zero prompts a large language model to act as a policy prior, value function, user simulator, and system model during the tree search."""
HiddenTables and PyQTax: A Cooperative Game and Dataset For TableQA to Ensure Scale and Data Privacy Across a Myriad of Taxonomies,Yes.,5,"""A myriad of different Large Language Models (LLMs) face a common challenge in contextually analyzing table question-answering tasks. These challenges are engendered from (1) finite context windows for large tables, (2) multi-faceted discrepancies amongst tokenization patterns against cell boundaries, and (3) various limitations stemming from data confidentiality in the process of using external models such as"
"Speak, Memory: An Archaeology of Books Known to ChatGPT/GPT-4",Yes.,4,"""The ability of these models to memorize an unknown set of books complicates assessments of measurement validity for cultural analytics by contaminating test data; we show that models perform much better on memorized books than on non-memorized books for downstream tasks."""
Copyright Violations and Large Language Models,Yes.,5,"""This work explores the issue of copyright violations and large language models through the lens of verbatim memorization, focusing on possible redistribution of copyrighted text."""
Symbolic Planning and Code Generation for Grounded Dialogue,Yes.,5,"""LLMs have had limited applicability in grounded task-oriented dialogue as they are difficult to steer toward task objectives and fail to handle novel grounding."""
Universal Self-Adaptive Prompting,Yes.,3,"""zero-shot performances in LLMs are still typically weaker due to the lack of guidance and the difficulty of applying existing automatic prompt design methods in general tasks when ground-truth labels are unavailable."""
Beat LLMs at Their Own Game: Zero-Shot LLM-Generated Text Detection via Querying ChatGPT,Yes.,2,"""Despite their great potential, LLMs also incur serious concerns as they are likely to be misused."""
Faithful Model Evaluation for Model-Based Metrics,Yes.,3,"""Existing works usually do not consider the variance change due to metric model errors, which can lead to wrong conclusions."""
Have LLMs Advanced Enough? A Challenging Problem Solving Benchmark For Large Language Models,Yes.,5,"""The typical failure modes of GPT-4, the best model, are errors in algebraic manipulation, difficulty in grounding abstract concepts into mathematical equations accurately and failure in retrieving relevant domain-specific concepts."""
SCITAB: A Challenging Benchmark for Compositional Reasoning and Claim Verification on Scientific Tables,Yes.,3,"""SCITAB poses a significant challenge to state-of-the-art models, including table-based pretraining models and large language models. All models except GPT-4 achieved performance barely above random guessing."""
Task-Agnostic Low-Rank Adapters for Unseen English Dialects,Yes.,4,"""Large Language Models (LLMs) are trained on corpora disproportionally weighted in favor of Standard American English. As a result, speakers of other dialects experience significantly more failures when interacting with these technologies."""
Federated Learning of Large Language Models with Parameter-Efficient Prompt Tuning and Adaptive Optimization,Yes.,4,"""the training process of Large Language Models (LLMs) generally incurs the update of significant parameters, which limits the applicability of FL techniques to tackle the LLMs in real scenarios,"" and ""Prompt tuning can significantly reduce the number of parameters to update, but it either incurs performance degradation or low training efficiency,"" and ""the decentralized data is generally non-Independent and Identically Distributed ("
TheoremQA: A Theorem-driven Question Answering Dataset,Yes.,2,"""However, their capabilities to solve more challenging math problems which require domain-specific knowledge (i.e. theorem) have yet to be investigated."""
Automatic Prompt Optimization with “Gradient Descent” and Beam Search,,,
Active Retrieval Augmented Generation,Yes.,5,"""Despite the remarkable ability of large language models (LMs) to comprehend and generate language, they have a tendency to hallucinate and create factually inaccurate output."""
DialCoT Meets PPO: Decomposing and Exploring Reasoning Paths in Smaller Language Models,Yes.,3,"""Chain-of-Thought (CoT) prompting has successfully enhanced the reasoning capabilities of Large Language Models (LLMs) with at least 100 billion parameters. However, it is ineffective, or even detrimental, to the performance on reasoning tasks in Smaller Language Models (SLMs"
Reasoning with Language Model is Planning with World Model,Yes.,5,"""However, LLMs can still struggle with problems that are easy for humans, such as generating action plans for executing tasks or performing complex math or logical reasoning. This is due to LLMs’ absence of an internal world model for predicting world states (e.g., environment status, variable values) and simulating"
LLM-enhanced Self-training for Cross-domain Constituency Parsing,Yes.,1,"""To overcome this limitation, we propose enhancing self-training with the large language model (LLM) to generate domain-specific raw corpora iteratively."""
Editing Common Sense in Transformers,Yes.,3,"""Commonsense knowledge with multiple correct answers, e.g., an apple can be green or red but not transparent, has not been studied but is as essential for enhancing transformers’ reliability and usefulness."""
IfQA: A Dataset for Open-domain Question Answering under Counterfactual Presuppositions,,,
How Do Large Language Models Capture the Ever-changing World Knowledge? A Review of Recent Advances,Yes.,3,"""Although large language models (LLMs) are impressive in solving various tasks, they can quickly be outdated after deployment. Maintaining their up-to-date status is a pressing concern in the current era."""
DecipherPref: Analyzing Influential Factors in Human Preference Judgments via GPT-4,Yes.,2,"""It is also unclear if there are other hidden factors influencing human judgments."""
Generating Data for Symbolic Language with Large Language Models,,,
DALE: Generative Data Augmentation for Low-Resource Legal NLP,Yes.,1,"""DALE outperforms all our baselines, including LLMs, qualitatively and quantitatively, with absolute improvements of 1%-50%."""
trlX: A Framework for Large Scale Reinforcement Learning from Human Feedback,Yes.,1,"""Reinforcement learning from human feedback (RLHF) utilizes human feedback to better align large language models with human preferences via online optimization against a learned reward model."""
This is not a Dataset: A Large Negation Benchmark to Challenge Large Language Models,Yes.,5,"""they fail to interpret negation, a crucial step in Natural Language Processing,"" and ""Our findings show that, while LLMs are proficient at classifying affirmative sentences, they struggle with negative sentences and lack a deep understanding of negation, often relying on superficial cues,"" and ""the lack of generalization in handling negation is persistent, highlighting the ongoing challenges of LLMs"
SOUL: Towards Sentiment and Opinion Understanding of Language,Yes.,5,"""Experimental results indicate that SOUL is a challenging task for both small and large language models, with a performance gap of up to 27% when compared to human performance. Furthermore, evaluations conducted with both human experts and GPT-4 highlight the limitations of the small language model in generating reasoning-based justifications."""
Regulation and NLP (RegNLP): Taming Large Language Models,Yes.,2,"""important debates emerge regarding the benefits and risks of their development, deployment and use"" and ""highlighting the shortcomings of current NLP discussions dealing with risk assessment."""
"MedEval: A Multi-Level, Multi-Task, and Multi-Domain Medical Benchmark for Language Model Evaluation",Yes.,2,"""Our evaluations reveal varying effectiveness of the two categories of language models across different tasks, from which we notice the importance of instruction tuning for few-shot usage of large language models."""
Evaluation Metrics in the Era of GPT-4: Reliably Evaluating Large Language Models on Sequence to Sequence Tasks,Yes.,2,"""We aim to improve the understanding of current models’ performance by providing a preliminary and hybrid evaluation on a range of open and closed-source generative LLMs"" and ""the quality of automatic evaluation metrics is not keeping up with the pace of development of generative models."""
“Mistakes Help Us Grow”: Facilitating and Evaluating Growth Mindset Supportive Language in Classrooms,Yes.,1,"""We explore whether large language models (LLMs) can provide automated, personalized coaching to support teachers’ use of GMSL."""
Unnatural Error Correction: GPT-4 Can Almost Perfectly Handle Unnatural Scrambled Text,Yes.,2,"""While Large Language Models (LLMs) have achieved remarkable performance in many tasks, much about their inner workings remains unclear."""
Detecting and Mitigating Hallucinations in Multilingual Summarisation,Yes.,5,"""Hallucinations pose a significant challenge to the reliability of neural models for abstractive summarisation."" and ""we assess a broad range of multilingual large language models, and find that they all tend to hallucinate often in languages different from English."""
SelfCheckGPT: Zero-Resource Black-Box Hallucination Detection for Generative Large Language Models,,,
Revisiting Instruction Fine-tuned Model Evaluation to Guide Industrial Applications,Yes.,1,"""Instruction Fine-Tuning (IFT) is a powerful paradigm that strengthens the zero-shot capabilities of Large Language Models (LLMs), but in doing so induces new evaluation metric requirements."""
EasyQuant: An Efficient Data-free Quantization Algorithm for LLMs,Yes.,5,"""However, their expensive computations and high memory requirements are prohibitive for deployment."" and ""the quantized model was calibrated using few samples from the training data, which might affect the generalization of the quantized LLMs to unknown cases and tasks."""
APrompt: Attention Prompt Tuning for Efficient Adaptation of Pre-trained Language Models,Yes.,2,"""most existing prompt tuning approaches only introduce prompts at the input layer, limiting their performance and leaving large rooms for improvement."""
Learning Preference Model for LLMs via Automatic Preference Data Generation,Yes.,3,"""Despite the advanced capacities of the state-of-the-art large language models (LLMs), they suffer from issues of hallucination, stereotype, etc."""
Revisiting Automated Topic Model Evaluation with Large Language Models,Yes.,2,"""the setup of the evaluation task is crucial — LLMs perform better on coherence ratings of word sets than on intrusion detection."""
ORCHID: A Chinese Debate Corpus for Target-Independent Stance Detection and Argumentative Dialogue Summarization,Yes.,1,"""Dialogue agents have been receiving increasing attention for years, and this trend has been further boosted by the recent progress of large language models (LLMs)."""
Explore-Instruct: Enhancing Domain-Specific Instruction Coverage through Active Exploration,Yes.,2,"""existing data employed for such tuning often exhibit an inadequate coverage of individual domains, limiting the scope for nuanced comprehension and interactions within these areas."""
Just Adjust One Prompt: Enhancing In-Context Dialogue Scoring via Constructing the Optimal Subgraph of Demonstrations and Prompts,Yes.,3,"""The use of modern Large Language Models (LLMs) as chatbots still has some problems such as hallucinations and lack of empathy."""
EpiK-Eval: Evaluation for Language Models as Epistemic Models,Yes.,5,"""Evaluations across various LLMs reveal significant weaknesses in this domain."" and ""We contend that these shortcomings stem from the intrinsic nature of prevailing training objectives."""
On Bilingual Lexicon Induction with Large Language Models,Yes.,2,"""We also conduct a series of in-depth analyses and ablation studies, providing more insights on BLI with (m)LLMs, also along with their limitations."""
"CRaSh: Clustering, Removing, and Sharing Enhance Fine-tuning without Full Large Language Model",Yes.,2,"""However, when tuning publicly accessible, centralized LLMs with private instruction data, privacy concerns are inevitable."""
Large Language Models are biased to overestimate profoundness,Yes.,5,"""However, LLMs systematically overestimate the profoundness of nonsensical statements"" and ""this work provides insights into the potential biases induced by Reinforcement Learning from Human Feedback (RLHF), inducing an increase in the bias to overestimate the profoundness of statements."""
SummEdits: Measuring LLM Ability at Factual Reasoning Through The Lens of Summarization,Yes.,5,"""Most LLMs struggle on SummEdits, with performance close to random chance. The best-performing model, GPT-4, is still 8% below estimated human performance, highlighting the gaps in LLMs’ ability to reason about facts and detect inconsistencies when they occur."""
Quantifying the redundancy between prosody and text,Yes.,1,"""We use large language models (LLMs) to estimate how much information is redundant between prosody and the words themselves."""
Label Words are Anchors: An Information Flow Perspective for Understanding In-Context Learning,Yes.,3,"""the underlying mechanism of how LLMs learn from the provided context remains under-explored."""
Prompting Scientific Names for Zero-Shot Species Recognition,Yes.,3,"""However, it is underexplored how to use CLIP for zero-shot recognition of highly specialized concepts, e.g., species of birds, plants, and animals, for which their scientific names are written in Latin or Greek. Indeed, CLIP performs poorly for zero-shot species recognition with prompts that use scientific names, e.g., 'a photo of Lepus Timidus' ("
Do All Languages Cost the Same? Tokenization in the Era of Commercial Language Models,Yes.,4,"""We show evidence that speakers of a large number of the supported languages are overcharged while obtaining poorer results."""
MULTITuDE: Large-Scale Multilingual Machine-Generated Text Detection Benchmark,Yes.,2,"""There is a lack of research into capabilities of recent LLMs to generate convincing text in languages other than English and into performance of detectors of machine-generated text in multilingual settings."""
Revisiting Block-based Quantisation: What is Important for Sub-8-bit LLM Inference?,,,
Reducing Sequence Length by Predicting Edit Spans with Large Language Models,Yes.,3,"""the models that generate all target tokens in such tasks have a tendency to simply copy the input text as is, without making needed changes, because the difference between input and output texts is minimal in the training data. This is also inefficient because the computational cost grows quadratically with the target sequence length with Transformer."""
Instruct and Extract: Instruction Tuning for On-Demand Information Extraction,Yes.,2,"""However, when it comes to information extraction – a classic task in natural language processing – most task-specific systems cannot align well with long-tail ad hoc extraction use cases for non-expert users."""
Rethinking the Evaluation for Conversational Recommendation in the Era of Large Language Models,Yes.,2,"""revealing the inadequacy of the existing evaluation protocol"" and ""To overcome the limitation, we further propose an interactive Evaluation approach based on LLMs."""
Appraising the Potential Uses and Harms of LLMs for Medical Systematic Reviews,Yes.,5,"""However, LLMs sometimes generate inaccurate (and potentially misleading) texts by hallucination or omission. In healthcare, this can make LLMs unusable at best and dangerous at worst."" and ""They also raised concerns regarding confidently composed but inaccurate LLM outputs and other potential downstream harms, including decreased accountability and proliferation of low-quality reviews."""
Contrastive Learning for Inference in Dialogue,Yes.,3,"""While recent large language models show remarkable advances in inference tasks, their performance in inductive reasoning, where not all information is present in the context, is far behind deductive reasoning."""
"Editing Large Language Models: Problems, Methods, and Opportunities",Yes.,3,"""Despite the ability to train capable LLMs, the methodology for maintaining their relevancy and rectifying errors remains elusive."" and ""an exhaustive overview of the task definition and challenges associated with model editing, along with an in-depth empirical analysis of the most progressive methods currently at our disposal."""
Large Language Models Meet Open-World Intent Discovery and Recognition: An Evaluation of ChatGPT,Yes.,5,"""we summarize and discuss the challenges faced by LLMs including clustering, domain-specific understanding, and cross-domain in-context learning scenarios."""
The Distributional Hypothesis Does Not Fully Explain the Benefits of Masked Language Model Pretraining,Yes.,3,"""Our results illustrate our limited understanding of model pretraining and provide future research directions."""
Learning to Rank Context for Named Entity Recognition Using a Synthetic Dataset,Yes.,3,"""While recent pre-trained transformer-based models can perform named entity recognition (NER) with great accuracy, their limited range remains an issue when applied to long documents such as whole novels."""
Improving Diversity of Demographic Representation in Large Language Models via Collective-Critiques and Self-Voting,Yes.,5,"""A crucial challenge for generative large language models (LLMs) is diversity"
Hidding the Ghostwriters: An Adversarial Evaluation of AI-Generated Student Essay Detection,Yes.,4,"""the utilization of these models carries inherent risks, including but not limited to plagiarism, the dissemination of fake news, and issues in educational exercises,"" and ""the existing detectors can be easily circumvented using straightforward automatic adversarial attacks."""
Contextual Interaction for Argument Post Quality Assessment,Yes.,3,"""while LLMs with in-context examples showcase a commendable ability to identify high-quality argument posts, they exhibit relatively limited efficacy in discerning between argument posts with a narrow quality gap."""
Synthetic Data Generation with Large Language Models for Text Classification: Potential and Limitations,Yes.,5,"""the effectiveness of the LLM-generated synthetic data in supporting model training is inconsistent across different classification tasks"" and ""subjectivity, at both the task level and instance level, is negatively associated with the performance of the model trained on synthetic data."""
People Make Better Edits: Measuring the Efficacy of LLM-Generated Counterfactually Augmented Data for Harmful Language Detection,Yes.,3,"""One key reason for the lower performance of automated methods is that the changes they introduce are often insufficient to flip the original label."""
Learning from Mistakes via Cooperative Study Assistant for Large Language Models,Yes.,5,"""However, the feedback from LLM itself is often inaccurate, thereby limiting its benefits."""
Conceptor-Aided Debiasing of Large Language Models,Yes.,5,"""Pre-trained large language models (LLMs) reflect the inherent social biases of their training corpus,"" and ""many methods have been proposed to mitigate this issue, but they often fail to debias or they sacrifice model accuracy."""
CoMPosT: Characterizing and Evaluating Caricature in LLM Simulations,Yes.,5,"""there is growing concern that these LLM simulations are flattened caricatures of the personas that they aim to simulate, failing to capture the multidimensionality of people and perpetuating stereotypes."""
Grammar-Constrained Decoding for Structured NLP Tasks without Finetuning,Yes.,3,"""Despite their impressive performance, large language models (LMs) still struggle with reliably generating complex output structures when not finetuned to follow the required output format exactly."""
Evaluating Evaluation Metrics: A Framework for Analyzing NLG Evaluation Metrics using Measurement Theory,Yes.,2,"""identified issues related to conflated validity structure in human-eval and reliability in LLM-based metrics."""
Revisiting the Knowledge Injection Frameworks,Yes.,5,"""we find that injecting unaligned (i.e., random) knowledge tuple into the LLMs achieves comparable (and sometimes better) results than the aligned knowledge being injected,"" and ""how to adapt these LLMs to better suit the vertical domain-specific tasks by utilizing external knowledge remains not completely solved."""
Collaborative Generative AI: Integrating GPT-k for Efficient Editing in Text-to-Image Generation,Yes.,3,"""a common issue encountered by users is the need for repetitive editing of input prompts in order to receive a satisfactory image, which is time-consuming and labor-intensive."""
clembench: Using Game Play to Evaluate Chat-Optimized Language Models as Conversational Agents,Yes.,1,"""showing that current chat-optimised LLMs are, to an extent, capable of following game-play instructions."""
Polyglot or Not? Measuring Multilingual Encyclopedic Knowledge in Foundation Models,Yes.,4,"""an analysis of LLaMA’s errors reveals significant limitations in its ability to recall facts in languages other than English, plus difficulties related to the location and gender of fact subjects."""
UDAPDR: Unsupervised Domain Adaptation via LLM Prompting and Distillation of Rerankers,Yes.,1,"""To address this challenge, we develop and motivate a method for using large language models (LLMs) to generate large numbers of synthetic queries cheaply."""
Data Similarity is Not Enough to Explain Language Model Performance,Yes.,3,"""Large language models achieve high performance on many but not all downstream tasks,"" and ""This suggests that the relationship between pretraining data and downstream tasks is more complex than often assumed."""
Do LLMs Understand Social Knowledge? Evaluating the Sociability of Large Language Models with SocKET Benchmark,Yes.,3,"""we demonstrate that current models attain only moderate performance but reveal significant potential for task transfer among different types and categories of tasks"" and ""points to clear room for improvement to build more socially-aware LLMs."""
Integrating Language Models into Direct Speech Translation: An Inference-Time Solution to Control Gender Inflection,Yes.,4,"""The existing solutions to do so, though effective, are hardly feasible in practice as they involve dedicated model re-training on gender-labeled ST data."""
StoryAnalogy: Deriving Story-level Analogies from Large Language Models to Unlock Analogical Understanding,Yes.,5,"""Interestingly, we find that the analogy identification tasks are incredibly difficult not only for sentence embedding models but also for the recent large language models (LLMs) such as ChatGPT and LLaMa."""
CESAR: Automatic Induction of Compositional Instructions for Multi-turn Dialogs,Yes.,3,"""While publicly available LLMs have shown promising performance, when exposed to complex instructions with multiple constraints, they lag against state-of-the-art models like ChatGPT."""
Reward-Augmented Decoding: Efficient Controlled Text Generation With a Unidirectional Reward Model,Yes.,3,"""While large language models have proven effective in a huge range of downstream applications, they often generate text that is problematic or lacks a desired attribute."""
Cabbage Sweeter than Cake? Analysing the Potential of Large Language Models for Learning Conceptual Spaces,Yes.,3,"""we also find that fine-tuned models of the BERT family are able to match or even outperform the largest GPT-3 model, despite being 2 to 3 orders of magnitude smaller."""
An Empirical Study of Translation Hypothesis Ensembling with Large Language Models,Yes.,4,"""Large language models (LLMs) are becoming a one-fits-many solution, but they sometimes hallucinate or produce unreliable output."""
Visually-Situated Natural Language Understanding with Contrastive Reading Model and Frozen Large Language Models,Yes.,2,"""their performance on text-rich images still requires improvement."""
Unlearn What You Want to Forget: Efficient Unlearning for LLMs,,,
Precedent-Enhanced Legal Judgment Prediction with LLM and Domain-Model Collaboration,Yes.,1,"""These can be broken down into two categories"
FActScore: Fine-grained Atomic Evaluation of Factual Precision in Long Form Text Generation,Yes.,5,"""Evaluating the factuality of long-form text generated by large language models (LMs) is non-trivial because (1) generations often contain a mixture of supported and unsupported pieces of information, making binary judgments of quality inadequate, and (2) human evaluation is time-consuming"
Calc-X and Calcformers: Empowering Arithmetical Chain-of-Thought through Interaction with Symbolic Systems,Yes.,5,"""language models are notoriously inclined to make factual errors in tasks requiring arithmetic computation."""
CoF-CoT: Enhancing Large Language Models with Coarse-to-Fine Chain-of-Thought Prompting for Multi-domain NLU Tasks,Yes.,1,"""While Chain-of-Thought prompting is popular in reasoning tasks, its application to Large Language Models (LLMs) in Natural Language Understanding (NLU) is under-explored."""
StereoMap: Quantifying the Awareness of Human-like Stereotypes in Large Language Models,Yes.,4,"""Large Language Models (LLMs) have been observed to encode and perpetuate harmful associations present in the training data."" and ""This study contributes to the understanding of how LLMs perceive and represent social groups, shedding light on their potential biases and the perpetuation of harmful associations."""
"Select, Prompt, Filter: Distilling Large Language Models for Summarizing Conversations",Yes.,3,"""Large language models (LLMs) like ChatGPT can be expensive to train, deploy, and use for specific natural language generation tasks such as text summarization and for certain domains. A promising alternative is to fine-tune relatively smaller language models (LMs) on a particular task using"
UPRISE: Universal Prompt Retrieval for Improving Zero-Shot Evaluation,Yes.,2,"""the need for model-specific fine-tuning or task-specific prompt engineering can hinder their generalization"" and ""UPRISE mitigates the hallucination problem in our experiments with ChatGPT."""
Large Language Models Only Pass Primary School Exams in Indonesia: A Comprehensive Test on IndoMMLU,Yes.,5,"""Our empirical evaluations show that GPT-3.5 only manages to pass the Indonesian primary school level, with limited knowledge of local Indonesian languages and culture."""
Multi-Source Multi-Type Knowledge Exploration and Exploitation for Dialogue Generation,Yes.,1,"""Recently, large language models (LLMs) have shown impressive performance on natural language processing tasks."""
Multilingual Large Language Models Are Not (Yet) Code-Switchers,Yes.,3,"""despite multilingual LLMs exhibiting promising outcomes in certain tasks using zero or few-shot prompting, they still underperform in comparison to fine-tuned models of much smaller scales."""
Large Language Models: The Need for Nuance in Current Debates and a Pragmatic Perspective on Understanding,Yes.,5,"""critically assess three points recurring in critiques of LLM capacities"
The CoT Collection: Improving Zero-shot and Few-shot Learning of Language Models via Chain-of-Thought Fine-Tuning,Yes.,2,"""Language models (LMs) with less than 100B parameters are known to perform poorly on chain-of-thought (CoT) reasoning in contrast to large LMs when solving unseen tasks."""
Explaining Interactions Between Text Spans,Yes.,1,"""We then investigate the decision-making processes of multiple fine-tuned large language models in terms of the employed connections between spans in separate parts of the input and compare them to the human reasoning processes."""
Question Answering as Programming for Solving Time-Sensitive Questions,Yes.,5,"""our experiments reveal that the aforementioned problems still pose a significant challenge to existing LLMs. This can be attributed to the LLMs’ inability to perform rigorous reasoning based on surface-level text semantics."""
Context Compression for Auto-regressive Transformers with Sentinel Tokens,Yes.,5,"""The quadratic complexity of the attention module makes it gradually become the bulk of compute in Transformer-based LLMs during generation. Moreover, the excessive key-value cache that arises when dealing with long inputs also brings severe issues on memory footprint and inference latency."""
Generative Adversarial Training with Perturbed Token Detection for Model Robustness,No.,1,The abstract does not mention LLMs or any specific limitations related to them.
Large Language Models and Multimodal Retrieval for Visual Word Sense Disambiguation,Yes.,1,"""Additionally, we utilize Large Language Models (LLMs) as knowledge bases to enhance the given phrases and resolve ambiguity related to the target word."""
Doolittle: Benchmarks and Corpora for Academic Writing Formalization,Yes.,2,"""Our experiments reveal that existing text transfer models and grammatical error correction models address certain aspects of AWF but still have a significant performance gap compared to human performance."""
Token Prediction as Implicit Classification to Identify LLM-Generated Text,Yes.,1,"""This paper introduces a novel approach for identifying the possible large language models (LLMs) involved in text generation."""
LLMLingua: Compressing Prompts for Accelerated Inference of Large Language Models,,,
Conversation Chronicles: Towards Diverse Temporal and Relational Dynamics in Multi-Session Conversations,Yes.,1,"""However, a major limitation of existing open-domain chatbot research is its singular focus on short single-session dialogue, neglecting the potential need for understanding contextual information in multiple consecutive sessions that precede an ongoing dialogue."""
CLAIR: Evaluating Image Captions with Large Language Models,Yes.,1,"""Here, we propose CLAIR, a novel method that leverages the zero-shot language modeling capabilities of large language models (LLMs) to evaluate candidate captions."""
MoPe: Model Perturbation based Privacy Attacks on Language Models,Yes.,5,"""Recent work has shown that Large Language Models (LLMs) can unintentionally leak sensitive information present in their training data."""
Aligning Large Language Models through Synthetic Feedback,Yes.,1,"""Aligning large language models (LLMs) to human values has become increasingly important as it enables sophisticated steering of LLMs."""
You Told Me That Joke Twice: A Systematic Investigation of Transferability and Robustness of Humor Detection Models,Yes.,2,"""The behavior of the models on out-of-domain data is unstable, suggesting that some of the models overfit, while others learn non-specific humor characteristics."""
Empower Nested Boolean Logic via Self-Supervised Curriculum Learning,Yes.,5,"""We find that any pre-trained language models even including large language models only behave like a random selector in the face of multi-nested boolean logic, a task that humans can handle with ease."""
DADA: Dialect Adaptation via Dynamic Aggregation of Linguistic Rules,Yes.,3,"""Existing large language models (LLMs) that mainly focus on Standard American English (SAE) often lead to significantly worse performance when being applied to other English dialects."""
Can We Edit Multimodal Large Language Models?,Yes.,3,"""Empirically, we notice that previous baselines can implement editing multimodal LLMs to some extent, but the effect is still barely satisfactory, indicating the potential difficulty of this task."""
ClusterLLM: Large Language Models as a Guide for Text Clustering,Yes.,1,"""We introduce ClusterLLM, a novel text clustering framework that leverages feedback from an instruction-tuned large language model, such as ChatGPT."""
Syllogistic Reasoning for Legal Judgment Analysis,Yes.,2,"""people can hardly trust the results generated by a model without reliable analysis of legal judgement."""
KCTS: Knowledge-Constrained Tree Search Decoding with Token-Level Hallucination Detection,Yes.,5,"""Large Language Models (LLMs) have demonstrated remarkable human-level natural language generation capabilities. However, their potential to generate misinformation, often called the *hallucination* problem, poses a significant risk to their deployment."""
CRUSH4SQL: Collective Retrieval Using Schema Hallucination For Text2SQL,Yes.,1,"""First, we use an LLM to hallucinate a minimal DB schema that it deems adequate to answer the query."""
Language Models with Rationality,Yes.,5,"""This lack of interpretability is a growing impediment to widespread use of LLMs."" and ""resolve inconsistencies that may exist."""
Mitigating Temporal Misalignment by Discarding Outdated Facts,Yes.,5,"""While large language models are able to retain vast amounts of world knowledge seen during pretraining, such knowledge is prone to going out of date and is nontrivial to update."""
Fighting Fire with Fire: The Dual Role of LLMs in Crafting and Detecting Elusive Disinformation,Yes.,2,"""Recent ubiquity and disruptive impacts of large language models (LLMs) have raised concerns about their potential to be misused (i.e., generating large-scale harmful and misleading content)."""
Let GPT be a Math Tutor: Teaching Math Word Problem Solvers with Customized Exercise Generation,Yes.,1,"""In this paper, we present a novel approach for distilling math word problem solving capabilities from large language models (LLMs) into smaller, more efficient student models."""
FANToM: A Benchmark for Stress-testing Machine Theory of Mind in Interactions,Yes,5,"We show that FANToM is challenging for state-of-the-art LLMs, which perform significantly worse than humans even with chain-of-thought reasoning or fine-tuning."
FreeAL: Towards Human-Free Active Learning in the Era of Large Language Models,Yes,2,their performances are still subject to human intervention.
Outlier Dimensions Encode Task Specific Knowledge,Yes,3,"Previous works have argued that although ablating these outlier dimensions in LLM representations hurts downstream performance, outlier dimensions are detrimental to the representational quality of embeddings."
Enhancing Computation Efficiency in Large Language Models through Weight and Activation Quantization,Yes,2,"Large Language Models (LLMs) are proficient in natural language processing tasks, but their deployment is often restricted by extensive parameter sizes and computational demands."
Assessing Step-by-Step Reasoning against Lexical Negation: A Case Study on Syllogism,Yes,5,"We observed that dozens of modern LLMs were not robust against lexical negation (e.g., plausible→implausible) when performing CoT-style reasoning, and the results highlight unique limitations in each LLM family."
Chain-of-Thought Tuning: Masked Language Models can also Think Step By Step in Natural Language Understanding,Yes,3,LLMs perform less well than small-scale Masked Language Models (MLMs).
Is ChatGPT Good at Search? Investigating Large Language Models as Re-Ranking Agents,Yes,3,The discrepancy between the pre-training objectives of LLMs and the ranking objective poses another challenge.
Dr ChatGPT tell me what I want to hear: How different prompts impact health answer correctness,Yes,5,reveal that knowledge passed in the prompt can bias the model to the detriment of answer correctness.
Prompting with Pseudo-Code Instructions,Yes,1,we explore if prompting via pseudo-code instructions helps improve the performance of pre-trained language models.
CRAB: Assessing the Strength of Causal Relationships Between Real-world Events,Yes,5,find that models perform worse on causal reasoning when events are derived from complex causal structures compared to simple linear causal chains.
Specialist or Generalist? Instruction Tuning for Specific NLP Tasks,Yes,3,generalist data containing hallucinatory information may negatively affect the model’s performance.
Making Large Language Models Better Data Creators,Yes,3,"deploying them for downstream applications is still challenging due to cost, responsiveness, control, or concerns around privacy and security."
Hallucination Detection for Generative Large Language Models by Bayesian Sequential Estimation,Yes,5,"the propensity of LLMs to generate inaccurate or non-factual content, termed “hallucinations”, remains a significant challenge."
Guideline Learning for In-Context Information Extraction,Yes,3,"However, the performance of In-context IE generally lags behind the state-of-the-art supervised expert models. We highlight a key reason for this shortfall: underspecified task description. The limited-length context struggles to thoroughly express the intricate IE task instructions and various edge cases, leading to misalignment in task comprehension with humans."
Self-ICL: Zero-Shot In-Context Learning with Self-Generated Demonstrations,Yes,3,"different methods are proposed to select representative demonstrations from existing training corpora. However, such settings are not aligned with real-world practices, as end-users usually query LMs without access to demonstration pools."
MQuAKE: Assessing Knowledge Editing in Language Models via Multi-Hop Questions,Yes,5,"current knowledge-editing approaches can recall edited facts accurately, they fail catastrophically on the constructed multi-hop questions."
NL2TL: Transforming Natural Languages to Temporal Logics using Large Language Models,Yes,1,exploring the use of Large Language Models (LLMs) at multiple stages.
Consistency Analysis of ChatGPT,Yes,5,"prompt designing, few-shot learning and employing larger large language models (LLMs) are unlikely to be the ultimate solution to resolve the inconsistency issue of LLMs."
AnyTOD: A Programmable Task-Oriented Dialog System,Yes,1,"We view TOD as a program executed by a language model (LM), where program logic and ontology is provided by a designer as a schema."
Zero-Shot Multi-Label Topic Inference with Sentence Encoders and LLMs,Yes,1,"Through extensive experimentation on seven diverse data sets, we observed that LLMs, such as ChatGPT-3.5 and PaLM, demonstrated superior generality compared to other LLMs, e.g., BLOOM and GPT-NeoX."
Exploring Distributional Shifts in Large Language Models for Code Analysis,Yes,3,We establish that samples from each new domain present all the models with a significant challenge of distribution shift.
A Benchmark for Reasoning with Spatial Prepositions,Yes,3,"Our results show considerable variability in the performance of smaller and larger models, as well as across prompts and languages. However, none of the models reaches human performance."
Document-Level Machine Translation with Large Language Models,Yes,1,"Large language models (LLMs) such as ChatGPT can produce coherent, cohesive, relevant, and fluent answers for various natural language processing (NLP) tasks."
LLM-driven Instruction Following: Progresses and Concerns,Yes,3,What concerns remain in LLM-driven instruction following?
Mitigating Societal Harms in Large Language Models,Yes,5,"We will provide an overview of potential social issues in language generation, including toxicity, social biases, misinformation, factual inconsistency, and privacy violations."
Creative Natural Language Generation,Yes,3,"Large language models such as GPT-3, GPT4, Claude etc., have advanced the state of the art in several natural language generation tasks such as text summarization and machine translation. However when it comes to open-ended tasks with a focus on creativity such as generating stories, poetry, or various forms of figurative language, these state-of-the-art language models are often found to be inadequate. This tutorial aims to bring awareness of the important and emerging research"
Fabricator: An Open Source Toolkit for Generating Labeled Training Data with Teacher LLMs,Yes,1,"Current research addresses this bottleneck by exploring a novel paradigm called zero-shot learning via dataset generation. Here, a powerful LLM is prompted with a task description to generate labeled data that can be used to train a downstream NLP model."
CHATREPORT: Democratizing Sustainability Disclosure Analysis through LLM-based Tools,Yes,3,"However, developing such tools is challenging due to (1) the hallucination of LLMs and (2) the inefficiency of bringing domain experts into the AI development loop."
RaLLe: A Framework for Developing and Evaluating Retrieval-Augmented Large Language Models,Yes,2,current libraries for building R-LLMs provide high-level abstractions without sufficient transparency for evaluating and optimizing prompts within specific inference processes such as retrieval and generation.
H2O Open Ecosystem for State-of-the-art Large Language Models,Yes,5,"LLMs represent a revolution in AI. However, they also pose many significant risks, such as the presence of biased, private, copyrighted or harmful text."
FLEEK: Factual Error Detection and Correction with Evidence Retrieved from External Knowledge,Yes,5,LLMs’ inability to attribute their claims to external knowledge and their tendency to hallucinate makes it difficult to rely on their responses.
CLEVA: Chinese Language Models EVAluation Platform,Yes,4,"The absence of a comprehensive Chinese benchmark that thoroughly assesses a model’s performance, the unstandardized and incomparable prompting procedure, and the prevalent risk of contamination pose major challenges in the current evaluation of Chinese LLMs."
MusicAgent: An AI Agent for Music Understanding and Generation with Large Language Models,Yes,1,"Inspired by the recent success of large language models (LLMs) in task automation, we develop a system, named MusicAgent, which integrates numerous music-related tools and an autonomous workflow to address user requirements."
MiniChain: A Small Library for Coding with Large Language Models,Yes,3,"LLMs are accurate enough, on average, to replace core functionality, yet make basic mistakes that demonstrate a lack of robustness."
Okapi: Instruction-tuned Large Language Models in Multiple Languages with Reinforcement Learning from Human Feedback,Yes,2,"existing open-source LLMs have only been instruction-tuned for English and a few popular languages, thus hindering their accessibility to many other languages in the world."
InsightPilot: An LLM-Empowered Automated Data Exploration System,Yes,1,"we introduce InsightPilot, an LLM (Large Language Model)-based, automated data exploration system designed to simplify the data exploration process."
Prompt2Model: Generating Deployable Models from Natural Language Instructions,Yes,3,LLMs are a step backward from traditional special-purpose NLP models; they require extensive computational resources for deployment and can be gated behind APIs.
NeMo Guardrails: A Toolkit for Controllable and Safe LLM Applications with Programmable Rails,Yes,1,NeMo Guardrails is an open-source toolkit for easily adding programmable guardrails to LLM-based conversational systems.
LM-Polygraph: Uncertainty Estimation for Language Models,Yes,5,"However, a significant challenge arises as these models often “hallucinate”, i.e., fabricate facts without providing users an apparent means to discern the veracity of their statements."
Prompterator: Iterate Efficiently towards More Effective Prompts,Yes,1,"Finding well-performing prompts, however, is a non-trivial task which requires experimentation in order to arrive at a prompt that solves a specific task."
Video-LLaMA: An Instruction-tuned Audio-Visual Language Model for Video Understanding,Yes,1,"Video-LLaMA enables video comprehension by tackling two challenges: (1) capturing the temporal changes in visual scenes, (2) integrating audio-visual signals."
Gatekeeper to save COGS and improve efficiency of Text Prediction,Yes,3,"As LLMs require massive amounts of computation and storage, such an approach incurs network and high execution cost."
Text2Topic: Multi-Label Text Classification System for Efficient Topic Detection in User Generated Content with Zero-Shot Capabilities,Yes,1,"The final model achieves accurate and comprehensive results compared to state-of-the-art baselines, including large language models (LLMs)."
Investigating Table-to-Text Generation Capabilities of Large Language Models in Real-World Information Seeking Scenarios,Yes,2,"a significant performance gap still exists between other open-sourced LLMs (e.g., Vicuna and LLaMA-2) and GPT-4 models."
WordArt Designer: User-Driven Artistic Typography Synthesis using Large Language Models,Yes,1,"This paper introduces WordArt Designer, a user-driven framework for artistic typography synthesis, relying on the Large Language Model (LLM). The system incorporates four key modules: the LLM Engine, SemTypo, StyTypo, and TexTypo modules. 1) The LLM Engine, empowered by the LLM (e.g. GPT-3.5), interprets user inputs and"
Empower Large Language Model to Perform Better on Industrial Domain-Specific Question Answering,Yes,3,"Large Language Model (LLM) has gained popularity and achieved remarkable results in open-domain tasks, but its performance in real industrial domain-specific scenarios is average due to its lack of specific domain knowledge. This issue has attracted widespread attention, but there are few relevant benchmarks available. In this paper, we provide a benchmark Question Answering (QA) dataset named MSQA, centered around Microsoft products and IT technical"
Building Real-World Meeting Summarization Systems using Large Language Models: A Practical Perspective,Yes,3,"Considering the privacy concerns of closed-source models for only being accessible via API, alongside the high cost associated with using fine-tuned versions of the closed-source models."
Building Real-World Meeting Summarization Systems using Large Language Models: A Practical Perspective,Yes.,2.,"""Considering the privacy concerns of closed-source models for only being accessible via API, alongside the high cost associated with using fine-tuned versions of the closed-source models."""
AART: AI-Assisted Red-Teaming with Diverse Data Generation for New LLM-powered Applications,Yes.,3.,"""This provides transparency of developers evaluation intentions and enables quick adaptation to new use cases and newly discovered model weaknesses."""
Are ChatGPT and GPT-4 General-Purpose Solvers for Financial Text Analytics? A Study on Several Typical Tasks,Yes.,2.,"""We report both the strengths and limitations of the current models by comparing them to the state-of-the-art fine-tuned approaches and the recently released domain-specific pretrained models."""
PILLOW: Enhancing Efficient Instruction Fine-tuning via Prompt Matching,Yes.,2.,"""Instruction fine-tuning has conventionally been employed to adapt Large Language Models (LLMs) to a variety of diverse tasks. Nonetheless, this technique often necessitates substantial computational resources, making it impractical for deployment by individuals or small-scale entities."""
CarExpert: Leveraging Large Language Models for In-Car Conversational Question Answering,Yes.,5.,"""leveraging LLMs for domain-specific question answering suffers from severe limitations. The generated answer tends to hallucinate due to the training data collection time (when using off-the-shelf), complex user utterance and wrong retrieval (in retrieval-augmented generation). Furthermore, due to the"
JarviX: A LLM No code Platform for Tabular Data Analysis and Optimization,Yes.,1.,"""JarviX is designed to employ Large Language Models (LLMs) to facilitate an automated guide and execute high-precision data analyzes on tabular datasets."""
"Self-Criticism: Aligning Large Language Models with their Understanding of Helpfulness, Honesty, and Harmlessness",Yes.,3.,"""RLHF, which incorporates independent reward models trained on high-quality human feedback datasets, incurs high costs in terms of hardware resources and human efforts."""
InstructPTS: Instruction-Tuning LLMs for Product Title Summarization,,,
LLM4Vis: Explainable Visualization Recommendation using ChatGPT,Yes.,1.,"""To address this research gap, we propose LLM4Vis, a novel ChatGPT-based prompting approach to perform visualization recommendation and return human-like explanations using very few demonstration examples."""
Harnessing LLMs for Temporal Data - A Study on Explainable Financial Time Series Forecasting,Yes.,1.,"""Furthermore, fine-tuned public LLMs, such as Open-LLaMA, can generate reasonable and explainable forecasts, although they underperform compared to GPT-4."""
"ViGPTQA - State-of-the-Art LLMs for Vietnamese Question Answering: System Overview, Core Models Training, and Evaluations",Yes.,3.,"""Large language models (LLMs) and their applications in low-resource languages (such as in Vietnamese) are limited due to lack of training data and benchmarking datasets."""
On Sample-Efficient Code Generation,Yes.,3.,"""Large language models often struggle to predict runtime behavior in code generation tasks, leading to a reliance on rejection sampling (best-of-n) to generate multiple code snippets then select the best."""
Graph Meets LLM: A Novel Approach to Collaborative Filtering for Robust Conversational Understanding,Yes.,1.,"""This paper then further explores the use of Large Language Models (LLMs) in conjunction with graph traversal, leading to a significant increase in index coverage for unseen interactions."""
DELPHI: Data for Evaluating LLMs’ Performance in Handling Controversial Issues,Yes.,4.,"""This dataset presents challenges concerning knowledge recency, safety, fairness, and bias."""
