Title,Talks about LLMs,Rate,Evidence,Published
Named Entity Recognition Under Domain Shift via Metric Learning for Life Sciences,Yes.,3.,"""Named entity recognition is a key component of Information Extraction (IE), particularly in scientific domains such as biomedicine and chemistry, where large language models (LLMs), e.g., ChatGPT, fall short.""",2024
Assessing Logical Puzzle Solving in Large Language Models: Insights from a Minesweeper Case Study,Yes.,5.,"""Despite these advancements, it remains an open question whether LLMs are fundamentally capable of reasoning and planning, or if they primarily rely on recalling and synthesizing information from their training data."" and ""Our experiments, including trials with the advanced GPT-4 model, indicate that while LLMs possess the foundational abilities required for this task, they struggle to integrate these into a coherent,",2024
On Linearizing Structured Data in Encoder-Decoder Language Models: Insights from Text-to-SQL,Yes.,3.,"""Crucially, there remains a gap in our understanding of how these linearization-based methods handle structured data, which is inherently non-linear.""",2024
Measuring and Improving Chain-of-Thought Reasoning in Vision-Language Models,Yes.,5.,"""even the best-performing model is unable to demonstrate strong visual reasoning capabilities and consistency, indicating that substantial efforts are required to enable VLMs to perform visual reasoning as systematically and consistently as humans.""",2024
Adaptive Rank Selections for Low-Rank Approximation of Language Models,Yes.,3.,"""However, such a uniform rank selection is sub-optimal since different operations (layers) have non-uniform demand in capacity."" and ""However, a globally-optimized selection of ranks for neural networks is still an open problem, and this is a non-trivial challenge since the selection is discrete.""",2024
Unleashing the Emergent Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration,Yes.,2.,"""experimental results demonstrate that SPP effectively reduces factual hallucination, and maintains strong reasoning capabilities. Additionally, comparative experiments show that cognitive synergy only emerges in GPT-4 and does not appear in less capable models, such as GPT-3.5-turbo and Llama2-13b-chat.""",2024
Self-Prompting Large Language Models for Zero-Shot Open-Domain QA,Yes.,3.,"""While recent Large Language Models (LLMs) like GPT-3 have demonstrated their effectiveness in zero-shot ODQA using direct prompting methods, these methods still fall short of fully harnessing the potential of LLMs when implicitly invoked.""",2024
Head-to-Tail: How Knowledgeable are Large Language Models (LLMs)? A.K.A. Will LLMs Replace Knowledge Graphs?,Yes.,5.,"""we show that existing LLMs are still far from being perfect in terms of their grasp of factual knowledge, especially for facts of torso-to-tail entities.""",2024
LLMs Are Few-Shot In-Context Low-Resource Language Learners,Yes.,3.,"""Nonetheless, there is only a handful of works explored ICL for low-resource languages with most of them focusing on relatively high-resource languages, such as French and Spanish."" and ""identifies the shortcomings of in-context label alignment, and introduces a more effective alternative",2024
Rethinking Tabular Data Understanding with Large Language Models,Yes.,3.,"""We discover that structural variance of tables presenting the same content reveals a notable performance decline, particularly in symbolic reasoning tasks.""",2024
FLAP: Flow-Adhering Planning with Constrained Decoding in LLMs,Yes.,3.,"""However, the faithfulness of the plans to predefined workflows and API dependencies, is not guaranteed with LLMs.""",2024
Embrace Divergence for Richer Insights: A Multi-document Summarization Benchmark and a Case Study on Summarizing Diverse Information from News Articles,Yes.,5.,"""Our analyses suggest that despite the extraordinary capabilities of LLMs in single-document summarization, the proposed task remains a complex challenge for them mainly due to their limited coverage, with GPT-4 only able to cover under 40% of the diverse information on average.""",2024
ALoRA: Allocating Low-Rank Adaptation for Fine-tuning Large Language Models,Yes.,1.,"""Parameter-efficient fine-tuning (PEFT) is widely studied for its effectiveness and efficiency in the era of large language models.""",2024
InsCL: A Data-efficient Continual Learning Paradigm for Fine-tuning Large Language Models with Instructions,Yes.,3.,"""LLMs necessitate continual task-specific adaptation without catastrophic forgetting."" and ""traditional replay-based methods do not fully utilize instructions to customize the replay strategy.""",2024
An Examination of the Compositionality of Large Generative Vision-Language Models,Yes.,4.,"""We identify the syntactical bias in current benchmarks, which is exploited by the linguistic capability of GVLMs. The bias renders VisualGPTScore an insufficient metric for assessing GVLMs.""",2024
Two Heads are Better than One: Nested PoE for Robust Defense Against Multi-Backdoors,Yes.,3.,"""Data poisoning backdoor attacks can cause undesirable behaviors in large language models (LLMs), and defending against them is of increasing importance.""",2024
VertAttack: Taking Advantage of Text Classifiers’ Horizontal Vision,,,,2024
BeLLM: Backward Dependency Enhanced Large Language Model for Sentence Embeddings,Yes.,3.,"""Existing LLMs mainly adopted autoregressive architecture without explicit backward dependency modeling.""",2024
Assessing Factual Reliability of Large Language Model Knowledge,Yes.,5.,"""The factual knowledge of LLMs is typically evaluated using accuracy, yet this metric does not capture the vulnerability of LLMs to hallucination-inducing factors like prompt and context variability.""",2024
Toolink: Linking Toolkit Creation and Using through Chain-of-Solving on Open-Source Model,Yes.,3.,"""Large Language Models (LLMs) have demonstrated remarkable progress in utilizing tools, but their closed-source nature and high inference costs pose limitations on their adaptability, necessitating a valid method that leverages smaller, open-sourced models.""",2024
Neurocache: Efficient Vector Retrieval for Long-range Language Modeling,Yes.,1.,"""This paper introduces Neurocache, an approach to extend the effective context size of large language models (LLMs) using an external vector cache to store its past states.""",2024
Unveiling the Generalization Power of Fine-Tuned Large Language Models,,,,2024
A Closer Look at the Self-Verification Abilities of Large Language Models in Logical Reasoning,Yes.,5.,"""Despite significant advancements made by large language models (LLMs), they still struggle with complex logical reasoning problems."" and ""Our main findings suggest that existing LLMs could struggle to identify fallacious reasoning steps accurately and may fall short of guaranteeing the validity of self-verification methods",2024
Exploring Self-supervised Logic-enhanced Training for Large Language Models,Yes.,3.,"""Yet, our experiments reveal a gap in their performance on logical reasoning benchmarks when compared to state-of-the-art fine-tuning based models.""",2024
MATHSENSEI: A Tool-Augmented Large Language Model for Mathematical Reasoning,Yes.,3.,"""We further observe that TALMs are not as effective for simpler math word problems (in GSM-8K), and the benefit increases as the complexity and required knowledge increases (progressively over AQuA, MMLU-Math, and higher level complex questions in MATH).""",2024
On Large Language Models’ Hallucination with Regard to Known Facts,Yes.,5.,"""Large language models are successful in answering factoid questions but are also prone to hallucination."" and ""We investigate the phenomenon of LLMs possessing correct answer knowledge yet still hallucinating from the perspective of inference dynamics.""",2024
"Language Models Hallucinate, but May Excel at Fact Verification",Yes.,5.,"""LLMs frequently “hallucinate,” resulting in non-factual outputs,"" and ""analyze the reliance of these LLMs on high-quality evidence, as well as their deficiencies in robustness and generalization ability.""",2024
Ensuring Safe and High-Quality Outputs: A Guideline Library Approach for Language Models,Yes.,5.,"""Large Language Models (LLMs) exhibit impressive capabilities but also present risks such as biased content generation and privacy issues.""",2024
"E5: Zero-shot Hierarchical Table Analysis using Augmented LLMs via Explain, Extract, Execute, Exhibit and Extrapolate",Yes.,4.,"""their application to hierarchical tables is constrained by the reliance on manually curated exemplars and the model’s token capacity limitations.""",2024
"S3Eval: A Synthetic, Scalable, Systematic Evaluation Suite for Large Language Model",Yes.,5.,"""The rapid development of Large Language Models (LLMs) has led to great strides in model capabilities like long-context understanding and reasoning. However, as LLMs are able to process longer contexts, it becomes more challenging to evaluate whether they have acquired certain capabilities, since the length",2024
MMC: Advancing Multimodal Chart Understanding with Large-scale Instruction Tuning,Yes.,4.,"""Extensive experiments on MMC-Benchmark reveal the limitations of existing LMMs on correctly interpreting charts, even for the most recent GPT-4V model.""",2024
AutoPRM: Automating Procedural Supervision for Multi-Step Reasoning via Controllable Question Decomposition,Yes.,3.,"""Recent advancements in large language models (LLMs) have shown promise in multi-step reasoning tasks, yet their reliance on extensive manual labeling to provide procedural feedback remains a significant impediment.""",2024
SEMQA: Semi-Extractive Multi-Source Question Answering,Yes.,3.,"""Yet, attributing and verifying their generated abstractive answers can be difficult, and automatically evaluating their accuracy remains an ongoing challenge.""",2024
Fine-Tuning Language Models with Reward Learning on Policy,Yes.,3.,"""Despite its popularity, however, (fixed) reward models may suffer from inaccurate off-distribution, since policy optimization continuously shifts LLMs’ data distribution.""",2024
IterAlign: Iterative Constitutional Alignment of Large Language Models,Yes.,3.,"""However, these methods require either heavy human annotations or explicitly pre-defined constitutions, which are labor-intensive and resource-consuming.""",2024
Large Language Models Help Humans Verify Truthfulness – Except When They Are Convincingly Wrong,Yes.,5.,"""Users reading LLM explanations are significantly more efficient than those using search engines while achieving similar accuracy. However, they over-rely on the LLMs when the explanation is wrong."" and ""natural language explanations by LLMs may not be a reliable replacement for reading the retrieved",2024
Evaluating Large Language Models as Generative User Simulators for Conversational Recommendation,Yes.,3.,"""Through evaluation of baseline simulators, we demonstrate these tasks effectively reveal deviations of language models from human behavior, and offer insights on how to reduce the deviations with model selection and prompting strategies.""",2024
JAMDEC: Unsupervised Authorship Obfuscation using Constrained Decoding over Small Language Models,Yes.,3.,"""Our approach builds on small language models such as GPT2-XL in order to help avoid disclosing the original content to proprietary LLM’s APIs, while also reducing the performance gap between small and large language models via algorithmic enhancement.""",2024
MSciNLI: A Diverse Benchmark for Scientific Natural Language Inference,Yes.,3.,"""Furthermore, we show that domain shift degrades the performance of scientific NLI models which demonstrates the diverse characteristics of different domains in our dataset.""",2024
SELF-GUARD: Empower the LLM to Safeguard Itself,Yes.,4.,"""Safety training involves fine-tuning the LLM with adversarial samples, which activate the LLM’s capabilities against jailbreak. However, it is not always effective in countering new attacks and often leads to potential performance degradation."" and ""Safeguards, on the other hand, are methods using",2024
COSIGN: Contextual Facts Guided Generation for Knowledge Graph Completion,Yes.,1.,"""a contextual facts organizer is proposed to learn the organized capabilities of LLMs through knowledge distillation.""",2024
Toward Informal Language Processing: Knowledge of Slang in Large Language Models,Yes.,1.,"""Recent advancement in large language models (LLMs) has offered a strong potential for natural language systems to process informal language.""",2024
Ghostbuster: Detecting Text Ghostwritten by Large Language Models,Yes.,1.,"""We introduce Ghostbuster, a state-of-the-art system for detecting AI-generated text.""",2024
End-to-End Beam Retrieval for Multi-Hop Question Answering,Yes.,1.,"""To establish a complete QA system, we incorporate a supervised reader or a large language model (LLM).""",2024
Leveraging Generative Large Language Models with Visual Instruction and Demonstration Retrieval for Multimodal Sarcasm Detection,Yes.,1.,"""we propose a generative multimodal sarcasm model consisting of a designed instruction template and a demonstration retrieval module based on the large language model.""",2024
Ungrammatical-syntax-based In-context Example Selection for Grammatical Error Correction,Yes.,3.,"""However, applying LLMs to grammatical error correction (GEC) is still a challenging task.""",2024
BUFFET: Benchmarking Large Language Models for Few-shot Cross-lingual Transfer,Yes.,3.,"""Our findings reveal significant room for improvement in few-shot in-context cross-lingual transfer. Strong multilingual pre-trained or instruction-tuned models such as BLOOM or ChatGPT often lag behind much smaller mT5-base models given the same number of few-shot samples, particularly in low-resource languages.""",2024
zrLLM: Zero-Shot Relational Learning on Temporal Knowledge Graphs with Large Language Models,Yes.,3.,"""they face a strong challenge in modeling the unseen zero-shot relations that have no prior graph context.""",2024
Embodied Executable Policy Learning with Language-based Scene Summarization,Yes.,3.,"""the performance of pretrained LLMs heavily relies on domain-specific templated text data, which may be infeasible in real-world robot learning tasks with image-based observations. Moreover, existing LLMs with text inputs lack the capability to evolve with non-expert interactions with environments.""",2024
Metacognitive Prompting Improves Understanding in Large Language Models,Yes.,3.,"""the nuanced understanding abilities of these models, crucial for processing and interpreting complex information, remain underexplored.""",2024
MART: Improving LLM Safety with Multi-round Automatic Red-Teaming,Yes.,4.,"""Red-teaming is a common practice for mitigating unsafe behaviors in Large Language Models (LLMs), which involves thoroughly assessing LLMs to identify potential flaws and addressing them with responsible and accurate responses. While effective, manual red-teaming is costly, and existing automatic red-teaming typically discovers safety risks",2024
Are Multilingual LLMs Culturally-Diverse Reasoners? An Investigation into Multicultural Proverbs and Sayings,Yes.,5.,"""Our experiments reveal that",2024
The Colorful Future of LLMs: Evaluating and Improving LLMs as Emotional Supporters for Queer Youth,Yes.,5.,"""However, they tend to be generic, not empathetic enough, and lack personalization, resulting in nonreliable and potentially harmful advice.""",2024
QualEval: Qualitative Evaluation for Model Improvement,Yes.,2.,"""Quantitative evaluation metrics have been pivotal in gauging the advancements of AI systems like large language models (LLMs). However, due to the intricate nature of real-world tasks, a single scalar to quantify and compare performance trivializes the fine-grained nuances of model behavior.""",2024
A Wolf in Sheep’s Clothing: Generalized Nested Jailbreak Prompts can Fool Large Language Models Easily,,,,2024
Bridging the Novice-Expert Gap via Models of Decision-Making: A Case Study on Remediating Math Mistakes,Yes.,1.,"""Our work explores the potential of large language models (LLMs) to close the novice-expert knowledge gap in remediating math mistakes.""",2024
ReTA: Recursively Thinking Ahead to Improve the Strategic Reasoning of Large Language Models,Yes.,5.,"""Experimental results demonstrate that existing state-of-the-art LLMs and reasoning schemes are largely ineffective for strategic reasoning tasks.""",2024
Program-Aided Reasoners (Better) Know What They Know,Yes.,3.,"""However, while accuracy is essential, it is also important for such reasoners to 'know what they know', which can be quantified through the calibration of the model.""",2024
"First Tragedy, then Parse: History Repeats Itself in the New Era of Large Language Models",Yes.,4.,"""We argue that disparities in scale are transient and researchers can work to reduce them; that data, rather than hardware, is still a bottleneck for many applications; that meaningful realistic evaluation is still an open problem; and that there is still room for speculative approaches.""",2024
Found in the Middle: Permutation Self-Consistency Improves Listwise Ranking in Large Language Models,Yes.,5.,"""Large language models (LLMs) exhibit positional bias in how they use context, which especially affects listwise ranking.""",2024
From Language Modeling to Instruction Following: Understanding the Behavior Shift in LLMs after Instruction Tuning,Yes.,1.,"""Large Language Models (LLMs) have achieved remarkable success, where instruction tuning is the critical step in aligning LLMs with user intentions.""",2024
LLM-based Medical Assistant Personalization with Short- and Long-Term Memory Coordination,Yes.,3.,"""the resource consumption is unaffordable"" and ""a mere memory module is inadequate and fully training an LLM can be excessively costly.""",2024
How Well Do Large Language Models Truly Ground?,Yes.,5.,"""To reduce issues like hallucinations and lack of control in Large Language Models (LLMs),"" and ""We perform experiments across 25 LLMs of different sizes and training methods and provide insights into factors that influence grounding performance.""",2024
MILL: Mutual Verification with Large Language Models for Zero-Shot Query Expansion,Yes.,3.,"""Generation-based methods, utilizing large language models (LLMs), generally lack corpus-specific knowledge and entail high fine-tuning costs.""",2024
PaD: Program-aided Distillation Can Teach Small Models Reasoning Better than Chain-of-thought Fine-tuning,Yes.,3.,"""While large language models (LLMs) excel in various natural language processing tasks, their huge size and the inaccessibility of parameters present challenges for practical deployment.""",2024
"MEGAVERSE: Benchmarking Large Language Models Across Languages, Modalities, Models and Tasks",Yes.,3.,"""There has been a surge in LLM evaluation research to understand LLM capabilities and limitations."" and ""We also perform a study on data contamination and find that several models are likely to be contaminated with multilingual evaluation benchmarks, necessitating approaches to detect and handle contamination while assessing the",2024
Unlocking Emergent Modularity in Large Language Models,Yes.,2.,"""Despite the benefits of modularity, most Language Models (LMs) are still treated as monolithic models in the pre-train and fine-tune paradigm, with their emergent modularity locked and underutilized.""",2024
PatentEval: Understanding Errors in Patent Generation,Yes.,3.,"""These approaches provide valuable insights into the capabilities and limitations of current language models in the specialized field of patent text generation.""",2024
Contextual Refinement of Translations: Large Language Models for Sentence and Document-Level Post-Editing,Yes.,3.,"""Large language models (LLMs) have demonstrated considerable success in various natural language processing tasks, but open-source LLMs have yet to attain state-of-the-art performance in Neural Machine Translation (NMT)."" and ""Surprisingly, our initial experiments found that fine-tuning",2024
How Trustworthy are Open-Source LLMs? An Assessment under Malicious Demonstrations Shows their Vulnerabilities,Yes.,5.,"""However, there is still a limited understanding of their trustworthiness"" and ""scrutinizing them across eight different aspects including toxicity, stereotypes, ethics, hallucination, fairness, sycophancy, privacy, and robustness against adversarial demonstrations"" and ""our result analysis reveals that models with superior performance in general NLP tasks do not always have greater trustworthiness; in fact, larger",2024
Paraphrase and Solve: Exploring and Exploiting the Impact of Surface Form on Mathematical Reasoning in Large Language Models,Yes.,5.,"""We find that subtle alterations in the surface form can significantly impact the answer distribution and the solve rate, exposing the language model’s lack of robustness and sensitivity to the surface form in reasoning through complex problems.""",2024
TriSum: Learning Summarization Ability from Large Language Models with Structured Rationale,Yes.,3.,"""However, their large size and computational demands, coupled with privacy concerns in data transmission, limit their use in resource-constrained and privacy-centric settings.""",2024
GenRES: Rethinking Evaluation for Generative Relation Extraction in the Era of Large Language Models,Yes.,3.,"""prompting LLMs with a fixed set of relations or entities can cause hallucinations.""",2024
TopicGPT: A Prompt-based Topic Modeling Framework,Yes.,1.,"""we introduce TopicGPT, a prompt-based framework that uses large language models (LLMs) to uncover latent topics in a text collection.""",2024
ChatGPT as an Attack Tool: Stealthy Textual Backdoor Attack via Blackbox Generative Model Trigger,Yes.,1.,"""The rise of advanced generative models, such as GPT-4, with their capacity for human-like rewriting, makes these attacks increasingly challenging to detect.""",2024
LoRETTA: Low-Rank Economic Tensor-Train Adaptation for Ultra-Low-Parameter Fine-Tuning of Large Language Models,Yes.,3.,"""existing PEFT methods are still limited by the growing number of trainable parameters with the rapid deployment of Large Language Models (LLMs).""",2024
Do Localization Methods Actually Localize Memorized Data in LLMs? A Tale of Two Benchmarks,Yes.,4.,"""methods for localization have never been systematically and directly evaluated"" and ""even successful methods identify neurons that are not specific to a single memorized sequence.""",2024
Instructional Fingerprinting of Large Language Models,,,,2024
Uncertainty Quantification for In-Context Learning of Large Language Models,Yes.,3.,"""trustworthy issues with LLM’s response, such as hallucination, have also been actively discussed"" and ""highlighting that such uncertainties may stem from both the provided demonstrations (aleatoric uncertainty) and ambiguities tied to the model’s configurations (epistemic uncertainty).""",2024
HelpSteer: Multi-attribute Helpfulness Dataset for SteerLM,Yes.,3.,"""Existing open-source helpfulness preference datasets do not specify what makes some responses more helpful and others less so. Models trained on these datasets can incidentally learn to model dataset artifacts (e.g. preferring longer but unhelpful responses only due to their length).""",2024
A Preference-driven Paradigm for Enhanced Translation with Large Language Models,Yes.,3.,"""SFT simply instructs the model to imitate the reference translations at the token level, making it vulnerable to the noise present in the references. Hence, the assistance from SFT often reaches a plateau once the LLMs have achieved a certain level of translation capability, and further increasing the size of parallel data",2024
Fair Abstractive Summarization of Diverse Perspectives,Yes.,4.,"""Experiments show that both the model-generated and the human-written reference summaries suffer from low fairness.""",2024
Making Language Models Better Tool Learners with Execution Feedback,Yes.,3.,"""Existing tool learning methodologies, encompassing supervised fine-tuning and prompt engineering approaches, often induce large language models to utilize tools indiscriminately, as complex tasks often exceed their own competencies. However, introducing tools for simple tasks, which the models themselves can readily resolve, can inadvertently propagate errors rather than enhance performance.""",2024
Confronting LLMs with Traditional ML: Rethinking the Fairness of Large Language Models in Tabular Classifications,Yes.,5.,"""LLMs have been shown to exhibit harmful social biases that reflect the stereotypes and inequalities present in society."" and ""LLMs tend to inherit social biases from their training data which significantly impact their fairness in tabular classification tasks."" and ""the social",2024
Ada-LEval: Evaluating long-context LLMs with length-adaptable benchmarks,Yes.,5.,"""The evaluation results demonstrate the limitations of current LLMs, especially in ultra-long-context settings.""",2024
Long-form evaluation of model editing,Yes.,3.,"""while some methods (ROME and MEMIT) perform well in making consistent edits within a limited scope, they suffer much more from factual drift than other methods.""",2024
Analyzing the Role of Semantic Representations in the Era of Large Language Models,Yes.,3.,"""We find that it is difficult to predict which input examples AMR may help or hurt on, but errors tend to arise with multi-word expressions, named entities, and in the final inference step where the LLM must connect its reasoning over the AMR to its prediction.""",2024
TRAQ: Trustworthy Retrieval Augmented Question Answering via Conformal Prediction,Yes.,5.,"""large language models (LLMs) frequently generate incorrect responses based on made-up facts, which are called hallucinations.""",2024
On-the-fly Definition Augmentation of LLMs for Biomedical NER,Yes.,5.,"""Despite their general capabilities, LLMs still struggle on biomedical NER tasks, which are difficult due to the presence of specialized terminology and lack of training data.""",2024
"This Land is Your, My Land: Evaluating Geopolitical Bias in Language Models through Territorial Disputes",Yes.,5.,"""we show that LLMs recall certain geographical knowledge inconsistently when queried in different languages—a phenomenon we term geopolitical bias,"" and ""use the proposed metrics to discover numerous inconsistencies in how these models respond in different languages,"" and ""highlights how brittle LLMs are and how they tailor their responses depending on cues from the interaction context.""",2024
Set-Aligning Framework for Auto-Regressive Event Temporal Graph Generation,Yes.,3.,"""these methods have often led to suboptimal graph generation as the linearised graphs exhibit set characteristics which are instead treated sequentially by language models. This discrepancy stems from the conventional text generation objectives, leading to erroneous penalisation of correct predictions caused by the misalignment of elements in target sequences.""",2024
Towards Improved Multi-Source Attribution for Long-Form Answer Generation,Yes.,5.,"""current LLMs struggle with attribution for long-form responses which require reasoning over multiple evidence sources.""",2024
Can Knowledge Graphs Reduce Hallucinations in LLMs? : A Survey,Yes.,5.,"""The contemporary LLMs are prone to producing hallucinations, stemming mainly from the knowledge gaps within the models.""",2024
Take One Step at a Time to Know Incremental Utility of Demonstration: An Analysis on Reranking for Few-Shot In-Context Learning,Yes.,1.,"""In-Context Learning (ICL) is an emergent capability of Large Language Models (LLMs).""",2024
LM-Infinite: Zero-Shot Extreme Length Generalization for Large Language Models,Yes.,5.,"""Today’s large language models (LLMs) typically train on short text segments (e.g., <4K tokens) due to the quadratic complexity of their Transformer architectures. As a result, their performance suffers drastically on inputs longer than those encountered during training, substantially limiting their applications in real-world",2024
CONSCENDI: A Contrastive and Scenario-Guided Distillation Approach to Guardrail Models for Virtual Assistants,Yes.,2.,"""A major challenge in deploying LLM-based virtual conversational assistants in real world settings is ensuring they operate within what is admissible for the task."" and ""relying on commonly used, prompt-based guardrails can be difficult to engineer correctly and comprehensively",2024
DoG-Instruct: Towards Premium Instruction-Tuning Data via Text-Grounded Instruction Wrapping,Yes.,3.,"""Unfortunately, the current methods used to collect the pairs suffer from either unaffordable labor costs or severe hallucinations in the self-generation of LLM.""",2024
MDR: Model-Specific Demonstration Retrieval at Inference Time for In-Context Learning,Yes.,3.,"""distinct LLMs exhibit different biases for 'what is a good demonstration' since they possess differences in training data, model architectures and training methods"" and ""Previous approaches ignore the model bias and fail to retrieve the most appropriate demonstrations for different inference LLMs, resulting in a degradation of ICL performance.""",2024
Exploring Cross-Cultural Differences in English Hate Speech Annotations: From Dataset Construction to Analysis,Yes.,3.,"""Lastly, we evaluate large language models (LLMs) under a zero-shot setting and show that current LLMs tend to show higher accuracies on Anglosphere country labels in CREHate.""",2024
Enhancing Contextual Understanding in Large Language Models through Contrastive Decoding,Yes.,5.,"""Large language models (LLMs) tend to inadequately integrate input context during text generation, relying excessively on encoded prior knowledge in model parameters, potentially resulting in generated text with factual inconsistencies or contextually unfaithful content.""",2024
Rectifying Demonstration Shortcut in In-Context Learning,Yes.,3.,"""LLMs often rely on their pre-trained semantic priors of demonstrations rather than on the input-label relationships to proceed with ICL prediction.""",2024
Differentially Private Next-Token Prediction of Large Language Models,Yes.,3.,"""DP-SGD overestimates an adversary’s capabilities in having white box access to the model and, as a result, causes longer training times and larger memory usage than SGD.""",2024
"Impossible Distillation for Paraphrasing and Summarization: How to Make High-quality Lemonade out of Small, Low-quality Model",Yes.,1.,"""Unlike prior works that rely on an extreme-scale teacher model (e.g., GPT3) or task-specific architecture, we hypothesize and verify the paraphrastic proximity intrinsic to pre-trained LMs (e.g., GPT2),",2024
TofuEval: Evaluating Hallucinations of LLMs on Topic-Focused Dialogue Summarization,,,,2024
Fixing Rogue Memorization in Many-to-One Multilingual Translators of Extremely-Low-Resource Languages by Rephrasing Training Samples,Yes.,5.,"""However, we also found that many-to-one multilingual systems have a tendency to learn a 'rogue' strategy of storing output strings from the training data in the LLM structure and retrieving them instead of performing actual translations.""",2024
Flames: Benchmarking Value Alignment of LLMs in Chinese,Yes.,4.,"""there is still a significant gap in LLMs’ deeper alignment with human values and achieving genuine harmlessness"" and ""Our findings indicate that all the evaluated LLMs demonstrate relatively poor performance on Flames, particularly in the safety and fairness dimensions.""",2024
Effective Long-Context Scaling of Foundation Models,Yes.,5.,"""We delve into Llama’s position encodings and discuss its key limitation in modeling long data.""",2024
Aligning as Debiasing: Causality-Aware Alignment via Reinforcement Learning with Interventional Feedback,Yes.,5.,"""Large language models (LLMs) often generate biased outputs containing offensive, toxic, or stereotypical text.""",2024
Fake Alignment: Are LLMs Really Aligned Well?,Yes.,5.,"""This study investigates an under-explored issue about the evaluation of LLMs, namely the substantial discrepancy in performance between multiple-choice questions and open-ended questions.""",2024
"In-context Learning Generalizes, But Not Always Robustly: The Case of Syntax",Yes.,5.,"""Do models guided via ICL infer the underlying structure of the task defined by the context, or do they rely on superficial heuristics that only generalize to identically distributed examples?"" and ""we find large variance across LMs. The variance is explained more by the composition of the pre",2024
Anisotropy is Not Inherent to Transformers,,,,2024
Stealthy and Persistent Unalignment on Large Language Models via Backdoor Injections,Yes.,4.,"""While being effective, such fine-tuning-based unalignment approaches also have their own limitations",2024
Leveraging Code to Improve In-Context Learning for Semantic Parsing,,,,2024
SportQA: A Benchmark for Sports Understanding in Large Language Models,Yes.,3.,"""Our results reveal that while LLMs exhibit competent performance in basic sports knowledge, they struggle with more complex, scenario-based sports reasoning, lagging behind human expertise.""",2024
Revisiting subword tokenization: A case study on affixal negation in large language models,Yes.,3.,"""the negated meaning is expressed through a negative morpheme, which is potentially challenging for LLMs as their tokenizers are often not morphologically plausible.""",2024
Teaching Language Models to Self-Improve through Interactive Demonstrations,Yes.,3.,"""However, this ability has been shown to be absent and difficult to learn for smaller models, thus widening the performance gap between state-of-the-art LLMs and more cost-effective and faster ones.""",2024
MAGID: An Automated Pipeline for Generating Synthetic Multi-modal Datasets,Yes.,1.,"""Development of multimodal interactive systems is hindered by the lack of rich, multimodal (text, images) conversational data, which is needed in large quantities for LLMs.""",2024
Does GPT-4 pass the Turing test?,Yes.,3.,"""Despite known limitations as a test of intelligence, we argue that the Turing test continues to be relevant as an assessment of naturalistic communication and deception.""",2024
You don’t need a personality test to know these models are unreliable: Assessing the Reliability of Large Language Models on Psychometric Instruments,Yes.,5.,"""Our experiments on 17 different LLMs reveal that even simple perturbations significantly downgrade a model’s question-answering ability, and that most LLMs have low negation consistency.""",2024
MacGyver: Are Large Language Models Creative Problem Solvers?,Yes.,5.,"""In contrast, LLMs, exposed to a variety of specialized knowledge, attempt broader problems but fail by proposing physically-infeasible actions."" and ""Finally, we provide a detailed error analysis of LLMs, and demonstrate the potential of enhancing their problem-solving ability with novel prompting techniques such as iterative step",2024
Enhancing Large Language Models Against Inductive Instructions with Dual-critique Prompting,Yes.,5.,"""we uncovered a universal vulnerability among LLMs in processing inductive instructions.""",2024
GLiNER: Generalist Model for Named Entity Recognition using Bidirectional Transformer,Yes.,3.,"""However, their size and cost, particularly for those accessed via APIs like ChatGPT, make them impractical in resource-limited scenarios."" and ""an advantage over the slow sequential token generation of LLMs.""",2024
XSTest: A Test Suite for Identifying Exaggerated Safety Behaviours in Large Language Models,Yes.,5.,"""Without proper safeguards, large language models will readily follow malicious instructions and generate toxic content."" and ""we use the test suite to highlight systematic failure modes in state-of-the-art language models as well as more general challenges in building safer language models.""",2024
Fine-grained Gender Control in Machine Translation with Large Language Models,Yes.,3.,"""we discover an emergence of gender interference phenomenon when controlling the gender of multiple entities"" and ""address the limitations of existing gender accuracy evaluation metrics.""",2024
LLatrieval: LLM-Verified Retrieval for Verifiable Generation,Yes.,3.,"""the widely used retrievers become the bottleneck of the entire pipeline and limit the overall performance. Their capabilities are usually inferior to LLMs since they often have much fewer parameters than the large language model and have not been demonstrated to scale well to the size of LLMs.""",2024
Evidence-Driven Retrieval Augmented Response Generation for Online Misinformation,Yes.,3.,"""existing methods are often trained end-to-end without leveraging external knowledge, resulting in subpar text quality and excessively repetitive responses.""",2024
Understanding the Capabilities and Limitations of Large Language Models for Cultural Commonsense,Yes.,5.,"""LLMs have a significant discrepancy in performance when tested on culture-specific commonsense knowledge for different cultures;"" and ""LLMs’ general commonsense capability is affected by cultural context;"" and ""The language used to query the LLMs can impact their performance on cultural-related tasks.""",2024
Do Large Language Models Rank Fairly? An Empirical Study on the Fairness of LLMs as Rankers,Yes.,4.,"""However, their fairness remains largely unexplored."" and ""Our analysis delves into how these LLMs handle queries and documents related to these attributes, aiming to uncover biases in their ranking algorithms.""",2024
TabSQLify: Enhancing Reasoning Capabilities of LLMs Through Table Decomposition,Yes.,5.,"""Large language models (LLMs) have shown impressive capabilities in natural language understanding and generation, but they often struggle with large tables due to their limited input length.""",2024
RESPROMPT: Residual Connection Prompting Advances Multi-Step Reasoning in Large Language Models,Yes.,5.,"""Chain-of-thought (CoT) has impressively unlocked the reasoning potential of large language models (LLMs). Yet, it falls short when tackling problems that require multiple reasoning steps. This limitation arises from the complex nature of multi-step reasoning processes",2024
"The ART of LLM Refinement: Ask, Refine, and Trust",Yes.,3.,"""recent empirical evidence points in the opposite direction, suggesting that LLMs often struggle to accurately identify errors when reasoning is involved.""",2024
ParallelPARC: A Scalable Pipeline for Generating Natural-Language Analogies,Yes.,3.,"""We test LLMs’ and humans’ analogy recognition in binary and multiple-choice settings, and found that humans outperform the best models (∼13% gap) after a light supervision."" and ""Lastly, we show challenging distractors confuse LLMs, but not humans.""",2024
TableLlama: Towards Open Large Generalist Models for Tables,Yes.,1.,"""We further develop the first open-source generalist model for tables, TableLlama, by fine-tuning Llama 2 (7B) with LongLoRA to address the long context challenge.""",2024
Backdooring Instruction-Tuned Large Language Models with Virtual Prompt Injection,Yes.,3.,"""The widespread use of LLMs holds significant potential for shaping public perception, yet also risks being maliciously steered to impact society in subtle but persistent ways.""",2024
Exploring the Factual Consistency in Dialogue Comprehension of Large Language Models,Yes.,5.,"""Our evaluation shows that, on average, 26.8% of the summaries generated by LLMs contain factual inconsistency. Even ChatGPT, the strongest model evaluated, has such errors in 16% of its summaries. For answering the factual questions, which is more challenging, the",2024
"Multilingual Pretraining and Instruction Tuning Improve Cross-Lingual Knowledge Alignment, But Only Shallowly",Yes.,5.,"""current large language models show imbalance abilities in different languages"" and ""the overall cross-lingual knowledge alignment, especially in the conductivity level, is unsatisfactory for all tested LLMs, and neither multilingual pretraining nor instruction tuning can substantially improve the cross-lingual knowledge conductivity.""",2024
DialogBench: Evaluating LLMs as Human-like Dialogue Systems,Yes.,3.,"""instruction tuning improves the human likeness of LLMs to a certain extent, but most LLMs still have much room for improvement as human-like dialogue systems."" and ""the positioning of assistant AI can make instruction tuning weaken the human emotional perception of LLMs and their mastery of information about human daily life.""",2024
CMB: A Comprehensive Medical Benchmark in Chinese,Yes.,1.,"""Large Language Models (LLMs) provide a possibility to make a great breakthrough in medicine.""",2024
SlimFit: Memory-Efficient Fine-Tuning of Transformer-based Models Using Training Dynamics,Yes.,2.,"""Transformer-based models, such as BERT and ViT, have achieved state-of-the-art results across different natural language processing (NLP) and computer vision (CV) tasks. However, these models are extremely memory intensive during their fine-tuning process, making them difficult to deploy on GPUs with limited memory resources.""",2024
Effective Large Language Model Adaptation for Improved Grounding and Citation Generation,Yes.,4.,"""However, one major issue towards their widespread deployment in the real world is that they can generate 'hallucinated' answers that are not factual.""",2024
Assisting in Writing Wikipedia-like Articles From Scratch with Large Language Models,Yes.,2.,"""The expert feedback also helps identify new challenges for generating grounded long articles, such as source bias transfer and over-association of unrelated facts.""",2024
Grounding Gaps in Language Model Generations,Yes.,5.,"""We find that—compared to humans—LLMs generate language with less conversational grounding, instead generating text that appears to simply presume common ground.""",2024
Language Model Based Unsupervised Dependency Parsing with Conditional Mutual Information and Grammatical Constraints,Yes.,3.,"""Previous methods based on Large Language Models (LLM) perform unsupervised dependency parsing by maximizing bi-lexical dependence scores. However, these previous methods adopt dependence scores that are difficult to interpret. These methods cannot incorporate grammatical constraints that previous grammar-based parsing research has shown beneficial to",2024
Global Gallery: The Fine Art of Painting Culture Portraits through Multilingual Instruction Tuning,Yes.,4.,"""they also uncover inconsistencies and biases, particularly in non-Western cultures.""",2024
MT-PATCHER: Selective and Extendable Knowledge Distillation from Large Language Models for Machine Translation,Yes.,3.,"""Large Language Models (LLM) have demonstrated their strong ability in the field of machine translation, yet they suffer from high computational cost and latency.""",2024
LinkPrompt: Natural and Universal Adversarial Attacks on Prompt-based Language Models,Yes.,2.,"""raising concerns about the adversarial vulnerability of this paradigm.""",2024
CoE-SQL: In-Context Learning for Multi-Turn Text-to-SQL with Chain-of-Editions,Yes.,1.,"""Recently, Large Language Models (LLMs) have been demonstrated to possess impressive capabilities in a variety of domains and tasks.""",2024
ContraDoc: Understanding Self-Contradictions in Documents with Large Language Models,Yes.,5.,"""While GPT4 performs the best and can outperform humans on this task, we find that it is still unreliable and struggles with self-contradictions that require more nuance and context.""",2024
PlanRAG: A Plan-then-Retrieval Augmented Generation for Generative Large Language Models as Decision Makers,Yes.,1.,"""In this paper, we conduct a study to utilize LLMs as a solution for decision making that requires complex data analysis.""",2024
A Survey of Confidence Estimation and Calibration in Large Language Models,Yes.,4.,"""Despite their impressive performance, they can be unreliable due to factual errors in their generations."" and ""we outline the challenges and we summarize recent technical advancements for LLM confidence estimation and calibration.""",2024
Not All Metrics Are Guilty: Improving NLG Evaluation by Diversifying References,,,,2024
ACLSum: A New Dataset for Aspect-based Summarization of Scientific Publications,Yes.,3.,"""the prompting-based approach with LLMs shows a limitation in extracting sentences from source documents.""",2024
Intent-conditioned and Non-toxic Counterspeech Generation using Multi-Task Instruction Tuning with RLAIF,Yes.,3.,"""These expressions challenge language models, especially in seq2seq tasks, as model performance typically excels with longer contexts.""",2024
"Attacks, Defenses and Evaluations for LLM Conversation Safety: A Survey",Yes.,4.,"""However, their risks of misuse for generating harmful responses have raised serious societal concerns and spurred recent research on LLM conversation safety.""",2024
Mind’s Mirror: Distilling Self-Evaluation Capability and Comprehensive Thinking from Large Language Models,Yes.,4.,"""the massive scale and computational demands of these models present formidable challenges when considering their practical deployment in resource-constrained environments"" and ""there is a risk that distilled SLMs may still inherit flawed reasoning and hallucinations from LLMs.""",2024
Divergent Token Metrics: Measuring degradation to prune away LLM components – and optimize quantization,Yes.,3.,"""However, their ever-increasing size has raised concerns about their effective deployment and the need for LLM compression."" and ""addressing the limitations of traditional perplexity or accuracy measures that fail to accurately reflect text generation quality.""",2024
Beyond Performance: Quantifying and Mitigating Label Bias in LLMs,Yes.,4.,"""However, recent work revealed they also exhibit *label bias*—an undesirable preference toward predicting certain answers over others."" and ""Our investigation reveals substantial label bias in models both before and after debiasing attempts."" and ""Our results emphasize that label bias in the predictions of LLMs remains a barrier to their reliability.""",2024
Instructing Large Language Models to Identify and Ignore Irrelevant Conditions,Yes.,5.,"""However, they were seriously confused by the irrelevant conditions, resulting in low accuracy.""",2024
On the Effectiveness of Adversarial Robustness for Abuse Mitigation with Counterspeech,No.,1.,The abstract does not mention LLMs or any specific type of language models.,2024
Leveraging the Structure of Pre-trained Embeddings to Minimize Annotation Effort,Yes.,2.,"""However, for some challenging classification tasks, providing enough annotations to ensure a reliable classification continues to be the main bottleneck.""",2024
Adaptive-RAG: Learning to Adapt Retrieval-Augmented Large Language Models through Question Complexity,Yes.,3.,"""they either handle simple queries with unnecessary computational overhead or fail to adequately address complex multi-step queries.""",2024
Knowing What LLMs DO NOT Know: A Simple Yet Effective Self-Detection Method,Yes.,5.,"""recent literature reveals that LLMs hallucinate intermittently, which impedes their reliability for further utilization.""",2024
Are Large Language Model Temporally Grounded?,Yes.,5.,"""Generally, we find that LLMs lag significantly behind both human performance as well as small-scale, specialised LMs."" and ""Crucially, LLMs struggle the most with self-consistency, displaying incoherent behaviour in at least 27.23% of their predictions."" and ""Moreover, public instruction",2024
R-Tuning: Instructing Large Language Models to Say ‘I Don’t Know’,Yes.,5.,"""A predominant issue is the propensity for these models to generate non-existent facts, a concern termed hallucination."" and ""When the question is out of the parametric knowledge, it will try to make up something and fail to indicate when it lacks knowledge.""",2024
Bridging the Gap between Different Vocabularies for LLM Ensemble,Yes.,3.,"""Nevertheless, vocabulary discrepancies among various LLMs have constrained previous studies to either selecting or blending completely generated outputs. This limitation hinders the dynamic correction and enhancement of outputs during the generation process, resulting in a limited capacity for effective ensemble.""",2024
Towards Reducing Diagnostic Errors with Interpretable Risk Prediction,Yes.,1.,"""In this work we propose a method to use LLMs to identify pieces of evidence in patient EHR data that indicate increased or decreased risk of specific diagnoses.""",2024
The steerability of large language models toward data-driven personas,Yes.,3.,"""Large language models (LLMs) are known to generate biased responses where the opinions of certain groups and populations are underrepresented.""",2024
CERET: Cost-Effective Extrinsic Refinement for Text Generation,Yes.,3.,"""Large Language Models (LLMs) are powerful models for generation tasks, but they may not generate good quality outputs in their first attempt."" and ""Despite their effectiveness, these methods are hindered by their high computational cost and lack of scalability.""",2024
LeanReasoner: Boosting Complex Logical Reasoning with Lean,Yes.,5.,"""Large language models (LLMs) often struggle with complex logical reasoning due to logical inconsistencies and the inherent difficulty of such reasoning.""",2024
UICoder: Finetuning Large Language Models to Generate User Interface Code through Automated Feedback,Yes.,4.,"""Many large language models (LLMs) struggle to consistently generate UI code that compiles and produces visually relevant designs.""",2024
MisgenderMender: A Community-Informed Approach to Interventions for Misgendering,Yes.,3.,"""highlighting challenges for future models to address"" and ""annotated for the presence of misgendering, with additional annotations for correcting misgendering in LLM-generated text.""",2024
From Quantity to Quality: Boosting LLM Performance with Self-Guided Data Selection for Instruction Tuning,Yes.,1.,"""In the realm of Large Language Models (LLMs), the balance between instruction data quality and quantity is a focal point.""",2024
Deceptive Semantic Shortcuts on Reasoning Chains: How Far Can Models Go without Hallucination?,Yes.,5.,"""Despite the high performances of large language models (LLMs) across numerous benchmarks, recent research has unveiled their suffering from hallucinations and unfaithful reasoning."" and ""Experiments show that existing LLMs cannot follow correct reasoning paths and resist the attempt of greedy shortcuts, with GPT-4 only achieving 62% accuracy.""",2024
Leveraging LLMs for Synthesizing Training Data Across Many Languages in Multilingual Dense Retrieval,Yes.,1.,"""SAP assists the LLM in generating informative queries in the target language.""",2024
A Theory Guided Scaffolding Instruction Framework for LLM-Enabled Metaphor Reasoning,Yes.,3.,"""LLM-based methods for metaphor detection and reasoning are still faced with the challenging issue of bringing the explainable concepts for metaphor reasoning and their linguistic manifestation.""",2024
Learning to Compress Prompt in Natural Language Formats,Yes.,5.,"""Large language models (LLMs) are great at processing multiple natural language processing tasks, but their abilities are constrained by inferior performance with long context, slow inference speed, and the high cost of computing the results.""",2024
Naive Bayes-based Context Extension for Large Language Models,Yes.,5.,"""conventional In-Context Learning (ICL) approaches are often impeded by length limitations of transformer architecture, which pose challenges when attempting to effectively integrate supervision from a substantial number of demonstration examples.""",2024
Actively Learn from LLMs with Uncertainty Propagation for Generalized Category Discovery,Yes.,1.,"""we propose to integrate the feedback from LLMs into an active learning paradigm.""",2024
Large Language Models can Contrastively Refine their Generation for Better Sentence Representation Learning,Yes.,3.,"""the effectiveness of these methods is largely influenced by the content generated from LLMs, highlighting the need for more refined generation in the context of sentence representation learning.""",2024
“You are an expert annotator”: Automatic Best–Worst-Scaling Annotations for Emotion Intensity Modeling,Yes.,3.,"""This raises the question if large language model-based annotation methods show similar patterns, namely that they perform worse on rating scale annotation tasks than on comparative annotation tasks.""",2024
What Matters in Training a GPT4-Style Language Model with Multimodal Inputs?,Yes.,2.,"""there is considerable scope for enhancing open-source multi-modal LLMs, especially in terms of multi-modal understanding accuracy and instruction-following proficiency.""",2024
Defining and Detecting Vulnerability in Human Evaluation Guidelines: A Preliminary Study Towards Reliable NLG Evaluation,Yes.,2.,"""We then introduce a taxonomy of eight vulnerabilities and formulate a principle for composing evaluation guidelines. Furthermore, a method for detecting guideline vulnerabilities has been explored using LLMs, and we offer a set of recommendations to enhance reliability in human evaluation.""",2024
SemRoDe: Macro Adversarial Training to Learn Representations that are Robust to Word-Level Attacks,Yes.,3.,"""Language models (LMs) are indispensable tools for natural language processing tasks, but their vulnerability to adversarial attacks remains a concern.""",2024
BUST: Benchmark for the evaluation of detectors of LLM-Generated Text,Yes.,1.,"""We introduce BUST, a comprehensive benchmark designed to evaluate detectors of texts generated by instruction-tuned large language models (LLMs).""",2024
"AceGPT, Localizing Large Language Models in Arabic",Yes.,3.,"""Significant concerns emerge when addressing cultural sensitivity and local values.""",2024
Depression Detection in Clinical Interviews with LLM-Empowered Structural Element Graph,Yes.,1.,"""Additionally, we further empower SEGA by devising novel principle-guided data augmentation with large language models (LLMs) to supplement high-quality synthetic data and enable graph contrastive learning.""",2024
ARM: Alignment with Residual Energy-Based Model,Yes.,3.,"""RLHF methods achieve successes in aligning LLM responses with human preferences and improving the controllability of LLM behavior with human instruction. However, RLHF methods are considerably complicated to implement, computationally expensive to train, and notoriously tricky to tune.""",2024
Branch-Solve-Merge Improves Large Language Model Evaluation and Generation,Yes.,5.,"""However, their performance can fall short, due to the model’s lack of coherence and inability to plan and decompose the problem.""",2024
Efficient End-to-End Visual Document Understanding with Rationale Distillation,Yes.,3.,"""However, such methods have high computational and engineering complexity.""",2024
Evaluating the Deductive Competence of Large Language Models,Yes.,5.,"""The tested LLMs have limited abilities to solve these problems in their conventional form."" and ""Overall, our results suggest that LLMs have unique reasoning biases that are only partially predicted from human reasoning performance and the human-generated language corpora that informs them.""",2024
Large Human Language Models: A Need and the Challenges,Yes.,4.,"""At the same time, our NLP systems have become heavily reliant on LLMs, most of which do not model authors."" and ""This brings to the fore a range of design considerations and challenges in terms of what human aspects to capture, how to represent them, and what modeling strategies to pursue.""",2024
On Learning to Summarize with Large Language Models as References,Yes.,3.,"""showing that LLMs are not well-aligned with human evaluators. Particularly, our expert human evaluation reveals remaining nuanced performance gaps between LLMs and our fine-tuned models, which LLMs fail to capture.""",2024
Hallucination Diversity-Aware Active Learning for Text Summarization,Yes.,5.,"""Large Language Models (LLMs) have shown propensity to generate hallucinated outputs, i.e., texts that are factually incorrect or unsupported."" and ""Existing methods for alleviating hallucinations typically require costly human annotations to identify and correct hallucinations in LLM outputs.""",2024
Investigating Data Contamination in Modern Benchmarks for Large Language Models,Yes.,5.,"""Recent observations have underscored a disparity between the inflated benchmark scores and the actual performance of LLMs, raising concerns about potential contamination of evaluation benchmarks.""",2024
Value FULCRA: Mapping Large Language Models to the Multidimensional Spectrum of Basic Human Value,Yes.,3.,"""Existing work mainly specifies values as risk criteria formulated in the AI community, e.g., fairness and privacy protection, suffering from poor clarity, adaptability and transparency.""",2024
IndiBias: A Benchmark Dataset to Measure Social Biases in Language Models for Indian Context,Yes.,4.,"""The pervasive influence of social biases in language data has sparked the need for benchmark datasets that capture and evaluate these biases in Large Language Models (LLMs)."" and ""We observed that the language models exhibit more bias across a majority of the intersectional groups.""",2024
Revisiting Zero-Shot Abstractive Summarization in the Era of Large Language Models from the Perspective of Position Bias,Yes.,5.,"""Position bias captures the tendency of a model unfairly prioritizing information from certain parts of the input text over others, leading to undesirable behavior.""",2024
Struc-Bench: Are Large Language Models Good at Generating Complex Structured Tabular Data?,Yes.,4.,"""producing complex, structured tabular data remains challenging"" and ""In-depth error analysis and creating an ability map across six dimensions, coverage, formatting, reasoning, comprehension, pragmatics, and hallucination, highlight areas for future enhancements and suggest forthcoming research trajectories.""",2024
"Unlocking Structure Measuring: Introducing PDD, an Automatic Metric for Positional Discourse Coherence",Yes.,3.,"""existing lexical or semantic metrics such as BLEU, ROUGE, BertScore cannot effectively capture the discourse coherence.""",2024
MultiParaDetox: Extending Text Detoxification with Parallel Data to New Languages,Yes.,1.,"""Recently, text detoxification methods found their applications in various task such as detoxification of Large Language Models (LLMs)...""",2024
A Multi-Aspect Framework for Counter Narrative Evaluation using Large Language Models,Yes.,1.,"""To address prior evaluation limitations, we propose a novel evaluation framework prompting LLMs to provide scores and feedback for generated counter narrative candidates using 5 defined aspects derived from guidelines from counter narrative specialized NGOs.""",2024
Unveiling Divergent Inductive Biases of LLMs on Temporal Data,,,,2024
On Retrieval Augmentation and the Limitations of Language Model Training,Yes.,3.,"""This task is challenging even for GPT-3.5 Turbo.""",2024
Advancing the Robustness of Large Language Models through Self-Denoised Smoothing,Yes.,5.,"""Although large language models (LLMs) have achieved significant success, their vulnerability to adversarial perturbations, including recent jailbreak attacks, has raised considerable concerns.""",2024
Can LLM’s Generate Human-Like Wayfinding Instructions? Towards Platform-Agnostic Embodied Instruction Synthesis,Yes.,1.,"""We present a novel approach to automatically synthesize 'wayfinding instructions' for an embodied robot agent.""",2024
Discourse-Aware In-Context Learning for Temporal Expression Normalization,Yes.,1.,"""we explore the feasibility of proprietary and open-source large language models (LLMs) for TE normalization using in-context learning to inject task, document, and example information into the model.""",2024
ALOHa: A New Measure for Hallucination in Captioning Models,Yes.,1.,"""we propose a modernized open-vocabulary metric, ALOHa, which leverages large language models (LLMs) to measure object hallucinations.""",2024
Beyond Yes and No: Improving Zero-Shot LLM Rankers via Scoring Fine-Grained Relevance Labels,Yes.,3.,"""the lack of intermediate relevance label options may cause the LLM to provide noisy or biased answers for documents that are partially relevant to the query.""",2024
Control-DAG: Constrained Decoding for Non-Autoregressive Directed Acyclic T5 using Weighted Finite State Automata,No.,1.,"The abstract discusses a non-autoregressive model (DA-T5) and its application to NLG tasks, but does not mention LLMs or their limitations.",2024
Lost in Space: Probing Fine-grained Spatial Understanding in Vision and Language Resamplers,Yes.,5.,"""more fine-grained tasks that require spatial understanding have not been thoroughly examined"" and ""Our results show that this information is largely absent from the resampler output when kept frozen during training of the classifiers.""",2024
A Continued Pretrained LLM Approach for Automatic Medical Note Generation,Yes.,3.,"""However, the use of the most advanced LLMs, such as GPT-4, is often prohibitively expensive for most specialized fields.""",2024
Self-Improving for Zero-Shot Named Entity Recognition with Large Language Models,Yes.,3.,"""Through comprehensive experimental analysis, we find that increasing the size of unlabeled corpus or iterations of self-improving does not guarantee further improvement, but the performance might be boosted via more advanced strategies for reliable annotation selection.""",2024
Language Models (Mostly) Do Not Consider Emotion Triggers When Predicting Emotion,Yes.,3.,"""Our analysis reveals that emotion triggers are largely not considered salient features for emotion prediction models, instead there is intricate interplay between various features and the task of emotion detection.""",2024
CPopQA: Ranking Cultural Concept Popularity by LLMs,Yes.,1.,"""Experiments on four strong LLMs show that open-sourced LLMs still lag way behind close LLM API (e.g., GPT-3.5) in statistical ranking of cultural concepts.""",2024
The Impact of Language on Arithmetic Proficiency: A Multilingual Investigation with Cross-Agent Checking Computation,Yes.,5.,"""This paper critically examines the arithmetic capabilities of Large Language Models (LLMs), uncovering significant limitations in their performance.""",2024
Removing RLHF Protections in GPT-4 via Fine-Tuning,Yes.,4.,"""fine-tuning allows attackers to remove RLHF protections with as few as 340 examples and a 95% success rate"" and ""Our results show the need for further research on protections on LLMs.""",2024
Arithmetic Reasoning with LLM: Prolog Generation & Permutation,Yes.,3.,"""the CoT approach relies on an LLM to generate a sequence of arithmetic calculations which can be prone to cascaded calculation errors.""",2024
MuLan: A Study of Fact Mutability in Language Models,Yes.,4.,"""We hypothesize that mutable facts are encoded differently than immutable ones, hence being easier to update. In a detailed evaluation of six popular large language models, we consistently find differences in the LLMs’ confidence, representations, and update behavior, depending on the mutability of a fact.""",2024
DoubleLingo: Causal Estimation with Large Language Models,Yes.,3.,"""flexible large language models that excel at predictive tasks with text data do not meet the statistical assumptions necessary for causal estimation.""",2024
Breaking the Language Barrier: Can Direct Inference Outperform Pre-Translation in Multilingual LLM Applications?,Yes.,3.,"""However, inherent biases stemming from predominantly English-centric pre-training have led to the widespread practice of pre-translation, i.e., translating non-English inputs to English before inference, leading to complexity and information loss.""",2024
Low-code LLM: Graphical User Interface over Large Language Models,Yes.,3.,"""Utilizing Large Language Models (LLMs) for complex tasks is challenging, often involving a time-consuming and uncontrollable prompt engineering process.""",2024
DIALIGHT: Lightweight Multilingual Development and Evaluation of Task-Oriented Dialogue Systems with Large Language Models,Yes.,4.,"""we also identify significant challenges of LLMs in adherence to task-specific instructions and generating outputs in multiple languages, highlighting areas for future research.""",2024
OpinionGPT: Modelling Explicit Biases in Instruction-Tuned LLMs,Yes.,4.,"""an open research question concerns the inherent biases of trained models and their responses"" and ""Current research work seeks to de-bias such models, or suppress potentially biased answers.""",2024
RedCoast: A Lightweight Tool to Automate Distributed Training of LLMs on Any GPU/TPUs,Yes.,3.,"""However, their escalating memory requirements introduce challenges for machine learning (ML) researchers and engineers.""",2024
Newspaper Signaling for Crisis Prediction,Yes.,1.,"""The model works with unstructured news data and combines multiple transformer-based models for pre-processing (STANZA) and content filtering (RoBERTa, GPT-3.5).""",2024
AgentQuest: A Modular Benchmark Framework to Measure Progress and Improve LLM Agents,Yes.,3.,"""existing benchmarks are often narrow and simply compute overall task success"" and ""we identify common failure points and refine the agent architecture to obtain a significant performance increase.""",2024
Rephrasing Invokes Better Generations for Large Language Models,Yes.,2.,"""However, automatic input pre-processing when LLMs are unavailable is currently under-studied.""",2024
Exploring Compositional Generalization of Large Language Models,Yes.,3.,"""Interestingly, our experimental results indicate that training LLMs on higher-order compositional instructions enhances their performance on lower-order ones, but the reverse does not hold true.""",2024
LUCID: LLM-Generated Utterances for Complex and Interesting Dialogues,Yes.,3.,"""Yet a major bottleneck to achieving genuinely transformative task-oriented dialogue capabilities remains the scarcity of high quality data."" and ""Existing datasets, while impressive in scale, have limited domain coverage and contain few genuinely challenging conversational phenomena; those which are present are typically unlabelled, making it difficult",2024
Exploring Inherent Biases in LLMs within Korean Social Context: A Comparative Analysis of ChatGPT and GPT-4,Yes.,4.,"""LLMs have been critiqued for perpetuating stereotypes against diverse groups based on race, sexual orientation, and other attributes,"" and ""Our findings indicate that certain personas or prompt combinations consistently yield harmful content, highlighting the potential risks associated with specific persona-issue alignments within the Korean cultural framework.""",2024
Detecting Response Generation Not Requiring Factual Judgment,Yes.,3.,"""With the remarkable development of large language models (LLMs), ensuring the factuality of output has become a challenge.""",2024
Investigating Web Corpus Filtering Methods for Language Model Development in Japanese,Yes.,2.,"""Indeed, we empirically present that strong filtering methods can rather lead to lesser performance in downstream tasks.""",2024
Distilling Text Style Transfer With Self-Explanation From LLMs,Yes.,1.,"""we propose CoTeX, a framework that leverages large language models (LLMs) alongside chain-of-thought (CoT) prompting to facilitate TST.""",2024
Coding Open-Ended Responses using Pseudo Response Generation by Large Language Models,Yes.,1.,"""To address this issue, we propose an LLM-based method to automate parts of the grounded theory approach (GTA), a representative approach of the qualitative data analysis.""",2024
HybridBERT - Making BERT Pretraining More Efficient Through Hybrid Mixture of Attention Mechanisms,Yes.,5.,"""The pretraining phase is extremely compute-intensive and requires several high-performance computing devices like GPUs and several days or even months of training, but it is crucial for the model to capture global knowledge and also has a significant impact on the fine-tuning task. This is a major",2024
Catch Me If You GPT: Tutorial on Deepfake Texts,Yes.,2.,"""While this is a celebratory feat for NLG, it poses new security risks (e.g., the generation of misinformation).""",2024
Combating Security and Privacy Issues in the Era of Large Language Models,Yes.,5.,"""This tutorial seeks to provide a systematic summary of risks and vulnerabilities in security, privacy and copyright aspects of large language models (LLMs), and most recent solutions to address those issues."" and ""will conclude the discussions by outlining emergent challenges in security, privacy and reliability of LLMs that deserve timely investigation by the community.""",2024
Explanation in the Era of Large Language Models,Yes.,4.,"""the sheer sizes and the opaque nature of LLMs introduce challenges to the explanation methods.""",2024
Human-AI Interaction in the Age of LLMs,Yes.,2.,"""exploring the challenges, opportunities, and ethical considerations that arise in this dynamic landscape.""",2024
