Title,Talks about LLMs,Rate,Evidence,Published
$Se^2$: Sequential Example Selection for In-Context Learning,Yes.,3.,"""such approaches often neglect the internal relationships between examples and exist an inconsistency between the training and inference.""",2024-02-21T15:35:04Z
An Explainable Transformer-based Model for Phishing Email Detection: A Large Language Model Approach,Yes.,1.,"""Large Language Models (LLMs) and Masked Language Models (MLMs) possess immense potential to offer innovative solutions to address long-standing challenges.""",2024-02-21T15:23:21Z
Kuaiji: the First Chinese Accounting Large Language Model,Yes.,3.,"""Large Language Models (LLMs) like ChatGPT and GPT-4 have demonstrated impressive proficiency in comprehending and generating natural language. However, they encounter difficulties when tasked with adapting to specialized domains such as accounting.""",2024-02-21T15:14:20Z
Semantic Mirror Jailbreak: Genetic Algorithm Based Jailbreak Prompts Against Open-source LLMs,Yes.,5.,"""Large Language Models (LLMs)... are vulnerable to jailbreak attacks, where crafted prompts induce harmful outputs."" and ""existing jailbreak prompt designs generally suffer from excessive semantic differences, resulting in an inability to resist defenses that use simple semantic metrics as thresholds.""",2024-02-21T15:13:50Z
Large Language Models are Advanced Anonymizers,Yes.,2.,"""existing text anonymization methods are currently lacking behind regulatory requirements and adversarial threats.""",2024-02-21T14:44:00Z
LLM4SBR: A Lightweight and Effective Framework for Integrating Large Language Models in Session-based Recommendation,Yes.,2.,"""However, constrained by high time and space costs, as well as the brief and anonymous nature of session data, the first LLM recommendation framework suitable for industrial deployment has yet to emerge in the field of SBR.""",2024-02-21T14:38:02Z
Beyond Hate Speech: NLP's Challenges and Opportunities in Uncovering Dehumanizing Language,Yes.,4.,"""Our findings reveal that while these models demonstrate potential, achieving a 70% accuracy rate in distinguishing dehumanizing language from broader hate speech, they also display biases. They are over-sensitive in classifying other forms of hate speech as dehumanization for a specific subset of target groups, while more frequently failing to identify clear cases of dehumanization for other target groups.""",2024-02-21T13:57:36Z
LLM Based Multi-Agent Generation of Semi-structured Documents from Semantic Templates in the Public Administration Domain,Yes.,1.,"""The recent introduction of Large Language Models (LLMs) has enabled the creation of customized text output satisfying user requests.""",2024-02-21T13:54:53Z
CriticBench: Evaluating Large Language Models as Critic,Yes.,2.,"""how to comprehensively and reliably measure the critique abilities of LLMs is under-explored.""",2024-02-21T12:38:59Z
Factual Consistency Evaluation of Summarisation in the Era of Large Language Models,Yes.,4.,"""Our findings reveal that despite proprietary models prevailing on the task, open-source LLMs lag behind."" and ""Experiments on TreatFact suggest that both previous methods and LLM-based evaluators are unable to capture factual inconsistencies in clinical summaries, posing a new challenge for FC evaluation.""",2024-02-21T12:35:19Z
LongRoPE: Extending LLM Context Window Beyond 2 Million Tokens,Yes.,5.,"""due to high fine-tuning costs, scarcity of long texts, and catastrophic values introduced by new token positions, current extended context windows are limited to around 128k tokens.""",2024-02-21T12:30:33Z
Breaking the Barrier: Utilizing Large Language Models for Industrial Recommendation Systems through an Inferential Knowledge Graph,Yes.,1.,"""In summary, LLM-KERec addresses the limitations of traditional recommendation systems by incorporating complementary knowledge and utilizing a large language model to capture user intent transitions, adapt to new items, and enhance recommendation efficiency in the evolving e-commerce landscape.""",2024-02-21T12:22:01Z
Unlocking Instructive In-Context Learning with Tabular Prompting for Relational Triple Extraction,Yes.,3.,"""Existing methods, however, fail to address these challenges appropriately. On the one hand, they usually recast RTE task to text-to-text prompting formats, which is unnatural and results in a mismatch between the output format at the pre-training time and the inference time for large language models (LLMs).""",2024-02-21T12:12:16Z
From Text to CQL: Bridging Natural Language and Corpus Search Engine,Yes.,1.,"""This paper presents the first text-to-CQL task that aims to automate the translation of natural language into CQL. We present a comprehensive framework for this task, including a specifically curated large-scale dataset and methodologies leveraging large language models (LLMs) for effective text-to-CQL task.""",2024-02-21T12:11:28Z
Ouroboros: Speculative Decoding with Large Model Enhanced Drafting,Yes.,3.,"""Suffering from the high verification failure probability, existing decoding methods cannot draft too much content for verification at one time, achieving sub-optimal inference acceleration.""",2024-02-21T11:31:28Z
$\infty$Bench: Extending Long Context Evaluation Beyond 100K Tokens,Yes.,5.,"""The results indicate that existing long context LLMs still require significant advancements to effectively process 100K+ context.""",2024-02-21T11:30:29Z
Neeko: Leveraging Dynamic LoRA for Efficient Multi-Character Role-Playing Agent,Yes.,3.,"""Large Language Models (LLMs) have revolutionized open-domain dialogue agents but encounter challenges in multi-character role-playing (MCRP) scenarios.""",2024-02-21T11:30:20Z
An Evaluation of Large Language Models in Bioinformatics Research,Yes.,3.,"""In addition, we provide a thorough analysis of their limitations in the context of complicated bioinformatics tasks.""",2024-02-21T11:27:31Z
SaGE: Evaluating Moral Consistency in Large Language Models,Yes.,5.,"""we show that even state-of-the-art LLMs are morally inconsistent in their generations, questioning their reliability (and trustworthiness in general)."" and ""Our results reveal that task-accuracy and consistency are independent problems, and there is a dire need to investigate these issues further.""",2024-02-21T11:23:21Z
Investigating Multilingual Instruction-Tuning: Do Polyglot Models Demand for Multilingual Instructions?,Yes.,1.,"""The adaption of multilingual pre-trained Large Language Models (LLMs) into eloquent and helpful assistants is essential to facilitate their use across different language regions.""",2024-02-21T11:07:07Z
KInIT at SemEval-2024 Task 8: Fine-tuned LLMs for Multilingual Machine-Generated Text Detection,Yes.,1.,"""Such a detection is important for preventing a potential misuse of large language models (LLMs), the newest of which are very capable in generating multilingual human-like texts.""",2024-02-21T10:09:56Z
Self-Distillation Bridges Distribution Gap in Language Model Fine-Tuning,Yes.,3.,"""fine-tuning them for specific tasks often encounters challenges in balancing performance and preserving general instruction-following abilities"" and ""the distribution gap between task datasets and the LLMs serves as the primary underlying cause.""",2024-02-21T10:06:08Z
GCOF: Self-iterative Text Generation for Copywriting Using Large Language Model,Yes.,3.,"""Large language models(LLM) such as ChatGPT have substantially simplified the generation of marketing copy, yet producing content satisfying domain specific requirements, such as effectively engaging customers, remains a significant challenge.""",2024-02-21T09:59:20Z
Privacy-Preserving Instructions for Aligning Large Language Models,Yes.,3.,"""These instructions, which potentially contain sensitive information, are annotated by human workers in the process. This poses a new privacy risk not addressed by the typical private optimization.""",2024-02-21T09:45:08Z
Unsupervised Text Style Transfer via LLMs and Attention Masking with Multi-way Interactions,Yes.,3.,"""Among existing methods for UTST tasks, attention masking approach and Large Language Models (LLMs) are deemed as two pioneering methods. However, they have shortcomings in generating unsmooth sentences and changing the original contents, respectively.""",2024-02-21T09:28:02Z
UniGraph: Learning a Cross-Domain Graph Foundation Model From Natural Language,Yes.,1.,"""Foundation models like ChatGPT and GPT-4 have revolutionized artificial intelligence, exhibiting remarkable abilities to generalize across a wide array of tasks and applications beyond their initial training objectives.""",2024-02-21T09:06:31Z
FLAME: Self-Supervised Low-Resource Taxonomy Expansion using Large Language Models,Yes.,2.,"""Furthermore, we elucidate the strengths and weaknesses of FLAME through an extensive case study, error analysis and ablation studies on the benchmarks.""",2024-02-21T08:50:40Z
Data-driven Discovery with Large Generative Models,,,,2024-02-21T08:26:43Z
CODIS: Benchmarking Context-Dependent Visual Comprehension for Multimodal Large Language Models,Yes.,5.,"""Our findings indicate that MLLMs consistently fall short of human performance on this benchmark. Further analysis confirms that these models struggle to effectively extract and utilize contextual information to improve their understanding of images.""",2024-02-21T08:21:12Z
A Comprehensive Study of Multilingual Confidence Estimation on Large Language Models,Yes.,5.,"""The tendency of Large Language Models to generate hallucinations and exhibit overconfidence in predictions raises concerns regarding their reliability.""",2024-02-21T08:20:06Z
KorNAT: LLM Alignment Benchmark for Korean Social Values and Common Knowledge,Yes.,3.,"""The experiment results of seven LLMs reveal that only a few models met our reference score, indicating a potential for further enhancement.""",2024-02-21T08:12:26Z
Hybrid Reasoning Based on Large Language Models for Autonomous Car Driving,Yes.,2.,"""However, their ability to generalize this advanced reasoning with a combination of natural language text for decision-making in dynamic situations requires further exploration.""",2024-02-21T08:09:05Z
User-LLM: Efficient LLM Contextualization with User Embeddings,Yes.,2.,"""effectively incorporating complex and potentially noisy user interaction data remains a challenge.""",2024-02-21T08:03:27Z
Knowledge Graph Enhanced Large Language Model Editing,Yes.,3.,"""Large language models (LLMs) are pivotal in advancing natural language processing (NLP) tasks, yet their efficacy is hampered by inaccuracies and outdated knowledge.""",2024-02-21T07:52:26Z
APTQ: Attention-aware Post-Training Mixed-Precision Quantization for Large Language Models,Yes.,2.,"""the high computational load and huge model sizes pose a grand challenge for deployment on edge devices.""",2024-02-21T07:45:22Z
A Multimodal In-Context Tuning Approach for E-Commerce Product Description Generation,Yes.,3.,"""However, the generated description is often inaccurate and generic since same-category products have similar copy-writings, and optimizing the overall framework on large-scale samples makes models concentrate on common words yet ignore the product features.""",2024-02-21T07:38:29Z
WinoViz: Probing Visual Properties of Objects Under Different States,Yes.,3.,"""Large language models such as GPT-4 demonstrate effective performance, but when it comes to multi-hop data, their performance is significantly degraded."" and ""Large models perform well on pragmatic reasoning, but visual knowledge reasoning is a bottleneck in our task.""",2024-02-21T07:31:47Z
BBA: Bi-Modal Behavioral Alignment for Reasoning with Large Vision-Language Models,Yes.,3.,"""the vanilla Chain-of-Thought (CoT) prompting method faces challenges in effectively leveraging the unique strengths of visual and DSL representations, primarily due to their differing reasoning mechanisms. Additionally, it often falls short in addressing critical steps in multi-step reasoning tasks.""",2024-02-21T07:16:29Z
DyVal 2: Dynamic Evaluation of Large Language Models by Meta Probing Agents,,,,2024-02-21T06:46:34Z
Cognitive Visual-Language Mapper: Advancing Multimodal Comprehension with Enhanced Visual Knowledge Alignment,Yes.,2.,"""we observe that widely-used visual-language projection approaches (e.g., Q-former or MLP) focus on the alignment of image-text descriptions yet ignore the visual knowledge-dimension alignment,"" and ""Ablation studies also verify the effectiveness of VKA and FKA,",2024-02-21T06:34:46Z
Are LLMs Effective Negotiators? Systematic Evaluation of the Multifaceted Capabilities of LLMs in Negotiation Dialogues,Yes.,5.,"""Our analysis adds to the increasing evidence for the superiority of GPT-4 across various tasks while also providing insights into specific tasks that remain difficult for LLMs. For instance, the models correlate poorly with human players when making subjective assessments about the negotiation dialogues and often struggle to generate responses that are contextually appropriate as well as strategically advantageous.""",2024-02-21T06:11:03Z
ActiveRAG: Revealing the Treasures of Knowledge via Active Learning,Yes.,3.,"""current RAG models position LLMs as passive knowledge receptors, thereby restricting their capacity for learning and comprehending external knowledge.""",2024-02-21T06:04:53Z
LLMs Meet Long Video: Advancing Long Video Comprehension with An Interactive Visual Adapter in LLMs,Yes.,5.,"""this approach incurs high computational costs due to the extensive array of video tokens, experiences reduced visual clarity as a consequence of token aggregation, and confronts challenges arising from irrelevant visual tokens while answering video-related questions.""",2024-02-21T05:56:52Z
ARL2: Aligning Retrievers for Black-box Large Language Models via Self-guided Adaptive Relevance Labeling,Yes.,3.,"""existing retrievers are often misaligned with LLMs due to their separate training processes and the black-box nature of LLMs.""",2024-02-21T05:41:34Z
Exploring the Limits of Semantic Image Compression at Micro-bits per Pixel,Yes.,2.,"""we use GPT-4V and DALL-E3 from OpenAI to explore the quality-compression frontier for image compression and identify the limitations of current technology.""",2024-02-21T05:14:30Z
FinGPT-HPC: Efficient Pretraining and Finetuning Large Language Models for Financial Applications with High-Performance Computing,Yes.,5.,"""Large language models (LLMs) are computationally intensive. The computation workload and the memory footprint grow quadratically with the dimension (layer width). Most of LLMs' parameters come from the linear layers of the transformer structure and are highly redundant. These linear layers contribute more than 80% of the computation workload and 99% of the model size. To pretrain and",2024-02-21T05:03:17Z
OMGEval: An Open Multilingual Generative Evaluation Benchmark for Large Language Models,Yes.,2.,"""Modern large language models (LLMs) should generally benefit individuals from various cultural backgrounds around the world. However, most recent advanced generative evaluation benchmarks tailed for LLMs mainly focus on English.""",2024-02-21T04:42:41Z
AgentScope: A Flexible yet Robust Multi-Agent Platform,Yes.,3.,"""However, the complexities in coordinating agents' cooperation and LLMs' erratic performance pose notable challenges in developing robust and efficient multi-agent applications.""",2024-02-21T04:11:28Z
RITFIS: Robust input testing framework for LLMs-based intelligent software,Yes.,4.,"""existing methods generally have limitations, especially when dealing with lengthy texts and structurally complex threat models.""",2024-02-21T04:00:54Z
Round Trip Translation Defence against Large Language Model Jailbreaking Attacks,Yes.,4.,"""Large language models (LLMs) are susceptible to social-engineered attacks that are human-interpretable but require a high level of comprehension for LLMs to counteract. Existing defensive measures can only mitigate less than half of these attacks at most.""",2024-02-21T03:59:52Z
ProSparse: Introducing and Enhancing Intrinsic Activation Sparsity within Large Language Models,Yes.,1.,"""Nevertheless, most large language models (LLMs) adopt activation functions without intrinsic activation sparsity (e.g., GELU and Swish).""",2024-02-21T03:58:49Z
From Self-Attention to Markov Models: Unveiling the Dynamics of Generative Transformers,Yes.,5.,"""This provides a mathematical explanation to the tendency of modern LLMs to generate repetitive text.""",2024-02-21T03:51:34Z
The Lay Person's Guide to Biomedicine: Orchestrating Large Language Models,Yes.,2.,"""Existing approaches using pre-trained language models, possibly augmented with external background knowledge, tend to struggle with effective simplification and explanation.""",2024-02-21T03:21:14Z
GradSafe: Detecting Unsafe Prompts for LLMs via Safety-Critical Gradient Analysis,Yes.,3.,"""Existing methods for detecting unsafe prompts are primarily online moderation APIs or finetuned LLMs. These strategies, however, often require extensive and resource-intensive data collection and training processes.""",2024-02-21T03:09:21Z
Retrieval Helps or Hurts? A Deeper Dive into the Efficacy of Retrieval Augmentation to Language Models,Yes.,5.,"""While large language models (LMs) demonstrate remarkable performance, they encounter challenges in providing accurate responses when queried for information beyond their pre-trained memorization."" and ""our extensive experiments with diverse LMs and retrievers reveal when retrieval does not consistently enhance LMs from the viewpoints of fact-centric popularity.""",2024-02-21T03:05:50Z
ProPD: Dynamic Token Tree Pruning and Generation for LLM Parallel Decoding,Yes.,3.,"""However, their efficiency is hampered by the inherent limitations in autoregressive token generation."" and ""it often struggles with maintaining contextual relationships due to its independent token prediction approach and incurs significant verification overhead, especially with large tree sizes and batch processing.""",2024-02-21T02:51:07Z
Retrieval-Augmented Data Augmentation for Low-Resource Domain Tasks,Yes.,4.,"""Despite large successes of recent language models on diverse tasks, they suffer from severe performance degeneration in low-resource settings with limited training data available.""",2024-02-21T02:45:46Z
STENCIL: Submodular Mutual Information Based Weak Supervision for Cold-Start Active Learning,Yes.,2.,"""As supervised fine-tuning of pre-trained models within NLP applications increases in popularity, larger corpora of annotated data are required, especially with increasing parameter counts in large language models.""",2024-02-21T01:54:58Z
RefuteBench: Evaluating Refuting Instruction-Following for Large Language Models,Yes.,5.,"""We conduct evaluations on numerous LLMs and find that LLMs are stubborn, i.e. exhibit inclination to their internal knowledge, often failing to comply with user feedback. Additionally, as the length of the conversation increases, models gradually forget the user's stated feedback and roll back to their own responses.""",2024-02-21T01:39:56Z
Potential and Challenges of Model Editing for Social Debiasing,Yes.,5.,"""Large language models (LLMs) trained on vast corpora suffer from inevitable stereotype biases."" and ""Our findings in three scenarios reveal both the potential and challenges of debias editing",2024-02-21T01:35:26Z
Learning to Poison Large Language Models During Instruction Tuning,Yes.,5.,"""Despite their advancements, LLMs face vulnerabilities to data poisoning attacks, where adversaries insert backdoor triggers into training data to manipulate outputs for malicious purposes.""",2024-02-21T01:30:03Z
LLM Jailbreak Attack versus Defense Techniques -- A Comprehensive Study,Yes.,5.,"""the phenomenon of 'jailbreaking', where carefully crafted prompts elicit harmful responses from models, persists as a significant challenge.""",2024-02-21T01:26:39Z
CAMELoT: Towards Large Language Models with Training-Free Consolidated Associative Memory,Yes.,5.,"""Large Language Models (LLMs) struggle to handle long input sequences due to high memory and runtime costs.""",2024-02-21T01:00:17Z
Ranking Large Language Models without Ground Truth,Yes.,1.,"""Evaluation methods either require human responses which are expensive to acquire or use pairs of LLMs to evaluate each other which can be unreliable.""",2024-02-21T00:49:43Z
Large Language Models for Data Annotation: A Survey,Yes.,4.,"""Furthermore, the paper includes an in-depth taxonomy of methodologies employing LLMs for data annotation, a comprehensive review of learning strategies for models incorporating LLM-generated annotations, and a detailed discussion on primary challenges and limitations associated with using LLMs for data annotation.""",2024-02-21T00:44:04Z
DrBenchmark: A Large Language Understanding Evaluation Benchmark for French Biomedical Domain,Yes.,2.,"""Our experiments reveal that no single model excels across all tasks, while generalist models are sometimes still competitive.""",2024-02-20T23:54:02Z
Explaining Relationships Among Research Papers,Yes.,1.,"""In this work, we explore a feature-based, LLM-prompting approach to generate richer citation texts, as well as generating multiple citations at once to capture the complex relationships among research papers.""",2024-02-20T23:38:39Z
The Wolf Within: Covert Injection of Malice into MLLM Societies via an MLLM Operative,Yes.,5.,"""This subtle, yet potent method of indirect influence marks a significant escalation in the security risks associated with MLLMs"" and ""Our work underscores the urgent need for developing robust mechanisms to detect and mitigate such covert manipulations within MLLM societies, ensuring their safe and ethical utilization in societal applications.""",2024-02-20T23:08:21Z
Structure Guided Prompt: Instructing Large Language Model in Multi-Step Reasoning by Exploring Graph Structure of the Text,Yes.,5.,"""Large Language Models (LLMs) excel at addressing straightforward reasoning tasks, they frequently struggle with difficulties when confronted by more complex multi-step reasoning due to a range of factors.""",2024-02-20T22:56:23Z
Harnessing Large Language Models as Post-hoc Correctors,,,,2024-02-20T22:50:41Z
Reliable LLM-based User Simulator for Task-Oriented Dialogue Systems,Yes.,2.,"""Notably, we have observed that fine-tuning enhances the simulator's coherence with user goals, effectively mitigating hallucinations -- a major source of inconsistencies in simulator responses.""",2024-02-20T20:57:47Z
EvoGrad: A Dynamic Take on the Winograd Schema Challenge with Human Adversaries,Yes.,5.,"""While Large Language Models (LLMs) excel at the Winograd Schema Challenge (WSC), a coreference resolution task testing common-sense reasoning through pronoun disambiguation, they struggle with instances that feature minor alterations or rewording."" and ""This highlights ongoing model limitations and the value of dynamic datasets in uncovering them.""",2024-02-20T20:53:24Z
ChatEL: Entity Linking with Chatbots,Yes.,2.,"""Fortunately, Large Language Models (LLMs) like GPT provide a highly-advanced solution to the problems inherent in EL models, but simply naive prompts to LLMs do not work well.""",2024-02-20T20:52:57Z
A Simple but Effective Approach to Improve Structured Language Model Output for Information Extraction,Yes.,5.,"""their performance can be inconsistent when tasked with producing text that adheres to specific structured formats, which is crucial in applications like named entity recognition (NER) or relation extraction (RE).""",2024-02-20T20:42:02Z
TofuEval: Evaluating Hallucinations of LLMs on Topic-Focused Dialogue Summarization,Yes.,5.,"""Our analysis shows that existing LLMs hallucinate significant amounts of factual errors in the dialogue domain, regardless of the model's size."" and ""when LLMs, including GPT-4, serve as binary factual evaluators, they perform poorly and can be outperformed by prevailing state-of-the-art specialized factuality evaluation metrics.""",2024-02-20T18:58:49Z
Investigating Cultural Alignment of Large Language Models,Yes.,3.,"""Further analysis reveals that misalignment becomes more pronounced for underrepresented personas and for culturally sensitive topics, such as those probing social values.""",2024-02-20T18:47:28Z
Smaug: Fixing Failure Modes of Preference Optimisation with DPO-Positive,Yes.,4.,"""first we show theoretically that the standard DPO loss can lead to a \textit{reduction} of the model's likelihood of the preferred examples,"" and ""we then show empirically that this phenomenon occurs when fine-tuning LLMs on common datasets, especially datasets in which",2024-02-20T18:42:34Z
RoCode: A Dataset for Measuring Code Intelligence from Problem Definitions in Romanian,Yes.,3.,"""Code intelligence and problem solving still remain a difficult task, even for the most advanced LLMs.""",2024-02-20T18:32:47Z
How Easy is It to Fool Your Multimodal LLMs? An Empirical Analysis on Deceptive Prompts,Yes.,5.,"""The remarkable advancements in Multimodal Large Language Models (MLLMs) have not rendered them immune to challenges, particularly in the context of handling deceptive information in prompts, thus producing hallucinated responses under such conditions.""",2024-02-20T18:31:27Z
Soft Self-Consistency Improves Language Model Agents,Yes.,3.,"""Generations from large language models (LLMs) can be improved by sampling and scoring multiple solutions to select a final answer. Current 'sample and select' methods such as self-consistency (SC) rely on majority voting to score answers. However, when tasks have many distinct and valid answers, selection by voting requires a large number of samples. This makes SC prohibitively expensive for",2024-02-20T18:22:38Z
Can Large Language Models be Good Emotional Supporter? Mitigating Preference Bias on Emotional Support Conversation,Yes.,5.,"""despite the remarkable conversational ability of large language models (LLMs), previous studies have suggested that they often struggle with providing useful emotional support"" and ""revealing challenges in selecting the correct strategy and a notable preference for a specific strategy"" and ""LLMs alone cannot become good emotional supporters.""",2024-02-20T18:21:32Z
Bayesian Reward Models for LLM Alignment,Yes.,4.,"""this process is vulnerable to reward overoptimization or hacking, in which the responses selected have high rewards due to errors in the reward model rather than a genuine preference. This is especially problematic as the prompt or response diverges from the training data.""",2024-02-20T18:20:59Z
Benchmarking Retrieval-Augmented Generation for Medicine,Yes.,5.,"""While large language models (LLMs) have achieved state-of-the-art performance on a wide range of medical question answering (QA) tasks, they still face challenges with hallucinations and outdated knowledge.""",2024-02-20T17:44:06Z
Is the System Message Really Important to Jailbreaks in Large Language Models?,Yes.,4.,"""This term refers to the unexpected and potentially harmful responses generated by LLMs when prompted with malicious questions."" and ""we explore the transferability of jailbreak across LLMs.""",2024-02-20T17:39:40Z
Defending Jailbreak Prompts via In-Context Adversarial Game,Yes.,3.,"""However, concerns regarding their security, particularly the vulnerability to jailbreak attacks, persist.""",2024-02-20T17:04:06Z
Are ELECTRA's Sentence Embeddings Beyond Repair? The Case of Semantic Textual Similarity,Yes.,3.,"""While BERT produces high-quality sentence embeddings, its pre-training computational cost is a significant drawback. In contrast, ELECTRA delivers a cost-effective pre-training objective and downstream task performance improvements, but not as performant sentence embeddings.""",2024-02-20T16:43:20Z
TreeEval: Benchmark-Free Evaluation of Large Language Models through Tree Planning,,,,2024-02-20T16:38:33Z
CIF-Bench: A Chinese Instruction-Following Benchmark for Evaluating the Generalizability of Large Language Models,Yes.,5.,"""their effectiveness often diminishes in low-resource languages like Chinese, exacerbated by biased evaluations from data leakage, casting doubt on their true generalizability to new linguistic territories."" and ""highlighting the limitations of LLMs in less familiar language and task contexts",2024-02-20T16:02:12Z
ELAD: Explanation-Guided Large Language Models Active Distillation,Yes.,5.,"""The deployment and application of Large Language Models (LLMs) is hindered by their memory inefficiency, computational demands, and the high costs of API inferences.""",2024-02-20T15:47:59Z
Event-level Knowledge Editing,Yes.,3.,"""We find that ELKEN poses significant challenges to existing knowledge editing approaches.""",2024-02-20T15:36:41Z
Slot-VLM: SlowFast Slots for Video-Language Modeling,Yes.,1.,"""A pivotal challenge is the development of an efficient method to encapsulate video content into a set of representative tokens to align with LLMs.""",2024-02-20T15:30:09Z
Identifying Semantic Induction Heads to Understand In-Context Learning,Yes.,3.,"""the lack of transparency in their inference logic raises concerns about their trustworthiness.""",2024-02-20T14:43:39Z
Stable Knowledge Editing in Large Language Models,Yes.,3.,"""previous methods implicitly assume that knowledge is localized and isolated within the model, an assumption that oversimplifies the interconnected nature of model knowledge.""",2024-02-20T14:36:23Z
Effective and Efficient Conversation Retrieval for Dialogue State Tracking with Implicit Text Summaries,Yes.,1.,"""Few-shot dialogue state tracking (DST) with Large Language Models (LLM) relies on an effective and efficient conversation retriever to find similar in-context examples for prompt learning.""",2024-02-20T14:31:17Z
Text-Guided Molecule Generation with Diffusion Language Model,Yes.,1.,"""a novel approach that leverages diffusion models to address the limitations of autoregressive methods.""",2024-02-20T14:29:02Z
SiLLM: Large Language Models for Simultaneous Machine Translation,,,,2024-02-20T14:23:34Z
Learning to Check: Unleashing Potentials for Self-Correction in Large Language Models,Yes.,3.,"""recent studies suggest that self-correction can be limited or even counterproductive without external accurate knowledge, raising questions about the limits and effectiveness of self-correction.""",2024-02-20T14:23:23Z
SoMeLVLM: A Large Vision Language Model for Social Media Processing,Yes.,2.,"""the general domain models often fall short in aligning with the unique speaking style and context of social media tasks.""",2024-02-20T14:02:45Z
Understanding the effects of language-specific class imbalance in multilingual fine-tuning,Yes.,4.,"""We show evidence that fine-tuning a transformer-based Large Language Model (LLM) on a dataset with this imbalance leads to worse performance, a more pronounced separation of languages in the latent space, and the promotion of uninformative features.""",2024-02-20T13:59:12Z
Code Needs Comments: Enhancing Code LLMs with Comment Augmentation,Yes.,1.,"""We examine the impact of pre-training data on code-focused LLMs' performance by assessing the comment density as a measure of PL-NL alignment.""",2024-02-20T13:56:38Z
An Autonomous Large Language Model Agent for Chemical Literature Data Mining,Yes.,1.,"""This AI agent employs large language models (LLMs) for prompt generation and iterative optimization.""",2024-02-20T13:21:46Z
TRAP: Targeted Random Adversarial Prompt Honeypot for Black-Box Identification,Yes.,1.,"""Large Language Model (LLM) services and models often come with legal rules on who can use them and how they must use them.""",2024-02-20T13:20:39Z
Can GNN be Good Adapter for LLMs?,,,,2024-02-20T13:13:13Z
Comparing Inferential Strategies of Humans and Large Language Models in Deductive Reasoning,Yes.,3.,"""Nonetheless, a significant portion of research primarily assesses the accuracy of LLMs in solving such tasks, often overlooking a deeper analysis of their reasoning behavior."" and ""we assert that a model's accuracy, that is the correctness of its final conclusion, does not necessarily reflect the validity of its reasoning process.""",2024-02-20T12:58:14Z
GlórIA -- A Generative and Open Large Language Model for Portuguese,Yes.,1.,"""Significant strides have been made in natural language tasks, largely attributed to the emergence of powerful large language models (LLMs).""",2024-02-20T12:36:40Z
Prompt Stealing Attacks Against Large Language Models,,,,2024-02-20T12:25:26Z
GumbelSoft: Diversified Language Model Watermarking via the GumbelMax-trick,Yes.,3.,"""Large language models (LLMs) excellently generate human-like text, but also raise concerns about misuse in fake news and academic dishonesty."" and ""GM watermark encounters a major challenge with generation diversity, always yielding identical outputs for the same prompt, negatively impacting generation diversity and user experience.""",2024-02-20T12:05:47Z
A Literature Review of Literature Reviews in Pattern Analysis and Machine Intelligence,Yes.,2.,"""The newly emerging AI-generated literature reviews are also appraised, and the observed differences suggest that most AI-generated reviews still lag behind human-authored reviews in multiple aspects.""",2024-02-20T11:28:50Z
Large Language Model-based Human-Agent Collaboration for Complex Task Solving,Yes.,5.,"""LLM-based agents frequently demonstrate notable shortcomings in adjusting to dynamic environments and fully grasping human needs.""",2024-02-20T11:03:36Z
OPDAI at SemEval-2024 Task 6: Small LLMs can Accelerate Hallucination Detection with Weakly Supervised Data,Yes.,2.,"""This task aims to detect hallucination with LLMs for three different text-generation tasks without labeled training data.""",2024-02-20T11:01:39Z
Chain of Thought Empowers Transformers to Solve Inherently Serial Problems,Yes.,3.,"""CoT empowers the model with the ability to perform inherently serial computation, which is otherwise lacking in transformers, especially when depth is low.""",2024-02-20T10:11:03Z
Exploring the Impact of Table-to-Text Methods on Augmenting LLM-based Question Answering with Domain Hybrid Data,Yes.,1.,"""Augmenting Large Language Models (LLMs) for Question Answering (QA) with domain specific data has attracted wide attention.""",2024-02-20T10:00:58Z
MoELoRA: Contrastive Learning Guided Mixture of Experts on Parameter-Efficient Fine-Tuning for Large Language Models,Yes.,3.,"""the process of updating billions of parameters demands significant computational resources and training time, which poses a substantial obstacle to the widespread application of large-scale models in various scenarios.""",2024-02-20T09:30:48Z
Instruction-tuned Language Models are Better Knowledge Learners,Yes.,3.,"""we find that LLMs trained with this recipe struggle to answer questions, even though the perplexity of documents is minimized.""",2024-02-20T09:20:32Z
PromptKD: Distilling Student-Friendly Knowledge for Generative Language Models via Prompt Tuning,Yes.,2.,"""Recent advancements in large language models (LLMs) have raised concerns about inference costs, increasing the need for research into model compression.""",2024-02-20T09:10:08Z
PANDA: Preference Adaptation for Enhancing Domain-Specific Abilities of LLMs,Yes.,3.,"""While Large language models (LLMs) have demonstrated considerable capabilities across various natural language tasks, they often fall short of the performance achieved by domain-specific state-of-the-art models.""",2024-02-20T09:02:55Z
Identifying Factual Inconsistency in Summaries: Towards Effective Utilization of Large Language Model,,,,2024-02-20T08:41:23Z
"Fine-Tuning, Prompting, In-Context Learning and Instruction-Tuning: How Many Labelled Samples Do We Need?",Yes.,2.,"""When solving a task with limited labelled data, researchers can either use a general large language model without further update, or use the few examples to tune a specialised smaller model. When enough labels are available, the specialised models outperform the general ones on many",2024-02-20T08:38:24Z
SymBa: Symbolic Backward Chaining for Multi-step Natural Language Reasoning,,,,2024-02-20T08:27:05Z
Few shot clinical entity recognition in three languages: Masked language models outperform LLM prompting,Yes.,5.,"""few-shot learning using Large language models is not production ready for named entity recognition in the clinical domain.""",2024-02-20T08:20:49Z
Chain-of-Specificity: An Iteratively Refining Method for Eliciting Knowledge from Large Language Models,Yes.,3.,"""previous research found that LLMs sometimes struggle with adhering to specific constraints (e.g., in specific place or at specific time), at times even overlooking them, which leads to responses that are either too generic or not fully satisfactory.""",2024-02-20T08:03:05Z
Advancing Large Language Models to Capture Varied Speaking Styles and Respond Properly in Spoken Conversations,Yes.,3.,"""When using text-only LLMs to model spoken dialogue, text-only LLMs cannot give different responses based on the speaking style of the current turn.""",2024-02-20T07:51:43Z
Me LLaMA: Foundation Large Language Models for Medical Applications,Yes.,3.,"""However, their performance on medical tasks is suboptimal and can be improved by training on extensive domain-specific datasets.""",2024-02-20T06:37:31Z
An LLM Maturity Model for Reliable and Transparent Text-to-Query,Yes.,4.,"""Recognizing the imperative to address the reliability and transparency issues of Large Language Models (LLM), this work proposes an LLM maturity model tailored for text-to-query applications.""",2024-02-20T06:20:09Z
MuLan: Multimodal-LLM Agent for Progressive Multi-Object Diffusion,Yes.,2.,"""Existing text-to-image models still struggle to generate images of multiple objects, especially in handling their spatial positions, relative sizes, overlapping, and attribute bindings.""",2024-02-20T06:14:30Z
Can Large Language Models be Used to Provide Psychological Counselling? An Analysis of GPT-4-Generated Responses Using Role-play Dialogues,Yes.,1.,"""there is a need for more evaluations of the performance of counseling dialogue systems that use large language models.""",2024-02-20T06:05:36Z
Modality-Aware Integration with Large Language Models for Knowledge-based Visual Question Answering,Yes.,3.,"""While several attempts have been proposed to leverage large language models (LLMs) as an implicit knowledge source, it remains challenging since LLMs may generate hallucinations.""",2024-02-20T05:32:24Z
Are Large Language Models Rational Investors?,Yes.,4.,"""However, their application in the financial domain is challenged by intrinsic biases (i.e., risk-preference bias) and a superficial grasp of market intricacies, underscoring the need for a thorough assessment of their financial insight.""",2024-02-20T04:26:08Z
Thermometer: Towards Universal Calibration for Large Language Models,Yes.,5.,"""Recent studies have found that common interventions such as instruction tuning often result in poorly calibrated LLMs"" and ""calibrating LLMs is uniquely challenging. These challenges stem as much from the severe computational requirements of LLMs as from their versatility, which allows them to be applied to diverse tasks.""",2024-02-20T04:13:48Z
SQL-CRAFT: Text-to-SQL through Interactive Refinement and Enhanced Reasoning,Yes.,3.,"""Modern LLMs have become increasingly powerful, but they are still facing challenges in specialized tasks such as Text-to-SQL.""",2024-02-20T03:57:55Z
FormulaQA: A Question Answering Dataset for Formula-Based Numerical Reasoning,Yes.,1.,"""We further conduct evaluations on LLMs with size ranging from 7B to over 100B parameters utilizing zero-shot and few-shot chain-of-thoughts methods and we explored the approach of using retrieval-augmented LLMs when providing an external formula database.""",2024-02-20T03:39:49Z
The FinBen: An Holistic Financial Benchmark for Large Language Models,Yes.,4.,"""The findings indicate that GPT-4 leads in quantification, extraction, numerical reasoning, and stock trading, while Gemini shines in generation and forecasting; however, both struggle with complex extraction and forecasting, showing a clear need for targeted enhancements. Instruction tuning boosts simple task performance but falls short in improving complex reasoning and forecasting abilities.""",2024-02-20T02:16:16Z
CHATATC: Large Language Model-Driven Conversational Agents for Supporting Strategic Air Traffic Flow Management,Yes.,2.,"""We test the query and response capabilities of CHATATC, documenting successes (e.g., providing correct GDP rates, durations, and reason) and shortcomings (e.g,. superlative questions).""",2024-02-20T01:59:11Z
Bias in Language Models: Beyond Trick Tests and Toward RUTEd Evaluation,Yes.,4.,"""Bias benchmarks are a popular method for studying the negative impacts of bias in LLMs,"" and ""We conclude that evaluations that are not based in realistic use are likely insufficient to mitigate and assess bias and real-world harms.""",2024-02-20T01:49:15Z
Multimodal Fusion of EHR in Structures and Semantics: Integrating Clinical Records and Notes with Hypergraph and LLM,Yes.,1.,"""In this work, we propose a new framework called MINGLE, which integrates both structures and semantics in EHR effectively.""",2024-02-19T23:48:40Z
Standardize: Aligning Language Models with Expert-Defined Standards for Content Generation,Yes.,1.,"""current works in controllable text generation have yet to explore using these standards as references for control.""",2024-02-19T23:18:18Z
Detecting misinformation through Framing Theory: the Frame Element-based Model,Yes.,1.,"""To tackle this challenge, we propose an innovative approach leveraging the power of pre-trained Large Language Models and deep neural networks to detect misinformation originating from accurate facts portrayed under different frames.""",2024-02-19T21:50:42Z
GenAudit: Fixing Factual Errors in Language Model Outputs with Evidence,Yes.,5.,"""LLMs can generate factually incorrect statements even when provided access to reference documents. Such errors can be dangerous in high-stakes applications (e.g., document-grounded QA for healthcare or finance).""",2024-02-19T21:45:55Z
Confidence Matters: Revisiting Intrinsic Self-Correction Capabilities of Large Language Models,Yes.,3.,"""Overlooking this factor may cause the models to over-criticize themselves, resulting in unreliable conclusions regarding the efficacy of self-correction.""",2024-02-19T21:38:02Z
TrustScore: Reference-Free Evaluation of LLM Response Trustworthiness,Yes.,4.,"""However, concerns have arisen regarding the trustworthiness of LLMs outputs, particularly in closed-book question-answering tasks, where non-experts may struggle to identify inaccuracies due to the absence of contextual or ground truth information.""",2024-02-19T21:12:14Z
Your Vision-Language Model Itself Is a Strong Filter: Towards High-Quality Instruction Tuning with Data Selection,Yes.,1.,"""Data selection in instruction tuning emerges as a pivotal process for acquiring high-quality data and training instruction-following large language models (LLMs), but it is still a new and unexplored research area for vision-language models (VLMs).""",2024-02-19T20:08:48Z
Artifacts or Abduction: How Do LLMs Answer Multiple-Choice Questions Without the Question?,Yes.,3.,"""To see if MCQA assesses LLMs as intended, we probe if LLMs can perform MCQA with choices-only prompts, where models must select the correct answer only from the choices."" and ""We hope to motivate the use of stronger baselines in MCQA benchmarks, the design of robust MCQA datasets, and further efforts to explain LLM decision-making.""",2024-02-19T19:38:58Z
"Sequoia: Scalable, Robust, and Hardware-aware Speculative Decoding",Yes.,1.,"""As the usage of large language models (LLMs) grows, performing efficient inference with these models becomes increasingly important.""",2024-02-19T18:58:32Z
AnaloBench: Benchmarking the Identification of Abstract and Long-context Analogies,Yes.,5.,"""Surprisingly, scale offers minimal gains when, (i) analogies involve lengthy scenarios, or (ii) recalling relevant scenarios from a large pool of information, a process analogous to finding a needle in a haystack.""",2024-02-19T18:56:44Z
A Critical Evaluation of AI Feedback for Aligning Large Language Models,Yes.,2.,"""we question whether the complexity of this RL step is truly warranted for AI feedback"" and ""we find that the gains from RLAIF vary substantially across base model families, test-time evaluation protocols, and critic models.""",2024-02-19T18:53:54Z
DeepCode AI Fix: Fixing Security Vulnerabilities with Large Language Models,Yes.,3.,"""We show that the task is difficult as it requires the model to learn long-range code relationships, a task that inherently relies on extensive amounts of training data. At the same time, creating a large, clean dataset for complex program bugs and their corresponding fixes is non-trivial.""",2024-02-19T18:35:40Z
Graph-Based Retriever Captures the Long Tail of Biomedical Knowledge,Yes.,4.,"""LLMs are prone to highlight the most frequently seen pieces of information from the training set and to neglect the rare ones"" and ""Retrieval Augmented Generation (RAG) has been proposed to alleviate some of the shortcomings of LLMs by augmenting the prompts with context retrieved from external datasets.""",2024-02-19T18:31:11Z
GTBench: Uncovering the Strategic Reasoning Limitations of LLMs via Game-Theoretic Evaluations,Yes.,5.,"""We observe that (1) LLMs have distinct behaviors regarding various gaming scenarios; for example, LLMs fail in complete and deterministic games yet they are competitive in probabilistic gaming scenarios.""",2024-02-19T18:23:36Z
Emulated Disalignment: Safety Alignment for Large Language Models May Backfire!,Yes.,5.,"""this paper introduces an inference-time attack method, demonstrating that safety alignment can be easily reversed to produce harmful language models without additional training.""",2024-02-19T18:16:51Z
Robust CLIP: Unsupervised Adversarial Fine-Tuning of Vision Embeddings for Robust Large Vision-Language Models,Yes.,3.,"""Prior work has shown that these models are highly vulnerable to adversarial attacks on the vision modality. These attacks can be leveraged to spread fake information or defraud users, and thus pose a significant risk, which makes the robustness of large multi-modal foundation models a pressing problem.""",2024-02-19T18:09:48Z
Query-Based Adversarial Prompt Generation,Yes.,3.,"""Recent work has shown it is possible to construct adversarial examples that cause an aligned language model to emit harmful strings or perform harmful behavior.""",2024-02-19T18:01:36Z
LLM Agents for Psychology: A Study on Gamified Assessments,Yes.,3.,"""While game-based and LLM-based tools have been explored to improve user interest and automate assessment, they struggle to balance engagement with generalizability.""",2024-02-19T18:00:30Z
Large Language Model for Mental Health: A Systematic Review,Yes.,4.,"""Findings reveal LLMs' effectiveness in mental health issue detection and the enhancement of telepsychological services through personalised healthcare. Nonetheless, risks like text inconsistencies, hallucinatory content, and the lack of an ethical framework raise concerns about their clinical use.""",2024-02-19T17:58:41Z
ARKS: Active Retrieval in Knowledge Soup for Code Generation,Yes.,1.,"""Recently the retrieval-augmented generation (RAG) paradigm has raised much attention for its potential in incorporating external knowledge into large language models (LLMs) without further training.""",2024-02-19T17:37:28Z
Is Open-Source There Yet? A Comparative Study on Commercial and Open-Source LLMs in Their Ability to Label Chest X-Ray Reports,Yes.,1.,"""In this paper, we show that while GPT-4 is superior to open-source models in zero-shot report labeling, the implementation of few-shot prompting can bring open-source models on par with GPT-4.""",2024-02-19T17:23:10Z
Adaptive Skeleton Graph Decoding,Yes.,3.,"""LLM inference incurs significant computation and memory costs"" and ""they often suffer from reduced response quality.""",2024-02-19T16:47:04Z
"WorldCoder, a Model-Based LLM Agent: Building World Models by Writing Code and Interacting with the Environment",Yes.,1.,"""We do this by extending work on program synthesis via LLMs.""",2024-02-19T16:39:18Z
Tables as Images? Exploring the Strengths and Limitations of LLMs on Multimodal Representations of Tabular Data,Yes.,3.,"""We introduce for the first time the assessment of LLMs' performance on image-based table representations. Specifically, we compare five text-based and three image-based table representations, demonstrating the influence of representation and prompting on LLM performance.""",2024-02-19T16:34:50Z
High-quality Data-to-Text Generation for Severely Under-Resourced Languages with Out-of-the-box Large Language Models,,,,2024-02-19T16:29:40Z
Uncertainty quantification in fine-tuned LLMs using LoRA ensembles,Yes.,3.,"""a general understanding of what the fine-tuned model has learned, forgotten and how to trust its predictions is still missing.""",2024-02-19T16:26:00Z
NEO-BENCH: Evaluating Robustness of Large Language Models with Neologisms,Yes.,5.,"""The performance of Large Language Models (LLMs) degrades from the temporal drift between data used for model training and newer text seen during inference"" and ""Model performance is nearly halved in machine translation when a single neologism is introduced in a sentence.""",2024-02-19T16:19:15Z
Open3DSG: Open-Vocabulary 3D Scene Graphs from Point Clouds with Queryable Objects and Open-Set Relationships,Yes.,1.,"""predicting the inter-object relationships from a grounded LLM with scene graph features and queried object classes as context.""",2024-02-19T16:15:03Z
Shallow Synthesis of Knowledge in GPT-Generated Texts: A Case Study in Automatic Related Work Composition,Yes.,5.,"""GPT-4 can generate reasonable coarse-grained citation groupings to support human users in brainstorming, but fails to perform detailed synthesis of related works without human intervention.""",2024-02-19T16:14:04Z
"Same Task, More Tokens: the Impact of Input Length on the Reasoning Performance of Large Language Models",Yes.,5.,"""Our findings show a notable degradation in LLMs' reasoning performance at much shorter input lengths than their technical maximum.""",2024-02-19T16:04:53Z
CovRL: Fuzzing JavaScript Engines with Coverage-Guided Reinforcement Learning for LLM-based Mutation,Yes.,1.,"""Recently, researchers have adopted language models for context-aware mutation in fuzzing to address this problem.""",2024-02-19T15:30:40Z
Reformatted Alignment,Yes.,3.,"""Current methods to improve data quality are either labor-intensive or prone to factual errors caused by LLM hallucinations.""",2024-02-19T15:21:58Z
Polarization of Autonomous Generative AI Agents Under Echo Chambers,Yes.,4.,"""We investigated the potential for polarization to occur among a group of autonomous AI agents based on generative language models in an echo chamber environment."" and ""we found that the group of agents based on ChatGPT tended to become polarized in echo chamber environments.""",2024-02-19T15:14:15Z
Enhancing Multilingual Capabilities of Large Language Models through Self-Distillation from Resource-Rich Languages,Yes.,3.,"""their performance still lags behind in most languages compared to a few resource-rich languages"" and ""using the data obtained solely relying on translation while ignoring the original capabilities of LLMs across languages is not always effective, which we show will limit the performance of cross-lingual knowledge transfer.""",2024-02-19T15:07:32Z
Browse and Concentrate: Comprehending Multimodal Content via prior-LLM Context Fusion,Yes.,4.,"""However, they fall short to comprehend context involving multiple images. A primary reason for this shortcoming is that the visual features for each images are encoded individually by frozen encoders before feeding into the LLM backbone, lacking awareness of other images and the multimodal instructions.""",2024-02-19T14:59:07Z
A Chinese Dataset for Evaluating the Safeguards in Large Language Models,Yes.,5.,"""Many studies have demonstrated that large language models (LLMs) can produce harmful responses, exposing users to unexpected risks when LLMs are deployed."" and ""Our experiments on five LLMs show that region-specific risks are the prevalent type of risk, presenting the major issue with all Chinese LLMs we experimented with.""",2024-02-19T14:56:18Z
Stick to your Role! Stability of Personal Values Expressed in Large Language Models,Yes.,3.,"""We argue that context-dependence should be studied as another dimension of LLM comparison alongside others such as cognitive abilities, knowledge, or model size."" and ""When instructed to simulate particular personas, LLMs exhibit low Rank-Order stability, and this stability further diminishes with conversation length.""",2024-02-19T14:53:01Z
Mafin: Enhancing Black-Box Embeddings with Model Augmented Fine-Tuning,Yes.,2.,"""Retrieval Augmented Generation (RAG) has emerged as an effective solution for mitigating hallucinations in Large Language Models (LLMs).""",2024-02-19T14:33:24Z
BIDER: Bridging Knowledge Inconsistency for Efficient Retrieval-Augmented LLMs via Key Supporting Evidence,Yes.,4.,"""However, inconsistencies between retrieval knowledge and the necessary knowledge for LLMs, leading to a decline in LLM's answer quality.""",2024-02-19T14:28:31Z
Transformer-based Causal Language Models Perform Clustering,Yes.,3.,"""the capability of an LLM to follow human instructions is still a concern"" and ""the mechanisms responsible for effective instruction-following capabilities remain inadequately understood.""",2024-02-19T14:02:31Z
Your Large Language Model is Secretly a Fairness Proponent and You Should Prompt it Like One,Yes.,4.,"""LLMs frequently present dominant viewpoints while ignoring alternative perspectives from minority parties, resulting in potential biases.""",2024-02-19T14:02:22Z
Purifying Large Language Models by Ensembling a Small Language Model,Yes.,5.,"""well-constructed LLMs have been reported to suffer from copyright infringement, data poisoning, and/or privacy violations, which would impede practical deployment of LLMs.""",2024-02-19T14:00:39Z
End-to-end multilingual fact-checking at scale,Yes.,1.,"""We also show through an experimental benchmark that fine-tuned models tailored for fact-checking tasks outperform Large Language Models such as GPT-4, GPT-3.5-Turbo, and Mistral-7b.""",2024-02-19T14:00:35Z
Meta Ranking: Less Capable Language Models are Capable for Single Response Judgement,Yes.,3.,"""Although Large Language Models (LLMs) have demonstrated strong performance on a wide range of tasks, they still face reliability challenges such as hallucination.""",2024-02-19T13:57:55Z
Do Large Language Models Understand Logic or Just Mimick Context?,Yes.,5.,"""Based on our analysis, it is found that LLMs do not truly understand logical rules; rather, in-context learning has simply enhanced the likelihood of these models arriving at the correct answers. If one alters certain words in the context text or changes the concepts of logical terms, the outputs of LLMs can",2024-02-19T12:12:35Z
Can LLMs Compute with Reasons?,Yes.,5.,"""Large language models (LLMs) often struggle with complex mathematical tasks, prone to 'hallucinating' incorrect answers due to their reliance on statistical patterns. This limitation is further amplified in average Small LangSLMs with limited context and training data.""",2024-02-19T12:04:25Z
LVCHAT: Facilitating Long Video Comprehension,Yes.,3.,"""Existing works show promise on short videos whereas long video (longer than e.g.~1 minute) comprehension remains challenging. The major problem lies in the over-compression of videos, i.e., the encoded video representations are not enough to represent the whole video.""",2024-02-19T11:59:14Z
EmoBench: Evaluating the Emotional Intelligence of Large Language Models,Yes.,4.,"""Our findings reveal a considerable gap between the EI of existing LLMs and the average human, highlighting a promising direction for future research.""",2024-02-19T11:48:09Z
WKVQuant: Quantizing Weight and Key/Value Cache for Large Language Models Gains More,Yes.,3.,"""Large Language Models (LLMs) face significant deployment challenges due to their substantial memory requirements and the computational demands of auto-regressive text generation process.""",2024-02-19T11:33:21Z
All Language Models Large and Small,Yes.,1.,"""Many leading language models (LMs) use high-intensity computational resources both during training and execution.""",2024-02-19T11:28:20Z
Are LLM-based Evaluators Confusing NLG Quality Criteria?,Yes.,5.,"""we discover that LLMs seem to confuse different evaluation criteria, which reduces their reliability"" and ""Our experimental results reveal confusion issues inherent in LLMs, as well as other noteworthy phenomena, and necessitate further research and improvements for LLM-based evaluation.""",2024-02-19T11:19:02Z
Model Tailor: Mitigating Catastrophic Forgetting in Multi-modal Large Language Models,Yes.,5.,"""Catastrophic forgetting emerges as a critical challenge when fine-tuning multi-modal large language models (MLLMs), where improving performance on unseen tasks often leads to a significant performance drop on the original tasks.""",2024-02-19T11:02:05Z
Self-AMPLIFY: Improving Small Language Models with Self Post Hoc Explanations,Yes.,2.,"""rationales currently require human-annotation or the use of auxiliary proxy models to target promising samples or generate high-quality rationales.""",2024-02-19T10:47:09Z
Towards Cross-Tokenizer Distillation: the Universal Logit Distillation Loss for LLMs,Yes.,4.,"""Deploying large language models (LLMs) of several billion parameters can be impractical in most industrial use cases due to constraints such as cost, latency limitations, and hardware accessibility."" and ""these methods based on logits often require both teacher and student models to share the same tokenizer",2024-02-19T10:37:29Z
Acquiring Clean Language Models from Backdoor Poisoned Datasets by Downscaling Frequency Space,Yes.,3.,"""the reliability of LMs is susceptible to backdoor attacks"" and ""Prior research attempts to mitigate backdoor learning while training the LMs on the poisoned dataset, yet struggles against complex backdoor attacks in real-world scenarios.""",2024-02-19T10:34:48Z
Speech Translation with Speech Foundation Models and Large Language Models: What is There and What is Missing?,Yes.,3.,"""we outline recommendations for future works on the topic aimed at better understanding the strengths and weaknesses of the SFM+LLM solutions for ST.""",2024-02-19T10:34:13Z
Evaluation of ChatGPT's Smart Contract Auditing Capabilities Based on Chain of Thought,Yes.,5.,"""GPT-4 performed poorly in detecting smart contract vulnerabilities, with a high Precision of 96.6%, but a low Recall of 37.8%, and an F1-score of 41.1%, indicating a tendency to miss vulnerabilities during detection."" and ""These experimental results indicate that GPT-4 lacks the ability to detect smart contract vulnerabilities effectively.""",2024-02-19T10:33:29Z
Distilling Large Language Models for Text-Attributed Graph Learning,Yes.,3.,"""Large language models (LLMs) have recently demonstrated remarkable capabilities in few-shot and zero-shot TAG learning, but they suffer from scalability, cost, and privacy issues.""",2024-02-19T10:31:53Z
EBFT: Effective and Block-Wise Fine-Tuning for Sparse LLMs,Yes.,3.,"""Existing methods for fine-tuning sparse LLMs often suffer from resource-intensive requirements and high retraining costs. Additionally, many fine-tuning methods often rely on approximations or heuristic optimization strategies, which may lead to suboptimal solutions.""",2024-02-19T09:55:32Z
Remember This Event That Year? Assessing Temporal Information and Reasoning in Large Language Models,Yes.,5.,"""Large Language Models (LLMs) are increasingly becoming ubiquitous, yet their ability to reason about and retain temporal information remains limited. This hinders their application in real-world scenarios where understanding the sequential nature of events is crucial. This paper experiments with state-of-the-art models on a novel, large-scale temporal dataset, TempUN, to reveal significant limitations in temporal retention and reasoning abilities.""",2024-02-19T09:43:03Z
Structure Guided Large Language Model for SQL Generation,Yes.,3.,"""Existing models typically input queries and database schemas into the LLM and rely on the LLM to perform semantic-structure matching and generate structured SQL. However, such solutions overlook the structural information within user queries and databases, which can be utilized to enhance the generation of structured SQL. This oversight can lead to inaccurate or unexecutable SQL generation.""",2024-02-19T09:07:59Z
DB-LLM: Accurate Dual-Binarization for Efficient LLMs,Yes.,3.,"""the expensive memory and computation consumption impede their practical deployment"" and ""existing ultra-low-bit quantization always causes severe accuracy drops.""",2024-02-19T09:04:30Z
Automatic Evaluation for Mental Health Counseling using LLMs,Yes.,1.,"""This paper proposes an innovative and efficient automatic approach using large language models (LLMs) to evaluate the working alliance in counseling conversations.""",2024-02-19T09:00:10Z
LEMMA: Towards LVLM-Enhanced Multimodal Misinformation Detection with External Knowledge Augmentation,Yes.,3.,"""even though LVLM has a superior performance compared to LLMs, its profound reasoning may present limited power with a lack of evidence.""",2024-02-19T08:32:27Z
Comprehensive Cognitive LLM Agent for Smartphone GUI Automation,Yes.,3.,"""However, those GUI agents require comprehensive cognition ability including exhaustive perception and reliable action response.""",2024-02-19T08:29:03Z
MRKE: The Multi-hop Reasoning Evaluation of LLMs by Knowledge Edition,Yes.,5.,"""1) LLMs show a performance gap between the original HotpotQA and our edited data, deeming that current MHQA benchmarks have the potential risk of data contamination that hard to evaluate LLMs' performance objectively and scientifically; 2) LLMs only get a small percentage of the right reasoning chain, e.g. GPT-4 only gets 36.3",2024-02-19T08:12:30Z
Direct Large Language Model Alignment Through Self-Rewarding Contrastive Prompt Distillation,Yes.,1.,"""Aligning large language models (LLMs) with human expectations without human-annotated preference data is an important problem.""",2024-02-19T07:46:40Z
Learning to Edit: Aligning LLMs with Knowledge Editing,Yes.,3.,"""existing methods predominantly rely on memorizing the updated knowledge, impeding LLMs from effectively combining the new knowledge with their inherent knowledge when answering questions.""",2024-02-19T07:45:17Z
SoLA: Solver-Layer Adaption of LLM for Better Logic Reasoning,Yes.,3.,"""Considering the challenges faced by large language models (LLMs) on logical reasoning, prior efforts have sought to transform problem-solving through tool learning.""",2024-02-19T07:38:57Z
Investigating Multi-Hop Factual Shortcuts in Knowledge Editing of Large Language Models,Yes.,5.,"""However, the reliability of LLMs in combining these two capabilities into reasoning through multi-hop facts has not been widely explored."" and ""Analysis shows that approximately 20% of the failures are attributed to shortcuts.""",2024-02-19T07:34:10Z
SIBO: A Simple Booster for Parameter-Efficient Fine-Tuning,Yes.,3.,"""Fine-tuning all parameters of large language models (LLMs) necessitates substantial computational power and extended time."" and ""the issue of over-smoothing diminishes the effectiveness of these Transformer-based LLMs, resulting in suboptimal performances in downstream tasks.""",2024-02-19T07:22:29Z
Have Seen Me Before? Automating Dataset Updates Towards Reliable and Timely Evaluation,Yes.,3.,"""Due to the expanding capabilities and pre-training data, Large Language Models (LLMs) are facing increasingly serious evaluation challenges."" and ""the data leakage issue cause over-estimation on existing benchmarks.""",2024-02-19T07:15:59Z
Discerning and Resolving Knowledge Conflicts through Adaptive Decoding with Contextual Information-Entropy Constraint,Yes.,4.,"""This raises a crucial dilemma known as knowledge conflicts, where the contextual knowledge clashes with the parametric knowledge internalized during pre-training.""",2024-02-19T07:10:30Z
ROSE Doesn't Do That: Boosting the Safety of Instruction-Tuned Large Language Models with Reverse Prompt Contrastive Decoding,Yes.,2.,"""the current approaches for aligning the LLMs output with expected safety usually require substantial training efforts, e.g., high-quality safety data and expensive computational resources, which are costly and inefficient.""",2024-02-19T06:58:42Z
RJUA-MedDQA: A Multimodal Benchmark for Medical Document Question Answering and Clinical Reasoning,Yes.,4.,"""Although impressive results have been achieved, we find that existing benchmarks do not reflect the complexity of real medical reports and specialized in-depth reasoning capabilities."" and ""The overall performance of existing LMMs is still limited; however LMMs more robust to low",2024-02-19T06:57:02Z
The Colorful Future of LLMs: Evaluating and Improving LLMs as Emotional Supporters for Queer Youth,Yes.,4.,"""We find that LLM responses are supportive and inclusive, outscoring humans. However, they tend to be generic, not empathetic enough, and lack personalization, resulting in nonreliable and potentially harmful advice.""",2024-02-19T06:54:55Z
NOTE: Notable generation Of patient Text summaries through Efficient approach based on direct preference optimization,Yes.,2.,"""large language models' application programming interfaces (LLMs' APIs) are widely available, but importing and exporting medical data presents significant challenges due to privacy protection policies in healthcare institutions.""",2024-02-19T06:43:25Z
LoRA Training in the NTK Regime has No Spurious Local Minima,Yes.,1.,"""Low-rank adaptation (LoRA) has become the standard approach for parameter-efficient fine-tuning of large language models (LLM), but our theoretical understanding of LoRA has been limited.""",2024-02-19T06:22:09Z
Modularized Networks for Few-shot Hateful Meme Detection,Yes.,1.,"""We commence by fine-tuning large language models (LLMs) with LoRA on selected tasks pertinent to hateful meme detection, thereby generating a suite of LoRA modules.""",2024-02-19T05:15:13Z
UniST: A Prompt-Empowered Universal Model for Urban Spatio-Temporal Prediction,Yes.,1.,"""Drawing inspiration from large language models, UniST achieves success through",2024-02-19T05:04:11Z
Ask Optimal Questions: Aligning Large Language Models with Retriever's Preference in Conversational Search,Yes.,3.,"""most existing methods produce sub-optimal query rewrites due to the limited ability to incorporate signals from the retrieval results.""",2024-02-19T04:41:31Z
Microstructures and Accuracy of Graph Recall by Large Language Models,Yes.,5.,"""We find that LLMs not only underperform often in graph recall, but also tend to favor more triangles and alternating 2-paths. Moreover, we find that more advanced LLMs have a striking dependence on the domain that a real-world graph comes from -- by yielding the best recall accuracy when the graph is narrated in a language style consistent with its original domain.""",2024-02-19T04:29:45Z
Head-wise Shareable Attention for Large Language Models,Yes.,4.,"""Large Language Models (LLMs) suffer from huge number of parameters, which restricts their deployment on edge devices.""",2024-02-19T04:19:36Z
HU at SemEval-2024 Task 8A: Can Contrastive Learning Learn Embeddings to Detect Machine-Generated Text?,Yes.,3.,"""Machine-generated texts have been one of the main concerns due to the use of large language models (LLM) in fake text generation, phishing, cheating in exams, or even plagiarizing copyright materials."" and ""Nonetheless, the majority of these systems rely on the text-generating model. This limitation is impractical in real-world scenarios, as it's often impossible to know which specific",2024-02-19T04:11:34Z
FIPO: Free-form Instruction-oriented Prompt Optimization with Preference Dataset and Modular Fine-tuning Schema,Yes.,1.,"""In the quest to facilitate the deep intelligence of Large Language Models (LLMs) accessible in final-end user-bot interactions, the art of prompt crafting emerges as a critical yet complex task for the average user.""",2024-02-19T03:56:44Z
LLM as Prompter: Low-resource Inductive Reasoning on Arbitrary Knowledge Graphs,Yes.,1.,"""In this paper, we attempt to address this challenge with Large Language Models (LLMs).""",2024-02-19T03:21:19Z
What Evidence Do Language Models Find Convincing?,Yes.,4.,"""Overall, we find that current models rely heavily on the relevance of a website to the query, while largely ignoring stylistic features that humans find important such as whether a text contains scientific references or is written with a neutral tone.""",2024-02-19T02:15:34Z
ChatGPT Based Data Augmentation for Improved Parameter-Efficient Debiasing of LLMs,Yes.,4.,"""Large Language models (LLMs), while powerful, exhibit harmful social biases. Debiasing is often challenging due to computational costs, data constraints, and potential degradation of multi-task language capabilities.""",2024-02-19T01:28:48Z
"Large Language Models for Stemming: Promises, Pitfalls and Failures",Yes.,5.,"""We find that while vocabulary stemming and contextual stemming fail to achieve higher effectiveness than traditional stemmers, entity-based contextual stemming can achieve a higher effectiveness than using Porter stemmer alone, under specific conditions.""",2024-02-19T01:11:44Z
MARS: Meaning-Aware Response Scoring for Uncertainty Estimation in Generative LLMs,Yes.,5.,"""However, their tendency to produce inaccurate or misleading outputs poses a potential risk, particularly in high-stakes environments.""",2024-02-19T01:04:22Z
SPML: A DSL for Defending Language Models Against Prompt Attacks,Yes.,4.,"""post-deployment the chatbot definitions are fixed and are vulnerable to attacks by malicious users,"" and ""Existing studies explore user prompts' impact on LLM-based chatbots, yet practical methods to contain attacks on application-specific chatbots remain unexplored.""",2024-02-19T00:53:48Z
ArtPrompt: ASCII Art-based Jailbreak Attacks against Aligned LLMs,Yes.,5.,"""We show that five SOTA LLMs (GPT-3.5, GPT-4, Gemini, Claude, and Llama2) struggle to recognize prompts provided in the form of ASCII art.""",2024-02-19T00:43:31Z
RFBES at SemEval-2024 Task 8: Investigating Syntactic and Semantic Features for Distinguishing AI-Generated and Human-Written Texts,Yes.,2.,"""However, an important issue is how we can detect AI-generated texts from human-written ones.""",2024-02-19T00:40:17Z
In-Context Learning Demonstration Selection via Influence Analysis,Yes.,3.,"""ICL generalization performance is sensitive to the selected demonstrations. Selecting effective demonstrations for ICL is still an open research challenge.""",2024-02-19T00:39:31Z
Language Models are Homer Simpson! Safety Re-Alignment of Fine-tuned Language Models through Task Arithmetic,Yes.,5.,"""Aligned language models face a significant limitation as their fine-tuning often results in compromised safety.""",2024-02-19T00:18:09Z
"Utilizing BERT for Information Retrieval: Survey, Applications, Resources, and Challenges",Yes.,2.,"""Despite the popularity of LLMs, we find that for specific tasks, finely tuned BERT encoders still outperform, and at a lower deployment cost.""",2024-02-18T23:22:40Z
Solving Data-centric Tasks using Large Language Models,Yes.,3.,"""Our experiments show that LLM performance is indeed sensitive to the amount of data passed in the prompt, and that for tasks with a lot of syntactic variation in the input table, our cluster-then-select technique outperforms a random selection baseline.""",2024-02-18T23:19:21Z
How Susceptible are Large Language Models to Ideological Manipulation?,Yes.,5.,"""Our findings reveal a concerning vulnerability",2024-02-18T22:36:19Z
Shaping Human-AI Collaboration: Varied Scaffolding Levels in Co-writing with Language Models,Yes.,1.,"""Advances in language modeling have paved the way for novel human-AI co-writing experiences.""",2024-02-18T22:27:42Z
Modelling Political Coalition Negotiations Using LLM-based Agents,Yes.,1.,"""We evaluate the performance of state-of-the-art large language models (LLMs) as agents in handling coalition negotiations, offering insights into their capabilities and paving the way for future advancements in political modelling.""",2024-02-18T21:28:06Z
MORL-Prompt: An Empirical Analysis of Multi-Objective Reinforcement Learning for Discrete Prompt Optimization,Yes.,1.,"""RL-based techniques can be used to search for prompts that when fed into a target language model maximize a set of user-specified reward functions.""",2024-02-18T21:25:09Z
GNNavi: Navigating the Information Flow in Large Language Models by Graph Neural Network,Yes.,2.,"""fine-tuning still remains crucial to further enhance their adaptability"" and ""high demands on computing resources limit its practicality.""",2024-02-18T21:13:05Z
Search Engines Post-ChatGPT: How Generative Artificial Intelligence Could Make Search Less Reliable,Yes.,4.,"""Our discussion highlights challenges in the early stages of GenAI integration, particularly around factual inconsistencies and biases."" and ""output from GenAI carries an unwarranted sense of credibility, while decreasing transparency and sourcing ability.""",2024-02-18T21:10:18Z
Can ChatGPT Support Developers? An Empirical Evaluation of Large Language Models for Code Generation,Yes.,5.,"""Our empirical findings indicate that the current practice of using LLM-generated code is typically limited to either demonstrating high-level concepts or providing examples in documentation, rather than to be used as production-ready code. These findings indicate that there is much future work needed to improve LLMs in code generation before they can be integral parts of modern software development.""",2024-02-18T20:48:09Z
Why Lift so Heavy? Slimming Large Language Models by Cutting Off the Layers,Yes.,4.,"""the sheer size of these models poses challenges in terms of storage, training and inference due to the inclusion of billions of parameters through layer stacking.""",2024-02-18T20:47:10Z
Vision-Flan: Scaling Human-Labeled Tasks in Visual Instruction Tuning,Yes.,4.,"""two substantial challenges persist within the existing VLM frameworks",2024-02-18T19:38:44Z
One Prompt To Rule Them All: LLMs for Opinion Summary Evaluation,Yes.,1.,"""Recent studies suggest using Large Language Models (LLMs) as reference-free metrics for NLG evaluation, however, they remain unexplored for opinion summary evaluation.""",2024-02-18T19:13:52Z
A Multi-Aspect Framework for Counter Narrative Evaluation using Large Language Models,,,,2024-02-18T18:56:07Z
Autocorrect for Estonian texts: final report from project EKTB25,Yes.,2.,"""The final results show that the approach we have developed provides better scores than GPT4 and the result is usable but not entirely reliable yet.""",2024-02-18T18:20:57Z
Learning From Failure: Integrating Negative Examples when Fine-tuning Large Language Models as Agents,Yes.,5.,"""LLMs are not optimized specifically for tool use during training or alignment, limiting their effectiveness as agents."" and ""the standard approach has been to simply discard trajectories that do not finish the task successfully, which, on the one hand, leads to a significant waste of data and resources, and on the other hand, has the potential to limit the possible optimization paths during fine-tuning.""",2024-02-18T17:10:07Z
Stealthy Attack on Large Language Model based Recommendation,Yes.,5.,"""we reveal that the introduction of LLMs into recommendation models presents new security vulnerabilities due to their emphasis on the textual content of items.""",2024-02-18T16:51:02Z
Towards Versatile Graph Learning Approach: from the Perspective of Large Language Models,Yes.,1.,"""This paper proposes a novel conceptual prototype for designing versatile graph learning methods with LLMs, with a particular focus on the 'where' and 'how' perspectives.""",2024-02-18T16:43:21Z
Stumbling Blocks: Stress Testing the Robustness of Machine-Generated Text Detectors Under Attacks,Yes.,3.,"""Our attacks assume limited access to the generator LLMs,"" and ""Our experiments reveal that almost none of the existing detectors remain robust under all the attacks, and all detectors exhibit different loopholes.""",2024-02-18T16:36:00Z
Self-seeding and Multi-intent Self-instructing LLMs for Generating Intent-aware Information-Seeking dialogs,Yes.,1.,"""While large language models (LLMs) have been shown to be effective in generating synthetic data, there is no study on using LLMs to generate intent-aware information-seeking dialogs.""",2024-02-18T16:20:43Z
On the Roles of LLMs in Planning: Embedding LLMs into Planning Graphs,Yes.,1.,"""Intrigued by the claims of emergent planning capabilities in large language models (LLMs), works have been proposed to investigate the planning effectiveness of LLMs, without considering any utilization of off-the-shelf planning techniques in LLMs.""",2024-02-18T15:53:32Z
SpeCrawler: Generating OpenAPI Specifications from API Documentation Using Large Language Models,Yes.,1.,"""In this paper we introduce SpeCrawler, a comprehensive system that utilizes large language models (LLMs) to generate OpenAPI Specifications from diverse API documentation through a carefully crafted pipeline.""",2024-02-18T15:33:24Z
Decoding News Narratives: A Critical Analysis of Large Language Models in Framing Bias Detection,Yes.,3.,"""Our study also found that models, particularly GPT-4, often misinterpret emotional language as an indicator of framing bias, underscoring the challenge of distinguishing between reporting genuine emotional expression and intentionally use framing bias in news headlines.""",2024-02-18T15:27:48Z
Multi-Task Inference: Can Large Language Models Follow Multiple Instructions at Once?,Yes.,1.,"""Large language models (LLMs) are typically prompted to follow a single instruction per inference call.""",2024-02-18T14:25:19Z
Revisiting Zeroth-Order Optimization for Memory-Efficient LLM Fine-Tuning: A Benchmark,Yes.,5.,"""the substantial memory overhead from back-propagation (BP) for FO gradient computation presents a significant challenge.""",2024-02-18T14:08:48Z
BESA: Pruning Large Language Models with Blockwise Parameter-Efficient Sparsity Allocation,Yes.,3.,"""While their performance is impressive, the computational footprint due to their vast number of parameters can be prohibitive.""",2024-02-18T12:44:15Z
Ain't Misbehavin' -- Using LLMs to Generate Expressive Robot Behavior in Conversations with the Tabletop Robot Haru,,,,2024-02-18T12:35:52Z
LongAgent: Scaling Language Models to 128k Context through Multi-Agent Collaboration,Yes.,5.,"""LLMs with long context windows have been notorious for their expensive training costs and high inference latency. Even the most advanced models such as GPT-4 and Claude2 often make mistakes when processing inputs of over $100k$ tokens, a phenomenon also known as \textit{lost in the",2024-02-18T11:46:52Z
KMMLU: Measuring Massive Multitask Language Understanding in Korean,Yes.,4.,"""identifying significant room for improvement,"" ""Current LLMs tailored to Korean, such as Polyglot-Ko, perform far worse,"" and ""even the most capable proprietary LLMs, e.g., GPT-4 and HyperCLOVA X, achieve 59.95% and 53.40%, respectively. This suggests that further work is needed to improve Korean",2024-02-18T11:41:07Z
ModelGPT: Unleashing LLM's Capabilities for Tailored Model Generation,Yes.,2.,"""However, they still struggle to accommodate the diverse and specific needs of users and simplify the utilization of AI models for the average user.""",2024-02-18T11:24:34Z
Deciphering the Impact of Pretraining Data on Large Language Models through Machine Unlearning,Yes.,3.,"""the impact of each component of the pretraining corpus remains opaque"" and ""the organization of the pretraining corpus is still empirical and may deviate from the optimal.""",2024-02-18T10:36:05Z
Ploutos: Towards interpretable stock movement prediction with financial large language model,Yes.,3.,"""First, they struggle to fuse textual and numerical information flexibly for stock movement prediction. Second, traditional methods lack clarity and interpretability, which impedes their application in scenarios where the justification for predictions is essential.""",2024-02-18T10:28:18Z
Chain-of-Instructions: Compositional Instruction Tuning on Large Language Models,Yes.,3.,"""However, most existing instruction datasets include only single instructions, and they struggle to follow complex instructions composed of multiple subtasks (Wang et al., 2023a).""",2024-02-18T10:10:40Z
Efficient Multimodal Learning from Data-centric Perspective,Yes.,3.,"""their deployment is hindered by substantial computational costs in both training and inference, limiting accessibility to the broader research and user communities.""",2024-02-18T10:09:10Z
Large Language Model-driven Meta-structure Discovery in Heterogeneous Information Network,Yes.,1.,"""We propose a novel REasoning meta-STRUCTure search (ReStruct) framework that integrates LLM reasoning into the evolutionary procedure.""",2024-02-18T09:21:12Z
Knowledge-to-SQL: Enhancing SQL Generation with Data Expert LLM,Yes.,3.,"""there is some necessary knowledge that is not explicitly included in the database schema or has been learned by LLMs. Thus, the generated SQL of the knowledge-insufficient queries may be inaccurate, which negatively impacts the robustness of the text-to-SQL models.""",2024-02-18T09:10:04Z
From Prejudice to Parity: A New Approach to Debiasing Large Language Model Word Embeddings,Yes.,4.,"""Given that these embeddings themselves often reflect or exhibit bias, it stands to reason that these models may also inadvertently learn this bias.""",2024-02-18T08:53:41Z
Federated Fine-tuning of Large Language Models under Heterogeneous Language Tasks and Client Resources,Yes.,3.,"""it raises significant challenges due to the heterogeneous resources and data distributions of clients.""",2024-02-18T08:32:59Z
What's the Plan? Evaluating and Developing Planning-Aware Techniques for LLMs,Yes.,5.,"""we demonstrate through experimentation that LLMs lack necessary skills required for planning.""",2024-02-18T07:42:49Z
MIKE: A New Benchmark for Fine-grained Multimodal Entity Knowledge Editing,Yes.,4.,"""Despite its potential, current benchmarks predominantly focus on coarse-grained knowledge, leaving the intricacies of fine-grained (FG) multimodal entity knowledge largely unexplored."" and ""we demonstrate that the current state-of-the-art methods face significant challenges in tackling our proposed benchmark, underscoring",2024-02-18T07:15:03Z
ChatDiet: Empowering Personalized Nutrition-Oriented Food Recommender Chatbots through an LLM-Augmented Framework,Yes.,2.,"""While Large Language Models (LLMs) bring interpretability and explainability, their standalone use falls short of achieving true personalization.""",2024-02-18T06:07:17Z
scInterpreter: Training Large Language Models to Interpret scRNA-seq Data for Cell Type Annotation,Yes.,3.,"""Despite the inherent limitations of existing Large Language Models in directly reading and interpreting single-cell omics data, they demonstrate significant potential and flexibility as the Foundation Model.""",2024-02-18T05:39:00Z
When Do LLMs Need Retrieval Augmentation? Mitigating LLMs' Overconfidence Helps Retrieval Augmentation,Yes.,5.,"""Large Language Models (LLMs) have been found to have difficulty knowing they do not possess certain knowledge and tend to provide specious answers in such cases.""",2024-02-18T04:57:19Z
FactPICO: Factuality Evaluation for Plain Language Summarization of Medical Evidence,Yes.,5.,"""We find that plain language summarization of medical evidence is still challenging, especially when balancing between simplicity and factuality, and that existing metrics correlate poorly with expert judgments on the instance level.""",2024-02-18T04:45:01Z
LoRA-Flow: Dynamic LoRA Fusion for Large Language Models in Generative Tasks,Yes.,1.,"""LoRA employs lightweight modules to customize large language models (LLMs) for each downstream task or domain.""",2024-02-18T04:41:25Z
MatPlotAgent: Method and Evaluation for LLM-Based Agentic Scientific Data Visualization,Yes.,1.,"""Despite its importance, the use of Large Language Models (LLMs) for scientific data visualization remains rather unexplored.""",2024-02-18T04:28:28Z
AutoPRM: Automating Procedural Supervision for Multi-Step Reasoning via Controllable Question Decomposition,Yes.,3.,"""Recent advancements in large language models (LLMs) have shown promise in multi-step reasoning tasks, yet their reliance on extensive manual labeling to provide procedural feedback remains a significant impediment.""",2024-02-18T04:28:16Z
SciAgent: Tool-augmented Language Models for Scientific Reasoning,Yes.,3.,"""Scientific reasoning poses an excessive challenge for even the most advanced Large Language Models (LLMs).""",2024-02-18T04:19:44Z
In-Context Example Ordering Guided by Label Distributions,Yes.,3.,"""However, a number of problems persist in ICL. In particular, its performance is sensitive to the choice and order of in-context examples.""",2024-02-18T04:08:10Z
Benchmark Self-Evolving: A Multi-Agent Framework for Dynamic LLM Evaluation,Yes.,5.,"""This paper presents a benchmark self-evolving framework to dynamically evaluate rapidly advancing Large Language Models (LLMs), aiming for a more accurate assessment of their capabilities and limitations."" and ""Experimental results show a general performance decline in most LLMs against their original results.""",2024-02-18T03:40:06Z
Can LLMs Reason with Rules? Logic Scaffolding for Stress-Testing and Improving LLMs,Yes.,5.,"""their mastery of underlying inferential rules still falls short of human capabilities,"" and ""reveals significant gaps in LLMs' logic understanding compared to human performance, especially in compositional and structural complex rules with certain bias patterns,"" and ""our work sheds light on",2024-02-18T03:38:51Z
InfuserKI: Enhancing Large Language Models with Knowledge Graphs via Infuser-Guided Knowledge Integration,Yes.,3.,"""Though Large Language Models (LLMs) have shown remarkable open-generation capabilities across diverse domains, they struggle with knowledge-intensive tasks."" and ""Injecting new knowledge poses the risk of forgetting previously acquired knowledge.""",2024-02-18T03:36:26Z
Perils of Self-Feedback: Self-Bias Amplifies in Large Language Models,Yes.,5.,"""We find that self-bias is prevalent in all examined LLMs across multiple languages and tasks. Our analysis reveals that while the self-refine pipeline improves the fluency and understandability of model outputs, it further amplifies self-bias.""",2024-02-18T03:10:39Z
Momentor: Advancing Video Large Language Model with Fine-Grained Temporal Reasoning,Yes.,4.,"""existing Video-LLMs can only capture the coarse-grained semantics and are unable to effectively handle tasks related to comprehension or localization of specific video segments.""",2024-02-18T03:04:38Z
"Can Deception Detection Go Deeper? Dataset, Evaluation, and Benchmark for Deception Reasoning",Yes.,1.,"""This dataset can also be used to evaluate the complex reasoning capability of current large language models and serve as a reasoning benchmark for further research.""",2024-02-18T02:52:54Z
EventRL: Enhancing Event Extraction with Outcome Supervision for Large Language Models,Yes.,4.,"""EventRL utilizes outcome supervision with specific reward functions to tackle prevalent challenges in LLMs, such as instruction following and hallucination, manifested as the mismatch of event structure and the generation of undefined event types.""",2024-02-18T02:41:06Z
Rethinking the Roles of Large Language Models in Chinese Grammatical Error Correction,Yes.,3.,"""Previous studies have shown that LLMs' performance as correctors on CGEC remains unsatisfactory due to its challenging task focus.""",2024-02-18T01:40:34Z
LoRETTA: Low-Rank Economic Tensor-Train Adaptation for Ultra-Low-Parameter Fine-Tuning of Large Language Models,Yes.,3.,"""However, existing PEFT methods are still limited by the growing number of trainable parameters with the rapid deployment of Large Language Models (LLMs).""",2024-02-18T01:20:00Z
Aligning Modalities in Vision Large Language Models via Preference Fine-tuning,Yes.,4.,"""This procedure is not perfect and can cause the model to hallucinate - provide answers that do not accurately reflect the image, even when the core LLM is highly factual and the vision backbone has sufficiently complete representations.""",2024-02-18T00:56:16Z
Multi-dimensional Evaluation of Empathetic Dialog Responses,Yes.,3.,"""measuring conversational empathy remains a challenging task for prompting frozen LLMs, reflected by less satisfying performance of GPT-4 and Flan family models.""",2024-02-18T00:32:33Z
Don't Go To Extremes: Revealing the Excessive Sensitivity and Calibration Limitations of LLMs in Implicit Hate Speech Detection,Yes.,5.,"""LLMs exhibit two extremes",2024-02-18T00:04:40Z
Reasoning before Comparison: LLM-Enhanced Semantic Similarity Metrics for Domain Specialized Text Analysis,Yes.,1.,"""In this study, we leverage LLM to enhance the semantic analysis and develop similarity metrics for texts, addressing the limitations of traditional unsupervised NLP metrics like ROUGE and BLEU.""",2024-02-17T22:46:44Z
CliqueParcel: An Approach For Batching LLM Prompts That Jointly Optimizes Efficiency And Faithfulness,Yes.,3.,"""LLMs still require substantial resources,"" and ""Existing strategies to optimize inference efficiency often compromise on output quality, leading to a discounted output problem.""",2024-02-17T22:37:17Z
Training Language Model Agents without Modifying Language Models,Yes.,1.,"""we present a novel paradigm of training LLM agents without modifying the LLM weights, which is particularly useful when the LLMs are difficult or inaccessible for modifications.""",2024-02-17T18:31:21Z
Understanding the Impact of Long-Term Memory on Self-Disclosure with Large Language Model-Driven Chatbots for Public Health Intervention,Yes.,3.,"""However, we also observed challenges in promoting self-disclosure through LTM, particularly around addressing chronic health conditions and privacy concerns.""",2024-02-17T18:05:53Z
Tasks That Language Models Don't Learn,Yes.,5.,"""We argue that there are certain properties of language that our current large language models (LLMs) don't learn."" and ""highlighting the limitations of knowledge acquired in the absence of sensory experience.""",2024-02-17T17:52:24Z
PhaseEvo: Towards Unified In-Context Prompt Optimization for Large Language Models,Yes.,3.,"""Crafting an ideal prompt for Large Language Models (LLMs) is a challenging task that demands significant resources and expert human input."" and ""formulating such optimization in the discrete and high-dimensional natural language space introduces challenges in terms of convergence and computational efficiency.""",2024-02-17T17:47:10Z
EVEDIT: Event-based Knowledge Editing with Deductive Editing Boundaries,Yes.,3.,"""current KE approaches, which typically operate on (subject, relation, object) triples, ignore the contextual information and the relation among different knowledge. Such editing methods could thus encounter an uncertain editing boundary, leaving a lot of relevant knowledge in ambiguity.""",2024-02-17T16:34:50Z
Dissecting Human and LLM Preferences,Yes.,3.,"""Yet, these preferences merely reflect broad tendencies, resulting in less explainable and controllable models with potential safety risks.""",2024-02-17T14:34:31Z
OneBit: Towards Extremely Low-bit Large Language Models,Yes.,3.,"""existing quantization methods suffer severe performance degradation when the bit-width is extremely reduced.""",2024-02-17T14:26:57Z
Puzzle Solving using Reasoning of Large Language Models: A Survey,Yes.,4.,"""identifying significant challenges in complex puzzle scenarios"" and ""highlight the disparity between LLM capabilities and human-like reasoning.""",2024-02-17T14:19:38Z
Can Large Multimodal Models Uncover Deep Semantics Behind Images?,,,,2024-02-17T13:41:44Z
Multi-Perspective Consistency Enhances Confidence Estimation in Large Language Models,Yes.,3.,"""However, existing methods often fail to overcome the issue of overconfidence on incorrect answers.""",2024-02-17T13:37:39Z
MoRAL: MoE Augmented LoRA for LLMs' Lifelong Learning,Yes.,1.,"""Adapting large language models (LLMs) to new domains/tasks and enabling them to be efficient lifelong learners is a pivotal challenge.""",2024-02-17T12:25:31Z
C-ICL: Contrastive In-context Learning for Information Extraction,Yes.,2.,"""Although researchers are exploring the use of few-shot information extraction through in-context learning with LLMs, they tend to focus only on using correct or positive examples for demonstration, neglecting the potential value of incorporating incorrect or negative examples into the learning process.""",2024-02-17T11:28:08Z
Aligning Large Language Models by On-Policy Self-Judgment,Yes.,1.,"""Existing approaches for aligning large language models with human preferences face a trade-off that requires a separate reward model (RM) for on-policy learning.""",2024-02-17T11:25:26Z
LLM can Achieve Self-Regulation via Hyperparameter Aware Generation,Yes.,3.,"""The current decoding generation process often relies on empirical and heuristic manual adjustments to hyperparameters based on types of tasks and demands. However, this process is typically cumbersome, and the decoding hyperparameters may not always be optimal for each sample.""",2024-02-17T11:18:22Z
Can Large Language Models perform Relation-based Argument Mining?,Yes.,1.,"""In this paper, we show that general-purpose Large Language Models (LLMs), appropriately primed and prompted, can significantly outperform the best performing (RoBERTa-based) baseline.""",2024-02-17T10:37:51Z
When LLMs Meets Acoustic Landmarks: An Efficient Approach to Integrate Speech into Large Language Models for Depression Detection,Yes.,3.,"""However, their primary limitation arises from their exclusive dependence on textual input, which constrains their overall capabilities.""",2024-02-17T09:39:46Z
Controlled Text Generation for Large Language Model with Dynamic Attribute Graphs,Yes.,1.,"""This framework utilizes an attribute scorer to evaluate the attributes of sentences generated by LLMs and constructs dynamic attribute graphs.""",2024-02-17T08:14:37Z
Asclepius: A Spectrum Evaluation Benchmark for Medical Multi-Modal Large Language Models,Yes.,3.,"""Moreover, these benchmarks are susceptible to data leakage, since Med-MLLMs are trained on large assemblies of publicly available data.""",2024-02-17T08:04:23Z
Watch Out for Your Agents! Investigating Backdoor Threats to LLM-Based Agents,Yes.,4.,"""the safety issues of LLM-based agents are currently under-explored"" and ""LLM-based agents suffer severely from backdoor attacks, indicating an urgent need for further research on the development of defenses against backdoor attacks on LLM-based agents.""",2024-02-17T06:48:45Z
Direct Evaluation of Chain-of-Thought in Multi-hop Reasoning with Knowledge Graphs,Yes.,5.,"""However, previous research on evaluating LLMs has solely focused on answer accuracy, neglecting the correctness of the generated CoT."" and ""we find that LLMs possess sufficient knowledge to perform reasoning. However, there exists a significant disparity between answer accuracy and faithfulness of the CoT reasoning generated by LLMs, indicating that they often arrive at correct answers through incorrect reasoning",2024-02-17T05:22:56Z
Evaluating LLMs' Mathematical Reasoning in Financial Document Question Answering,Yes.,4.,"""Large Language Models (LLMs), excel in natural language understanding, but their capability for complex mathematical reasoning with an amalgamation of structured tables and unstructured text is uncertain."" and ""The results provide insights into LLMs' capabilities and limitations in handling complex mathematical scenarios for semi-structured tables.""",2024-02-17T05:10:18Z
I Learn Better If You Speak My Language: Enhancing Large Language Model Fine-Tuning with Style-Aligned Response Adjustments,Yes.,3.,"""The potential for overfitting on a limited number of examples can negatively impact the model's ability to generalize and retain its original skills.""",2024-02-17T05:05:31Z
Disclosure and Mitigation of Gender Bias in LLMs,Yes.,5.,"""Our experiments demonstrate that all tested LLMs exhibit explicit and/or implicit gender bias, even when gender stereotypes are not present in the inputs.""",2024-02-17T04:48:55Z
LaCo: Large Language Model Pruning via Layer Collapse,Yes.,3.,"""Large language models (LLMs) based on transformer are witnessing a notable trend of size expansion, which brings considerable costs to both model training and inference. However, existing methods such as model quantization, knowledge distillation, and model pruning are constrained by various issues, including hardware support limitations, the need for extensive training, and alterations to the internal structure of the model.""",2024-02-17T04:16:30Z
KnowTuning: Knowledge-aware Fine-tuning for Large Language Models,Yes.,5.,"""large language models (LLMs) still struggle to effectively leverage knowledge for knowledge-intensive tasks, manifesting limitations such as generating incomplete, non-factual, or illogical answers.""",2024-02-17T02:54:32Z
M4GT-Bench: Evaluation Benchmark for Black-Box Machine-Generated Text Detection,Yes.,3.,"""Human evaluation for Task 2 shows less than random guess performance, demonstrating the challenges to distinguish unique LLMs.""",2024-02-17T02:50:33Z
Token-Ensemble Text Generation: On Attacking the Automatic AI-Generated Text Detection,,,,2024-02-17T02:25:57Z
GenDec: A robust generative Question-decomposition method for Multi-hop reasoning,Yes.,4.,"""Existing large language models'(LLMs) reasoning ability in multi-hop question answering remains exploration, which is inadequate in answering multi-hop questions. Moreover, it is unclear whether LLMs follow a desired reasoning chain to reach the right final answer.""",2024-02-17T02:21:44Z
KG-Agent: An Efficient Autonomous Agent Framework for Complex Reasoning over Knowledge Graph,Yes.,1.,"""In this paper, we aim to improve the reasoning ability of large language models (LLMs) over knowledge graphs (KGs) to answer complex questions.""",2024-02-17T02:07:49Z
PANDA (Pedantic ANswer-correctness Determination and Adjudication):Improving Automatic Evaluation for Question Answering and Text Generation,Yes.,3.,"""current answer correctness (AC) metrics do not align with human judgments, particularly verbose, free form answers from large language models (LLM)."" and ""There are two challenges",2024-02-17T01:56:19Z
Grasping the Essentials: Tailoring Large Language Models for Zero-Shot Relation Extraction,Yes.,3.,"""existing models typically rely on extensive annotated data for training, which can be both costly and time-consuming to acquire"" and ""these models often struggle to adapt to new or unseen relationships.""",2024-02-17T00:20:06Z
Boosting of Thoughts: Trial-and-Error Problem Solving with Large Language Models,Yes.,3.,"""Recent work, e.g., Tree of Thoughts, has pointed out the importance of exploration and self-evaluation in reasoning step selection for complex problem solving."" and ""uses error analysis obtained from the LLM on them to explicitly revise prompting.""",2024-02-17T00:13:36Z
Contrastive Instruction Tuning,Yes.,5.,"""current LLMs exhibit limited robustness to unseen instructions, generating inconsistent outputs when the same instruction is phrased with slightly varied forms or language styles. This behavior indicates LLMs' lack of robustness to textual variations and generalizability to unseen instructions, potentially leading to trustworthiness issues.""",2024-02-17T00:09:32Z
TuneTables: Context Optimization for Scalable Prior-Data Fitted Networks,No.,1.,The abstract does not mention LLMs or any other language models. It focuses on prior-data fitted networks (PFNs) and their limitations.,2024-02-17T00:02:23Z
Orca-Math: Unlocking the potential of SLMs in Grade School Math,No.,1.,The paper focuses on small language models (SLMs) and does not mention large language models (LLMs) or their limitations.,2024-02-16T23:44:38Z
BlendFilter: Advancing Retrieval-Augmented Large Language Models via Query Generation Blending and Knowledge Filtering,Yes.,3.,"""However, these methods often face challenges with complex inputs and encounter difficulties due to noisy knowledge retrieval, notably hindering model effectiveness.""",2024-02-16T23:28:02Z
Born With a Silver Spoon? Investigating Socioeconomic Bias in Large Language Models,Yes.,5.,"""Our analysis reveals that while humans disagree on which situations require empathy toward the underprivileged, most large language models are unable to empathize with the socioeconomically underprivileged regardless of the situation.""",2024-02-16T23:18:19Z
Navigating the Dual Facets: A Comprehensive Evaluation of Sequential Memory Editing in Large Language Models,Yes.,5.,"""Regrettably, previous studies on ME evaluation have two critical limitations",2024-02-16T23:08:55Z
When LLMs Meet Cunning Questions: A Fallacy Understanding Benchmark for Large Language Models,Yes.,4.,"""we challenge the reasoning and understanding abilities of LLMs by proposing a FaLlacy Understanding Benchmark (FLUB) containing cunning questions that are easy for humans to understand but difficult for models to grasp.""",2024-02-16T22:12:53Z
Word Embeddings Revisited: Do LLMs Offer Something New?,Yes.,2.,"""it is still unclear whether the performance improvement is merely because of scale or whether underlying embeddings they produce significantly differ from classical encoding models like Sentence-BERT (SBERT) or Universal Sentence Encoder (USE).""",2024-02-16T21:47:30Z
VQAttack: Transferable Adversarial Attacks on Visual Question Answering via Pre-trained Models,,,,2024-02-16T21:17:42Z
AFaCTA: Assisting the Annotation of Factual Claim Detection with Reliable LLM Annotators,Yes.,2.,"""To address (2), we introduce AFaCTA (Automatic Factual Claim deTection Annotator), a novel framework that assists in the annotation of factual claims with the help of large language models (LLMs).""",2024-02-16T20:59:57Z
Bridging Causal Discovery and Large Language Models: A Comprehensive Survey of Integrative Approaches and Future Directions,Yes.,3.,"""Our analysis reveals the strengths and potential of LLMs in both enhancing traditional CD methods and as an imperfect expert, alongside the challenges and limitations inherent in current practices.""",2024-02-16T20:48:53Z
Persona-DB: Efficient Large Language Model Personalization for Response Prediction with Collaborative Data Refinement,Yes.,2.,"""Existing research, however, has largely focused on enhancing the retrieval stage and devoted limited exploration toward optimizing the representation of the database, a crucial aspect for tasks such as personalization.""",2024-02-16T20:20:43Z
Large Language Models Fall Short: Understanding Complex Relationships in Detective Narratives,Yes.,5.,"""Our experiments with advanced Large Language Models (LLMs) like GPT-3.5, GPT-4, and Llama2 reveal their limitations in inferencing complex relationships and handling longer narratives.""",2024-02-16T19:59:45Z
Retrieval-Augmented Generation: Is Dense Passage Retrieval Retrieving?,,,,2024-02-16T19:28:52Z
PAT-Questions: A Self-Updating Benchmark for Present-Anchored Temporal Question-Answering,Yes.,5.,"""large language models (LLMs) may have outdated knowledge,"" and ""The results highlight the limitations of existing solutions in PATQA and motivate the need for new methods to improve PATQA reasoning capabilities.""",2024-02-16T19:26:09Z
PaLM2-VAdapter: Progressively Aligned Language Model Makes a Strong Vision-language Adapter,Yes.,3.,"""we observe that the vision-language alignment with perceiver resampler exhibits slow convergence and limited scalability with a lack of direct supervision.""",2024-02-16T18:54:47Z
RLVF: Learning from Verbal Feedback without Overgeneralization,Yes.,5.,"""we find that simply prompting a model with such feedback leads to overgeneralization of the feedback to contexts where it is not relevant.""",2024-02-16T18:50:24Z
Proving membership in LLM pretraining data via data watermarks,Yes.,1.,"""Detecting whether copyright holders' works were used in LLM pretraining is poised to be an important problem.""",2024-02-16T18:49:27Z
Instruction Diversity Drives Generalization To Unseen Tasks,Yes.,2.,"""Its practical success depends on the model learning a broader set of instructions than those it was trained on. Yet the factors that determine model generalization to such unseen tasks are not well understood.""",2024-02-16T18:47:21Z
When is Tree Search Useful for LLM Planning? It Depends on the Discriminator,Yes.,5.,"""current LLMs' discrimination abilities have not met the needs of advanced planning methods to achieve such improvements"" and ""tree search is at least 10--20 times slower but leads to negligible performance gains, which hinders its real-world applications.""",2024-02-16T18:45:58Z
Multi-modal preference alignment remedies regression of visual instruction tuning on language model,Yes.,4.,"""the current MLLMs trained with visual-question-answering (VQA) datasets could suffer from degradation, as VQA datasets lack the diversity and complexity of the original text instruction datasets which the underlying language model had been trained with.""",2024-02-16T18:42:08Z
Exploring Value Biases: How LLMs Deviate Towards the Ideal,Yes.,4.,"""Understanding the non-deliberate(ive) mechanism of LLMs in giving responses is essential in explaining their performance and discerning their biases in real-world applications."" and ""We show that this bias manifests in unexpected places and has implications on relevant application scenarios, like choosing exemplars.""",2024-02-16T18:28:43Z
EcoRank: Budget-Constrained Text Re-ranking Using Large Language Models,Yes.,3.,"""A limitation of these ranking strategies with LLMs is their cost",2024-02-16T18:03:42Z
Time Series Forecasting with LLMs: Understanding and Enhancing Model Capabilities,Yes.,5.,"""For example, our study shows that LLMs excel in predicting time series with clear patterns and trends but face challenges with datasets lacking periodicity."" and ""Overall, this study contributes to insight into the advantages and limitations of LLMs in time series forecasting under different conditions.""",2024-02-16T17:15:28Z
RAG-Driver: Generalisable Driving Explanations with Retrieval-Augmented In-Context Learning in Multi-Modal Large Language Model,Yes.,5.,"""severe data scarcity due to expensive annotation costs and significant domain gaps between different datasets makes the development of a robust and generalisable system an extremely challenging task. Moreover, the prohibitively expensive training requirements of MLLM and the unsolved problem of catastrophic forgetting further limit their generalisability post-deployment.""",2024-02-16T16:57:18Z
Quantifying the Persona Effect in LLM Simulations,Yes.,3.,"""Most subjective NLP datasets fall into this category, casting doubt on simulating diverse perspectives in the current NLP landscape.""",2024-02-16T16:35:35Z
In Search of Needles in a 11M Haystack: Recurrent Memory Finds What LLMs Miss,Yes.,5.,"""Our evaluation, which includes benchmarks for GPT-4 and RAG, reveals that common methods are effective only for sequences up to $10^4$ elements.""",2024-02-16T16:15:01Z
EdgeQAT: Entropy and Distribution Guided Quantization-Aware Training for the Acceleration of Lightweight LLMs on the Edge,Yes.,3.,"""the wide applications of LLMs on edge devices are limited due to their massive parameters and computations"" and ""Post-Training Quantization (PTQ) methods dramatically degrade in quality when quantizing weights, activations, and KV cache",2024-02-16T16:10:38Z
A Condensed Transition Graph Framework for Zero-shot Link Prediction with Large Language Models,Yes.,3.,"""Even though Large Language Models (LLMs) offer a promising solution to predict unobserved relations between the head and tail entity in a zero-shot manner, their performance is still restricted due to the inability to leverage all the (exponentially many) paths' information between two entities, which",2024-02-16T16:02:33Z
AutoGPT+P: Affordance-based Task Planning with Large Language Models,Yes.,3.,"""Recent advances in task planning leverage Large Language Models (LLMs) to improve generalizability by combining such models with classical planning algorithms to address their inherent limitations in reasoning capabilities.""",2024-02-16T16:00:50Z
How Reliable Are Automatic Evaluation Methods for Instruction-Tuned LLMs?,Yes.,3.,"""we observe considerable variability in correlations between automatic methods and human evaluators when scores are differentiated by task type"" and ""their reliability is highly context-dependent.""",2024-02-16T15:48:33Z
ToolSword: Unveiling Safety Issues of Large Language Models in Tool Learning Across Three Stages,Yes.,5.,"""Experiments conducted on 11 open-source and closed-source LLMs reveal enduring safety challenges in tool learning, such as handling harmful queries, employing risky tools, and delivering detrimental feedback, which even GPT-4 is susceptible to.""",2024-02-16T15:19:46Z
GenRES: Rethinking Evaluation for Generative Relation Extraction in the Era of Large Language Models,Yes.,5.,"""traditional relation extraction (RE) metrics like precision and recall fall short in evaluating GRE methods,"" ""prompting LLMs with a fixed set of relations or entities can cause hallucinations,"" and ""precision/recall fails to justify the performance of GRE methods.""",2024-02-16T15:01:24Z
Let's Learn Step by Step: Enhancing In-Context Learning Ability with Curriculum Learning,Yes.,3.,"""LLMs exhibit a weaker capacity compared to humans in discerning the difficulty levels of demonstrations.""",2024-02-16T14:55:33Z
Assessing the Reasoning Abilities of ChatGPT in the Context of Claim Verification,Yes.,5.,"""Our results show that ChatGPT struggles in abductive reasoning,"" and ""Our study contributes to the growing body of research suggesting that ChatGPT's reasoning processes are unlikely to mirror human-like reasoning, and that LLMs need to be more rigorously evaluated to distinguish between hype and actual capabilities",2024-02-16T14:52:05Z
A Novel BERT-based Classifier to Detect Political Leaning of YouTube Videos based on their Titles,Yes.,1.,"""we propose a novel classifier based on Bert -- a language model from Google -- to classify YouTube videos merely based on their titles into six categories""",2024-02-16T14:44:30Z
An Empirical Study on Cross-lingual Vocabulary Adaptation for Efficient Generative LLM Inference,Yes.,4.,"""recent studies have shown that their inference efficiency deteriorates when generating text in languages other than English. This results in increased inference time and costs.""",2024-02-16T14:15:15Z
AutoSAT: Automatically Optimize SAT Solvers via Large Language Models,Yes.,1.,"""AutoSAT is based on Large Large Models (LLMs) which is able to autonomously generate code, conduct evaluation, then utilize the feedback to further optimize heuristics, thereby reducing human intervention and enhancing solver capabilities.""",2024-02-16T14:04:56Z
Multi-Cultural Commonsense Knowledge Distillation,Yes.,3.,"""Despite recent progress, large language models (LLMs) still face the challenge of appropriately reacting to the intricacies of social and cultural conventions.""",2024-02-16T13:46:38Z
Opening the Black Box of Large Language Models: Two Views on Holistic Interpretability,Yes.,4.,"""concerns around potential harms like toxicity, unfairness, and hallucination threaten user trust"" and ""we review the landscape around mechanistic interpretability and representation engineering, summarizing approaches, discussing limitations and applications, and outlining future challenges.""",2024-02-16T13:46:06Z
LongHeads: Multi-Head Attention is Secretly a Long Context Processor,Yes.,5.,"""Large language models (LLMs) have achieved impressive performance in numerous domains but often struggle to process lengthy inputs effectively and efficiently due to limited length generalization and attention's quadratic computational demands.""",2024-02-16T13:39:34Z
German Text Simplification: Finetuning Large Language Models with Semi-Synthetic Data,Yes.,2.,"""This paper employs various methodologies for evaluation and demonstrates the limitations of currently used rule-based metrics.""",2024-02-16T13:28:44Z
Decomposition for Enhancing Attention: Improving LLM-based Text-to-SQL through Workflow Paradigm,,,,2024-02-16T13:24:05Z
OpenFMNav: Towards Open-Set Zero-Shot Object Navigation via Vision-Language Foundation Models,Yes.,1.,"""We first unleash the reasoning abilities of large language models (LLMs) to extract proposed objects from natural language instructions that meet the user's demand.""",2024-02-16T13:21:33Z
Humans or LLMs as the Judge? A Study on Judgement Biases,Yes.,5.,"""Results show that human and LLM judges are vulnerable to perturbations to various degrees, and that even the most cutting-edge judges possess considerable biases.""",2024-02-16T13:21:06Z
Improving Demonstration Diversity by Human-Free Fusing for Text-to-SQL,Yes.,2.,"""human labeling suffers from the limitations of insufficient diversity and high labeling overhead.""",2024-02-16T13:13:18Z
Network Formation and Dynamics Among Multi-LLMs,Yes.,1.,"""Our study analyzes LLMs' network formation behavior to examine whether the dynamics of multiple LLMs are similar to or different from human social dynamics.""",2024-02-16T13:10:14Z
Enhancing Numerical Reasoning with the Guidance of Reliable Reasoning Processes,Yes.,4.,"""current methods have the limitation that most methods generate reasoning processes with large language models (LLMs), which are 'unreliable' since such processes could contain information unrelated to the answer.""",2024-02-16T13:02:11Z
AbsInstruct: Eliciting Abstraction Ability from LLMs through Explanation Tuning with Plausibility Estimation,Yes.,3.,"""Existing work shows that LLMs are deficient in abstract ability, and how to improve it remains unexplored.""",2024-02-16T12:47:11Z
Can Separators Improve Chain-of-Thought Prompting?,Yes.,3.,"""the densely structured prompt exemplars of CoT may cause the cognitive overload of LLMs.""",2024-02-16T12:46:16Z
BitDistiller: Unleashing the Potential of Sub-4-Bit LLMs via Self-Distillation,Yes.,2.,"""The upscaling of Large Language Models (LLMs) has yielded impressive advances in natural language processing, yet it also poses significant deployment challenges.""",2024-02-16T12:27:15Z
Enhancing Role-playing Systems through Aggressive Queries: Evaluation and Improvement,Yes.,5.,"""existing LLM-based RPSs still struggle to align with roles when handling intricate and trapped queries in boundary scenarios."" and ""we find that existing models exhibit a general deficiency in role alignment capabilities.""",2024-02-16T12:12:05Z
Can LLMs Speak For Diverse People? Tuning LLMs via Debate to Generate Controllable Controversial Statements,Yes.,4.,"""existing LLMs lack sufficient controllability to the stance of their generated content, which often contains inconsistent, neutral, or biased statements.""",2024-02-16T12:00:34Z
Retrieve Only When It Needs: Adaptive Retrieval Augmentation for Hallucination Mitigation in Large Language Models,Yes.,5.,"""Hallucinations pose a significant challenge for the practical implementation of large language models (LLMs). The utilization of parametric knowledge in generating factual content is constrained by the limited knowledge of LLMs, potentially resulting in internal hallucinations.""",2024-02-16T11:55:40Z
Jailbreaking Proprietary Large Language Models using Word Substitution Cipher,Yes.,4.,"""Large Language Models (LLMs) are aligned to moral and ethical guidelines but remain susceptible to creative prompts called Jailbreak that can bypass the alignment process."" and ""Additionally, we discuss the over-defensiveness of these models.""",2024-02-16T11:37:05Z
Efficiency at Scale: Investigating the Performance of Diminutive Language Models in Clinical Tasks,Yes.,3.,"""The entry of large language models (LLMs) into research and commercial spaces has led to a trend of ever-larger models, with initial promises of generalisability, followed by a widespread desire to downsize and create specialised models without the need for complete fine-tuning, using Parameter Efficient Fine-tuning (PEFT) methods.""",2024-02-16T11:30:11Z
Do Llamas Work in English? On the Latent Language of Multilingual Transformers,Yes.,3.,"""our evidence suggests that the abstract 'concept space' lies closer to English than to other languages, which may have important consequences regarding the biases held by multilingual language models.""",2024-02-16T11:21:28Z
Threads of Subtlety: Detecting Machine-Generated Texts Through Discourse Motifs,Yes.,1.,"""With the advent of large language models (LLM), the line between human-crafted and machine-generated texts has become increasingly blurred.""",2024-02-16T11:20:30Z
LinkNER: Linking Local Named Entity Recognition Models to Large Language Models using Uncertainty,Yes.,3.,"""Large Language Models (LLMs) like GPT-4 possess extensive external knowledge, but research indicates that they lack specialty for NER tasks. Furthermore, non-public and large-scale weights make tuning LLMs difficult.""",2024-02-16T11:02:29Z
LLMs in the Heart of Differential Testing: A Case Study on a Medical Rule Engine,Yes.,3.,"""We experimented with four different LLMs, two medical rule engine implementations, and 58 real medical rules to investigate the hallucination, success, time efficiency, and robustness of the LLMs to generate tests.""",2024-02-16T10:56:15Z
InSaAF: Incorporating Safety through Accuracy and Fairness | Are LLMs ready for the Indian Legal Domain?,Yes.,4.,"""Despite their immense potential, these models have been proven to learn and exhibit societal biases and make unfair predictions.""",2024-02-16T10:54:10Z
SPAR: Personalized Content-Based Recommendation via Long Engagement Attention,Yes.,2.,"""existing works still struggle with processing very long user historical text and insufficient user-item interaction.""",2024-02-16T10:36:38Z
Disordered-DABS: A Benchmark for Dynamic Aspect-Based Summarization in Disordered Texts,Yes.,2.,"""our comprehensive experiments and detailed human evaluations reveal that Disordered-DABS poses unique challenges to contemporary summarization models, including state-of-the-art language models such as GPT-3.5.""",2024-02-16T10:35:18Z
Conversational SimulMT: Efficient Simultaneous Translation with Large Language Models,Yes.,3.,"""Recent studies have shown that LLMs can achieve good performance in SimulMT tasks. However, this often comes at the expense of high inference cost and latency.""",2024-02-16T10:32:16Z
Properties and Challenges of LLM-Generated Explanations,Yes.,4.,"""However, current LLMs do not (only) rely on specifically annotated data; nonetheless, they frequently explain their outputs,"" and ""We discuss reasons and consequences of the properties' presence or absence. In particular, we outline positive and negative implications depending on the goals and user groups of the self-rationalising system.""",2024-02-16T09:37:54Z
Can We Verify Step by Step for Incorrect Answer Detection?,Yes.,3.,"""This benchmark aims to measure the falsehood of the final output of LLMs based on the reasoning steps.""",2024-02-16T09:29:50Z
Zero-shot sampling of adversarial entities in biomedical question answering,Yes.,5.,"""Our investigations illustrate the brittleness of domain knowledge in LLMs and reveal a shortcoming of standard evaluations for high-capacity models.""",2024-02-16T09:29:38Z
LLM Comparator: Visual Analytics for Side-by-Side Evaluation of Large Language Models,Yes.,2.,"""analyzing the results from this evaluation approach raises scalability and interpretability challenges.""",2024-02-16T09:14:49Z
"Any-Precision LLM: Low-Cost Deployment of Multiple, Different-Sized LLMs",Yes.,2.,"""considerable efforts have been directed towards compressing Large Language Models (LLMs), which showcase groundbreaking capabilities across diverse applications but entail significant deployment costs due to their large sizes.""",2024-02-16T09:06:06Z
Provably Sample Efficient RLHF via Active Preference Optimization,Yes.,3.,"""the dependence on high-quality human preference data poses a costly bottleneck in practical implementation of RLHF.""",2024-02-16T08:19:34Z
Comparing Hallucination Detection Metrics for Multilingual Generation,Yes.,3.,"""Our findings highlight existing gaps in multilingual hallucination detection and motivate future research to develop more robust detection methods for LLM hallucination in other languages.""",2024-02-16T08:10:34Z
Unsupervised LLM Adaptation for Question Answering,Yes.,5.,"""they have difficulties in accessing information located in the middle or at the end of documents.""",2024-02-16T06:29:16Z
Large Language Models as Zero-shot Dialogue State Tracker through Function Calling,Yes.,3.,"""However, their effectiveness in task-oriented dialogues (TOD), which requires not only response generation but also effective dialogue state tracking (DST) within specific tasks and domains, remains less satisfying.""",2024-02-16T06:13:18Z
QDyLoRA: Quantized Dynamic Low-Rank Adaptation for Efficient Large Language Model Tuning,Yes.,3.,"""Finetuning large language models requires huge GPU memory, restricting the choice to acquire Larger models."" and ""finding the efficient LoRA rank is still challenging.""",2024-02-16T05:42:17Z
WilKE: Wise-Layer Knowledge Editor for Lifelong Knowledge Editing,Yes.,5.,"""This study reveals a performance degradation encountered by knowledge editing in lifelong editing, characterized by toxicity buildup and toxicity flash, with the primary cause identified as pattern unmatch.""",2024-02-16T05:29:59Z
Steering Conversational Large Language Models for Long Emotional Support Conversations,Yes.,3.,"""In this study, we address the challenge of consistently following emotional support strategies in long conversations by large language models (LLMs).""",2024-02-16T05:03:01Z
I Am Not Them: Fluid Identities and Persistent Out-group Bias in Large Language Models,Yes.,4.,"""The results indicate that when imbued with a particular social identity, ChatGPT discerns in-group and out-group, embracing in-group values while eschewing out-group values. Notably, the negativity towards the out-group, from which prejudices and discrimination arise, exceeded the positivity towards the in-group."" and ""this replication unveiled an intrinsic Democratic bias in Large Language Models (LL",2024-02-16T03:54:48Z
Smaller Language Models are capable of selecting Instruction-Tuning Training Data for Larger Language Models,Yes.,1.,"""Instruction-tuning language models has become a crucial step in aligning them for general use.""",2024-02-16T03:39:37Z
DELL: Generating Reactions and Explanations for LLM-Based Misinformation Detection,Yes.,5.,"""Large language models are limited by challenges in factuality and hallucinations to be directly employed off-the-shelf for judging the veracity of news articles, where factual accuracy is paramount.""",2024-02-16T03:24:56Z
Measuring and Reducing LLM Hallucination without Gold-Standard Answers via Expertise-Weighting,Yes.,5.,"""LLM hallucination, i.e. generating factually incorrect yet seemingly convincing answers, is currently a major threat to the trustworthiness and reliability of LLMs.""",2024-02-16T02:32:06Z
Understanding Survey Paper Taxonomy about Large Language Models via Graph Representation Learning,Yes.,1.,"""leveraging graph structure information on co-category graphs can significantly outperform the language models in two paradigms; pre-trained language models' fine-tuning and zero-shot/few-shot classifications using LLMs.""",2024-02-16T02:21:59Z
Chain of Logic: Rule-Based Reasoning with Large Language Models,Yes.,2.,"""Reasoning about compositional rules is challenging because it requires multiple reasoning steps, and attending to the logical relationships between elements.""",2024-02-16T01:54:43Z
DataDreamer: A Tool for Synthetic Data Generation and Reproducible LLM Workflows,Yes.,4.,"""However, challenges arise when using these models that stem from their scale, their closed source nature, and the lack of standardized tooling for these new and emerging workflows."" and ""The rapid rise to prominence of these models and these unique challenges has had immediate adverse impacts on open science and on the reproducibility of work that uses them.""",2024-02-16T00:10:26Z
BioMistral: A Collection of Open-Source Pretrained Large Language Models for Medical Domains,Yes.,2.,"""Despite the availability of various open-source LLMs tailored for health contexts, adapting general-purpose LLMs to the medical domain presents significant challenges.""",2024-02-15T23:39:04Z
Can we Soft Prompt LLMs for Graph Learning Tasks?,Yes.,3.,"""However, directly applying LLMs to graph modalities presents unique challenges due to the discrepancy and mismatch between the graph and text modalities.""",2024-02-15T23:09:42Z
Prompt-Based Bias Calibration for Better Zero/Few-Shot Learning of Language Models,Yes.,3.,"""Prompt learning is susceptible to intrinsic bias present in pre-trained language models (LMs), resulting in sub-optimal performance of prompt-based zero/few-shot learning.""",2024-02-15T22:54:24Z
Large Language Models for Forecasting and Anomaly Detection: A Systematic Literature Review,Yes.,5.,"""this review identifies several critical challenges that impede their broader adoption and effectiveness, including the reliance on vast historical datasets, issues with generalizability across different contexts, the phenomenon of model hallucinations, limitations within the models' knowledge boundaries, and the substantial computational resources required.""",2024-02-15T22:43:02Z
On the Safety Concerns of Deploying LLMs/VLMs in Robotics: Highlighting the Risks and Vulnerabilities,Yes.,5.,"""such integration can introduce significant vulnerabilities, in terms of their susceptibility to adversarial attacks due to the language models, potentially leading to catastrophic consequences"" and ""simple adversarial attacks can significantly undermine the effectiveness of LLM/VLM-robot integrated systems.""",2024-02-15T22:01:45Z
SportsMetrics: Blending Text and Numerical Data to Understand Information Fusion in LLMs,,,,2024-02-15T20:26:07Z
How to Discern Important Urgent News?,Yes.,1.,"""The found correlation should allow using clustering (as an alternative to LLM) for identifying the most important urgent news, or for filtering out unimportant articles.""",2024-02-15T20:08:07Z
LAVE: LLM-Powered Agent Assistance and Language Augmentation for Video Editing,Yes.,1.,"""we explore the integration of large language models (LLMs) into the video editing workflow to reduce these barriers.""",2024-02-15T19:53:11Z
Self-Play Fine-Tuning of Diffusion Models for Text-to-Image Generation,No.,1.,"The abstract focuses on diffusion models and their fine-tuning techniques, without mentioning LLMs or their limitations.",2024-02-15T18:59:18Z
A StrongREJECT for Empty Jailbreaks,Yes.,3.,"""there is no standard benchmark for measuring the severity of a jailbreak,"" and ""Some jailbreak techniques make the problem worse by decreasing the quality of model responses even on benign questions.""",2024-02-15T18:58:09Z
Chain-of-Thought Reasoning Without Prompting,Yes.,3.,"""These methods, while effective, often involve manually intensive prompt engineering.""",2024-02-15T18:55:41Z
A Trembling House of Cards? Mapping Adversarial Attacks against Language Agents,,,,2024-02-15T18:51:32Z
BitDelta: Your Fine-Tune May Only Be Worth One Bit,Yes.,3.,"""This interesting finding not only highlights the potential redundancy of information added during fine-tuning, but also has significant implications for the multi-tenant serving and multi-tenant storage of fine-tuned models.""",2024-02-15T18:50:06Z
Uncertainty Quantification for In-Context Learning of Large Language Models,Yes.,5.,"""trustworthy issues with LLM's response, such as hallucination"" and ""highlighting that such uncertainties may stem from both the provided demonstrations (aleatoric uncertainty) and ambiguities tied to the model's configurations (epistemic uncertainty).""",2024-02-15T18:46:24Z
Language Models with Conformal Factuality Guarantees,Yes.,5.,"""Guaranteeing the correctness and factuality of language model (LM) outputs is a major open problem.""",2024-02-15T18:31:53Z
OpenMathInstruct-1: A 1.8 Million Math Instruction Tuning Dataset,Yes.,2.,"""A key reason limiting the use of open-source LLMs in these data generation pipelines has been the wide gap between the mathematical skills of the best closed-source LLMs, such as GPT-4, and the best open-source LLMs.""",2024-02-15T18:26:11Z
Generative AI and Process Systems Engineering: The Next Frontier,Yes.,2.,"""Furthermore, the article identifies and discusses potential challenges in fully leveraging GenAI within PSE, including multiscale modeling, data requirements, evaluation metrics and benchmarks, and trust and safety.""",2024-02-15T18:20:42Z
OptiMUS: Scalable Optimization Modeling with (MI)LP Solvers and Large Language Models,Yes.,1.,"""This paper introduces OptiMUS, a Large Language Model (LLM)-based agent designed to formulate and solve (mixed integer) linear programming problems from their natural language descriptions.""",2024-02-15T18:19:18Z
Knowledge-Infused LLM-Powered Conversational Health Agent: A Case Study for Diabetes Patients,Yes.,3.,"""current LLM-based approaches are limited by their dependence on general sources and lack of integration with domain-specific knowledge, leading to inaccurate responses.""",2024-02-15T18:00:02Z
TOAD: Task-Oriented Automatic Dialogs with Diverse Response Styles,Yes.,2.,"""the creation of high-quality annotated data for Task-Oriented Dialog (TOD) is recognized to be slow and costly.""",2024-02-15T17:40:02Z
Selective Reflection-Tuning: Student-Selected Data Recycling for LLM Instruction-Tuning,Yes.,2.,"""its success heavily relies on the training data quality"" and ""many recent methods focus on improving the data quality but often overlook the compatibility of the data with the student model being finetuned.""",2024-02-15T17:06:21Z
Towards Reducing Diagnostic Errors with Interpretable Risk Prediction,Yes.,1.,"""We use an LLM to retrieve an initial pool of evidence, but then refine this set of evidence according to correlations learned by the model.""",2024-02-15T17:05:48Z
Quantized Embedding Vectors for Controllable Diffusion Language Models,Yes.,3.,"""the memory and computational power are still very demanding and fall short of expectations, which naturally results in low portability and instability for the models.""",2024-02-15T17:02:48Z
GeoEval: Benchmark for Evaluating LLMs and Multi-Modal Models on Geometry Problem-Solving,Yes.,3.,"""Our evaluation of ten LLMs and MMs across these varied subsets reveals that the WizardMath model excels, achieving a 55.67% accuracy rate on the main subset but only a 6.00% accuracy on the challenging subset. This highlights the",2024-02-15T16:59:41Z
Fine-tuning Large Language Model (LLM) Artificial Intelligence Chatbots in Ophthalmology and LLM-based evaluation using GPT-4,Yes.,3.,"""Notably, qualitative analysis and the glaucoma sub-analysis revealed clinical inaccuracies in the LLM-generated responses, which were appropriately identified by the GPT-4 evaluation.""",2024-02-15T16:43:41Z
Both Matter: Enhancing the Emotional Intelligence of Large Language Models without Compromising the General Intelligence,Yes.,3.,"""Previous works mainly focus on raising the emotion perception ability of them via naive fine-tuning on EI-related classification or regression tasks. However, this leads to the incomplete enhancement of EI and catastrophic forgetting of the general intelligence (GI).""",2024-02-15T16:36:04Z
Towards Safer Large Language Models through Machine Unlearning,Yes.,3.,"""LLMs often encounter challenges in generating harmful content when faced with problematic prompts.""",2024-02-15T16:28:34Z
Unmemorization in Large Language Models via Self-Distillation and Deliberate Imagination,Yes.,5.,"""Large Language Models (LLMs) still struggle with crucial issues of privacy violation and unwanted exposure of sensitive data.""",2024-02-15T16:21:14Z
SwissNYF: Tool Grounded LLM Agents for Black Box Setting,Yes.,3.,"""This methodology is practical for simpler APIs but faces scalability issues with irreversible APIs that significantly impact the system, such as a database deletion API. Similarly, processes requiring extensive time for each API call and those necessitating forward planning, like automated action pipelines, present complex challenges.""",2024-02-15T16:15:38Z
RS-DPO: A Hybrid Rejection Sampling and Direct Preference Optimization Method for Alignment of Large Language Models,,,,2024-02-15T16:00:58Z
Self-Augmented In-Context Learning for Unsupervised Word Translation,Yes.,3.,"""they still cannot match the performance of 'traditional' mapping-based approaches in the unsupervised scenario where no seed translation pairs are available, especially for lower-resource languages"" and ""we also conduct comprehensive analyses on SAIL and discuss its limitations.""",2024-02-15T15:43:05Z
LLMs as Bridges: Reformulating Grounded Multimodal Named Entity Recognition,Yes.,1.,"""In this paper, we propose RiVEG, a unified framework that reformulates GMNER into a joint MNER-VE-VG task by leveraging large language models (LLMs) as a connecting bridge.""",2024-02-15T14:54:33Z
Case Study: Testing Model Capabilities in Some Reasoning Tasks,Yes.,5.,"""However, their capabilities in reasoning and providing explainable outputs, especially within the context of reasoning abilities, remain areas for improvement. In this study, we delve into the reasoning abilities of LLMs, highlighting the current challenges and limitations that hinder their effectiveness in complex reasoning scenarios.""",2024-02-15T14:21:30Z
Crafting a Good Prompt or Providing Exemplary Dialogues? A Study of In-Context Learning for Persona-based Dialogue Generation,Yes.,3.,"""Previous explanations of the ICL mechanism, such as $n$-gram induction head, cannot fully account for this phenomenon.""",2024-02-15T14:03:33Z
Generative AI in the Construction Industry: A State-of-the-art Analysis,Yes.,1.,"""However, there is a gap in the literature on the current state, opportunities, and challenges of generative AI in the construction industry.""",2024-02-15T13:39:55Z
Enhancing Large Language Models with Pseudo- and Multisource- Knowledge Graphs for Open-ended Question Answering,Yes.,5.,"""Mitigating the hallucinations of Large Language Models (LLMs) and enhancing them is a crucial task. Although some existing methods employ model self-enhancement techniques, they fall short of effectively addressing unknown factual hallucinations.""",2024-02-15T12:20:02Z
DE-COP: Detecting Copyrighted Content in Language Models Training Data,Yes.,1.,"""We are motivated by the premise that a language model is likely to identify verbatim excerpts from its training text.""",2024-02-15T12:17:15Z
Inadequacies of Large Language Model Benchmarks in the Era of Generative Artificial Intelligence,Yes.,5.,"""Our research uncovered significant limitations, including biases, difficulties in measuring genuine reasoning, adaptability, implementation inconsistencies, prompt engineering complexity, evaluator diversity, and the overlooking of cultural and ideological norms in one comprehensive assessment.""",2024-02-15T11:08:10Z
Camouflage is all you need: Evaluating and Enhancing Language Model Robustness Against Camouflage Adversarial Attacks,Yes.,3.,"""This study undertakes a systematic exploration of this challenge in two distinct phases",2024-02-15T10:58:22Z
MuChin: A Chinese Colloquial Description Benchmark for Evaluating Language Models in the Field of Music,Yes.,1.,"""we present MuChin, the first open-source music description benchmark in Chinese colloquial language, designed to evaluate the performance of multimodal LLMs in understanding and describing music.""",2024-02-15T10:55:01Z
LAPDoc: Layout-Aware Prompting for Documents,Yes.,3.,"""In addition, we study the impact of noisy OCR and layout errors, as well as the limitations of LLMs when it comes to utilizing document layout.""",2024-02-15T10:00:49Z
EFUF: Efficient Fine-grained Unlearning Framework for Mitigating Hallucinations in Multimodal Large Language Models,Yes.,3.,"""Multimodal large language models (MLLMs) ... may still generate descriptions that include objects not present in the corresponding images, a phenomenon known as object hallucination.""",2024-02-15T08:58:03Z
NutePrune: Efficient Progressive Pruning with Numerous Teachers for Large Language Models,Yes.,3.,"""The considerable size of Large Language Models (LLMs) presents notable deployment challenges, particularly on resource-constrained hardware."" and ""Knowledge Distillation is well-suited for pruning, as the intact model can serve as an excellent teacher for pruned students. However, it becomes challenging in the context of LLMs due to memory constraints.""",2024-02-15T08:03:12Z
Aligning Crowd Feedback via Distributional Preference Reward Modeling,Yes.,3.,"""the conventional reward modelling has predominantly depended on human annotations provided by a select cohort of individuals. Such dependence may unintentionally result in models that are skewed to reflect the inclinations of these annotators, thereby failing to represent the expectations of the wider population adequately.""",2024-02-15T07:29:43Z
Grounding Language Model with Chunking-Free In-Context Retrieval,Yes.,3.,"""Traditional RAG systems often struggle with grounding responses using precise evidence text due to the challenges of processing lengthy documents and filtering out irrelevant content. Commonly employed solutions, such as document chunking and adapting language models to handle longer contexts, have their limitations.""",2024-02-15T07:22:04Z
Efficient Language Adaptive Pre-training: Extending State-of-the-Art Large Language Models for Polish,Yes.,1.,"""This study explores the potential of fine-tuning foundational English Large Language Models (LLMs) for generating Polish text.""",2024-02-15T07:17:10Z
Model Compression and Efficient Inference for Large Language Models: A Survey,Yes.,3.,"""However, the significant memory and computational costs incurred during the inference process make it challenging to deploy large models on resource-constrained devices.""",2024-02-15T06:58:30Z
AI Hospital: Interactive Evaluation and Collaboration of LLMs as Intern Doctors for Clinical Diagnosis,Yes.,3.,"""the application has predominantly been limited to discriminative and question-answering tasks, which does not fully leverage their interactive potential.""",2024-02-15T06:46:48Z
Toward a Team of AI-made Scientists for Scientific Discovery from Gene Expression Data,Yes.,1.,"""TAIS comprises simulated roles, including a project manager, data engineer, and domain expert, each represented by a Large Language Model (LLM).""",2024-02-15T06:30:12Z
Do LLMs Know about Hallucination? An Empirical Investigation of LLM's Hidden States,Yes.,5.,"""Large Language Models (LLMs) can make up answers that are not real, and this is known as hallucination."" and ""Our empirical findings suggest that LLMs react differently when processing a genuine response versus a fabricated one.""",2024-02-15T06:14:55Z
AbuseGPT: Abuse of Generative AI ChatBots to Create Smishing Campaigns,Yes.,2.,"""We have found strong empirical evidences to show that attackers can exploit ethical standards in the existing generative AI-based chatbot services by crafting prompt injection attacks to create newer smishing campaigns.""",2024-02-15T05:49:22Z
A Human-Inspired Reading Agent with Gist Memory of Very Long Contexts,Yes.,5.,"""Current Large Language Models (LLMs) are not only limited to some maximum context length, but also are not able to robustly consume long inputs.""",2024-02-15T05:40:21Z
Best Arm Identification for Prompt Learning under a Limited Budget,Yes.,2.,"""the cost incurred during the learning process (e.g., accessing LLM and evaluating the responses) has not been considered.""",2024-02-15T05:31:13Z
PAL: Proxy-Guided Black-Box Attack on Large Language Models,Yes.,5.,"""Large Language Models (LLMs) have surged in popularity in recent months, but they have demonstrated concerning capabilities to generate harmful content when manipulated. While techniques like safety fine-tuning aim to minimize harmful use, recent works have shown that LLMs remain vulnerable to attacks that elicit toxic responses.""",2024-02-15T02:54:49Z
How to Train Data-Efficient LLMs,Yes.,1.,"""The training of large language models (LLMs) is expensive.""",2024-02-15T02:27:57Z
CodeMind: A Framework to Challenge Large Language Models for Code Reasoning,Yes.,5.,"""Solely relying on test passing to evaluate Large Language Models (LLMs) for code synthesis may result in unfair assessment or promoting models with data leakage."" and ""their performance drops for code with higher complexity, non-trivial logical and arithmetic operators, non-primitive types, and API calls.""",2024-02-15T02:24:46Z
The Butterfly Effect of Model Editing: Few Edits Can Trigger Large Language Models Collapse,Yes.,5.,"""even a single edit can trigger model collapse, manifesting as significant performance degradation in various benchmark tasks"" and ""benchmarking LLMs after each edit, while necessary to prevent such collapses, is impractically time-consuming and resource-intensive.""",2024-02-15T01:50:38Z
ProtChatGPT: Towards Understanding Proteins with Large Language Models,Yes.,1.,"""Recent Large Language Models (LLMs) have made significant strides in comprehending task-specific knowledge, suggesting the potential for ChatGPT-like systems specialized in protein to facilitate basic research.""",2024-02-15T01:22:30Z
Answer is All You Need: Instruction-following Text Embedding via Answering the Question,Yes.,1.,"""InBedder demonstrates significantly improved instruction-following capabilities according to our proposed instruction awareness tests and instruction robustness tests, when applied to both large language models (LLMs) (e.g., llama-2-7b) and smaller encoder-based LMs (e.g., roberta",2024-02-15T01:02:41Z
LLM-Enhanced User-Item Interactions: Leveraging Edge Information for Optimized Recommendations,Yes.,3.,"""A primary challenge is the inability of LLMs to deeply exploit the edge information in graphs, which is critical for understanding complex node relationships. This gap limits the potential of LLMs to extract meaningful insights from graph structures, limiting their applicability in more complex graph-based analysis.""",2024-02-14T23:12:09Z
Probabilistic Reasoning in Generative Large Language Models,Yes.,5.,"""Despite improvements in the mathematical reasoning capabilities of LLMs, they still exhibit significant difficulties when it comes to probabilistic reasoning.""",2024-02-14T23:05:44Z
Emerging Opportunities of Using Large Language Models for Translation Between Drug Molecules and Indications,Yes.,3.,"""We also emphasize the current limitations and discuss future work that has the potential to improve the performance on this task.""",2024-02-14T21:33:13Z
Large Language Model-Based Interpretable Machine Learning Control in Building Energy Systems,Yes.,1.,"""combining them, LLM further packages these insights into a coherent, human-understandable narrative.""",2024-02-14T21:19:33Z
Rationality Report Cards: Assessing the Economic Rationality of Large Language Models,Yes.,2.,"""determining whether an LLM agent is reliable enough to be trusted -- requires a methodology for assessing such an agent's economic rationality.""",2024-02-14T20:05:26Z
How Secure Are Large Language Models (LLMs) for Navigation in Urban Environments?,Yes.,5.,"""However, the security aspects of these systems have received relatively less attention"" and ""Our results, derived from the Touchdown and Map2Seq street-view datasets under both few-shot learning and fine-tuning configurations, demonstrate notable performance declines across three metrics in the face of both white-box and black-box attacks.""",2024-02-14T19:45:17Z
"Arrange, Inpaint, and Refine: Steerable Long-term Music Audio Generation and Editing via Content-based Controls",Yes.,3.,"""While Large Language Models (LLMs) have shown promise in generating high-quality music, their focus on autoregressive generation limits their utility in music editing tasks.""",2024-02-14T19:00:01Z
AQA-Bench: An Interactive Benchmark for Evaluating LLMs' Sequential Reasoning Ability,Yes.,3.,"""Our investigations reveal several interesting findings",2024-02-14T18:59:33Z
Reinforcement Learning from Human Feedback with Active Queries,Yes.,2.,"""Despite their superior performance, current RLHF approaches often require a large amount of human-labelled preference data, which is expensive to collect.""",2024-02-14T18:58:40Z
Get More with LESS: Synthesizing Recurrence with KV Cache Compression for Efficient LLM Inference,Yes.,5.,"""Many computational factors limit broader deployment of large language models."" and ""we focus on a memory bottleneck imposed by the key-value (KV) cache, a computational shortcut that requires storing previous KV pairs during decoding.""",2024-02-14T18:54:56Z
"LlaSMol: Advancing Large Language Models for Chemistry with a Large-Scale, Comprehensive, High-Quality Instruction Tuning Dataset",Yes.,3.,"""existing research indicates that their performance on chemistry tasks is discouragingly low.""",2024-02-14T18:42:25Z
HGOT: Hierarchical Graph of Thoughts for Retrieval-Augmented In-Context Learning in Factuality Evaluation,Yes.,4.,"""With the widespread adoption of large language models (LLMs) in numerous applications, the challenge of factuality and the propensity for hallucinations raises significant concerns.""",2024-02-14T18:41:19Z
Massively Multi-Cultural Knowledge Acquisition & LM Benchmarking,Yes.,4.,"""Pretrained large language models have revolutionized many applications but still face challenges related to cultural bias and a lack of cultural commonsense knowledge crucial for guiding cross-culture communication and interactions.""",2024-02-14T18:16:54Z
Copyright Traps for Large Language Models,Yes.,3.,"""SOTA methods however rely on naturally occurring memorization of (part of) the content. While very effective against models that memorize a lot, we hypothesize--and later confirm--that they will not work against models that do not naturally memorize, e.g. medium-size 1B models.""",2024-02-14T18:09:53Z
HiRE: High Recall Approximate Top-$k$ Estimation for Efficient LLM Inference,Yes.,3.,"""Autoregressive decoding with generative Large Language Models (LLMs) on accelerators (GPUs/TPUs) is often memory-bound where most of the time is spent on transferring model parameters from high bandwidth memory (HBM) to cache.""",2024-02-14T18:04:36Z
Developing a Framework for Auditing Large Language Models Using Human-in-the-Loop,Yes.,5.,"""Examples include bias, inconsistencies, and hallucination."" and ""auditing the LLM for these problems is desirable, it is far from being easy or solved.""",2024-02-14T17:49:31Z
AuditLLM: A Tool for Auditing Large Language Models Using Multiprobe Approach,Yes.,4.,"""Probing LLMs with varied iterations of a single question could reveal potential inconsistencies in their knowledge or functionality."" and ""A certain level of inconsistency has been shown to be an indicator of potential bias, hallucinations, and other issues.""",2024-02-14T17:31:04Z
ICDPO: Effectively Borrowing Alignment Capability of Others via In-context Direct Preference Optimization,Yes.,2.,"""Due to the heavy cost associated with fine-tuning, fine-tuning-free methods have emerged, typically modifying LLM decoding with external auxiliary methods. However, these methods do not essentially enhance the LLM itself.""",2024-02-14T17:14:34Z
Trained Without My Consent: Detecting Code Inclusion In Language Models Trained on Code,Yes.,4.,"""The recent advent of Large Language Models (LLMs) as coding assistants in the software development process poses new challenges for code auditing."" and ""Given the non-disclosure of the training datasets, traditional approaches such as code clone detection are insufficient for asserting copyright infringement.""",2024-02-14T16:41:35Z
"Attacks, Defenses and Evaluations for LLM Conversation Safety: A Survey",Yes.,4.,"""Large Language Models (LLMs) are now commonplace in conversation applications. However, their risks of misuse for generating harmful responses have raised serious societal concerns and spurred recent research on LLM conversation safety.""",2024-02-14T16:14:03Z
Leveraging Large Language Models for Enhanced NLP Task Performance through Knowledge Distillation and Optimized Training Strategies,Yes.,1.,"""Emerging Large Language Models (LLMs) like GPT-4 have revolutionized Natural Language Processing (NLP), showing potential in traditional tasks such as Named Entity Recognition (NER).""",2024-02-14T16:10:45Z
Personalized Large Language Models,Yes.,4.,"""However, their universal nature poses limitations in scenarios requiring personalized responses, such as recommendation systems and chatbots.""",2024-02-14T15:55:30Z
Self-Alignment for Factuality: Mitigating Hallucinations in LLMs via Self-Evaluation,Yes.,5.,"""Despite showing increasingly human-like abilities, large language models (LLMs) often struggle with factual inaccuracies, i.e. 'hallucinations', even when they hold relevant knowledge.""",2024-02-14T15:52:42Z
SyntaxShap: Syntax-aware Explainability Method for Text Generation,Yes.,1.,"""To harness the power of large language models in safety-critical domains we need to ensure the explainability of their predictions.""",2024-02-14T15:45:56Z
Scaling the Authoring of AutoTutors with Large Language Models,Yes.,4.,"""A common pitfall of LLMs is their straying from desired pedagogical strategies such as leaking the answer to the student, and in general, providing no guarantees.""",2024-02-14T14:53:56Z
Ten Words Only Still Help: Improving Black-Box AI-Generated Text Detection via Proxy-Guided Efficient Re-Sampling,Yes.,4.,"""their abuse has caused many undesirable societal problems such as fake news, academic dishonesty, and information pollution.""",2024-02-14T14:32:16Z
(Ir)rationality and Cognitive Biases in Large Language Models,Yes.,5.,"""We find that, like humans, LLMs display irrationality in these tasks. However, the way this irrationality is displayed does not reflect that shown by humans. When incorrect answers are given by LLMs to these tasks, they are often incorrect in ways that differ from human-like biases. On top of this, the LLMs reveal an additional layer of irrationality",2024-02-14T14:17:21Z
"Rapid Adoption, Hidden Risks: The Dual Impact of Large Language Model Customization",Yes.,5.,"""the trustworthiness of third-party custom versions of LLMs remains an essential concern."" and ""Our findings highlight the vulnerability and the potential risks of LLM customization such as GPTs.""",2024-02-14T13:47:35Z
Leveraging the Context through Multi-Round Interactions for Jailbreaking Attacks,Yes.,5.,"""Large Language Models (LLMs) are susceptible to Jailbreaking attacks,"" and ""we guide the responses of the model toward revealing the 'desired' harmful information.""",2024-02-14T13:45:19Z
Attacking Large Language Models with Projected Gradient Descent,Yes.,3.,"""Current LLM alignment methods are readily broken through specifically crafted adversarial prompts.""",2024-02-14T13:13:26Z
Into the Unknown: Self-Learning Large Language Models,Yes.,5.,"""We address the main problem of self-learning LLM",2024-02-14T12:56:58Z
Exploring the Adversarial Capabilities of Large Language Models,Yes.,4.,"""While previous research delved into the security and privacy issues of LLMs, the extent to which these models can exhibit adversarial behavior remains largely unexplored."" and ""Our experiments, which focus on hate speech detection, reveal that LLMs succeed in finding adversarial perturbations, effectively undermining hate speech detection systems.""",2024-02-14T12:28:38Z
MPIrigen: MPI Code Generation through Domain-Specific Language Models,Yes.,3.,"""Findings reveal that widely used models such as GPT-3.5 and PolyCoder (specialized multi-lingual code models) exhibit notable performance degradation, when generating MPI-based programs compared to general-purpose programs.""",2024-02-14T12:24:21Z
Play Guessing Game with LLM: Indirect Jailbreak Attack with Implicit Clues,,,,2024-02-14T11:11:51Z
Soft Prompt Threats: Attacking Safety Alignment and Unlearning in Open-Source LLMs through the Embedding Space,Yes.,5.,"""We find that embedding space attacks circumvent model alignments and trigger harmful behaviors more efficiently than discrete attacks or model fine-tuning."" and ""embedding space attacks can extract supposedly deleted information from unlearned LLMs across multiple datasets and models.""",2024-02-14T10:20:03Z
L3GO: Language Agents with Chain-of-3D-Thoughts for Generating Unconventional Objects,Yes.,3.,"""Yet, these models are not robust in precisely reasoning about physical and spatial configurations of objects, especially when instructed with unconventional, thereby out-of-distribution descriptions, such as 'a chair with five legs'.""",2024-02-14T09:51:05Z
FGeo-TP: A Language Model-Enhanced Solver for Geometry Problems,Yes.,1.,"""we introduced FGeo-TP (Theorem Predictor), which utilizes the language model to predict theorem sequences for solving geometry problems.""",2024-02-14T09:44:28Z
SLEB: Streamlining LLMs through Redundancy Verification and Elimination of Transformer Blocks,Yes.,5.,"""However, their large number of parameters poses significant challenges for practical deployment.""",2024-02-14T09:01:13Z
Towards better Human-Agent Alignment: Assessing Task Utility in LLM-Powered Applications,Yes.,2.,"""a significant gap remains in assessing whether LLM-powered applications genuinely enhance user experience and task execution efficiency.""",2024-02-14T08:46:15Z
Multi-Query Focused Disaster Summarization via Instruction-Based Prompting,Yes.,1.,"""The summarizer module is based on the open-source Large Language Model (LLM) LLaMA-13b.""",2024-02-14T08:22:58Z
SafeDecoding: Defending against Jailbreak Attacks via Safety-Aware Decoding,Yes.,5.,"""Jailbreak attacks, aiming to provoke unintended and unsafe behaviors from LLMs, remain a significant/leading LLM safety threat.""",2024-02-14T06:54:31Z
GrounDial: Human-norm Grounded Safe Dialog Response Generation,Yes.,4.,"""Current conversational AI systems based on large language models (LLMs) are known to generate unsafe responses, agreeing to offensive user input or including toxic content.""",2024-02-14T06:25:50Z
