Title,Talks about LLMs,Rate,Evidence,Published
GitHub Copilot AI pair programmer: Asset or Liability?,No.,1.,"The abstract discusses GitHub Copilot, an AI pair programmer, but does not mention LLMs or their limitations.",2022-06-30T15:00:03Z
Compressing Pre-trained Transformers via Low-Bit NxM Sparsity for Natural Language Understanding,Yes.,3.,"""the huge size of these models brings significant challenges to their fine-tuning and online deployment due to latency and cost constraints.""",2022-06-30T04:33:50Z
Solving Quantitative Reasoning Problems with Language Models,Yes.,3.,"""state-of-the-art models have generally struggled with tasks that require quantitative reasoning, such as solving mathematics, science, and engineering problems at the college level.""",2022-06-29T18:54:49Z
Knowledge Distillation of Transformer-based Language Models Revisited,Yes.,5.,"""However, the large model size and high run-time latency are serious impediments to applying them in practice, especially on mobile phones and Internet of Things (IoT) devices.""",2022-06-29T02:16:56Z
Bottleneck Low-rank Transformers for Low-resource Spoken Language Understanding,Yes.,3.,"""The resulting models are too large for on-edge applications. For instance, BERT-based systems contain over 110M parameters.""",2022-06-28T23:08:32Z
CC-Riddle: A Question Answering Dataset of Chinese Character Riddles,Yes.,5.,"""The test results reveal that current language models still struggle to solve Chinese character riddles.""",2022-06-28T06:23:13Z
Flexible text generation for counterfactual fairness probing,Yes.,1.,"""We show that this LLM-based method can produce complex counterfactuals that existing methods cannot, comparing the performance of various counterfactual generation methods on the Civil Comments dataset and showing their value in evaluating a toxicity classifier.""",2022-06-28T05:07:20Z
NERDA-Con: Extending NER models for Continual Learning -- Integrating Distinct Tasks and Updating Distribution Shifts,Yes.,3.,"""Re-training NERs based on Large Language Models (LLMs) from scratch over newly acquired data poses economic disadvantages. In contrast, re-training only with newly acquired data will result in Catastrophic Forgetting of previously acquired knowledge.""",2022-06-28T03:22:55Z
A Disability Lens towards Biases in GPT-3 Generated Open-Ended Languages,Yes.,4.,"""concerns remain whether open-ended languages or text generated from these models reveal any biases toward a specific group of people, thereby risking the usability of a certain product.""",2022-06-23T21:57:08Z
BERT Rankers are Brittle: a Study using Adversarial Document Perturbations,Yes.,5.,"""we argue that BERT-rankers are not immune to adversarial attacks targeting retrieved documents given a query,"" and ""we find that BERT-rankers heavily rely on the document start/head for relevance prediction, making the initial part of the document more susceptible to adversarial attacks.""",2022-06-23T14:16:48Z
Towards WinoQueer: Developing a Benchmark for Anti-Queer Bias in Large Language Models,Yes.,4.,"""This paper presents exploratory work on whether and to what extent biases against queer and trans people are encoded in large language models (LLMs) such as BERT."" and ""We found that BERT shows significant homophobic bias.""",2022-06-23T05:30:47Z
Multi-LexSum: Real-World Summaries of Civil Rights Lawsuits at Multiple Granularities,Yes.,3.,"""We present extensive analysis demonstrating that despite the high-quality summaries in the training data (adhering to strict content and style guidelines), state-of-the-art summarization models perform poorly on this task.""",2022-06-22T07:26:55Z
Don't Forget About Pronouns: Removing Gender Bias in Language Models Without Losing Factual Gender Information,Yes.,4.,"""We aim to diminish the stereotypical bias in the representations while preserving the factual gender signal."" and ""Our filtering method shows that it is possible to decrease the bias of gender-neutral profession names without significant deterioration of language modeling capabilities.""",2022-06-21T21:38:25Z
Using cognitive psychology to understand GPT-3,Yes.,5.,"""Yet we also find that small perturbations to vignette-based tasks can lead GPT-3 vastly astray, that it shows no signatures of directed exploration, and that it fails miserably in a causal reasoning task.""",2022-06-21T20:06:03Z
PlanBench: An Extensible Benchmark for Evaluating Large Language Models on Planning and Reasoning about Change,Yes.,5.,"""Our studies also show that on many critical capabilities-including plan generation-LLM performance falls quite short, even with the SOTA models.""",2022-06-21T16:15:27Z
"Fewer Errors, but More Stereotypes? The Effect of Model Size on Gender Bias",Yes.,4.,"""we examine the connection between model size and its gender bias (specifically, occupational gender bias)."" and ""Our findings highlight the potential risks that can arise from increasing model size.""",2022-06-20T15:52:40Z
Domain-Adaptive Text Classification with Structured Knowledge from Unlabeled Data,,,,2022-06-20T06:38:51Z
Local Slot Attention for Vision-and-Language Navigation,No.,1.,The abstract does not mention LLMs or their limitations.,2022-06-17T09:21:26Z
Methods for Estimating and Improving Robustness of Language Models,Yes.,5.,"""large language models (LLMs) suffer notorious flaws related to their preference for simple, surface-level textual relations over full semantic complexity of the problem"" and ""weak ability to generalise outside of the training domain.""",2022-06-16T21:02:53Z
Characteristics of Harmful Text: Towards Rigorous Benchmarking of Language Models,Yes.,5.,"""However, recent literature and, increasingly, real world observations, have demonstrated that these models can generate language that is toxic, biased, untruthful or otherwise harmful.""",2022-06-16T17:28:01Z
Estimating Confidence of Predictions of Individual Classifiers and Their Ensembles for the Genre Classification Task,Yes.,3.,"""Neural models based on pre-trained transformers, such as BERT or XLM-RoBERTa, demonstrate SOTA results in many NLP tasks, including non-topical classification. However, in many cases, their downstream application to very large corpora, such as",2022-06-15T09:59:05Z
SBERT studies Meaning Representations: Decomposing Sentence Embeddings into Explainable Semantic Features,Yes.,3.,"""Models based on large-pretrained language models, such as S(entence)BERT, provide effective and efficient sentence embeddings that show high correlation to human similarity ratings, but lack interpretability.""",2022-06-14T17:37:18Z
Memory-Based Model Editing at Scale,Yes.,3.,"""Existing model editors have shown promise, but also suffer from insufficient expressiveness",2022-06-13T23:40:34Z
Bridging the Gap Between Training and Inference of Bayesian Controllable Language Models,Yes.,3.,"""However, it is difficult to control the pre-trained language models to generate sentences with the desired attribute such as topic and sentiment, etc."" and ""the mismatch between training and inference of BCLMs limits the performance of the models.""",2022-06-11T12:52:32Z
Measuring the Carbon Intensity of AI in Cloud Instances,Yes.,1.,"""We provide measurements of operational software carbon intensity for a set of modern models for natural language processing and computer vision, and a wide range of model sizes, including pretraining of a 6.1 billion parameter language model.""",2022-06-10T17:04:04Z
Beyond the Imitation Game: Quantifying and extrapolating the capabilities of language models,Yes.,5.,"""it is vital that we understand the present and near-future capabilities and limitations of language models"" and ""BIG-bench focuses on tasks that are believed to be beyond the capabilities of current language models"" and ""model performance and calibration both improve with scale, but are poor in absolute terms"" and ""social bias typically increases with scale in settings with ambiguous context, but this can be",2022-06-09T17:05:34Z
Neuro-Symbolic Procedural Planning with Commonsense Prompting,Yes.,4.,"""it remains a challenge for large language models (LLMs) that lack a deep understanding of the cause-effect relations in procedures"" and ""such elicited pre-trained knowledge in LLMs induces spurious correlations between goals and steps, which impair the model generalization to unseen tasks.""",2022-06-06T22:09:52Z
Domain-specific Language Pre-training for Dialogue Comprehension on Clinical Inquiry-Answering Conversations,Yes.,3.,"""Yet, due to the gap between pre-training and downstream clinical domains, it remains challenging to exploit the generic backbones for domain-specific applications.""",2022-06-06T08:45:03Z
Making Large Language Models Better Reasoners with Step-Aware Verifier,Yes.,3.,"""Large language models like GPT-3 and PaLM have made impressive progress in this area, but they still face difficulties in reasoning tasks such as GSM8K, a benchmark for arithmetic problems.""",2022-06-06T03:38:36Z
Exploring Cross-lingual Textual Style Transfer with Large Multilingual Language Models,Yes.,5.,"""However, models are not able to perform cross-lingual detoxification and direct fine-tuning on exact language is inevitable.""",2022-06-05T20:02:30Z
Offline RL for Natural Language Generation with Implicit Language Q Learning,Yes.,3.,"""Large language models distill broad knowledge from text corpora. However, they can be inconsistent when it comes to completing user specified tasks.""",2022-06-05T18:38:42Z
Fault-Aware Neural Code Rankers,Yes.,3.,"""However, these approaches assume that the unit tests are given and assume the ability to safely execute the generated programs (which can do arbitrary dangerous operations such as file manipulations). Both of the above assumptions are impractical in real-world software development.""",2022-06-04T22:01:05Z
Extreme Compression for Pre-trained Transformers Made Simple and Efficient,Yes.,2.,"""However, to preserve the accuracy for such aggressive compression schemes, cutting-edge methods usually introduce complicated compression pipelines, e.g., multi-stage expensive knowledge distillation with extensive hyperparameter tuning.""",2022-06-04T00:19:45Z
Differentially Private Model Compression,Yes.,2.,"""The inference cost of these models -- which consist of hundreds of millions of parameters -- however, can be prohibitively large.""",2022-06-03T22:04:36Z
Order-sensitive Shapley Values for Evaluating Conceptual Soundness of NLP Models,Yes.,5.,"""Previous works show that deep NLP models are not always conceptually sound",2022-06-01T02:30:12Z
A Mixture-of-Expert Approach to RL-based Dialogue Management,Yes.,3.,"""Despite recent advancements in language models (LMs), their application to dialogue management (DM) problems and ability to carry on rich conversations remain a challenge."" and ""As a result, they struggle to produce a successful and engaging dialogue even if they are warm-started with a pre-trained LM.""",2022-05-31T19:00:41Z
Automatic Short Math Answer Grading via In-context Meta-learning,Yes.,4.,"""However, these approaches have several key limitations, including i) they use pre-trained language models that are not well-adapted to educational subject domains and/or student-generated text and ii) they almost always train one model per question, ignoring the linkage across a question and result in a significant model storage problem due to the size of advanced language models.""",2022-05-30T16:26:02Z
CogVideo: Large-scale Pretraining for Text-to-Video Generation via Transformers,Yes.,5.,"""Its application to video generation is still facing many challenges",2022-05-29T19:02:15Z
Tranception: protein fitness prediction with autoregressive transformers and inference-time retrieval,Yes.,3.,"""Large language models trained on massive quantities of non-aligned protein sequences from diverse families address these problems and show potential to eventually bridge the performance gap.""",2022-05-27T04:51:15Z
Quark: Controllable Text Generation with Reinforced Unlearning,Yes.,5.,"""Large-scale language models often learn behaviors that are misaligned with user expectations. Generated text may contain offensive or toxic language, contain significant repetition, or be of a different sentiment than desired by the user.""",2022-05-26T21:11:51Z
Differentially Private Decoding in Large Language Models,Yes.,4.,"""LLMs, while effective, have been shown to memorize instances of training data thereby potentially revealing private information processed during pre-training.""",2022-05-26T20:50:58Z
BiT: Robustly Binarized Multi-distilled Transformer,No.,1.,The abstract discusses binarization of transformer models and improvements in optimization for resource-constrained environments but does not specifically mention language models or their limitations.,2022-05-25T19:01:54Z
Transcormer: Transformer for Sentence Scoring with Sliding Language Modeling,Yes.,3.,"""Previous works on sentence scoring mainly adopted either causal language modeling (CLM) like GPT or masked language modeling (MLM) like BERT, which have some limitations",2022-05-25T18:00:09Z
"Understanding Factual Errors in Summarization: Errors, Summarizers, Datasets, Error Detectors",No.,1.,The abstract does not mention LLMs or any specific limitations related to LLMs.,2022-05-25T15:26:48Z
PLOG: Table-to-Logic Pretraining for Logical Table-to-Text Generation,Yes.,3.,"""even large-scale pre-trained language models present low logical fidelity on logical table-to-text.""",2022-05-25T11:55:54Z
Large Language Models are Few-Shot Clinical Information Extractors,Yes.,1.,"""we show that large language models, such as InstructGPT, perform well at zero- and few-shot information extraction from clinical text despite not being trained specifically for the clinical domain.""",2022-05-25T11:49:58Z
RobustLR: Evaluating Robustness to Logical Perturbation in Deductive Reasoning,Yes.,5.,"""In our experiments with RoBERTa and T5, we find that the models trained in prior works do not perform consistently on the different perturbations in RobustLR, thus showing that the models are not robust to the proposed logical perturbations. Further, we find that the models",2022-05-25T09:23:50Z
Perturbation Augmentation for Fairer NLP,Yes.,4.,"""Unwanted and often harmful social biases are becoming ever more salient in NLP research, affecting both models and datasets."" and ""Lastly, we discuss outstanding questions about how best to evaluate the (un)fairness of large language models.""",2022-05-25T09:00:29Z
Gradient-Based Constrained Sampling from Language Models,Yes.,3.,"""Large pretrained language models generate fluent text but are notoriously hard to controllably sample from.""",2022-05-25T08:09:03Z
RLPrompt: Optimizing Discrete Text Prompts with Reinforcement Learning,Yes.,3.,"""Interestingly, the resulting optimized prompts are often ungrammatical gibberish text; and surprisingly, those gibberish prompts are transferrable between different LMs to retain significant performance, indicating LM prompting may not follow human language patterns.""",2022-05-25T07:50:31Z
Memorization in NLP Fine-tuning Methods,Yes.,4.,"""Large language models are shown to present privacy risks through memorization of training data,"" and ""we empirically study memorization of fine-tuning methods using membership inference and extraction attacks, and show that their susceptibility to attacks is very different.""",2022-05-25T05:49:31Z
Do we need Label Regularization to Fine-tune Pre-trained Language Models?,Yes.,1.,"""Considering the ever-growing size of pre-trained language models (PLMs), KD is often adopted in many NLP tasks involving PLMs.""",2022-05-25T01:26:31Z
Fine-tuned Language Models are Continual Learners,Yes.,5.,"""these models even though impressive still perform poorly on a wide range of tasks outside of their respective training and evaluation sets.""",2022-05-24T22:53:34Z
Toxicity Detection with Generative Prompt-based Inference,Yes.,3.,"""It is a long-known risk that language models (LMs), once trained on corpus containing undesirable content, have the power to manifest biases and toxicity.""",2022-05-24T22:44:43Z
Medical Scientific Table-to-Text Generation with Human-in-the-Loop under the Data Sparsity Constraint,Yes.,3.,"""inability of the state-of-the-art natural language generation models (including T5, PEGASUS and GPT-Neo) to produce accurate and reliable outputs.""",2022-05-24T21:10:57Z
Evaluating the Impact of Model Scale for Compositional Generalization in Semantic Parsing,,,,2022-05-24T17:57:39Z
PoeLM: A Meter- and Rhyme-Controllable Language Model for Unsupervised Poetry Generation,Yes.,1.,"""In this work, we propose an unsupervised approach to generate poems following any given meter and rhyme scheme, without requiring any poetic text for training.""",2022-05-24T17:09:55Z
Word-order typology in Multilingual BERT: A case study in subordinate-clause detection,Yes.,3.,"""The capabilities and limitations of BERT and similar models are still unclear when it comes to learning syntactic abstractions, in particular across languages.""",2022-05-24T11:35:39Z
The Authenticity Gap in Human Evaluation,Yes.,2.,"""For the latter, we propose a new human evaluation protocol called $\textit{system-level probabilistic assessment}$ (SPA). When human evaluation of stories is done with SPA, we can recover the ordering of GPT-3 models by size, with statistically significant results. However, when human evaluation is done with the standard protocol, less than half of the expected preferences can be recovered (",2022-05-24T09:51:27Z
Large Language Models are Zero-Shot Reasoners,Yes.,1.,"""Pretrained large language models (LLMs) are widely used in many sub-fields of natural language processing (NLP) and generally known as excellent few-shot learners with task-specific exemplars.""",2022-05-24T09:22:26Z
On Measuring Social Biases in Prompt-Based Multi-Task Learning,Yes.,4.,"""We consider an alternative measure and inquire whether the way in which an input is encoded affects social biases promoted in outputs."" and ""The results on two benchmarks suggest that given two different formulations of essentially the same input, T0 conspicuously acts more biased in question answering form, which is seen during training,",2022-05-23T20:01:20Z
Challenges in Measuring Bias via Open-Ended Language Generation,Yes.,4.,"""Researchers have devised numerous ways to quantify social biases vested in pretrained language models."" and ""We find out that the practice of measuring biases through text completion is prone to yielding contradicting results under different experiment settings.""",2022-05-23T19:57:15Z
On the Paradox of Learning to Reason from Data,No.,1.,The abstract does not mention LLMs or any specific language models. It focuses on BERT and logical reasoning in NLP tasks.,2022-05-23T17:56:48Z
Outliers Dimensions that Disrupt Transformers Are Driven by Frequency,Yes.,5.,"""While Transformer-based language models are generally very robust to pruning, there is the recently discovered outlier phenomenon",2022-05-23T15:19:09Z
Looking for a Handsome Carpenter! Debiasing GPT-3 Job Advertisements,Yes.,4.,"""We first assess the bias and realism of zero-shot generated advertisements and compare them to real-world advertisements. We then evaluate prompt-engineering and fine-tuning as debiasing methods. We find that prompt-engineering with diversity-encouraging prompts gives no significant improvement to bias, nor realism. Conversely, fine-tuning, especially on unbiased real advertisements, can improve realism and reduce",2022-05-23T15:05:27Z
RL with KL penalties is better viewed as Bayesian inference,Yes.,5.,"""We start by observing that the standard RL approach is flawed as an objective for fine-tuning LMs because it leads to distribution collapse",2022-05-23T12:47:13Z
Parameter-Efficient Sparsity for Large Language Models Fine-Tuning,Yes.,3.,"""there are challenges in the computational overhead and memory footprint of sparse training when compressing large-scale language models.""",2022-05-23T02:43:45Z
Improving Short Text Classification With Augmented Data Using GPT-3,Yes.,3.,"""Although researchers claim that it requires only a small number of in-context examples to learn a task, in practice GPT-3 requires these training examples to be either of exceptional quality or a higher quantity than easily created by hand.""",2022-05-23T01:10:38Z
Thor: Wielding Hammers to Integrate Language Models and Automated Theorem Provers,Yes.,5.,"""This presents a challenge for all theorem provers, especially the ones based on language models, due to their relative inability to reason over huge volumes of premises in text form.""",2022-05-22T18:03:03Z
Scaling Laws and Interpretability of Learning from Repeated Data,Yes.,5.,"""Recent large language models have been trained on vast datasets, but also often on repeated data... Some works have reported substantial negative performance effects of this repeated data."" and ""We find a strong double descent phenomenon, in which repeated data can lead test loss to increase midway through training. A predictable range of repetition frequency leads to surprisingly severe degradation in performance.""",2022-05-21T02:14:27Z
Towards Understanding Gender-Seniority Compound Bias in Natural Language Generation,Yes.,4.,"""Our results show that GPT-2 amplifies bias by considering women as junior and men as senior more often than the ground truth in both domains. These results suggest that NLP applications built using GPT-2 may harm women in professional capacities.""",2022-05-19T20:05:02Z
Overcoming Language Disparity in Online Content Classification with Multimodal Learning,Yes.,4.,"""Large language models are now the standard to develop state-of-the-art solutions for text detection and classification tasks. However, the development of advanced computational techniques and resources is disproportionately focused on the English language, sidelining a majority of the languages spoken globally."" and ""we situate our findings with respect",2022-05-19T17:56:02Z
"Great Power, Great Responsibility: Recommendations for Reducing Energy for Training Language Models",Yes.,3.,"""The energy requirements of current natural language processing models continue to grow at a rapid, unsustainable pace.""",2022-05-19T16:03:55Z
Are Prompt-based Models Clueless?,Yes.,4.,"""models with a task-specific head require a lot of training data, making them susceptible to learning and exploiting dataset-specific superficial cues that do not generalize to other datasets"" and ""Analyzing few-shot prompt-based models on MNLI, SNLI, HANS, and COPA has revealed that prompt-based models also exploit superficial cues.""",2022-05-19T02:47:58Z
Transformer-based Program Synthesis for Low-Data Environments,Yes.,5.,"""However, these models perform poorly on long-horizon and low-data tasks, and often don't seem to understand the semantics of the languages they generate.""",2022-05-18T23:33:33Z
The AI Teacher Test: Measuring the Pedagogical Ability of Blender and GPT-3 in Educational Dialogues,Yes.,3.,"""We find that, even though conversational agents (Blender in particular) perform well on conversational uptake, they are quantifiably worse than real teachers on several pedagogical dimensions, especially with regard to helpfulness (Blender",2022-05-16T09:36:30Z
Transkimmer: Transformer Learns to Layer-wise Skim,No.,1.,"The abstract discusses Transformer-based models in general, focusing on computational efficiency improvements, but does not specifically mention LLMs or their limitations.",2022-05-15T16:23:30Z
Discovering Latent Concepts Learned in BERT,Yes.,3.,"""The scope of the analyses is limited to pre-defined concepts that reinforce the traditional linguistic knowledge and do not reflect on how novel concepts are learned by the model."" and ""the discovered latent concepts highlight potential biases learned in the model.""",2022-05-15T09:45:34Z
PathologyBERT -- Pre-trained Vs. A New Transformer Language Model for Pathology Domain,Yes.,3.,"""a few approaches fine-tuned general transformer models on specialized corpora while maintaining the original tokenizer, but in fields requiring specialized terminology, these models often fail to perform adequately.""",2022-05-13T20:42:07Z
Towards Answering Open-ended Ethical Quandary Questions,Yes.,2.,"""We also discuss the remaining challenges and ethical issues involved in this task and suggest the direction toward developing responsible NLP systems by incorporating human values explicitly.""",2022-05-12T09:52:59Z
"Structured, flexible, and robust: benchmarking and improving large language models towards more human-like behavior in out-of-distribution reasoning tasks",Yes.,5.,"""We find that humans are far more robust than LLMs on this benchmark.""",2022-05-11T18:14:33Z
Clinical Prompt Learning with Frozen Language Models,Yes.,3.,"""the performance of even the largest PLMs such as GPT-3 do not perform well on specialized domains (e.g. medical text),"" and ""The reliance on fine-tuning large PLMs is problematic in clinical settings where data is often held in non-GPU environments, and more resource efficient methods of training specialized domain models is crucial.""",2022-05-11T14:25:13Z
Towards the Generation of Musical Explanations with GPT-3,Yes.,3.,"""Our results show that GPT-3 lacks the necessary intelligence to really understand musical decisions. A major barrier to reach a better performance is the lack of data that includes explanations of the creative process carried out by artists for musical pieces.""",2022-05-11T13:04:54Z
Query-Based Keyphrase Extraction from Long Documents,Yes.,3.,"""Transformer-based architectures in natural language processing force input size limits that can be problematic when long documents need to be processed.""",2022-05-11T10:29:30Z
Towards Unified Prompt Tuning for Few-shot Text Classification,Yes.,3.,"""PLMs are unfamiliar with prompt-style expressions during pre-training, which limits the few-shot learning performance on downstream tasks.""",2022-05-11T07:40:45Z
Reducing Activation Recomputation in Large Transformer Models,Yes.,1.,"""We evaluate our approach on language models up to one trillion parameters in scale and show that our method reduces activation memory by 5x, while reducing execution time overhead from activation recomputation by over 90%.""",2022-05-10T22:40:17Z
Problems with Cosine as a Measure of Embedding Similarity for High Frequency Words,No.,1.,The abstract discusses cosine similarity of contextual embeddings and does not mention language models (LLMs or LMs).,2022-05-10T18:00:06Z
Beyond Distributional Hypothesis: Let Language Models Learn Meaning-Text Correspondence,Yes.,5.,"""much recent evidence shows that large-size pre-trained language models (PLMs) do not satisfy this property"" and ""we observe that PLMs violate the LNP frequently.""",2022-05-08T08:37:36Z
Context-Aware Abbreviation Expansion Using Large Language Models,Yes.,1.,"""Our approach is to expand the abbreviations into full-phrase options by leveraging conversation context with the power of pretrained large language models (LLMs).""",2022-05-08T03:02:53Z
Vector Representations of Idioms in Conversational Systems,Yes.,1.,"""We experiment with three instances of the SoTA dialogue model, Dialogue Generative Pre-trained Transformer (DialoGPT), for conversation generation.""",2022-05-07T14:50:05Z
"When a sentence does not introduce a discourse entity, Transformer-based models still sometimes refer to it",Yes.,5.,"""We find that while the models are to a certain extent sensitive to the interactions we investigate, they are all challenged by the presence of multiple NPs and their behavior is not systematic, which suggests that even models at the scale of GPT-3 do not fully acquire basic entity tracking abilities.""",2022-05-06T20:49:27Z
The Unreliability of Explanations in Few-shot Prompting for Textual Reasoning,Yes.,5.,"""We further show that explanations generated by the LLMs may not entail the models' predictions nor be factually grounded in the input, even on simple tasks with extractive explanations.""",2022-05-06T17:57:58Z
Robust Conversational Agents against Imperceptible Toxicity Triggers,Yes.,3.,"""Existing work to generate such attacks is either based on human-generated attacks which is costly and not scalable or, in case of automatic attacks, the attack vector does not conform to human-like language, which can be detected using a language model loss.""",2022-05-05T01:48:39Z
Provably Confidential Language Modelling,Yes.,4.,"""Large language models are shown to memorize privacy information such as social security numbers in training data.""",2022-05-04T02:33:45Z
Data Governance in the Age of Large-Scale Data-Driven Language Technology,Yes.,1.,"""The recent emergence and adoption of Machine Learning technology, and specifically of Large Language Models, has drawn attention to the need for systematic and transparent management of language data.""",2022-05-04T00:44:35Z
Efficient Fine-Tuning of BERT Models on the Edge,Yes.,3.,"""With the increasing size of deep neural networks, as noted with the likes of BERT and other natural language processing models, comes increased resource requirements, namely memory, computation, energy, and time. Furthermore, training is far more resource intensive than inference. Resource-constrained on-device learning is thus doubly difficult, especially with large BERT-like models.""",2022-05-03T14:51:53Z
SemAttack: Natural Textual Attacks via Different Semantic Spaces,,,,2022-05-03T03:44:03Z
Improving Students' Academic Performance with AI and Semantic Technologies,No.,1.,The abstract does not mention LLMs or any pre-trained transformer-based language models.,2022-05-02T06:11:24Z
Medical Coding with Biomedical Transformer Ensembles and Zero/Few-shot Learning,Yes.,3.,"""automating this task is challenging due to a large number of LLT codes (as of writing over 80,000), limited availability of training data for long tail/emerging classes, and the general high accuracy demands of the medical domain.""",2022-05-01T22:49:28Z
"MRKL Systems: A modular, neuro-symbolic architecture that combines large language models, external knowledge sources and discrete reasoning",Yes.,5.,"""Although an essential element of modern AI, LMs are also inherently limited in a number of ways. We discuss these limitations and how they can be avoided by adopting a systems approach.""",2022-05-01T11:01:28Z
Training Language Models with Language Feedback,Yes.,5.,"""Pretrained language models often do not perform tasks in ways that are in line with our preferences, e.g., generating offensive text or factually incorrect summaries.""",2022-04-29T15:06:58Z
Inferring Implicit Relations in Complex Questions with Language Models,Yes.,5.,"""we investigate why current models struggle with implicit reasoning question answering (QA) tasks,"" and ""we evaluate models from the GPT-3 family and find that, while these models struggle on the implicit reasoning QA task, they often succeed at inferring implicit relations.""",2022-04-28T21:00:54Z
On the Effect of Pretraining Corpora on In-context Learning by a Large-scale Language Model,Yes.,5.,"""the in-depth analysis of when in-context learning occurs is still lacking"" and ""in-context learning performance heavily depends on the corpus domain source, and the size of the pretraining corpus does not necessarily determine the emergence of in-context learning"" and ""pretraining with a corpus related to a downstream task does not always guarantee the competitive in-context learning performance of the downstream task, especially in",2022-04-28T13:59:54Z
An End-to-End Dialogue Summarization System for Sales Calls,Yes.,1.,"""We show how GPT-3 can be leveraged as an offline data labeler to handle training data scarcity and accommodate privacy constraints in an industrial setting.""",2022-04-27T14:02:50Z
You Don't Know My Favorite Color: Preventing Dialogue Representations from Revealing Speakers' Private Personas,Yes.,4.,"""privacy concerns have arisen recently",2022-04-26T09:36:18Z
Pretraining Chinese BERT for Detecting Word Insertion and Deletion Errors,Yes.,3.,"""Chinese BERT models achieve remarkable progress in dealing with grammatical errors of word substitution. However, they fail to handle word insertion and deletion because BERT assumes the existence of a word at each position.""",2022-04-26T03:19:36Z
Data Distributional Properties Drive Emergent In-Context Learning in Transformers,Yes.,3.,"""In our initial experiments, we found that in-context learning traded off against more conventional weight-based learning, and models were unable to achieve both simultaneously.""",2022-04-22T16:10:50Z
KALA: Knowledge-Augmented Language Model Adaptation,Yes.,4.,"""Simple fine-tuning of PLMs, on the other hand, might be suboptimal for domain-specific tasks because they cannot possibly cover knowledge from all domains. While adaptive pre-training of PLMs can help them obtain domain-specific knowledge, it requires a large training cost. Moreover, adaptive pre-training can harm the PLM",2022-04-22T08:11:59Z
Making the Most of Text Semantics to Improve Biomedical Vision--Language Processing,Yes.,3.,"""Biomedical text with its complex semantics poses additional challenges in vision--language modelling compared to the general domain, and previous work has used insufficiently adapted models that lack domain-specific language understanding.""",2022-04-21T00:04:35Z
You Are What You Write: Preserving Privacy in the Era of Large Language Models,Yes.,4.,"""Large scale adoption of large language models has introduced a new era of convenient knowledge transfer for a slew of natural language processing tasks. However, these models also run the risk of undermining user trust by exposing unwanted information about the data subjects, which may be extracted by a malicious party, e",2022-04-20T11:12:53Z
Is BERT Robust to Label Noise? A Study on Learning with Noisy Labels in Text Classification,Yes.,3.,"""existing noise-handling methods do not always improve its performance, and may even deteriorate it, suggesting the need for further investigation.""",2022-04-20T10:24:19Z
What Makes Instruction Learning Hard? An Investigation and a New Challenge in a Synthetic Environment,Yes.,5.,"""The capabilities of large transformer models as instruction learners, however, remain poorly understood."" and ""our model, a fine-tuned T5-based text2text transformer, struggles with large regular languages, suggesting that less precise instructions are challenging for models. Additionally, instruction executions that require tracking longer contexts of prior steps are also more difficult.""",2022-04-19T22:11:47Z
Impact of Tokenization on Language Models: An Analysis for Turkish,Yes.,1.,"""Tokenization is an important text preprocessing step to prepare input tokens for deep language models.""",2022-04-19T12:01:46Z
DecBERT: Enhancing the Language Understanding of BERT with Causal Attention Masks,Yes.,3.,"""a common limitation of the attention mechanism utilized in Transformer Encoder is that it cannot automatically capture the information of word order, so explicit position embeddings are generally required to be fed into the target model.""",2022-04-19T06:12:48Z
Context-Aware Language Modeling for Goal-Oriented Dialogue Systems,Yes.,3.,"""While supervised learning with large language models is capable of producing realistic text, how to steer such responses towards completing a specific task without sacrificing language quality remains an open question.""",2022-04-18T17:23:11Z
L3Cube-HingCorpus and HingBERT: A Code Mixed Hindi-English Dataset and BERT Language Models,Yes.,1.,"""We present L3Cube-HingCorpus, the first large-scale real Hindi-English code mixed data in a Roman script. It consists of 52.93M sentences and 1.04B tokens, scraped from Twitter.""",2022-04-18T16:49:59Z
Pathologies of Pre-trained Language Models in Few-shot Fine-tuning,Yes.,5.,"""without fine-tuning, pre-trained models (e.g. BERT and RoBERTa) show strong prediction bias across labels"" and ""pursuing model performance with fewer examples may incur pathological prediction behavior, which requires further sanity check on model predictions and careful design in model evaluations in few-shot",2022-04-17T15:55:18Z
Just Fine-tune Twice: Selective Differential Privacy for Large Language Models,Yes.,3.,"""Yet applying differential privacy (DP), a canonical notion with provable privacy guarantees for machine learning models, to those models remains challenging due to the trade-off between model utility and privacy loss.""",2022-04-15T22:36:55Z
CAMERO: Consistency Regularized Ensemble of Perturbed Language Models with Weight Sharing,Yes.,1.,"""Our experiments using large language models demonstrate that CAMERO significantly improves the generalization performance of the ensemble model.""",2022-04-13T19:54:51Z
Building Markovian Generative Architectures over Pretrained LM Backbones for Efficient Task-Oriented Dialog Systems,Yes.,5.,"""A drawback of existing PLM-based models is their non-Markov architectures across turns, i.e., the whole history is used as the conditioning input at each turn. First, this brings inefficiencies in memory and computation. Furthermore, using the whole history increases model",2022-04-13T15:21:34Z
Curriculum: A Broad-Coverage Benchmark for Linguistic Phenomena in Natural Language Understanding,Yes.,4.,"""current evaluation methods show some significant shortcomings. In particular, they do not provide insight into how well a language model captures distinct linguistic skills essential for language understanding and reasoning. Thus they fail to effectively map out the aspects of language understanding that remain challenging to existing models, which makes it hard to discover potential limitations in models and datasets.""",2022-04-13T10:32:03Z
Impossible Triangle: What's Next for Pre-trained Language Models?,Yes.,5.,"""However, many of such models come with a dauntingly huge size that few institutions can afford to pre-train, fine-tune or even deploy, while moderate-sized models usually lack strong generalized few-shot learning capabilities."" and ""We argue that all existing PLM models lack one or more properties from the Impossible Triangle.""",2022-04-13T01:28:18Z
MuCoT: Multilingual Contrastive Training for Question-Answering in Low-resource Languages,Yes.,3.,"""directly training an mBERT-based QA system for low-resource languages is challenging due to the paucity of training data.""",2022-04-12T13:52:54Z
Do Not Fire the Linguist: Grammatical Profiles Help Language Models Detect Semantic Change,Yes.,3.,"""This indicates that language models do not fully cover the fine-grained morphological and syntactic signals that are explicitly represented in grammatical profiles.""",2022-04-12T11:20:42Z
Uniform Complexity for Text Generation,Yes.,5.,"""existing models still do not capture factors that contribute to producing consistent text"" and ""we find that models such as GPT-2 struggle to preserve the complexity of input prompts used in its generations, even if finetuned with professionally written texts.""",2022-04-11T15:19:47Z
Few-Shot Cross-lingual Transfer for Coarse-grained De-identification of Code-Mixed Clinical Texts,Yes.,1.,"""Pre-trained language models (LM) have shown great potential for cross-lingual transfer in low-resource settings.""",2022-04-10T21:46:52Z
BioBART: Pretraining and Evaluation of A Biomedical Generative Language Model,Yes.,2.,"""We emphasize the lack of in-domain generative language models and the unsystematic generative downstream benchmarks in the biomedical domain, hindering the development of the research community.""",2022-04-08T08:07:42Z
"Read, Revise, Repeat: A System Demonstration for Human-in-the-loop Iterative Text Revision",Yes.,3.,"""Despite the success of large language models on text revision tasks, they are limited to non-iterative, one-shot revisions.""",2022-04-07T18:33:10Z
Testing the limits of natural language models for predicting human language judgments,Yes.,5.,"""experiments also revealed significant shortcomings of its alignment with human perception.""",2022-04-07T17:12:57Z
Parameter-Efficient Neural Reranking for Cross-Lingual and Multilingual Retrieval,Yes.,3.,"""State-of-the-art neural (re)rankers are notoriously data-hungry which -- given the lack of large-scale training data in languages other than English -- makes them rarely used in multilingual and cross-lingual retrieval settings.""",2022-04-05T15:44:27Z
Data Augmentation for Intent Classification with Off-the-shelf Large Language Models,Yes.,3.,"""In tasks with semantically close intents, we observe that the generated data is less helpful. Our analysis shows that this is because GPT often generates utterances that belong to a closely-related intent instead of the desired one.""",2022-04-05T03:29:26Z
Applying Automatic Text Summarization for Fake News Detection,Yes.,3.,"""combines the power of transformer-based language models while simultaneously addressing one of their inherent problems"" and ""circumventing sequential limits and related loss of information the underlying transformer architecture typically suffers from.""",2022-04-04T21:00:55Z
"Do As I Can, Not As I Say: Grounding Language in Robotic Affordances",Yes.,5.,"""a significant weakness of language models is that they lack real-world experience, which makes it difficult to leverage them for decision making within a given embodiment.""",2022-04-04T17:57:11Z
CTRLEval: An Unsupervised Reference-Free Metric for Evaluating Controlled Text Generation,Yes.,2.,"""Existing reference-free metrics have obvious limitations for evaluating controlled text generation models. Unsupervised metrics can only provide a task-agnostic evaluation result which correlates weakly with human judgments, whereas supervised ones may overfit task-specific data with poor generalization ability to other datasets.""",2022-04-02T13:42:49Z
CharacterBERT and Self-Teaching for Improving the Robustness of Dense Retrievers on Queries with Typos,No.,1.,"The abstract discusses the robustness of dense retrievers and CharacterBERT, but does not mention large language models (LLMs) or their limitations.",2022-04-01T23:02:50Z
Evaluation of Fake News Detection with Knowledge-Enhanced Language Models,Yes.,3.,"""However, large-scale PLMs are generally not trained on structured factual data and hence may not possess priors that are grounded in factually accurate knowledge.""",2022-04-01T14:14:46Z
Domain Adaptation for Sparse-Data Settings: What Do We Gain by Not Using Bert?,Yes.,3.,"""While transfer learning with pre-trained language models outperforms other methods across tasks, alternatives do not perform much worse while requiring much less computational effort, thus significantly reducing monetary and environmental cost.""",2022-03-31T09:59:08Z
Leveraging pre-trained language models for conversational information seeking from text,Yes.,2.,"""It also highlight the challenge posed by control flow relations for which further training needs to be devised.""",2022-03-31T09:00:46Z
Reproducibility Issues for BERT-based Evaluation Metrics,No.,1.,"The abstract discusses issues related to BERT-based evaluation metrics, but it does not mention LLMs or their limitations.",2022-03-30T20:35:37Z
Training Compute-Optimal Large Language Models,Yes.,2.,"""We find that current large language models are significantly undertrained, a consequence of the recent focus on scaling language models whilst keeping the amount of training data constant.""",2022-03-29T13:38:03Z
GPT-D: Inducing Dementia-related Linguistic Anomalies by Deliberate Degradation of Artificial Neural Language Models,Yes.,2.,"""questions remain about their ability to generalize beyond the small reference sets that are publicly available for research.""",2022-03-25T00:25:42Z
Adversarial Training for Improving Model Robustness? Look at Both Prediction and Interpretation,Yes.,3.,"""Neural language models show vulnerability to adversarial examples which are semantically similar to their original counterparts with a few words replaced by their synonyms.""",2022-03-23T20:04:14Z
BERT-ASC: Implicit Aspect Representation Learning through Auxiliary-Sentence Construction for Sentiment Analysis,Yes.,2.,"""Unfortunately, the aspect is often expressed implicitly through a set of representatives and thus renders implicit mapping process unattainable unless sufficient labeled examples are available. However, high-quality labeled examples may not be readily available in real-world scenarios.""",2022-03-22T13:12:27Z
Mitigating Gender Bias in Machine Translation through Adversarial Learning,Yes.,4.,"""restructuring training objectives in the context of fine-tuning pretrained large language models"" and ""addresses these challenges to mitigate gender bias in seq2seq machine translation.""",2022-03-20T23:35:09Z
Entropy-based Attention Regularization Frees Unintended Bias Mitigation from Lists,Yes.,4.,"""Natural Language Processing (NLP) models risk overfitting to specific terms in the training data, thereby reducing their performance, fairness, and generalizability."" and ""severe unintended bias, and lower performance.""",2022-03-17T09:29:50Z
Fine- and Coarse-Granularity Hybrid Self-Attention for Efficient BERT,Yes.,3.,"""the standard self-attention mechanism of the Transformer suffers from quadratic computational cost in the input sequence length.""",2022-03-17T03:33:47Z
Multi-Stage Prompting for Knowledgeable Dialogue Generation,Yes.,3.,"""These models typically fail to generalize on topics outside of the knowledge base, and require maintaining separate potentially large checkpoints each time finetuning is needed.""",2022-03-16T16:53:43Z
Thinking about GPT-3 In-Context Learning for Biomedical IE? Think Again,Yes.,5.,"""However, our results show that GPT-3 still significantly underperforms compared to simply fine-tuning a smaller PLM. In addition, GPT-3 in-context learning also yields smaller gains in accuracy when more training data becomes available. Our in-depth analyses further reveal issues of the in-context",2022-03-16T05:56:08Z
Representation Learning for Resource-Constrained Keyphrase Generation,Yes.,1.,"""based on a pre-trained language model using large-scale unlabeled documents.""",2022-03-15T17:48:04Z
Do Language Models Plagiarize?,Yes.,5.,"""Given that a majority of LMs' training data is scraped from the Web without informing content owners, their reiteration of words, phrases, and even core ideas from training sets into generated texts has ethical implications. Their patterns are likely to exacerbate as both the size of LMs and their training data increase, raising concerns about indis",2022-03-15T03:11:11Z
Leveraging Visual Knowledge in Language Tasks: An Empirical Study on Intermediate Pre-training for Cross-modal Knowledge Transfer,Yes.,3.,"""Pre-trained language models are still far from human performance in tasks that need understanding of properties (e.g. appearance, measurable quantity) and affordances of everyday objects in the real world since the text lacks such information due to reporting bias.""",2022-03-14T22:02:40Z
"GrIPS: Gradient-free, Edit-based Instruction Search for Prompting Large Language Models",Yes.,3.,"""manual rewriting is time-consuming and requires subjective interpretation, while gradient-based tuning can be extremely computationally demanding for large models and may not be feasible for API-based models.""",2022-03-14T16:54:46Z
The Optimal BERT Surgeon: Scalable and Accurate Second-Order Pruning for Large Language Models,Yes.,3.,"""While these models are extremely accurate, they can be too large and computationally intensive to run on standard deployments.""",2022-03-14T16:40:31Z
Can pre-trained Transformers be used in detecting complex sensitive sentences? -- A Monsanto case study,Yes.,1.,"""In this paper, we wish to explore whether pre-trained transformer models are well suited to detect complex sensitive information.""",2022-03-14T00:17:34Z
Low-Rank Softmax Can Have Unargmaxable Classes in Theory but Rarely in Practice,Yes.,3.,"""In theory, the result is some words may be impossible to be predicted via argmax, irrespective of input features, and empirically, there is evidence this happens in small language models.""",2022-03-12T15:34:54Z
"When classifying grammatical role, BERT doesn't care about word order... except when it matters",Yes.,4.,"""Recent work has shown large language models to be surprisingly word order invariant,"" and ""highlight how models use context in the uncommon, but critical, instances where it matters.""",2022-03-11T19:00:15Z
Block-Sparse Adversarial Attack to Fool Transformer-Based Text Classifiers,No.,1.,The abstract focuses on adversarial attacks against transformer-based text classifiers but does not specifically discuss language models (LMs or LLMs) or their limitations.,2022-03-11T14:37:41Z
"Contextualized Sensorimotor Norms: multi-dimensional measures of sensorimotor strength for ambiguous English words, in context",Yes.,2.,"""Most large language models are trained on linguistic input alone, yet humans appear to ground their understanding of words in sensorimotor experience.""",2022-03-10T21:23:00Z
Speciesist Language and Nonhuman Animal Bias in English Masked Language Models,Yes.,4.,"""We found that pre-trained masked language models tend to associate harmful words with nonhuman animals and have a bias toward using speciesist language for some nonhuman animal names.""",2022-03-10T03:32:29Z
Sentence-Select: Large-Scale Language Model Data Selection for Rare-Word Speech Recognition,Yes.,3.,"""However, such corpora have properties that hinder downstream performance, including being (1) too large, (2) beset with domain-mismatched content, and (3) heavy-headed rather than heavy-tailed (excessively many duplicate search queries such as 'weather').""",2022-03-09T19:20:03Z
Extraction of Sleep Information from Clinical Notes of Patients with Alzheimer's Disease Using Natural Language Processing,Yes.,1.,"""We developed a rule-based Natural Language Processing (NLP) algorithm, machine learning models, and Large Language Model(LLM)-based NLP algorithms to automate the extraction of sleep-related concepts.""",2022-03-08T21:20:19Z
What Did You Say? Task-Oriented Dialog Datasets Are Not Conversational!?,No.,1.,The abstract does not mention LLMs or their limitations.,2022-03-07T14:26:23Z
Input-Tuning: Adapting Unfamiliar Inputs to Frozen Pretrained Models,Yes.,3.,"""one of the factors hindering the development of prompt-tuning on NLG tasks is the unfamiliar inputs (i.e., inputs are linguistically different from the pretraining corpus).""",2022-03-07T05:04:32Z
Training language models to follow instructions with human feedback,Yes.,5.,"""large language models can generate outputs that are untruthful, toxic, or simply not helpful to the user.""",2022-03-04T07:04:42Z
LiteTransformerSearch: Training-free Neural Architecture Search for Efficient Language Models,Yes.,3.,"""finding architectures with the optimal trade-off between task performance (perplexity) and hardware constraints like peak memory utilization and latency is non-trivial.""",2022-03-04T02:10:43Z
BoMD: Bag of Multi-label Descriptors for Noisy Chest X-ray Classification,Yes.,1.,"""The proposed method optimises a bag of multi-label descriptors (BoMD) to promote their similarity with the semantic descriptors produced by BERT models from the multi-label image annotation.""",2022-03-03T08:04:59Z
Logical Fallacy Detection,Yes.,5.,"""We find that existing pretrained large language models perform poorly on this task.""",2022-02-28T13:18:26Z
Confidence Based Bidirectional Global Context Aware Training Framework for Neural Machine Translation,No.,1.,The abstract focuses on neural machine translation models and does not mention LLMs or their limitations.,2022-02-28T10:24:22Z
A Systematic Evaluation of Large Language Models of Code,Yes.,3.,"""However, the current state-of-the-art code LMs (e.g., Codex (Chen et al., 2021)) are not publicly available, leaving many questions about their model and data design decisions.""",2022-02-26T15:53:55Z
AugESC: Dialogue Augmentation with Large Language Models for Emotional Support Conversation,Yes.,1.,"""we leverage large language models for dialogue augmentation in the task of emotional support conversation (ESC).""",2022-02-26T03:17:08Z
Rethinking the Role of Demonstrations: What Makes In-Context Learning Work?,,,,2022-02-25T17:25:19Z
TrimBERT: Tailoring BERT for Trade-offs,Yes.,3.,"""many of these large models require a great deal of computational resources and/or time for pre-training and fine-tuning which limits wider adoptability.""",2022-02-24T23:06:29Z
Oolong: Investigating What Makes Transfer Learning Hard with Controlled Studies,Yes.,5.,"""We find that models can largely recover from syntactic-style shifts, but cannot recover from vocabulary misalignment and embedding matrix re-initialization, even with continued pretraining on 15 million tokens.""",2022-02-24T19:00:39Z
Capturing Failures of Large Language Models via Human Cognitive Biases,Yes.,5.,"""To hypothesize and test for such qualitative errors, we draw inspiration from human cognitive biases -- systematic patterns of deviation from rational judgement."" and ""Our results indicate that experimental methodology from cognitive science can help characterize how machine learning systems behave.""",2022-02-24T18:58:52Z
Ask2Mask: Guided Data Selection for Masked Speech Modeling,No.,1.,The abstract discusses masked speech modeling (MSM) methods and their limitations but does not mention language models (LLMs or LMs).,2022-02-24T17:34:54Z
Speciesist bias in AI -- How AI applications perpetuate discrimination and unfair outcomes against animals,Yes.,3.,"""Speciesist biases are learned and solidified by AI applications when they are trained on datasets in which speciesist patterns prevail. These patterns can be found in image recognition systems, large language models, and recommender systems.""",2022-02-22T12:23:21Z
Adaptive Discounting of Implicit Language Models in RNN-Transducers,Yes.,3.,"""One main reason for the degradation in performance on rare words is that the language model (LM) internal to RNN-Ts can become overconfident and lead to hallucinated predictions that are acoustically inconsistent with the underlying speech.""",2022-02-21T08:44:56Z
GPT-based Open-Ended Knowledge Tracing,Yes.,1.,"""We develop an initial solution to the OKT problem, a student knowledge-guided code generation approach, that combines program synthesis methods using language models with student knowledge tracing methods.""",2022-02-21T02:33:34Z
Reward Modeling for Mitigating Toxicity in Transformer-based Language Models,Yes.,4.,"""language models that are pretrained on large unlabeled web text corpora have been shown to suffer from degenerating toxic content and social bias behaviors, consequently hindering their safe deployment.""",2022-02-19T19:26:22Z
SGPT: GPT Sentence Embeddings for Semantic Search,Yes.,3.,"""Yet, these large foundation models remain unusable for the related fields of semantic search and sentence embeddings. This prevents possibly new state-of-the-art results and forces organizations to train and maintain separate models.""",2022-02-17T21:35:56Z
Information Extraction in Low-Resource Scenarios: Survey and Perspective,Yes.,2.,"""we conduct empirical study on LLM-based methods compared with previous state-of-the-art models, and discover that (1) well-tuned LMs are still predominant; (2) tuning open-resource LLMs and ICL with GPT family is promising in general; (3) the optimal LLM-based",2022-02-16T13:44:00Z
Should You Mask 15% in Masked Language Modeling?,Yes.,3.,"""We first establish that 15% is not universally optimal, and larger models should adopt a higher masking rate.""",2022-02-16T11:42:34Z
Knowledge Transfer from Large-scale Pretrained Language Models to End-to-end Speech Recognizers,Yes.,3.,"""training of end-to-end speech recognizers always requires transcribed utterances. Since end-to-end models are also known to be severely data hungry, this constraint is crucial especially because obtaining transcribed utterances is costly and can possibly be impractical or impossible.""",2022-02-16T07:02:24Z
"A Survey of Pretraining on Graphs: Taxonomy, Methods, and Applications",No.,1.,The abstract focuses on Pretrained Graph Models (PGMs) and does not discuss language models (LLMs).,2022-02-16T07:00:52Z
Predicting on the Edge: Identifying Where a Larger Model Does Better,Yes.,3.,"""large models have the largest improvement on examples where the small model is most uncertain. On more certain examples, even those where the small model is not particularly accurate, large models are often unable to improve at all, and can even perform worse than the smaller model.""",2022-02-15T18:53:14Z
Quantifying Memorization Across Neural Language Models,Yes.,5.,"""Large language models (LMs) have been shown to memorize parts of their training data, and when prompted appropriately, they will emit the memorized training data verbatim. This is undesirable because memorization violates privacy (exposing user data), degrades utility (repeated easy-to-memorize text is often low quality),",2022-02-15T18:48:31Z
"Can Machines Help Us Answering Question 16 in Datasheets, and In Turn Reflecting on Inappropriate Content?",Yes.,1.,"""We propose to use the information stored in pre-trained transformer models to assist us in the documentation process.""",2022-02-14T13:00:31Z
Deduplicating Training Data Mitigates Privacy Risks in Language Models,Yes.,5.,"""Past work has shown that large language models are susceptible to privacy attacks,"" and ""Finally, we find that after applying methods to deduplicate training data, language models are considerably more secure against these types of privacy attacks.""",2022-02-14T08:20:15Z
Assessment of contextualised representations in detecting outcome phrases in clinical trials,Yes.,3.,"""several contextualized representations like BERT and ELMO have achieved unparalleled success in detecting various diseases, genes, proteins, and chemicals, however, the same cannot be emphatically stated for outcomes, because these models have been relatively under-tested and studied for the OD task.""",2022-02-13T15:08:00Z
ET-BERT: A Contextualized Datagram Representation with Pre-training Transformers for Encrypted Traffic Classification,Yes.,1.,"""we propose a new traffic representation model called Encrypted Traffic Bidirectional Encoder Representations from Transformer (ET-BERT), which pre-trains deep contextualized datagram-level representation from large-scale unlabeled data.""",2022-02-13T14:54:48Z
Semantic-Oriented Unlabeled Priming for Large-Scale Language Models,Yes.,2.,"""Unfortunately, for in-context learning there is currently no way to leverage unlabeled data, which is often much easier to obtain in large quantities than labeled examples.""",2022-02-12T19:50:59Z
Maximizing Communication Efficiency for Large-scale Training via 0/1 Adam,Yes.,2.,"""we demonstrate the non-linearity in Adam causes slow convergence even when 1-bit compression or local steps are individually applied. To alleviate this limitation, we propose 0/1 Adam that linearizes each Adam step via approximating its optimizer states using their stale estimates and linear correlation.""",2022-02-12T08:02:23Z
What Does it Mean for a Language Model to Preserve Privacy?,,,,2022-02-11T09:18:27Z
Topic Discovery via Latent Space Clustering of Pretrained Language Model Representations,Yes.,3.,"""we begin by analyzing the challenges of using PLM representations for topic discovery""",2022-02-09T17:26:08Z
Exploring the Limits of Domain-Adaptive Training for Detoxifying Large-Scale Language Models,Yes.,4.,"""Pre-trained language models (LMs) are shown to easily generate toxic language."" and ""We find that i) large LMs have similar toxicity levels as smaller ones given the same pre-training corpus, and ii) large LMs require more endeavor to detoxify.""",2022-02-08T22:10:40Z
Logical Reasoning for Task Oriented Dialogue Systems,Yes.,3.,"""lack of reasoning capabilities of dialogue platforms make it difficult to provide relevant and fluent responses, unless the designers of a conversational experience spend a considerable amount of time implementing these capabilities in external rule based modules.""",2022-02-08T21:46:27Z
Survey of Hallucination in Natural Language Generation,Yes.,4.,"""deep learning based generation is prone to hallucinate unintended text, which degrades the system performance and fails to meet user expectations in many real-world scenarios"" and ""hallucinations in large language models (LLMs).""",2022-02-08T03:55:01Z
Do Language Models Learn Position-Role Mappings?,Yes.,3.,"""We do, however, observe some limitations of this generalization when tasks involve constructions with novel ditransitive verbs, hinting at a degree of lexical specificity which underlies model performance.""",2022-02-08T02:50:53Z
Fine-Tuning Approach for Arabic Offensive Language Detection System: BERT-Based Model,No.,1.,The abstract focuses on the problem of online offensive language detection using fine-tuning across several Arabic offensive language datasets and does not mention LLMs or their limitations.,2022-02-07T17:26:35Z
Multilingual Hate Speech and Offensive Content Detection using Modified Cross-entropy Loss,Yes.,1.,"""Large language models are trained on a lot of data and they also make use of contextual embeddings.""",2022-02-05T20:31:40Z
JARVix at SemEval-2022 Task 2: It Takes One to Know One? Idiomaticity Detection using Zero and One-Shot Learning,Yes.,3.,"""In spite of their great success, these vector representations fail to capture meaning of idiomatic multi-word expressions (MWEs).""",2022-02-04T21:17:41Z
Pop Quiz! Can a Large Language Model Help With Reverse Engineering?,,,,2022-02-02T17:09:15Z
GatorTron: A Large Clinical Language Model to Unlock Patient Information from Unstructured Electronic Health Records,Yes.,2.,"""However, there are few clinical language models, the largest of which trained in the clinical domain is comparatively small at 110 million parameters (compared with billions of parameters in the general domain).""",2022-02-02T14:28:51Z
What Has Been Enhanced in my Knowledge-Enhanced Language Model?,Yes.,4.,"""Pretrained language models (LMs) do not capture factual knowledge very well."" and ""it is unclear how and what kind of knowledge is effectively integrated into these models and if such integration may lead to catastrophic forgetting of already learned knowledge.""",2022-02-02T11:23:36Z
Co-training Improves Prompt-based Learning for Large Language Models,,,,2022-02-02T00:48:26Z
Examining Scaling and Transfer of Language Model Architectures for Machine Translation,Yes.,3.,"""Several design choices, including causal masking and language-modeling objectives for the source sequence, have detrimental effects on translation quality.""",2022-02-01T16:20:15Z
ScaLA: Accelerating Adaptation of Pre-Trained Transformer-Based Language Models via Efficient Large-Batch Adversarial Noise,Yes.,3.,"""increasing the batch size often makes the optimization more difficult, leading to slow convergence or poor generalization that can require orders of magnitude more training time to achieve the same model quality.""",2022-01-29T01:47:01Z
Clinical-Longformer and Clinical-BigBird: Transformers for long clinical sequences,Yes.,3.,"""One of the core limitations of these transformers is the substantial memory consumption due to their full self-attention mechanism.""",2022-01-27T22:51:58Z
Going Extreme: Comparative Analysis of Hate Speech in Parler and Gab,No.,1.,"The abstract focuses on hate speech analysis on social platforms like Parler and Gab, and mentions the use of BERT classifier but does not discuss LLMs or their limitations.",2022-01-27T19:29:17Z
DiscoScore: Evaluating Text Generation with BERT and Discourse Coherence,No.,1.,The abstract discusses BERT-based evaluation metrics and their limitations in recognizing coherence but does not mention LLMs or their limitations.,2022-01-26T20:28:26Z
Cheating Automatic Short Answer Grading: On the Adversarial Usage of Adjectives and Adverbs,Yes.,3.,"""We observed a loss of prediction accuracy between 10 and 22 percentage points using the state-of-the-art models BERT and T5.""",2022-01-20T17:34:33Z
AstBERT: Enabling Language Model for Financial Code Understanding with Abstract Syntax Trees,Yes.,3.,"""there are several challenges in applying these language models to solve programming language-related problems directly.""",2022-01-20T03:27:26Z
Unveiling Project-Specific Bias in Neural Code Models,Yes.,5.,"""Although the Large Language Models (LLMs) based neural code models demonstrate commendable performance when trained and tested within the intra-project independent and identically distributed (IID) setting, they often struggle to generalize effectively to real-world inter-project out-of-distribution (OOD) data.""",2022-01-19T02:09:48Z
Language Models as Zero-Shot Planners: Extracting Actionable Knowledge for Embodied Agents,Yes.,3.,"""However, the plans produced naively by LLMs often cannot map precisely to admissible actions.""",2022-01-18T18:59:45Z
Hierarchical Neural Network Approaches for Long Document Classification,,,,2022-01-18T07:17:40Z
Unintended Bias in Language Model-driven Conversational Recommendation,Yes.,5.,"""pretrained LMs are well-known to be prone to intrinsic biases in their training data,"" and ""raises a red flag that advances in the language handling capability of LM-driven CRSs do not come without significant challenges related to mitigating unintended bias.""",2022-01-17T05:50:14Z
Memory-assisted prompt editing to improve GPT-3 after deployment,Yes.,5.,"""Large LMs such as GPT-3 are powerful, but can commit mistakes that are obvious to humans.""",2022-01-16T10:11:37Z
The Dark Side of the Language: Pre-trained Transformers in the DarkNet,Yes.,3.,"""Surprisingly, results show that syntactic and lexical neural networks perform on par with pre-trained Transformers even after fine-tuning. Only after what we call extreme domain adaptation, that is, retraining with the masked language model task on all the novel corpus, pre-trained Transformers reach their standard high results",2022-01-14T16:04:09Z
A Survey of Controllable Text Generation using Transformer-based Pre-trained Language Models,Yes.,3.,"""However, due to the limited level of interpretability of deep neural networks, the controllability of these methods need to be guaranteed.""",2022-01-14T08:32:20Z
Latency Adjustable Transformer Encoder for Language Understanding,Yes.,1.,"""The proposed method is applied to the BERT-base and GPT-2 models for evaluation.""",2022-01-10T13:04:39Z
Imagined versus Remembered Stories: Quantifying Differences in Narrative Flow,Yes.,1.,"""We quantify the differences between autobiographical and imagined stories by introducing sequentiality, a measure of narrative flow of events, drawing probabilistic inferences from a cutting-edge large language model (GPT-3).""",2022-01-07T20:10:47Z
Improving Mandarin End-to-End Speech Recognition with Word N-gram Language Model,Yes.,2.,"""the use of subword-level LMs will ignore the word-level information, which may limit the strength of the external LMs in E2E ASR.""",2022-01-06T10:04:56Z
Formal Analysis of Art: Proxy Learning of Visual Concepts from Style Through Language Models,Yes.,2.,"""The language modeling is a practical and scalable solution requiring no labeling, but it is inevitably imperfect.""",2022-01-05T21:03:29Z
Submix: Practical Private Prediction for Large-Scale Language Models,Yes.,4.,"""Recent data-extraction attacks have exposed that language models can memorize some training samples verbatim. This is a vulnerability that can compromise the privacy of the model's training data.""",2022-01-04T04:23:38Z
On Sensitivity of Deep Learning Based Text Classification Algorithms to Practical Input Perturbations,Yes.,3.,"""We show that these deep learning approaches including BERT are sensitive to such legitimate input perturbations on four standard benchmark datasets SST2, TREC-6, BBC News, and tweet_eval.""",2022-01-02T08:33:49Z
