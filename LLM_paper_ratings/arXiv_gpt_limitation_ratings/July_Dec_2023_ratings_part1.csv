Title,Talks about LLMs,Rate,Evidence,Published
Fairness in Serving Large Language Models,,,,2023-12-31T21:15:54Z
HSC-GPT: A Large Language Model for Human Settlements Construction,Yes.,2.,"""These factors lead to limitations when applying general generative AI in this field, further exacerbated by a lack of high-quality data for model training.""",2023-12-31T13:56:15Z
BatchEval: Towards Human-like Text Evaluation,Yes.,3.,"""current sample-wise evaluation paradigm suffers from the following issues",2023-12-31T09:34:51Z
RAGTruth: A Hallucination Corpus for Developing Trustworthy Retrieval-Augmented Language Models,Yes.,4.,"""Despite the integration of RAG, LLMs may still present unsupported or contradictory claims to the retrieved contents.""",2023-12-31T04:43:45Z
The Art of Defending: A Systematic Evaluation and Analysis of LLM Defense Strategies on Safety and Over-Defensiveness,Yes.,5.,"""reveals several interesting and important findings, such as (a) the widely popular 'self-checking' techniques indeed improve the safety against unsafe inputs, but this comes at the cost of extreme over-defensiveness on the safe inputs, (b) providing a safety instruction along with in-context exemplars (of both safe and unsafe inputs) consistently improves safety and also mitigates undue",2023-12-30T17:37:06Z
Advancing TTP Analysis: Harnessing the Power of Encoder-Only and Decoder-Only Language Models with Retrieval Augmented Generation,Yes.,5.,"""The state-of-the-art LLMs have shown to be prone to hallucination by providing inaccurate information, which is problematic in critical domains like cybersecurity."" and ""Our results reveal that both the direct-use of decoder-only LLMs (i",2023-12-30T16:56:24Z
Uncertainty-Penalized Reinforcement Learning from Human Feedback with Diverse Reward LoRA Ensembles,Yes.,3.,"""However, a notable challenge in RLHF is overoptimization, where beyond a certain threshold, the pursuit of higher rewards leads to a decline in human preferences.""",2023-12-30T14:14:14Z
Is Knowledge All Large Language Models Needed for Causal Reasoning?,Yes.,3.,"""On the contrary, in the absence of knowledge, LLMs still maintain a degree of causal reasoning using the available numerical data, albeit with limitations in the calculations.""",2023-12-30T04:51:46Z
Teach Large Language Models to Forget Privacy,Yes.,4.,"""Large Language Models (LLMs) have proven powerful, but the risk of privacy leakage remains a significant concern.""",2023-12-30T01:26:42Z
ChatEd: A Chatbot Leveraging ChatGPT for an Enhanced Learning Experience in Higher Education,Yes.,3.,"""the possibility of generating incorrect, biased, or unhelpful answers are a key challenge to resolve when deploying LLMs in an education context.""",2023-12-29T19:11:55Z
Principled Gradient-based Markov Chain Monte Carlo for Text Generation,Yes.,5.,"""previous attempts on this approach to text generation all fail to sample correctly from the target language model distributions.""",2023-12-29T18:00:56Z
Jatmo: Prompt Injection Defense by Task-Specific Finetuning,Yes.,5.,"""LLMs are vulnerable to prompt-injection attacks",2023-12-29T16:37:53Z
Gemini in Reasoning: Unveiling Commonsense in Multimodal Large Language Models,Yes.,4.,"""preliminary benchmarks indicate that Gemini lags behind GPT models in commonsense reasoning tasks"" and ""we identify common challenges faced by current LLMs and MLLMs in addressing commonsense problems, underscoring the need for further advancements in enhancing the commonsense reasoning abilities of these models.""",2023-12-29T15:57:49Z
Enhancing Quantitative Reasoning Skills of Large Language Models through Dimension Perception,Yes.,5.,"""However, the lack of dimension knowledge and quantity-related benchmarks has resulted in low performance of LLMs.""",2023-12-29T09:29:37Z
Differentially Private Low-Rank Adaptation of Large Language Model Using Federated Learning,Yes.,3.,"""1) despite avoiding raw data exposure, there is a risk of inferring sensitive information from model outputs, and 2) federated learning for LLMs incurs notable communication overhead.""",2023-12-29T06:50:38Z
Exploring the Sensitivity of LLMs' Decision-Making Capabilities: Insights from Prompt Variation and Hyperparameters,Yes.,3.,"""these studies have not always properly accounted for the sensitivity of LLMs' behavior to hyperparameters and variations in the prompt.""",2023-12-29T05:19:11Z
LISA++: An Improved Baseline for Reasoning Segmentation with Large Language Model,Yes.,3.,"""While LISA effectively bridges the gap between segmentation and large language models to enable reasoning segmentation, it poses certain limitations",2023-12-28T18:58:33Z
Fast Inference of Mixture-of-Experts Language Models with Offloading,Yes.,2.,"""Unfortunately, this makes state-of-the-art MoE language models difficult to run without high-end GPUs.""",2023-12-28T18:58:13Z
Large Language Model for Causal Decision Making,Yes.,3.,"""However, their capability to inference based on user-specified structured data and knowledge in corpus-rare concepts like causal decision-making is still limited.""",2023-12-28T16:59:06Z
How Far Are We from Believable AI Agents? A Framework for Evaluating the Believability of Human Behavior Simulation,,,,2023-12-28T16:51:11Z
GitAgent: Facilitating Autonomous Agent with GitHub by Tool Extension,Yes.,3.,"""While Large Language Models (LLMs) like ChatGPT and GPT-4 have demonstrated exceptional proficiency in natural language processing, their efficacy in addressing complex, multifaceted tasks remains limited.""",2023-12-28T15:47:30Z
Experiential Co-Learning of Software-Developing Agents,Yes.,3.,"""However, these agents often approach a diverse range of tasks in isolation, without benefiting from past experiences. This isolation can lead to repeated mistakes and inefficient trials in task solving.""",2023-12-28T13:50:42Z
AI Content Self-Detection for Transformer-based Large Language Models,Yes.,3.,"""Existing plagiarism detection systems can trace the source of submitted text but are not yet equipped with methods to accurately detect AI-generated text."" and ""Results reveal varying capabilities of AI systems to identify their generated text.""",2023-12-28T10:08:57Z
Spike No More: Stabilizing the Pre-training of Large Language Models,Yes.,5.,"""Loss spikes often occur during pre-training of large language models. The spikes degrade the performance of large language models and sometimes ruin the pre-training.""",2023-12-28T08:53:27Z
Large Language Models for Conducting Advanced Text Analytics Information Systems Research,Yes.,2.,"""We also outline potential challenges and limitations in adopting LLMs for IS.""",2023-12-27T19:49:00Z
Make BERT-based Chinese Spelling Check Model Enhanced by Layerwise Attention and Gaussian Mixture Model,Yes.,3.,"""traditional BERT-based methods still suffer from two limitations. First, although previous works have identified that explicit prior knowledge like Part-Of-Speech (POS) tagging can benefit in the CSC task, they neglected the fact that spelling errors inherent in CSC data can lead to incorrect",2023-12-27T16:11:07Z
"Adapting Large Language Models for Education: Foundational Capabilities, Potentials, and Challenges",Yes.,3.,"""Although LLMs have been successful in various fields, creating an LLM-based education system is still challenging for the wide range of educational skills required."" and ""Finally, we explore the challenges and future directions, providing new research opportunities and perspectives on adapting LLMs for education.""",2023-12-27T14:37:32Z
How Robust are LLMs to In-Context Majority Label Bias?,Yes.,4.,"""In this work, we study the robustness of in-context learning in LLMs to shifts that occur due to majority label bias within the purview of text classification tasks. Prior works have shown that in-context learning with LLMs is susceptible to such biases.""",2023-12-27T12:20:12Z
LLM Factoscope: Uncovering LLMs' Factual Discernment through Inner States Analysis,Yes.,5.,"""a critical issue with LLMs is their tendency to produce outputs that diverge from factual reality.""",2023-12-27T01:44:47Z
LLMs with User-defined Prompts as Generic Data Operators for Reliable Data Processing,Yes.,3.,"""we summarize the challenges and opportunities introduced by LLMs to provide a complete view of this design pattern for more discussions.""",2023-12-26T23:08:38Z
Task Contamination: Language Models May Not Be Few-Shot Anymore,Yes.,5.,"""However, their success in zero-shot and few-shot settings may be affected by task contamination, a potential limitation that has not been thoroughly examined."" and ""This strongly indicates that, for many LLMs, there exists task contamination on zero-shot and few-shot evaluation for datasets released prior to the LLMs' training data creation date."" and ""Importantly, we find that for",2023-12-26T21:17:46Z
Can ChatGPT Read Who You Are?,Yes.,3.,"""We also uncover a 'positivity bias' in ChatGPT's assessments across all personality dimensions"" and ""highlighting both the potential and limitations of using large language models for personality inference.""",2023-12-26T14:43:04Z
A Prompt Learning Framework for Source Code Summarization,Yes.,3.,"""instruction prompting involves designing crafted prompts for zero-shot learning or selecting appropriate samples for few-shot learning and requires users to have professional domain knowledge, while task-oriented fine-tuning requires high training costs.""",2023-12-26T14:37:55Z
MoTCoder: Elevating Large Language Models with Modular of Thought for Challenging Programming Tasks,Yes.,5.,"""Large Language Models (LLMs) have showcased impressive capabilities in handling straightforward programming tasks. However, their performance tends to falter when confronted with more challenging programming problems.""",2023-12-26T08:49:57Z
KnowledgeNavigator: Leveraging Large Language Models for Enhanced Reasoning over Knowledge Graph,Yes.,5.,"""LLM still suffers from knowledge limitation. Especially in scenarios that require long logical chains or complex reasoning, the hallucination and knowledge limitation of LLM limit its performance in question answering (QA).""",2023-12-26T04:22:56Z
SecQA: A Concise Question-Answering Dataset for Evaluating Large Language Models in Computer Security,Yes.,3.,"""Our results, encapsulated in the SecQA v1 and v2 datasets, highlight the varying capabilities and limitations of these models in the computer security context.""",2023-12-26T00:59:30Z
Large Language Models are Not Stable Recommender Systems,,,,2023-12-25T14:54:33Z
Alleviating Hallucinations of Large Language Models through Induced Hallucinations,,,,2023-12-25T12:32:49Z
EcomGPT-CT: Continual Pre-training of E-commerce Large Language Models with Semi-structured Data,Yes.,3.,"""applying these models to specific domains still poses significant challenges, such as lack of domain knowledge, limited capacity to leverage domain knowledge and inadequate adaptation to domain-specific data formats.""",2023-12-25T11:31:47Z
Instruction Fusion: Advancing Prompt Evolution through Hybridization,Yes.,2.,"""Despite the successes, existing methodologies like Evol-Instruct encounter performance limitations, impeding further enhancements in code generation tasks.""",2023-12-25T11:00:37Z
ESGReveal: An LLM-based approach for extracting structured data from ESG reports,Yes.,2.,"""While current iterations of ESGReveal do not process pictorial information, a functionality intended for future enhancement, the study calls for continued research to further develop and compare the analytical capabilities of various LLMs.""",2023-12-25T06:44:32Z
Privacy-Preserved Neural Graph Databases,Yes.,1.,"""In the era of large language models (LLMs), efficient and accurate data retrieval has become increasingly crucial for the use of domain-specific or private data in the retrieval augmented generation (RAG).""",2023-12-25T02:32:05Z
Reducing LLM Hallucinations using Epistemic Neural Networks,Yes.,5.,"""Reducing and detecting hallucinations in large language models is an open research problem.""",2023-12-25T01:17:01Z
The Challenge of Using LLMs to Simulate Human Behavior: A Causal Inference Perspective,Yes.,5.,"""we empirically and theoretically analyze the challenges of conducting LLM-simulated experiments, and explore potential solutions,"" and ""variations in the treatment included in the prompt (e.g., price of focal product) can cause variations in unspecified confounding factors,"" and ""suggesting this endogeneity issue generalizes to other contexts and won't be fully resolved by merely improving the training data.""",2023-12-24T16:32:35Z
A Group Fairness Lens for Large Language Models,Yes.,4.,"""The rapid advancement of large language models has revolutionized various applications but also raised crucial concerns about their potential to perpetuate biases and unfairness when deployed in social media contexts."" and ""Extensive evaluations of popular LLMs reveal inherent safety concerns.""",2023-12-24T13:25:15Z
Towards Consistent Language Models Using Declarative Constraints,Yes.,5.,"""However, they often return incorrect and inconsistent answers to input questions."" and ""Due to the complexity and uninterpretability of the internally learned representations, it is challenging to modify language models such that they provide correct and consistent results.""",2023-12-24T12:53:07Z
A Comprehensive Analysis of the Effectiveness of Large Language Models as Automatic Dialogue Evaluators,Yes.,3.,"""Yet, existing works on utilizing LLMs for automatic dialogue evaluation are limited in their scope in terms of the number of meta-evaluation datasets, mode of evaluation, coverage of LLMs, etc. Hence, it remains inconclusive how effective these LLMs are.""",2023-12-24T04:50:57Z
Fairness-Aware Structured Pruning in Transformers,Yes.,4.,"""The increasing size of large language models (LLMs) has introduced challenges in their training and inference."" and ""existing pruning methods solely focus on performance, without considering an essential aspect for the responsible use of LLMs",2023-12-24T03:57:52Z
"On the Promises and Challenges of Multimodal Foundation Models for Geographical, Environmental, Agricultural, and Urban Planning Applications",Yes.,4.,"""However, there are limitations in several tasks requiring fine-grained recognition and precise counting.""",2023-12-23T22:36:58Z
Towards Efficient Generative Large Language Model Serving: A Survey from Algorithms to Systems,Yes.,4.,"""the computational intensity and memory consumption of deploying these models present substantial challenges in terms of serving efficiency, particularly in scenarios demanding low latency and high throughput.""",2023-12-23T11:57:53Z
PERP: Rethinking the Prune-Retrain Paradigm in the Era of LLMs,Yes.,2.,"""with the rise of Large Language Models (LLMs), full retraining has become infeasible due to memory and compute constraints.""",2023-12-23T11:45:22Z
PokeMQA: Programmable knowledge editing for Multi-hop Question Answering,Yes.,3.,"""the coupling of these functionally-diverse reasoning tasks inhibits LLMs' advantages in comprehending and answering questions while disturbing them with the unskilled task of conflict checking.""",2023-12-23T08:32:13Z
ZO-AdaMU Optimizer: Adapting Perturbation by the Momentum and Uncertainty in Zeroth-order Optimization,Yes.,3.,"""the simulated perturbation stochastic approximation for gradient estimate in MeZO leads to severe oscillations and incurs a substantial time overhead. Moreover, without momentum regularization, MeZO shows severe over-fitting problems.""",2023-12-23T07:46:31Z
Sparsity-Guided Holistic Explanation for LLMs with Interpretable Inference-Time Intervention,Yes.,4.,"""the enigmatic 'black-box' nature of LLMs remains a significant challenge for interpretability, hampering transparent and accountable applications.""",2023-12-22T19:55:58Z
NPHardEval: Dynamic Benchmark on Reasoning Ability of Large Language Models via Complexity Classes,Yes.,4.,"""current benchmarks are inadequate in offering a rigorous evaluation of the full extent of reasoning abilities that LLMs are capable of achieving. They are also prone to the risk of overfitting, as these benchmarks, being publicly accessible and static, allow models to potentially tailor their responses to specific benchmark metrics, thereby inflating their performance.""",2023-12-22T18:07:44Z
Pangu-Agent: A Fine-Tunable Generalist Agent with Structured Reasoning,Yes.,3.,"""Large language models (LLMs) emerged as a fundamental way to incorporate cross-domain knowledge into AI agents but lack crucial learning and adaptation toward specific decision problems.""",2023-12-22T17:57:57Z
Robust Knowledge Extraction from Large Language Models using Social Choice Theory,Yes.,5.,"""they are ill-suited for query answering in high-stake domains like medicine because they are typically not robust - even the same query can result in different answers when prompted multiple times.""",2023-12-22T17:57:29Z
Turbulence: Systematically and Automatically Testing Instruction-Tuned Large Language Models for Code,Yes.,5.,"""This allows gaps in an LLM's code generation abilities to be identified, including $\textit{anomalies}$ where the LLM correctly solves $\textit{almost all}$ questions in a neighbourhood but fails for particular parameter instantiations."" and ""Our findings show that, across the board, Turbulence is able to reveal gaps in LLM reasoning ability.""",2023-12-22T17:29:08Z
"Plan, Posture and Go: Towards Open-World Text-to-Motion Generation",Yes.,2.,"""Conventional text-to-motion generation methods are usually trained on limited text-motion pairs, making them hard to generalize to open-world scenarios."" and ""The motion planner instructs Large Language Models (LLMs) to generate a sequence of scripts describing the key postures in the target motion.""",2023-12-22T17:02:45Z
Large Language Model (LLM) Bias Index -- LLMBI,Yes.,4.,"""This research introduces a novel metric, LLMBI, to systematically measure and mitigate biases potentially skewing model responses"" and ""The research reveals LLMs, whilst demonstrating impressive capabilities in text generation, exhibit varying degrees of bias across different dimensions.""",2023-12-22T15:38:13Z
Theory of Hallucinations based on Equivariance,Yes.,3.,"""Hallucinations in contemporary large language models are often attributed to a misunderstanding of real-world social relationships.""",2023-12-22T08:08:45Z
Empowering Working Memory for Large Language Model Agents,Yes.,5.,"""Large language models (LLMs) have achieved impressive linguistic capabilities. However, a key limitation persists in their lack of human-like memory faculties. LLMs exhibit constrained memory retention across sequential interactions, hindering complex reasoning.""",2023-12-22T05:59:00Z
Don't Believe Everything You Read: Enhancing Summarization Interpretability through Automatic Identification of Hallucinations in Large Language Models,Yes.,5.,"""these models can also be prone to hallucination, which can be detrimental to the faithfulness of any answers that the model provides"" and ""Recent works in combating hallucinations in LLMs deal with identifying hallucinated sentences and categorizing the different",2023-12-22T00:31:46Z
Logic-Scaffolding: Personalized Aspect-Instructed Recommendation Explanation Generation using LLMs,Yes.,3.,"""However, despite the size of the LLM, most existing models struggle to produce zero-shot explanations reliably.""",2023-12-22T00:30:10Z
Context-aware Decoding Reduces Hallucination in Query-focused Summarization,Yes.,5.,"""However, applying large language models (LLM) potentially leads to hallucinations, especially when the evidence contradicts the prior belief of LLMs.""",2023-12-21T23:42:13Z
Parameter Efficient Tuning Allows Scalable Personalization of LLMs for Text Entry: A Case Study on Abbreviation Expansion,Yes.,2.,"""our case study with a deployed 8B parameter LLM on a real user living with ALS, and experiments on movie character personalization indicates that (1) customization may be necessary in some scenarios and prompt-tuning generalizes well to those, (",2023-12-21T22:52:44Z
From Bytes to Biases: Investigating the Cultural Self-Perception of Large Language Models,Yes.,5.,"""technologies based on generative artificial intelligence (GenAI) are known to hallucinate, misinform, and display biases introduced by the massive datasets on which they are trained.""",2023-12-21T22:50:14Z
LiDAR-LLM: Exploring the Potential of Large Language Models for 3D LiDAR Understanding,Yes.,2.,"""While these models are powerful, they have not yet been developed to comprehend the more challenging 3D physical scenes, especially when it comes to the sparse outdoor LiDAR data.""",2023-12-21T17:52:12Z
T-Eval: Evaluating the Tool Utilization Capability of Large Language Models Step by Step,Yes.,2.,"""Yet, how to evaluate and analyze the tool-utilization capability of LLMs is still under-explored.""",2023-12-21T17:02:06Z
AsyncMLD: Asynchronous Multi-LLM Framework for Dialogue Recommendation System,Yes.,3.,"""we still need help with the utterance content's effectiveness and the efficiency of its output speed, even if using LLM.""",2023-12-21T15:12:59Z
SimLM: Can Language Models Infer Parameters of Physical Systems?,Yes.,5.,"""Our experiments suggest that they are not inherently suited to this task, even for simple systems.""",2023-12-21T12:05:19Z
On Task Performance and Model Calibration with Supervised and Self-Ensembled In-Context Learning,Yes.,5.,"""both paradigms are prone to suffer from the critical problem of overconfidence (i.e., miscalibration),"" and ""the problem of miscalibration exists across all learning methods in low-resource scenarios.""",2023-12-21T11:55:10Z
"Preparing to Integrate Generative Pretrained Transformer Series 4 models into Genetic Variant Assessment Workflows: Assessing Performance, Drift, and Nondeterminism Characteristics Relative to Classifying Functional Evidence in Literature",Yes.,5.,"""We observed substantial differences in intraday (nondeterminism) and across day (drift) results,"" and ""Nondeterminism and drift within LLMs must be assessed and monitored when introducing LLM based functionality into clinical workflows.""",2023-12-21T01:56:00Z
L-TUNING: Synchronized Label Tuning for Prompt and Prefix in LLMs,Yes.,1.,"""Efficiently fine-tuning Large Language Models (LLMs) for specific tasks presents a considerable challenge in natural language processing.""",2023-12-21T01:47:49Z
Benchmarking and Defending Against Indirect Prompt Injection Attacks on Large Language Models,Yes.,5.,"""the inability of LLMs to distinguish between instructions and external content and the absence of LLMs' awareness to not execute instructions within external content.""",2023-12-21T01:08:39Z
ASSISTGUI: Task-Oriented Desktop Graphical User Interface Automation,Yes.,3.,"""Our experimental results reveal that our GUI Parser and Reasoning mechanism outshine existing methods in performance. Nevertheless, the potential remains substantial, with the best model attaining only a 46% success rate on our benchmark. We conclude with a thorough analysis of the current methods' limitations, setting the stage for future breakthroughs in this domain.""",2023-12-20T15:28:38Z
Retrieval-augmented Multilingual Knowledge Editing,Yes.,3.,"""Knowledge represented in Large Language Models (LLMs) is quite often incorrect and can also become obsolete over time. Updating knowledge via fine-tuning is computationally resource-hungry and not reliable.""",2023-12-20T14:08:58Z
Assaying on the Robustness of Zero-Shot Machine-Generated Text Detectors,Yes.,3.,"""Existing zero-shot detectors, typically designed for specific tasks or topics, often assume uniform testing scenarios, limiting their practicality.""",2023-12-20T10:53:53Z
Testing the Segment Anything Model on radiology data,No.,1.,The abstract discusses the Segment Anything Model (SAM) and its application to MRI data but does not mention large language models (LLMs) or their limitations.,2023-12-20T09:45:21Z
CORECODE: A Common Sense Annotated Dialogue Dataset with Benchmark Tasks for Chinese Large Language Models,Yes.,5.,"""Experimental results demonstrate that these models are not competent to predict CORECODE's plentiful reasoning content, and even ChatGPT could only achieve 0.275 and 0.084 accuracy on the domain identification and slot identification tasks under the zero-shot setting.""",2023-12-20T09:06:18Z
Turning Dust into Gold: Distilling Complex Reasoning Capabilities from LLMs by Leveraging Negative Data,Yes.,3.,"""Large Language Models (LLMs) have performed well on various reasoning tasks, but their inaccessibility and numerous parameters hinder wide application in practice."" and ""In some cases, however, LLMs may produce incorrect reasoning chains, especially when facing complex mathematical problems.""",2023-12-20T08:28:36Z
ALMANACS: A Simulatability Benchmark for Language Model Explainability,Yes.,5.,"""Our results are sobering",2023-12-20T03:44:18Z
Learning and Forgetting Unsafe Examples in Large Language Models,Yes.,4.,"""We explore the behavior of LLMs finetuned on noisy custom data containing unsafe content, represented by datasets that contain biases, toxicity, and harmfulness,"" and ""aligned LLMs can readily learn this unsafe content, they also tend to forget it more significantly than other examples when subsequently finetuned on safer content.""",2023-12-20T03:18:50Z
A Case Study on Test Case Construction with Large Language Models: Unveiling Practical Insights and Challenges,Yes.,3.,"""Additionally, delves into challenges such as model interpretability and adaptation to diverse software contexts.""",2023-12-19T20:59:02Z
Bypassing the Safety Training of Open-Source LLMs with Priming Attacks,Yes.,5.,"""we show that SOTA open-source LLMs are vulnerable to simple, optimization-free attacks we refer to as $\textit{priming attacks}$, which are easy to execute and effectively bypass alignment from safety training.""",2023-12-19T16:47:12Z
On Early Detection of Hallucinations in Factual Question Answering,Yes.,5.,"""While large language models (LLMs) have taken great strides towards helping humans with a plethora of tasks like search and summarization, hallucinations remain a major impediment towards gaining user trust.""",2023-12-19T14:35:04Z
Parameter-Efficient Fine-Tuning Methods for Pretrained Language Models: A Critical Review and Assessment,Yes.,4.,"""the enormous size and computational demands of these models pose significant challenges for adapting them to specific downstream tasks, especially in environments with limited computational resources.""",2023-12-19T13:31:24Z
Curated LLM: Synergy of LLMs and Data Curation for tabular augmentation in ultra low-data regimes,Yes.,2.,"""However, not all the data generated by LLMs will improve downstream utility, as for any generative model.""",2023-12-19T12:34:46Z
A Performance Evaluation of a Quantized Large Language Model on Various Smartphones,Yes.,1.,"""This paper explores the feasibility and performance of on-device large language model (LLM) inference on various Apple iPhone models.""",2023-12-19T10:19:39Z
Climate Change from Large Language Models,Yes.,3.,"""we evaluate several state-of-the-art LLMs and find that their knowledge falls short in terms of timeliness.""",2023-12-19T09:26:46Z
Large Language Models Empowered Agent-based Modeling and Simulation: A Survey and Perspectives,Yes.,3.,"""We then discuss the motivation for applying large language models to agent-based simulation and systematically analyze the challenges in environment perception, human alignment, action generation, and evaluation.""",2023-12-19T09:06:45Z
Text-Conditioned Resampler For Long Form Video Understanding,Yes.,1.,"""In this paper we present a text-conditioned video resampler (TCR) module that uses a pre-trained and frozen visual encoder and large language model (LLM) to process long video sequences for a task.""",2023-12-19T06:42:47Z
Ethical Artificial Intelligence Principles and Guidelines for the Governance and Utilization of Highly Advanced Large Language Models,Yes.,3.,"""Currently, there are limited usage of ethical artificial intelligence (AI) principles and guidelines addressing advanced LLMs due to the fact that we have not reached that point yet. However, this is a problem as once we do reach that point, we will not be adequately prepared to deal with the aftermath of it in an ethical and optimal way, which will lead to undesired and unexpected",2023-12-19T06:28:43Z
Difficulty-Focused Contrastive Learning for Knowledge Tracing with a Large Language Model-Based Difficulty Prediction,Yes.,1.,"""a Large Language Model (LLM)-based framework for difficulty prediction.""",2023-12-19T06:26:25Z
Efficient LLM inference solution on Intel GPU,Yes.,3.,"""LLMs are usually complicatedly designed in model structure with massive operations and perform inference in the auto-regressive mode, making it a challenging task to design a system with high efficiency.""",2023-12-19T05:40:43Z
Tokenization Matters: Navigating Data-Scarce Tokenization for Gender Inclusive Language Technologies,Yes.,4.,"""Gender-inclusive NLP research has documented the harmful limitations of gender binary-centric large language models (LLM), such as the inability to correctly use gender-diverse English neopronouns (e.g., xe, zir, fae)."" and ""We discover LLM misgendering is significantly influenced by Byte-Pair Encoding (BPE) tokenization, the tokenizer powering many popular LLM",2023-12-19T01:28:46Z
Indoor and Outdoor 3D Scene Graph Generation via Language-Enabled Spatial Ontologies,Yes.,1.,"""In particular, we use a Large Language Model (LLM) to build such an ontology, thus largely reducing the amount of manual effort required.""",2023-12-18T21:20:28Z
Opportunities and Challenges of Applying Large Language Models in Building Energy Efficiency and Decarbonization Studies: An Exploratory Overview,Yes.,4.,"""Despite the promising potential of LLMs, challenges including complex and expensive computation, data privacy, security and copyright, complexity in fine-tuned LLMs, and self-consistency are discussed.""",2023-12-18T20:58:58Z
Evaluating Language-Model Agents on Realistic Autonomous Tasks,Yes.,4.,"""We find that these language model agents can only complete the easiest tasks from this list, although they make some progress on the more challenging tasks."" and ""we do not think that these evaluations provide good assurance that the ``next generation'' of language models (e.g. 100x effective compute scaleup on existing models) will not yield agents capable of ARA.""",2023-12-18T19:27:09Z
Traces of Memorisation in Large Language Models for Code,Yes.,5.,"""The content of these datasets is memorised and can be extracted by attackers with data extraction attacks."" and ""We find that large language models for code are vulnerable to data extraction attacks, like their natural language counterparts.""",2023-12-18T19:12:58Z
Language-Assisted 3D Scene Understanding,Yes.,3.,"""However, challenges remain, including the requirement for paired triplet data, redundancy and ambiguity in supervised features, and the disruption of the original priors.""",2023-12-18T18:54:56Z
G-LLaVA: Solving Geometric Problem with Multi-Modal Large Language Model,Yes.,3.,"""We first analyze the limitations of current Multimodal Large Language Models (MLLMs) in this area",2023-12-18T17:36:20Z
NoMIRACL: Knowing When You Don't Know for Robust Multilingual Retrieval-Augmented Generation,Yes.,5.,"""We measure LLM robustness using two metrics",2023-12-18T17:18:04Z
Evaluating and Enhancing Large Language Models for Conversational Reasoning on Knowledge Graphs,Yes.,3.,"""However, the performance of LLMs is constrained due to a lack of KG environment awareness and the difficulties in developing effective optimization mechanisms for intermediary reasoning stages.""",2023-12-18T15:23:06Z
MAC-SQL: A Multi-Agent Collaborative Framework for Text-to-SQL,Yes.,3.,"""Recent LLM-based Text-to-SQL methods usually suffer from significant performance degradation on 'huge' databases and complex user questions that require multi-step reasoning.""",2023-12-18T14:40:20Z
Linear Attention via Orthogonal Memory,Yes.,5.,"""most existing linear attention mechanisms suffer from an efficiency degradation problem, leading to inefficiencies in causal language modeling and hindering their application in long-range language models.""",2023-12-18T12:26:27Z
Split and Rephrase with Large Language Models,Yes.,4.,"""we evaluate large language models on the task, showing that they can provide large improvements over the state of the art on the main metrics, although still lagging in terms of splitting compliance"" and ""Our results provide a fine-grained analysis of the potential and limitations of large language models for SPRP, with significant improvements achievable using relatively small amounts of training data and model parameters overall,",2023-12-18T10:16:37Z
Retrieval-Augmented Generation for Large Language Models: A Survey,Yes.,5.,"""Large Language Models (LLMs) showcase impressive capabilities but encounter challenges like hallucination, outdated knowledge, and non-transparent, untraceable reasoning processes.""",2023-12-18T07:47:33Z
CLOVA: A Closed-Loop Visual Assistant with Tool Usage and Update,Yes.,2.,"""However, these methods often overlook the potential for continual learning, typically by freezing the utilized tools, thus limiting their adaptation to environments requiring new knowledge.""",2023-12-18T03:34:07Z
Students' Perceptions and Preferences of Generative Artificial Intelligence Feedback for Programming,Yes.,1.,"""This paper explored the feasibility of utilizing ChatGPT, one of the most popular LLMs, for automating feedback for Java programming assignments in an introductory computer science (CS1) class.""",2023-12-17T22:26:53Z
Mixed Distillation Helps Smaller Language Model Better Reasoning,Yes.,3.,"""While large language models (LLMs) have demonstrated exceptional performance in recent natural language processing (NLP) tasks, their deployment poses substantial challenges due to high computational and memory demands in real-world applications.""",2023-12-17T14:28:28Z
Can persistent homology whiten Transformer-based black-box models? A case study on BERT compression,Yes.,4.,"""However, they come with substantial computational and memory costs. Additionally, they are essentially black-box models, challenging to explain and interpret.""",2023-12-17T12:33:50Z
An Evaluation of GPT-4V and Gemini in Online VQA,Yes.,5.,"""Our zero-shot performance analysis highlights the types of questions that are most challenging for both models, including questions related to 'puzzling' topic, with 'Identification' user intention, with 'Sheet Music' image type, or labeled as 'hard' by GPT-4.""",2023-12-17T07:38:43Z
LLM-Twin: Mini-Giant Model-driven Beyond 5G Digital Twin Networking Framework with Semantic Secure Communication and Computation,Yes.,1.,"""we propose a large language model (LLM) empowered DTNs networking framework, LLM-Twin.""",2023-12-17T07:13:59Z
TrojFSP: Trojan Insertion in Few-shot Prompt Tuning,Yes.,1.,"""Prompt tuning is one of the most effective solutions to adapting a fixed pre-trained language model (PLM) for various downstream tasks, especially with only a few input samples.""",2023-12-16T14:49:36Z
Resolving Crash Bugs via Large Language Models: An Empirical Study,Yes.,3.,"""We observe that ChatGPT performs better at resolving code-related crash bugs compared to environment-related ones, and its primary challenge in resolution lies in inaccurate localization.""",2023-12-16T13:41:04Z
DeepArt: A Benchmark to Advance Fidelity Research in AI-Generated Content,Yes.,5.,"""The quantitative and qualitative experiments fully reveal the limitations of the GPT-4 model in image synthesis.""",2023-12-16T10:17:09Z
When Graph Data Meets Multimodal: A New Paradigm for Graph Understanding and Reasoning,Yes.,3.,"""integrating complex graph information into text sequences has become exceptionally difficult, which hinders the ability to interact with graph data through natural language instructions.""",2023-12-16T08:14:11Z
LLM-SQL-Solver: Can LLMs Determine SQL Equivalence?,Yes.,3.,"""Our experiments demonstrate using our techniques, LLMs is a promising tool to help data engineers in writing semantically equivalent SQL queries, however challenges still persist, and is a better metric for evaluating SQL generation than the popular execution accuracy.""",2023-12-16T05:01:23Z
KGLens: A Parameterized Knowledge Graph Solution to Assess What an LLM Does and Doesn't Know,Yes.,3.,"""Measuring the alignment between a Knowledge Graph (KG) and Large Language Models (LLMs) is an effective method to assess the factualness and identify the knowledge blind spots of LLMs.""",2023-12-15T23:34:05Z
Student as an Inherent Denoiser of Noisy Teacher,Yes.,3.,"""pseudo labels generated by teacher models are usually noisy and may influence KD performance.""",2023-12-15T20:21:45Z
Challenges with unsupervised LLM knowledge discovery,Yes.,5.,"""We show that existing unsupervised methods on large language model (LLM) activations do not discover knowledge -- instead they seem to discover whatever feature of the activations is most prominent.""",2023-12-15T18:49:43Z
LoRAMoE: Alleviate World Knowledge Forgetting in Large Language Models via MoE-Style Plugin,Yes.,5.,"""However, we find that large-scale increases in instruction data can damage the world knowledge previously stored in LLMs.""",2023-12-15T17:45:06Z
Red AI? Inconsistent Responses from GPT3.5 Models on Political Issues in the US and China,Yes.,4.,"""The rising popularity of ChatGPT and other AI-powered large language models (LLMs) has led to increasing studies highlighting their susceptibility to mistakes and biases."" and ""This disparity may stem from Chinese state censorship and US-China geopolitical tensions, which influence the training corpora of GPT bilingual models.""",2023-12-15T16:25:56Z
ProCoT: Stimulating Critical Thinking and Writing of Students through Engagement with Large Language Models (LLMs),Yes.,3.,"""These LLMs are also known for hallucinations (i.e. fake facts)"" and ""ProCoT can prevent cheating because of clear limitations in existing LLMs.""",2023-12-15T14:01:46Z
Taxonomy-based CheckList for Large Language Model Evaluation,Yes.,4.,"""the internal stereotypical representation may affect the fairness of the outputs,"" ""we present a checklist-style task that aims to probe and quantify LMs' unethical behaviors through question-answering (QA),"" and ""Our results indicate that transformer-based QA model's biased tendency positively correlates with its consistency, whereas LLM shows the opposite relation.""",2023-12-15T12:58:07Z
Prompting Large Language Models for Topic Modeling,Yes.,3.,"""existing models have certain limitations, particularly when dealing with short text datasets that lack co-occurring words. Moreover, these models often neglect sentence-level semantics, focusing primarily on token-level semantics.""",2023-12-15T11:15:05Z
Binary Code Summarization: Benchmarking ChatGPT/GPT-4 and Other Large Language Models,Yes.,3.,"""Our findings highlight both the transformative potential of LLMs in this field and the challenges yet to be overcome.""",2023-12-15T08:32:28Z
Extending Context Window of Large Language Models via Semantic Compression,Yes.,5.,"""Transformer-based Large Language Models (LLMs) often impose limitations on the length of the text input to ensure the generation of fluent and relevant responses. This constraint restricts their applicability in scenarios involving long texts.""",2023-12-15T07:04:33Z
Privacy-Aware Document Visual Question Answering,Yes.,3.,"""We highlight privacy issues in state of the art multi-modal LLM models used for DocVQA, and explore possible solutions.""",2023-12-15T06:30:55Z
Marathon: A Race Through the Realm of Long Context with Large Language Models,Yes.,5.,"""the existing long context benchmarks are no longer sufficient for evaluating the long context understanding and reasoning capability of large language models.""",2023-12-15T05:30:14Z
No-Skim: Towards Efficiency Robustness Evaluation on Skimming-based Language Models,Yes.,5.,"""our work for the first time reveals the acceleration may be vulnerable to Denial-of-Service (DoS) attacks"" and ""evaluate the vulnerability of the skimming acceleration in various LLM architectures.""",2023-12-15T02:42:05Z
CERN for AGI: A Theoretical Framework for Autonomous Simulation-Based Artificial Intelligence Testing and Alignment,Yes.,3.,"""Due to the rapid development and wide application of LLMs, challenges such as ethical alignment, controllability, and predictability of these models have become important research topics.""",2023-12-14T23:48:51Z
Auto MC-Reward: Automated Dense Reward Design with Large Language Models for Minecraft,Yes.,1.,"""leverages Large Language Models (LLMs) to automatically design dense reward functions, thereby enhancing the learning efficiency.""",2023-12-14T18:58:12Z
Measurement in the Age of LLMs: An Application to Ideological Scaling,Yes.,1.,"""This paper explores the use of large language models (LLMs) to flexibly navigate the conceptual clutter inherent to social scientific measurement tasks.""",2023-12-14T18:34:06Z
Towards Verifiable Text Generation with Evolving Memory and Self-Reflection,Yes.,5.,"""Despite the remarkable ability of large language models (LLMs) in language comprehension and generation, they often suffer from producing factually incorrect information, also known as hallucination.""",2023-12-14T16:10:56Z
Modeling Complex Mathematical Reasoning via Large Language Model based MathAgent,Yes.,5.,"""Large language models (LLMs) face challenges in solving complex mathematical problems that require comprehensive capacities to parse the statements, associate domain knowledge, perform compound logical reasoning, and integrate the intermediate rationales. Tackling all these problems once could be arduous for LLMs, thus leading to confusion in generation.""",2023-12-14T13:33:50Z
CogAgent: A Visual Language Model for GUI Agents,Yes.,3.,"""Large language models (LLMs) such as ChatGPT can assist people in tasks like writing emails, but struggle to understand and interact with GUIs, thus limiting their potential to increase automation levels.""",2023-12-14T13:20:57Z
Evaluating Large Language Models for Health-related Queries with Presuppositions,Yes.,5.,"""Given the moderate factual accuracy, and the inability of models to consistently correct false assumptions, our work calls for a careful assessment of current LLMs for use in high-stakes scenarios.""",2023-12-14T10:35:13Z
Future-proofing geotechnics workflows: accelerating problem-solving with large language models,Yes.,3.,"""It also addresses the challenges in implementing LLMs, particularly in achieving high precision and accuracy in specialized tasks, and underscores the need for expert oversight.""",2023-12-14T05:17:27Z
ChatSOS: LLM-based knowledge Q&A system for safety engineering,Yes.,4.,"""Despite these advancements, LLMs face constraints in processing specialized tasks, attributed to factors such as corpus size, input processing limitations, and privacy concerns.""",2023-12-14T03:25:23Z
Zebra: Extending Context Window with Layerwise Grouped Local-Global Attention,Yes.,3.,"""Recognizing the inherent challenges in extending the context window for LLMs, primarily built on Transformer architecture, we propose a new model architecture, referred to as Zebra.""",2023-12-14T02:45:31Z
Identifying Planetary Names in Astronomy Papers: A Multi-Step Approach,Yes.,1.,"""inference with a locally installed large language model (LLM) to reliably identify planetary names despite these challenges.""",2023-12-14T00:50:14Z
Distributed Inference and Fine-tuning of Large Language Models Over The Internet,Yes.,3.,"""However, using these 50B+ models requires high-end hardware, making them inaccessible to most researchers.""",2023-12-13T18:52:49Z
Distributional Preference Learning: Understanding and Accounting for Hidden Context in RLHF,Yes.,4.,"""Experimental results indicate that applying DPL to RLHF for LLM chatbots identifies hidden context in the data and significantly reduces subsequent jailbreak vulnerability.""",2023-12-13T18:51:34Z
Efficient Toxic Content Detection by Bootstrapping and Distilling Large Language Models,Yes.,3.,"""However, efficiently designing prompts for LLMs remains challenging. Moreover, the high run-time cost of LLMs may hinder their deployments in production.""",2023-12-13T17:22:19Z
Chat-3D v2: Bridging 3D Scene and Large Language Models with Object Identifiers,Yes.,3.,"""However, current models are constrained to addressing object-centric tasks, where each question-answer pair focuses solely on an individual object."" and ""While this solution appears straightforward, it presents two main challenges",2023-12-13T14:27:45Z
Breaking the Silence: the Threats of Using LLMs in Software Engineering,Yes.,5.,"""This paper initiates an open discussion on potential threats to the validity of LLM-based research including issues such as closed-source models, possible data leakage between LLM training data and research evaluation, and the reproducibility of LLM-based findings.""",2023-12-13T11:02:19Z
CoRTEx: Contrastive Learning for Representing Terms via Explanations with Applications on Constructing Biomedical Knowledge Graphs,Yes.,1.,"""we leverage the world knowledge from Large Language Models (LLMs) and propose Contrastive Learning for Representing Terms via Explanations (CoRTEx) to enhance term representation and significantly improves term clustering.""",2023-12-13T10:29:34Z
Modality Plug-and-Play: Elastic Modality Adaptation in Multimodal LLMs for Embodied AI,Yes.,3.,"""the growing diversity of input data modalities prevents incorporating all modalities into LLMs, especially when LLMs are deployed on resource-constrained edge devices for embodied AI applications"" and ""existing work adopts fixed connections between encoders and the LLM's input layer, leading to high training cost at runtime and ineffective cross-modal interaction.""",2023-12-13T04:08:59Z
Large Language Model Enhanced Multi-Agent Systems for 6G Communications,Yes.,4.,"""directly applying native LLMs in 6G encounters various challenges, such as a lack of private communication data and knowledge, limited logical reasoning, evaluation, and refinement abilities.""",2023-12-13T02:35:57Z
"Tell, don't show: Declarative facts influence how LLMs generalize",Yes.,3.,"""Nevertheless, the effect of declarative statements on model likelihoods is small in absolute terms and increases surprisingly little with model size (i.e. from 330 million to 175 billion parameters).""",2023-12-12T22:47:42Z
Can LLM find the green circle? Investigation and Human-guided tool manipulation for compositional generalization,Yes.,3.,"""We find that they struggle with complex compositional questions due to cumulative errors in long reasoning steps and intricate logic required for tool-making.""",2023-12-12T22:11:17Z
Large language models in healthcare and medical domain: A review,Yes.,4.,"""Finally, we summarize the prominent challenges and constraints faced by large language models in the healthcare sector, offering a holistic perspective on their potential benefits and shortcomings.""",2023-12-12T20:54:51Z
LLM in a flash: Efficient Large Language Model Inference with Limited Memory,Yes.,3.,"""However, their substantial computational and memory requirements present challenges, especially for devices with limited DRAM capacity.""",2023-12-12T18:57:08Z
Comparable Demonstrations are Important in In-Context Learning: A Novel Perspective on Demonstration Selection,Yes.,4.,"""Despite the great success of ICL, the limitation of the demonstration number may lead to demonstration bias, i.e. the input-label mapping induced by LLMs misunderstands the task's essence."" and ""we find that (1) demonstration bias does exist in LLMs, and CDs can significantly reduce such bias.""",2023-12-12T18:05:46Z
FairSISA: Ensemble Post-Processing to Improve Fairness of Unlearning in LLMs,Yes.,4.,"""Training large language models (LLMs) is a costly endeavour in terms of time and computational resources,"" and ""We evaluate the performance-fairness trade-off for SISA, and empirically demonstrate that SISA can indeed reduce fairness in LLMs.""",2023-12-12T16:44:47Z
ICL Markup: Structuring In-Context Learning using Soft-Token Tags,,,,2023-12-12T16:25:05Z
On Diversified Preferences of Large Language Model Alignment,Yes.,4.,"""However, in this pluralistic world, human preferences can be diversified due to annotators' different tastes, which hinders the effectiveness of LLM alignment methods."" and ""We find that diversified preference data negatively affect the calibration performance of RMs on human-shared preferences, such as Harmless&Helpful, thereby impairing the alignment performance of LLMs.""",2023-12-12T16:17:15Z
Large Language Models are Clinical Reasoners: Reasoning-Aware Diagnosis Framework with Prompt-Generated Rationales,Yes.,1.,"""Machine reasoning has made great progress in recent years owing to large language models (LLMs).""",2023-12-12T16:14:45Z
A Simple Recipe for Contrastively Pre-training Video-First Encoders Beyond 16 Frames,No.,1.,The abstract does not mention LLMs or their limitations.,2023-12-12T16:10:19Z
Sequential Planning in Large Partially Observable Environments guided by LLMs,Yes.,4.,"""But they still struggle with exploration and get stuck in local optima. Their planning capabilities are limited by the limited reasoning capability of the foundational LLMs on text data.""",2023-12-12T15:36:59Z
Maatphor: Automated Variant Analysis for Prompt Injection Attacks,Yes.,3.,"""Prompt injection has emerged as a serious security threat to large language models (LLMs)."" and ""variants of a prompt injection can be created to evade the LLM's guardrails.""",2023-12-12T14:22:20Z
Multilingual large language models leak human stereotypes across language boundaries,Yes.,5.,"""Previous research has shown that the presence of stereotypes and biases in monolingual large language models can be attributed to the nature of their training data, which is collected from humans and reflects societal biases."" and ""This raises the question",2023-12-12T10:24:17Z
Divide-and-Conquer Attack: Harnessing the Power of LLM to Bypass Safety Filters of Text-to-Image Models,Yes.,1.,"""We design attack helper prompts that effectively guide LLMs to break down an unethical drawing intent into multiple benign descriptions of individual image elements, allowing them to bypass safety filters while still generating unethical images.""",2023-12-12T10:04:43Z
LLMs Perform Poorly at Concept Extraction in Cyber-security Research Literature,Yes.,5.,"""The results suggest that LLMs do not produce good knowledge entities that reflect the cybersecurity context, but our results show some potential for noun extractors.""",2023-12-12T09:39:03Z
Context Matters: Data-Efficient Augmentation of Large Language Models for Scientific Applications,Yes.,5.,"""we explore the challenges inherent to Large Language Models (LLMs) like GPT-4, particularly their propensity for hallucinations, logic mistakes, and incorrect conclusions when tasked with answering complex questions.""",2023-12-12T08:43:20Z
Improving Factual Error Correction by Learning to Inject Factual Errors,,,,2023-12-12T08:02:06Z
Rethinking Compression: Reduced Order Modelling of Latent Features in Large Language Models,Yes.,3.,"""Due to the substantial scale of Large Language Models (LLMs), the direct application of conventional compression methodologies proves impractical. The computational demands associated with even minimal gradient updates present challenges, particularly on consumer-grade hardware.""",2023-12-12T07:56:57Z
HyperRouter: Towards Efficient Training and Inference of Sparse Mixture of Experts,Yes.,3.,"""However, this strategy has two key limitations",2023-12-12T07:40:23Z
Alignment for Honesty,Yes.,5.,"""a pivotal aspect of alignment for honesty involves discerning the limits of an LLM's knowledge, which is far from straightforward. This challenge demands comprehensive solutions in terms of metric development, benchmark creation, and training methodologies.""",2023-12-12T06:10:42Z
Hallucination Augmented Contrastive Learning for Multimodal Large Language Model,Yes.,5.,"""MLLMs still face a fundamental limitation of hallucinations, where they tend to generate erroneous or fabricated information.""",2023-12-12T04:05:15Z
Safety Alignment in NLP Tasks: Weakly Aligned Summarization as an In-Context Attack,Yes.,5.,"""Our study, focusing on safety-sensitive documents obtained through adversarial attacks, reveals significant disparities in the safety alignment of various NLP tasks."" and ""Moreover, the concurrent use of multiple NLP tasks with lesser safety alignment increases the risk of LLMs inadvertently processing harmful content.""",2023-12-12T01:39:29Z
Interactive Planning Using Large Language Models for Partially Observable Robotics Tasks,Yes.,3.,"""However, planning for these tasks in the presence of uncertainties is challenging as it requires \enquote{chain-of-thought} reasoning, aggregating information from the environment, updating state estimates, and generating actions based on the updated state estimates.""",2023-12-11T22:54:44Z
Building Domain-Specific LLMs Faithful To The Islamic Worldview: Mirage or Technical Possibility?,Yes.,4.,"""However, this impressive performance comes with inherent limitations, such as the tendency to perpetuate stereotypical biases or fabricate non-existent facts.""",2023-12-11T18:59:09Z
Large Language Models with Retrieval-Augmented Generation for Zero-Shot Disease Phenotyping,Yes.,3.,"""Large language models (LLMs) offer promise in text understanding but may not efficiently handle real-world clinical documentation.""",2023-12-11T15:45:27Z
MMICT: Boosting Multi-Modal Fine-Tuning with In-Context Examples,Yes.,2.,"""Although In-Context Learning (ICL) brings remarkable performance gains to Large Language Models (LLMs), the improvements remain lower than fine-tuning on downstream tasks.""",2023-12-11T13:11:04Z
Linguistic and Structural Basis of Engineering Design Knowledge,Yes.,2.,"""Existing ontological design theories are less likely to guide the large-language models whose applications are currently limited to ideation and learning purposes.""",2023-12-11T13:03:39Z
Learning Hierarchical Prompt with Structured Linguistic Knowledge for Vision-Language Models,Yes.,3.,"""Preexisting prompt tuning methods exhibit inadequacies in managing this structured knowledge.""",2023-12-11T12:14:06Z
GPTBIAS: A Comprehensive Framework for Evaluating Bias in Large Language Models,,,,2023-12-11T12:02:14Z
KnowGPT: Knowledge Injection for Large Language Models,Yes.,4.,"""However, these models often give inaccurate or incorrect responses when faced with questions requiring domain-specific or professional-specific knowledge not covered in their training corpus.""",2023-12-11T07:56:25Z
Unlocking Anticipatory Text Generation: A Constrained Approach for Large Language Models Decoding,Yes.,5.,"""However, achieving optimal results with a given prompt or instruction can be challenging, especially for billion-sized models. Additionally, undesired behaviors such as toxicity or hallucinations can manifest. While much larger models (e.g., ChatGPT) may demonstrate strength in mitigating these issues, there is still no guarantee of complete prevention.""",2023-12-11T06:35:33Z
GTA: Gated Toxicity Avoidance for LM Performance Preservation,Yes.,3.,"""However, existing CTG methods not only reduce toxicity but also negatively impact several aspects of the language model's generation performance, including topic consistency, grammar, and perplexity.""",2023-12-11T05:04:17Z
Can LLMs Configure Software Tools,Yes.,2.,"""Existing methods, including Bayesian optimization, have limitations regarding initial setup, computational cost, and convergence efficiency."" and ""While our initial insights are promising, they also indicate the need for further in-depth investigations and experiments in this domain.""",2023-12-11T05:03:02Z
User Modeling in the Era of Large Language Models: Current Research and Future Directions,Yes.,3.,"""Finally, it presents remaining challenges and future directions in the LLM-UM research.""",2023-12-11T03:59:36Z
EgoPlan-Bench: Benchmarking Egocentric Embodied Planning with Multimodal Large Language Models,Yes.,3.,"""We evaluate various open-source MLLMs, revealing that these models have not yet evolved into embodied planning generalists (even GPT-4V).""",2023-12-11T03:35:58Z
METAL: Metamorphic Testing Framework for Analyzing Large-Language Model Qualities,Yes.,4.,"""However, their black-boxed and probabilistic characteristics can lead to potential risks in the quality of outputs in diverse LLM applications."" and ""existing studies have limited their coverage of QAs and tasks in LLMs and are difficult to extend.""",2023-12-11T01:29:19Z
Large Language Models on Lexical Semantic Change Detection: An Evaluation,Yes.,1.,"""Despite the comprehensive coverage of various natural language processing domains by LLMs, there is a notable scarcity of literature concerning their application in this specific realm.""",2023-12-10T21:26:35Z
Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs,Yes.,5.,"""However, this knowledge is inherently limited, relying heavily on the characteristics of the training data."" and ""we find that LLMs struggle to learn new factual information through unsupervised fine-tuning, and that exposing them to numerous variations of the same fact during training could alleviate this problem.""",2023-12-10T16:52:00Z
Mutual Enhancement of Large and Small Language Models with Cross-Silo Knowledge Transfer,,,,2023-12-10T09:52:32Z
ASVD: Activation-aware Singular Value Decomposition for Compressing Large Language Models,Yes.,3.,"""We delve into the challenges of LLM compression, notably their dependency on extensive training data and computational resources.""",2023-12-10T08:41:24Z
Large Multimodal Model Compression via Efficient Pruning and Distillation at AntGroup,Yes.,4.,"""However, the deployment of such sizable models introduces challenges, particularly in increased latency and carbon emissions, which are antithetical to the ideals of Green AI.""",2023-12-10T06:57:48Z
Context Tuning for Retrieval Augmented Generation,Yes.,3.,"""RAG's tool retrieval step requires all the required information to be explicitly present in the query. This is a limitation, as semantic search, the widely adopted tool retrieval method, can fail when the query is incomplete or lacks context.""",2023-12-09T23:33:16Z
Understanding the Effect of Model Compression on Social Bias in Large Language Models,Yes.,4.,"""Large Language Models (LLMs) trained with self-supervision on vast corpora of web text fit to the social biases of that text. Without intervention, these social biases persist in the model's predictions in downstream tasks, leading to representational harm."" and ""We perform a carefully controlled study of the",2023-12-09T20:04:20Z
Two Directions for Clinical Data Generation with Large Language Models: Data-to-Label and Label-to-Data,Yes.,1.,"""Large language models (LLMs) can generate natural language texts for various domains and tasks, but their potential for clinical text mining, a domain with scarce, sensitive, and imbalanced medical data, is underexplored.""",2023-12-09T19:35:40Z
PILLOW: Enhancing Efficient Instruction Fine-tuning via Prompt Matching,Yes.,2.,"""Instruction fine-tuning has conventionally been employed to adapt Large Language Models (LLMs) to a variety of tasks. Nonetheless, this technique often necessitates substantial computational resources, making it impractical for deployment by individuals or small-scale entities.""",2023-12-09T17:38:39Z
Sim-GPT: Text Similarity via GPT Annotated Data,Yes.,1.,"""Sim-GPT framework utilizes LLMs to provide a substantial amount of reliable annotated data filling the gap of the lack of training signals for STS.""",2023-12-09T16:10:23Z
Enhancing Medical Specialty Assignment to Patients using NLP Techniques,,,,2023-12-09T14:13:45Z
ESPN: Memory-Efficient Multi-Vector Information Retrieval,Yes.,3.,"""However, these models significantly amplify memory and storage requirements for retrieval indices by an order of magnitude. This escalation in index size renders the scalability of multi-vector IR models progressively challenging due to their substantial memory demands.""",2023-12-09T00:19:42Z
PaperQA: Retrieval-Augmented Generative Agent for Scientific Research,Yes.,5.,"""Large Language Models (LLMs) generalize well across language tasks, but suffer from hallucinations and uninterpretability, making it difficult to assess their accuracy without ground-truth.""",2023-12-08T18:50:20Z
"Language Models, Agent Models, and World Models: The LAW for Machine Reasoning and Planning",Yes.,5.,"""Despite their tremendous success in many applications, large language models often fall short of consistent reasoning and planning in various (language, embodied, and social) scenarios, due to inherent limitations in their inference, learning, and modeling capabilities.""",2023-12-08T18:25:22Z
DeltaZip: Multi-Tenant Language Model Serving via Delta Compression,Yes.,2.,"""serving many different fine-tuned LLMs concurrently for users in multi-tenant environments is challenging.""",2023-12-08T18:07:05Z
HALO: An Ontology for Representing and Categorizing Hallucinations in Large Language Models,Yes.,5.,"""However, there is also a growing awareness that the models can be prone to problems such as making information up or `hallucinations', and faulty reasoning on seemingly simple problems.""",2023-12-08T17:57:20Z
DelucionQA: Detecting Hallucinations in Domain-specific Question Answering,Yes.,5.,"""Hallucination is a well-known phenomenon in text generated by large language models (LLMs). The existence of hallucinatory responses is found in almost all application scenarios e.g., summarization, question-answering (QA) etc. For applications requiring high reliability (e.g., customer-facing",2023-12-08T17:41:06Z
Assessing LLMs for Moral Value Pluralism,Yes.,4.,"""the fields of AI current lacks methods to quantitatively assess and potentially alter the moral values inherent in the output of large language models (LLMs)"" and ""we find that LLMs exhibit several Western-centric value biases; they overestimate how conservative people in non-Western countries are, they are less accurate in representing gender for non-Western countries, and portray older populations as having",2023-12-08T16:18:15Z
TypeFly: Flying Drones with Large Language Model,Yes.,5.,"""However, powerful LLMs and their vision counterparts are limited in three important ways. First, they are only available as cloud-based services. Sending images to the cloud raises privacy concerns. Second, they are expensive, costing proportionally to the request size. Finally, without expensive fine-tuning, existing LLMs",2023-12-08T15:57:18Z
LLM Interactive Optimization of Open Source Python Libraries -- Case Studies and Generalization,Yes.,3.,"""However, this is only the case in interactive use, with a human expert in the loop.""",2023-12-08T13:52:57Z
SparQ Attention: Bandwidth-Efficient LLM Inference,Yes.,3.,"""The computational difficulties of large language model (LLM) inference remain a significant obstacle to their widespread deployment.""",2023-12-08T11:47:35Z
Retrieval-based Video Language Model for Efficient Long Video Question Answering,Yes.,5.,"""However, employing LLMs for long video understanding presents significant challenges and remains under-explored. The extensive number of video tokens leads to considerable computational costs for LLMs while using aggregated tokens results in loss of vision details. Moreover, the presence of abundant question-irrelevant tokens introduces noise to the video QA process.""",2023-12-08T09:48:36Z
Exploring the Limits of ChatGPT in Software Security Applications,Yes.,5.,"""However, the impacts and limits of such LLMs in system security domain are less explored. In this paper, we delve into the limits of LLMs (i.e., ChatGPT) in seven software security applications... Also, certain limitations of ChatGPT in security-related tasks are identified, such as its constrained ability to process long code contexts.""",2023-12-08T03:02:37Z
DeceptPrompt: Exploiting LLM-driven Code Generation via Adversarial Natural Language Instructions,Yes.,5.,"""a dangerous nature is hidden in the code, which is the existence of fatal vulnerabilities,"" and ""shed light on the huge weakness of LLMs in the code generation task.""",2023-12-07T22:19:06Z
Purple Llama CyberSecEval: A Secure Coding Benchmark for Language Models,Yes.,4.,"""A significant observation from the study was the tendency of more advanced models to suggest insecure code, highlighting the critical need for integrating security considerations in the development of sophisticated LLMs.""",2023-12-07T22:07:54Z
Simul-LLM: A Framework for Exploring High-Quality Simultaneous Translation with Large Language Models,Yes.,3.,"""However, little research has focused on applying LLMs to the more difficult subset of NMT called simultaneous translation (SimulMT), where translation begins before the entire source context is available to the model.""",2023-12-07T20:42:05Z
Testing LLM performance on the Physics GRE: some observations,Yes.,2.,"""There is a need to evaluate these powerful language models on several benchmarks, in order to understand their risks and limitations.""",2023-12-07T17:33:12Z
Fortify the Shortest Stave in Attention: Enhancing Context Awareness of Large Language Models for Effective Tool Use,Yes.,5.,"""Specifically, the crucial information in the context will be potentially overlooked by model when it is positioned in the trough zone of the attention waveform, leading to decreased performance.""",2023-12-07T17:24:51Z
Prompt Highlighter: Interactive Control for Multi-Modal LLMs,Yes.,3.,"""Multi-modal LLMs empower multi-modality understanding with the capability of semantic generation yet bring less explainability and heavier reliance on prompt contents due to their autoregressive generative nature.""",2023-12-07T13:53:29Z
Hijacking Context in Large Multi-modal Models,Yes.,5.,"""we identify a new limitation of off-the-shelf LMMs where a small fraction of incoherent images or text descriptions mislead LMMs to only generate biased output about the hijacked context, not the originally intended context.""",2023-12-07T11:23:29Z
Analyzing the Inherent Response Tendency of LLMs: Real-World Instructions-Driven Jailbreak,Yes.,5.,"""However, LLMs still tend to generate harmful responses when faced with malicious instructions, a phenomenon referred to as 'Jailbreak Attack'.""",2023-12-07T08:29:58Z
Comparing Large Language Model AI and Human-Generated Coaching Messages for Behavioral Weight Loss,Yes.,3.,"""Participants appreciated AI's empathy and personalized suggestions but found them more formulaic, less authentic, and too data-focused.""",2023-12-07T05:45:24Z
Large Language Models for Intent-Driven Session Recommendations,Yes.,1.,"""Addressing these challenges, we introduce a novel ISR approach, utilizing the advanced reasoning capabilities of large language models (LLMs).""",2023-12-07T02:25:14Z
Cost-Effective In-Context Learning for Entity Resolution: A Design Space Exploration,Yes.,3.,"""existing ICL approaches to ER typically necessitate providing a task description and a set of demonstrations for each entity pair and thus have limitations on the monetary cost of interfacing LLMs.""",2023-12-07T02:09:27Z
Understanding (Un)Intended Memorization in Text-to-Image Generative Models,Yes.,3.,"""Historically, memorization in machine learning has been context-dependent, with diverse definitions emerging from classification tasks to complex models like Large Language Models (LLMs) and Diffusion models.""",2023-12-06T19:53:17Z
Empowering ChatGPT-Like Large-Scale Language Models with Local Knowledge Base for Industrial Prognostics and Health Management,Yes.,5.,"""Although ChatGPT-Like LLMs have rich knowledge reserves and powerful language understanding and generation capabilities, they lack domain-specific expertise, significantly limiting their practicability in PHM applications.""",2023-12-06T15:24:01Z
Think from Words(TFW): Initiating Human-Like Cognition in Large Language Models Through Think from Words for Japanese Text-level Classification,Yes.,3.,"""independent thinking by LLMs can introduce variability in their thought processes, leading to potential inaccuracies"" and ""offering insights into their potential to cause misinterpretations and errors in the overall comprehension of the final text.""",2023-12-06T12:34:46Z
SmoothQuant+: Accurate and Efficient 4-bit Post-Training WeightQuantization for LLM,Yes.,3.,"""However their huge model size and the consequent demand for computational and memory resources also pose challenges to model deployment.""",2023-12-06T11:10:55Z
Teaching Specific Scientific Knowledge into Large Language Models through Additional Training,Yes.,3.,"""the study highlights the complexities and limitations of incorporating specialized information into LLMs, suggesting areas for further improvement.""",2023-12-06T08:55:55Z
GPT vs Human for Scientific Reviews: A Dual Source Review on Applications of ChatGPT in Science,Yes.,5.,"""they lack the required deep understanding of complex methodologies, they have difficulty in evaluating innovative claims, and they are unable to assess ethical issues and conflicts of interest.""",2023-12-05T21:41:52Z
LLMs for Multi-Modal Knowledge Extraction and Analysis in Intelligence/Safety-Critical Applications,Yes.,5.,"""due to unresolved vulnerabilities and limitations, great care needs to be used before applying them to intelligence and safety-critical applications."" and ""The vulnerabilities are broken down into ten high-level categories and overlaid onto a high-level life cycle of an LLM.""",2023-12-05T19:04:50Z
Clinical Notes Reveal Physician Fatigue,Yes.,3.,"""Our model indicates that fatigued doctors write more predictable notes. Perhaps unsurprisingly, because word prediction is the core of how LLMs work, we find that LLM-written notes have 17% higher predicted fatigue than real physicians' notes. This indicates that LLMs may introduce distortions in generated text that are not yet fully understood.""",2023-12-05T19:00:18Z
Visual Program Distillation: Distilling Tools and Programmatic Reasoning into Vision-Language Models,Yes.,3.,"""generated programs are error-prone",2023-12-05T18:58:37Z
Rank-without-GPT: Building GPT-Independent Listwise Rerankers on Open-Source Large Language Models,Yes.,2.,"""current works in this direction all depend on the GPT models, making it a single point of failure in scientific reproducibility. Moreover, it raises the concern that the current research findings only hold for GPT models but not LLM in general.""",2023-12-05T18:57:40Z
Let the LLMs Talk: Simulating Human-to-Human Conversational QA via Zero-Shot LLM-to-LLM Interactions,Yes.,2.,"""To address this issue and investigate the applicability of large language models (LLMs) in CQA simulation,"" and ""understand the disparities between LLM- and human-generated conversations.""",2023-12-05T17:38:02Z
Inherent limitations of LLMs regarding spatial information,,,,2023-12-05T16:02:20Z
Weakly Supervised Detection of Hallucinations in LLM Activations,Yes.,4.,"""Our results confirm prior findings of BERT's limited internal capacity for encoding hallucinations, while OPT appears capable of encoding hallucination information internally.""",2023-12-05T14:35:11Z
How should the advent of large language models affect the practice of science?,Yes.,4.,"""Bender et al. argue that LLMs are often misused and over-hyped, and that their limitations warrant a focus on more specialized, easily interpretable tools.""",2023-12-05T10:45:12Z
"Building Trustworthy NeuroSymbolic AI Systems: Consistency, Reliability, Explainability, and Safety",Yes.,5.,"""Nevertheless, these models remain black boxes despite incorporating human feedback and instruction-guided tuning. For instance, ChatGPT can generate unsafe responses despite instituting safety guardrails.""",2023-12-05T06:13:55Z
Creative Agents: Empowering Agents with Imagination for Creative Tasks,Yes.,3.,"""This limitation comes from their inability to convert abstract language instructions into concrete task goals in the environment and perform long-horizon planning for such complicated goals.""",2023-12-05T06:00:52Z
E4SRec: An Elegant Effective Efficient Extensible Solution of Large Language Models for Sequential Recommendation,Yes.,5.,"""However, this approach necessitates items to possess rich semantic information, often generates out-of-range results, and suffers from notably low efficiency and limited extensibility. ... Nevertheless, the incapacity of LLMs to model IDs presents a formidable challenge when seeking to leverage LLMs for personalized recommendations.""",2023-12-05T02:50:18Z
Let's Think Outside the Box: Exploring Leap-of-Thought in Large Language Models with Creative Humor Generation,Yes.,5.,"""observe the insufficient LoT ability or failures of most existing LLMs on the Oogiri game.""",2023-12-05T02:41:57Z
MUFFIN: Curating Multi-Faceted Instructions for Improving Instruction-Following,Yes.,3.,"""LLMs under Scaling-Inputs tend to be overly sensitive to inputs, leading to misinterpretation or non-compliance with instructions. Conversely, Scaling Input-Free Tasks demands a substantial number of tasks but is less effective in instruction following when dealing with instances in Scaling-Inputs.""",2023-12-05T02:32:08Z
Decoding Data Quality via Synthetic Corruptions: Embedding-guided Pruning of Code Data,Yes.,3.,"""Code datasets, often collected from diverse and uncontrolled sources such as GitHub, potentially suffer from quality issues, thereby affecting the performance and training efficiency of Large Language Models (LLMs) optimized for code generation.""",2023-12-05T01:19:30Z
New Evaluation Metrics Capture Quality Degradation due to LLM Watermarking,Yes.,5.,"""Our experiments, conducted across various datasets, reveal that current watermarking methods are detectable by even simple classifiers, challenging the notion of watermarking subtlety. We also found, through the LLM judger, that watermarking impacts text quality, especially in degrading the coherence and depth of the response.""",2023-12-04T22:56:31Z
Competition-Level Problems are Effective LLM Evaluators,Yes.,5.,"""the challenges for any existing LLM to solve unseen complex reasoning problems"" and ""none of them is able to consistently mitigate the challenges.""",2023-12-04T18:58:57Z
TPPoet: Transformer-Based Persian Poem Generation using Minimal Data and Advanced Decoding Techniques,Yes.,3.,"""While LMs have exhibited exceptional performance across a wide range of natural language processing tasks, there are notable challenges associated with their utilization on small datasets and their ability to replicate more creative human capacities.""",2023-12-04T18:52:26Z
A Glitch in the Matrix? Locating and Detecting Language Model Grounding with Fakepedia,Yes.,3.,"""Yet the mechanisms underlying this contextual grounding remain unknown, especially in situations where contextual information contradicts factual knowledge stored in the parameters,"" and ""We benchmark various LLMs with Fakepedia and then we conduct a causal mediation analysis, based on our Masked Grouped Causal Tracing (MGCT), on LLM components when answering Fakepedia queries.""",2023-12-04T17:35:42Z
Know Your Audience: Do LLMs Adapt to Different Age and Education Levels?,Yes.,5.,"""Our results suggest LLM answers need to be better adapted to the intended audience demographics to be more comprehensible. They underline the importance of enhancing the adaptability of LLMs in education settings to cater to diverse age and education levels. Overall, current LLMs have set readability ranges and do",2023-12-04T17:19:53Z
Evaluating Dependencies in Fact Editing for Language Models: Specificity and Implication Awareness,Yes.,3.,"""Existing work on editing LLMs has partially addressed the issue of dependency,"" and ""Extensive experiments on DepEdit show that existing knowledge editing methods are sensitive to the surface form of knowledge, and that they have limited performance in inferring the implications of edited facts.""",2023-12-04T12:45:30Z
Intelligent Virtual Assistants with LLM-based Process Automation,Yes.,3.,"""applying LLMs to create more advanced virtual assistants still faces challenges like ensuring robust performance and handling variability in real-world user commands.""",2023-12-04T07:51:58Z
Mitigating Fine-Grained Hallucination by Fine-Tuning Large Vision-Language Models with Caption Rewrites,Yes.,5.,"""However, LVLMs may suffer from different types of object hallucinations. Nevertheless, LVLMs are evaluated for coarse-grained object hallucinations only (i.e., generated objects non-existent in the input image). The fine-grained object attributes and behaviors non-existent in the image may still be generated but not measured by the current evaluation methods.""",2023-12-04T07:43:02Z
"Explore, Select, Derive, and Recall: Augmenting LLM with Human-like Memory for Mobile Task Automation",Yes.,3.,"""However, due to the inherent unreliability and high operational cost of LLMs, their practical applicability is quite limited.""",2023-12-04T06:13:35Z
Expand BERT Representation with Visual Information via Grounded Language Learning with Multimodal Partial Alignment,Yes.,3.,"""Due to differences in the distribution and scale of visual-grounded datasets and language corpora, the language model tends to mix up the context of the tokens that occurred in the grounded data with those that do not. As a result, during representation learning, there is a mismatch",2023-12-04T03:16:48Z
Generating Action-conditioned Prompts for Open-vocabulary Video Action Recognition,Yes.,1.,"""we innovatively blend video models with Large Language Models (LLMs) to devise Action-conditioned Prompts.""",2023-12-04T02:31:38Z
Tackling Bias in Pre-trained Language Models: Current Trends and Under-represented Societies,Yes.,4.,"""However, introducing and using LLMs comes with biases and discrimination, resulting in concerns about equality, diversity and fairness, and must be addressed."" and ""This research presents a comprehensive survey synthesising the current trends and limitations in techniques used for identifying and mitigating bias in LLMs.""",2023-12-03T21:25:10Z
D-Bot: Database Diagnosis System using Large Language Models,,,,2023-12-03T16:58:10Z
TextGenSHAP: Scalable Post-hoc Explanations in Text Generation with Long Documents,Yes.,3.,"""there are major challenges in scaling up Shapley values for LLMs, particularly when dealing with long input contexts containing thousands of tokens and autoregressively generated output sequences.""",2023-12-03T04:35:04Z
Running cognitive evaluations on large language models: The do's and the don'ts,Yes.,4.,"""I describe common pitfalls that might arise when applying a cognitive test to an LLM"" and ""I conclude by discussing four areas where the do's and don'ts are currently under active discussion -- prompt sensitivity, cultural and linguistic diversity, using LLMs as research assistants, and running evaluations on open vs. closed LLMs.""",2023-12-03T04:28:19Z
Towards leveraging LLMs for Conditional QA,Yes.,5.,"""This study delves into the capabilities and limitations of Large Language Models (LLMs) in the challenging domain of conditional question-answering."" and ""these models encounter challenges in extractive question answering, where they lag behind the SOTA by over 10 points, and in mitigating the risk of injecting false information.""",2023-12-02T14:02:52Z
Large Language Models Are Zero-Shot Text Classifiers,Yes.,3.,"""text classification problems have garnered considerable focus, but still faced with some limitations related to expensive computational cost, time consumption, and robust performance to unseen classes.""",2023-12-02T06:33:23Z
Nash Learning from Human Feedback,Yes.,3.,"""an inherent limitation of current reward models is their inability to fully represent the richness of human preferences and their dependency on the sampling distribution.""",2023-12-01T19:26:23Z
Nonparametric Variational Regularisation of Pretrained Transformers,Yes.,4.,"""However, such large models are susceptible to overfitting to their training data, and as a result the models perform poorly when the domain changes."" and ""Also, due to the model's scale, the cost of fine-tuning the model to the new domain is large.""",2023-12-01T15:40:30Z
Questioning Biases in Case Judgment Summaries: Legal Datasets or Large Language Models?,Yes.,4.,"""a critical concern arises regarding the potential biases embedded within these summaries,"" and ""The study shows interesting evidences of biases in the outputs generated by the large language models and pre-trained abstractive summarization models.""",2023-12-01T13:00:45Z
LinguaLinked: A Distributed Large Language Model Inference System for Mobile Devices,Yes.,3.,"""Deploying Large Language Models (LLMs) locally on mobile devices presents a significant challenge due to their extensive memory requirements.""",2023-12-01T07:19:42Z
Sample Efficient Reinforcement Learning from Human Feedback via Active Exploration,Yes.,1.,"""A notable recent example arises in reinforcement learning from human feedback (RLHF) on large language models.""",2023-12-01T00:54:02Z
Towards Accurate Differential Diagnosis with Large Language Models,Yes.,1.,"""Interactive interfaces powered by Large Language Models (LLMs) present new opportunities to both assist and automate aspects of this process.""",2023-11-30T19:55:51Z
PoseGPT: Chatting about 3D Human Pose,Yes.,1.,"""PoseGPT addresses these limitations by embedding SMPL poses as a distinct signal token within a multi-modal LLM, enabling direct generation of 3D body poses from both textual and visual inputs.""",2023-11-30T18:59:52Z
Exposing Limitations of Language Model Agents in Sequential-Task Compositions on the Web,Yes.,5.,"""We show that while existing prompted LMAs (gpt-3.5-turbo or gpt-4) achieve 94.0% average success rate on base tasks, their performance degrades to 24.9% success rate on compositional tasks."" and ""their performance further degrades under different instruction compositions changing combinational order.""",2023-11-30T17:50:47Z
ArthModel: Enhance Arithmetic Skills to Large Language Model,Yes.,5.,"""However, the models have several limitations, such as toxicity and pool performance of arithmetic solving.""",2023-11-30T15:06:50Z
"FFT: Towards Harmlessness Evaluation and Analysis for LLMs with Factuality, Fairness, Toxicity",Yes.,5.,"""Experiments show that the harmlessness of LLMs is still under-satisfactory, and extensive analysis derives some insightful findings that could inspire future research for harmless LLM research.""",2023-11-30T14:18:47Z
OST: Refining Text Knowledge with Optimal Spatio-Temporal Descriptor for General Video Recognition,Yes.,3.,"""leading to less distinct semantic space and potential performance limitations"" and ""To address the limitations of the less distinct semantic space of category names, we prompt a large language model (LLM) to augment action class names into Spatio-Temporal Descriptors.""",2023-11-30T13:32:43Z
Evaluating the Rationale Understanding of Critical Reasoning in Logical Reading Comprehension,Yes.,5.,"""Experiments on our dataset show that recent large language models (e.g., InstructGPT) struggle to answer the subquestions even if they are able to answer the main questions correctly. We find that the models perform particularly poorly in answering subquestions written for the incorrect options of the main questions, implying that the models have a limited capability for explaining why incorrect alternatives should be eliminated.""",2023-11-30T08:44:55Z
mPLUG-PaperOwl: Scientific Diagram Analysis with the Multimodal Large Language Model,Yes.,3.,"""However, the weak diagram analysis abilities of LLMs or Multimodal LLMs greatly limit their application scenarios, especially for scientific academic paper writing.""",2023-11-30T04:43:26Z
Large Language Models for Travel Behavior Prediction,Yes.,3.,"""However, though in most of the cases, the output explanations are reasonable, we still observe cases that violate logic or with hallucinations.""",2023-11-30T04:35:55Z
Automatic Construction of a Korean Toxic Instruction Dataset for Ethical Tuning of Large Language Models,Yes.,3.,"""The advent of Large Language Models (LLMs) necessitates the development of training approaches that mitigate the generation of unethical language and aptly manage toxic user queries.""",2023-11-30T03:19:45Z
Positional Information Matters for Invariant In-Context Learning: A Case Study of Simple Function Classes,Yes.,5.,"""Despite the impressive ICL ability of LLMs, it has also been found that ICL in LLMs is sensitive to input demonstrations and limited to short context lengths.""",2023-11-30T02:26:55Z
Zero-shot Conversational Summarization Evaluations with small Large Language Models,Yes.,5.,"""We show that the summaries generated by models depend on the instructions and the performance of LLMs vary with different instructions sometimes resulting steep drop in ROUGE scores if prompts are not selected carefully."" and ""We also evaluate the models with human evaluations and discuss the limitations of the models on conversational summarization",2023-11-29T19:34:34Z
OPERA: Alleviating Hallucination in Multi-Modal Large Language Models via Over-Trust Penalty and Retrospection-Allocation,Yes.,5.,"""Hallucination, posed as a pervasive challenge of multi-modal large language models (MLLMs), has significantly impeded their real-world usage that demands precise judgment.""",2023-11-29T18:57:07Z
MM-SafetyBench: A Benchmark for Safety Evaluation of Multimodal Large Language Models,Yes.,5.,"""we observe that Multimodal Large Language Models (MLLMs) can be easily compromised by query-relevant images"" and ""Our analysis across 12 state-of-the-art models reveals that MLLMs are susceptible to breaches instigated by our approach, even when the equipped LLMs have been safety-aligned.""",2023-11-29T12:49:45Z
TaskWeaver: A Code-First Agent Framework,Yes.,3.,"""However, existing LLM frameworks face limitations in handling domain-specific data analytics tasks with rich data structures. Moreover, they struggle with flexibility to meet diverse user requirements.""",2023-11-29T11:23:42Z
LLM-State: Expandable State Representation for Long-horizon Task Planning in the Open World,Yes.,3.,"""Existing works fail to explicitly track key objects and attributes, leading to erroneous decisions in long-horizon tasks, or rely on highly engineered state features and feedback, which is not generalizable.""",2023-11-29T07:23:22Z
Improving the Robustness of Transformer-based Large Language Models with Dynamic Attention,Yes.,3.,"""recent studies show their vulnerability to textual adversarial attacks where the model's output can be misled by intentionally manipulating the text inputs.""",2023-11-29T07:09:13Z
Unveiling the Implicit Toxicity in Large Language Models,Yes.,5.,"""LLMs can generate diverse implicit toxic outputs that are exceptionally difficult to detect via simply zero-shot prompting."" and ""LLMs pose a significant threat in generating undetectable implicit toxic outputs.""",2023-11-29T06:42:36Z
Are Large Language Models Good Fact Checkers: A Preliminary Study,Yes.,5.,"""However, they encounter challenges in effectively handling Chinese fact verification and the entirety of the fact-checking pipeline due to language inconsistencies and hallucinations.""",2023-11-29T05:04:52Z
Exploring Large Language Models for Human Mobility Prediction under Public Events,Yes.,3.,"""Despite the great potential of LLMs, we also identify key challenges including misinformation and high costs that remain barriers to their broader adoption in large-scale human mobility analysis.""",2023-11-29T04:25:15Z
Contrastive Vision-Language Alignment Makes Efficient Instruction Learner,Yes.,3.,"""This task is crucial but challenging since the LLM is trained on text modality only, making it hard to effectively digest the visual modality.""",2023-11-29T03:29:46Z
Elo Uncovered: Robustness and Best Practices in Language Model Evaluation,Yes.,5.,"""We show that these axioms are not always satisfied raising questions about the reliability of current comparative evaluations of LLMs.""",2023-11-29T00:45:23Z
War and Peace (WarAgent): Large Language Model-based Multi-Agent Simulation of World Wars,Yes.,2.,"""By evaluating the simulation effectiveness, we examine the advancements and limitations of cutting-edge AI systems' abilities in studying complex collective human behaviors such as international conflicts under diverse settings.""",2023-11-28T20:59:49Z
Scalable Extraction of Training Data from (Production) Language Models,Yes.,5.,"""Our methods show practical attacks can recover far more data than previously thought, and reveal that current alignment techniques do not eliminate memorization.""",2023-11-28T18:47:03Z
Beyond Hallucinations: Enhancing LVLMs through Hallucination-Aware Direct Preference Optimization,Yes.,5.,"""they still suffer from a common issue known as the 'hallucination problem', in which the models generate textual descriptions that inaccurately depict or entirely fabricate content from associated images.""",2023-11-28T14:54:37Z
Reason out Your Layout: Evoking the Layout Master from Large Language Models for Text-to-Image Synthesis,Yes.,1.,"""In this work, we introduce a novel approach to improving T2I diffusion models using Large Language Models (LLMs) as layout generators.""",2023-11-28T14:51:13Z
Large Language Models Suffer From Their Own Output: An Analysis of the Self-Consuming Training Loop,Yes.,5.,"""We find that this self-consuming training loop initially improves both quality and diversity. However, after a few generations the output inevitably degenerates in diversity.""",2023-11-28T14:36:43Z
A Survey of the Evolution of Language Model-Based Dialogue Systems,Yes.,2.,"""we focus on emerging topics and discuss open challenges, providing valuable insights into future directions for LLM-based_dialogue_systems.""",2023-11-28T13:51:32Z
Embodied Multi-Modal Agent trained by an LLM from a Parallel TextWorld,Yes.,3.,"""While large language models (LLMs) excel in a simulated world of texts, they struggle to interact with the more realistic world without perceptions of other modalities such as visual or audio signals.""",2023-11-28T11:53:56Z
ClimateX: Do LLMs Accurately Assess Human Expert Confidence in Climate Statements?,Yes.,5.,"""Overall, models exhibit consistent and significant over-confidence on low and medium confidence statements.""",2023-11-28T10:26:57Z
SEED-Bench-2: Benchmarking Multimodal Large Language Models,Yes.,5.,"""By revealing the limitations of existing MLLMs through extensive evaluations, we aim for SEED-Bench-2 to provide insights that will motivate future research towards the goal of General Artificial Intelligence.""",2023-11-28T05:53:55Z
Methods to Estimate Large Language Model Confidence,Yes.,5.,"""Large Language Models have difficulty communicating uncertainty, which is a significant obstacle to applying LLMs to complex medical tasks."" and ""We conclude GPT4 has a limited ability to assess its own diagnostic accuracy.""",2023-11-28T05:44:06Z
A Rank Stabilization Scaling Factor for Fine-Tuning with LoRA,Yes.,3.,"""This scaling factor, which divides adapters by a factor of the rank, results in slowed learning and stunted performance for LoRA with higher-rank adapters. Consequently, the use of LoRA in practice has generally been limited to very low ranks.""",2023-11-28T03:23:20Z
Enabling Fast 2-bit LLM on GPUs: Memory Alignment and Asynchronous Dequantization,Yes.,4.,"""Nonnegligible accuracy loss for 2-bit quantization. Weights are quantized by groups, while the ranges of weights are large in some groups, resulting in large quantization errors and nonnegligible accuracy loss (e.g. >3% for Llama2-7b with 2-bit quantization in GPTQ and Greenbit)."" and ""Time-consuming",2023-11-28T02:44:59Z
Removing NSFW Concepts from Vision-and-Language Models for Text-to-Image Retrieval and Generation,Yes.,4.,"""However, these models are typically trained on web-scale data, which can introduce inappropriate content and lead to the development of unsafe and biased behavior. This, in turn, hampers their applicability in sensitive and trustworthy contexts and could raise significant concern in their adoption.""",2023-11-27T19:02:17Z
Visual cognition in multimodal large language models,Yes.,5.,"""Researchers have asserted these models' limitations in the domains of causal reasoning, intuitive physics, and intuitive psychology."" and ""Our findings reveal that, while these models demonstrate a notable proficiency in processing and interpreting visual data, they still fall short of human capabilities in these areas."" and ""Furthermore, in tasks requiring an intuitive theory of mind, the models fail altogether.""",2023-11-27T18:58:34Z
Self-correcting LLM-controlled Diffusion Models,Yes.,3.,"""current text-to-image diffusion models still often struggle to accurately interpret and follow complex input text prompts.""",2023-11-27T18:56:37Z
BERT Goes Off-Topic: Investigating the Domain Transfer Challenge using Genre Classification,Yes.,5.,"""they still suffer from a performance gap when the underlying distribution of topics changes"" and ""domain transfer remains challenging both for classic PLMs, such as BERT, and for modern large models, such as GPT-3.""",2023-11-27T18:53:31Z
MEDITRON-70B: Scaling Medical Pretraining for Large Language Models,Yes.,2.,"""the resulting models are either closed-source (e.g., PaLM, GPT-4) or limited in scale (<= 13B parameters), which restricts their abilities.""",2023-11-27T18:49:43Z
Decoding Logic Errors: A Comparative Study on Bug Detection by Students and Large Language Models,Yes.,3.,"""logic errors relate to the runtime performance of code and thus may not be as well suited to analysis by LLMs.""",2023-11-27T17:28:33Z
WorldSense: A Synthetic Benchmark for Grounded Reasoning in Large Language Models,Yes.,5.,"""We run our benchmark on three state-of-the-art chat-LLMs (GPT3.5, GPT4 and Llama2-chat) and show that these models make errors even with as few as three objects. Furthermore, they have quite heavy response biases, preferring certain responses irrespective of the question. Errors persist even with chain-of-thought prompting and in-context learning. Lastly",2023-11-27T15:38:17Z
vTrain: A Simulation Framework for Evaluating Cost-effective and Compute-optimal Large Language Model Training,Yes.,3.,"""Existing LLM training plans typically employ a heuristic based parallel training strategy which is based on empirical observations rather than grounded upon a thorough examination of the search space of LLM parallelization. Such limitation renders existing systems to leave significant performance left on the table, wasting millions of dollars worth of training cost.""",2023-11-27T13:35:15Z
"Knowledge Unlearning for LLMs: Tasks, Methods, and Challenges",Yes.,4.,"""Despite their excellent capability in knowledge-based question answering and reasoning, their potential to retain faulty or even harmful knowledge poses risks of malicious application."" and ""The challenge of mitigating this issue and transforming these models into purer assistants is crucial for their widespread applicability.""",2023-11-27T12:37:51Z
Justifiable Artificial Intelligence: Engineering Large Language Models for Legal Applications,Yes.,5.,"""Despite their large success and acceptance, their lack of explainability hinders legal experts to trust in their output, and this happens rightfully so.""",2023-11-27T10:59:16Z
RoboGPT: an intelligent agent of making embodied long-term decisions for daily instruction tasks,Yes.,3.,"""Despite LLMs' great generalization and comprehension of instruction tasks, LLMs-generated task plans sometimes lack feasibility and correctness.""",2023-11-27T09:20:23Z
Pre-trained Language Models Do Not Help Auto-regressive Text-to-Image Generation,Yes.,5.,"""we explore this gap by adapting a pre-trained language model for auto-regressive text-to-image generation, and find that pre-trained language models offer limited help"" and ""the text tokens in the image-text datasets are too simple compared to normal language model pre-training data, which causes the catastrophic degradation",2023-11-27T07:19:26Z
SpotServe: Serving Generative Large Language Models on Preemptible Instances,Yes.,2.,"""The high computational and memory requirements of generative large language models (LLMs) make it challenging to serve them cheaply.""",2023-11-27T06:31:17Z
Deficiency of Large Language Models in Finance: An Empirical Examination of Hallucination,Yes.,5.,"""The hallucination issue is recognized as a fundamental deficiency of large language models (LLMs),"" and ""our major finding is that off-the-shelf LLMs experience serious hallucination behaviors in financial tasks.""",2023-11-27T05:27:13Z
Function-constrained Program Synthesis,Yes.,3.,"""Generating computer programs in general-purpose programming languages like Python poses a challenge for LLMs when instructed to use code provided in the prompt."" and ""Moreover, current systems lack effective recovery methods, forcing users to iteratively re-prompt the model with modified prompts until a sufficient solution is reached.""",2023-11-27T02:55:34Z
DP-OPT: Make Large Language Model Your Privacy-Preserving Prompt Engineer,Yes.,3.,"""Nevertheless, concerns surrounding data privacy present obstacles due to the tuned prompts' dependency on sensitive private information."" and ""Alternative methods, like sending data to the model's provider for training, intensify these privacy issues facing an untrusted provider.""",2023-11-27T02:01:10Z
Machine-Generated Text Detection using Deep Learning,,,,2023-11-26T21:16:01Z
KOPPA: Improving Prompt-based Continual Learning with Key-Query Orthogonal Projection and Prototype-based One-Versus-All,Yes.,2.,"""However, they may encounter limitations when lacking control over the correlations between old task queries and keys of future tasks, the shift of features in the latent space, and the relative separation of latent vectors learned in independent tasks.""",2023-11-26T20:35:19Z
UHGEval: Benchmarking the Hallucination of Chinese Large Language Models via Unconstrained Generation,Yes.,5.,"""These models often produce hallucinated text, compromising their practical utility in professional contexts.""",2023-11-26T13:42:56Z
"Negotiating with LLMS: Prompt Hacks, Skill Gaps, and Reasoning Deficits",Yes.,5.,"""Furthermore, we highlight shortcomings of LLMs with respect to their reasoning capabilities and, in turn, susceptiveness to prompt hacking, which intends to manipulate the LLM to make agreements that are against its instructions or beyond any rationality.""",2023-11-26T08:44:58Z
Benchmarking Large Language Model Volatility,Yes.,5.,"""we uncover substantial variability in sentence-level sentiment classification results, underscoring the innate volatility of LLM outputs"" and ""These uncertainties cascade downstream, leading to more significant variations in portfolio construction and return.""",2023-11-26T03:54:03Z
Large Language Models in Law: A Survey,Yes.,5.,"""In addition, we explore the limitations of legal LLMs, including data, algorithms, and judicial practice.""",2023-11-26T00:48:12Z
Walking a Tightrope -- Evaluating Large Language Models in High-Risk Domains,Yes.,5.,"""Further qualitative analysis highlights the existing limitations inherent in current LLMs when evaluating in high-risk domains.""",2023-11-25T08:58:07Z
AutoEval-Video: An Automatic Benchmark for Assessing Large Vision Language Models in Open-Ended Video Question Answering,Yes.,5.,"""By conducting an extensive case study, we uncover several drawbacks of GPT-4V, such as limited temporal and dynamic comprehension, and overly general responses.""",2023-11-25T02:46:12Z
Gender inference: can chatGPT outperform common commercial tools?,Yes.,2.,"""An important limitation of these tools is that they fail to appropriately capture the fact that gender exists on a non-binary scale"" and ""In the future, it might even be possible for ChatGPT or other large scale language models to better identify self-reported gender rather than report gender on a binary scale.""",2023-11-24T22:09:14Z
One Pass Streaming Algorithm for Super Long Token Attention Approximation in Sublinear Space,Yes.,5.,"""Attention computation takes both the time complexity of $O(n^2)$ and the space complexity of $O(n^2)$ simultaneously, which makes deploying Large Language Models (LLMs) in streaming applications that involve long contexts requiring substantial computational resources.""",2023-11-24T18:35:00Z
Large Language Models as Automated Aligners for benchmarking Vision-Language Models,Yes.,2.,"""existing evaluation benchmarks, primarily relying on rigid, hand-crafted datasets to measure task-specific performance, face significant limitations in assessing the alignment of these increasingly anthropomorphic models with human intelligence.""",2023-11-24T16:12:05Z
Data-Efficient Alignment of Large Language Models with Human Feedback Through Natural Language,Yes.,2.,"""human preference on LLM outputs can come in much richer forms including natural language, which may provide detailed feedback on strengths and weaknesses of a given response.""",2023-11-24T15:20:36Z
Machine Translation for Ge'ez Language,Yes.,3.,"""We also attempt to finetune the NLLB-200 model, one of the most advanced translation models available today, but find that it performs poorly with only 4k training samples for Ge'ez."" and ""We observe that GPT-3.5 achieves a remarkable BLEU score of 9.2 with no initial knowledge of Ge'ez, but still lower",2023-11-24T14:55:23Z
Potential Societal Biases of ChatGPT in Higher Education: A Scoping Review,Yes.,4.,"""ChatGPT and other Generative Artificial Intelligence (GAI) models tend to inherit and even amplify prevailing societal biases as they are trained on large amounts of existing data."" and ""Our findings show that while there is an awareness of potential biases around large language models (LLMs) and",2023-11-24T10:00:23Z
Towards Auditing Large Language Models: Improving Text-based Stereotype Detection,Yes.,4.,"""LLMs often generate stereotypical output inherited from historical data, amplifying societal biases and raising ethical concerns.""",2023-11-23T17:47:14Z
Auditing and Mitigating Cultural Bias in LLMs,Yes.,5.,"""We audit large language models for cultural bias,"" and ""Our mitigation strategy reduces cultural bias in recent models but not for all countries/territories.""",2023-11-23T16:45:56Z
PrivateLoRA For Efficient Privacy Preserving LLM,Yes.,2.,"""End users face a choice between privacy and efficiency in current Large Language Model (LLM) service paradigms.""",2023-11-23T14:36:30Z
Probabilistic Tree-of-thought Reasoning for Answering Knowledge-intensive Complex Questions,Yes.,5.,"""However, they tend to generate factually incorrect reasoning steps when the required knowledge is not available or up-to-date in models' parameters. Recent works turn to retrieving external knowledge to augment CoT reasoning. Despite being promising, these chain-based methods suffer from",2023-11-23T12:52:37Z
Dialogue Quality and Emotion Annotations for Customer Support Conversations,Yes.,3.,"""However, with the advent of Large Language Models (LLMs) pretrained on extensive, multilingual and diverse text data, these limitations seem overcome. Nevertheless, their generalisability to different languages and domains in dialogue applications remains uncertain without benchmarking datasets.""",2023-11-23T10:56:14Z
Controlling Large Language Model-based Agents for Large-Scale Decision-Making: An Actor-Critic Approach,Yes.,5.,"""However, as the number of agents increases, the issues of hallucination in LLMs and coordination in MAS have become increasingly prominent.""",2023-11-23T10:14:58Z
Compositional Zero-shot Learning via Progressive Language-based Observations,Yes.,1.,"""PLO-LLM",2023-11-23T10:14:23Z
Challenges of Large Language Models for Mental Health Counseling,Yes.,5.,"""However, the application of LLMs in the mental health domain raises concerns regarding the accuracy, effectiveness, and reliability of the information provided. This paper investigates the major challenges associated with the development of LLMs for psychological counseling, including model hallucination, interpretability, bias, privacy, and clinical effectiveness.""",2023-11-23T08:56:41Z
Lego: Learning to Disentangle and Invert Concepts Beyond Object Appearance in Text-to-Image Diffusion Models,Yes.,3.,"""visual question answering using a large language model suggested Lego-generated concepts are better aligned with the text description of the concept."" and ""Two key characteristics of these concepts contribute to the limitations of current inversion methods.""",2023-11-23T07:33:38Z
Surpassing GPT-4 Medical Coding with a Two-Stage Approach,Yes.,5.,"""the GPT-4 LLM predicts an excessive number of ICD codes for medical coding tasks, leading to high recall but low precision.""",2023-11-22T23:35:13Z
Drilling Down into the Discourse Structure with LLMs for Long Document Question Answering,Yes.,5.,"""currently the LLMs can consume limited context lengths as input, thus providing document chunks as inputs might overlook the global context while missing out on capturing the inter-segment dependencies. Moreover, directly feeding the large input sets can incur significant computational costs, particularly when processing the entire document (and potentially incurring monetary expenses with enterprise APIs like OpenAI's GPT variants).""",2023-11-22T18:22:56Z
Soulstyler: Using Large Language Model to Guide Image Style Transfer for Target Object,,,,2023-11-22T18:15:43Z
Transfer Attacks and Defenses for Large Language Models on Coding Tasks,,,,2023-11-22T15:11:35Z
Large Language Model as a Policy Teacher for Training Reinforcement Learning Agents,Yes.,4.,"""However, LLM-based agents lack specialization in tackling specific target problems, particularly in real-time dynamic environments. Additionally, deploying an LLM-based agent in practical scenarios can be both costly and time-consuming.""",2023-11-22T13:15:42Z
Applying Large Language Models to Power Systems: Potential Security Threats,Yes.,5.,"""However, this action may also incur potential security threats, which have not been fully recognized so far.""",2023-11-22T12:55:02Z
Mitigating Large Language Model Hallucinations via Autonomous Knowledge Graph-based Retrofitting,Yes.,5.,"""Existing methods usually only use the user's input to query the knowledge graph, thus failing to address the factual hallucination generated by LLMs during its reasoning process.""",2023-11-22T11:08:38Z
Intention and Context Elicitation with Large Language Models in the Legal Aid Intake Process,Yes.,4.,"""a key challenge with current LLMs is their tendency to overconfidently deliver an immediate 'best guess' to a client's question based on the output distribution learned over the training data. This approach often overlooks the client's actual intentions or the specifics of their legal situation.""",2023-11-22T10:04:29Z
AutoKG: Efficient Automated Knowledge Graph Generation for Language Models,Yes.,3.,"""Traditional methods of linking large language models (LLMs) to knowledge bases via the semantic similarity search often fall short of capturing complex relational dynamics.""",2023-11-22T08:58:25Z
Enhancing Uncertainty-Based Hallucination Detection with Stronger Focus,Yes.,5.,"""LLMs are prone to hallucinate untruthful or nonsensical outputs that fail to meet user expectations in many real-world applications.""",2023-11-22T08:39:17Z
Large Language Models in Education: Vision and Opportunities,Yes.,3.,"""while still facing technical, ethical, and practical challenges requiring further research and exploration.""",2023-11-22T05:04:20Z
HalluciDoctor: Mitigating Hallucinatory Toxicity in Visual Instruction Data,Yes.,5.,"""the hallucinations inherent in machine-generated data, which could lead to hallucinatory outputs in MLLMs, remain under-explored.""",2023-11-22T04:52:58Z
Conditions for Length Generalization in Learning Reasoning Skills,Yes.,5.,"""However, numerous evaluations of the reasoning capabilities of LLMs have also showed some limitations. An outstanding limitation is length generalization, meaning that when trained on reasoning problems of smaller lengths or sizes, the resulting models struggle with problems of larger sizes or lengths.""",2023-11-22T03:36:18Z
Towards Better Parameter-Efficient Fine-Tuning for Large Language Models: A Position Paper,Yes.,4.,"""While LLMs possess remarkable capabilities, their extensive parameter requirements and associated computational demands hinder their practicality and scalability for real-world applications."" and ""recognizes significant challenges and open issues that must be addressed to fully harness the powerful abilities of LLMs.""",2023-11-22T03:28:34Z
Enhancing Logical Reasoning in Large Language Models to Facilitate Legal Applications,Yes.,4.,"""Large Language Models (LLMs) attempt to emulate human language understanding and generation, but their competency in logical reasoning remains limited.""",2023-11-22T01:51:50Z
A Baseline Analysis of Reward Models' Ability To Accurately Analyze Foundation Models Under Distribution Shift,Yes.,4.,"""However, there is little work measuring how robust these reward models are to distribution shifts."" and ""We show novel calibration patterns and accuracy drops due to OOD prompts and responses, and that the reward model is more sensitive to shifts in responses than prompts.""",2023-11-21T18:41:26Z
Keeping Users Engaged During Repeated Administration of the Same Questionnaire: Using Large Language Models to Reliably Diversify Questions,Yes.,1.,"""We propose utilizing large language models (LLMs) to generate diverse questionnaire versions while retaining good psychometric properties.""",2023-11-21T16:20:49Z
Can Large Language Models Understand Content and Propagation for Misinformation Detection: An Empirical Study,Yes.,3.,"""LLMs with diverse prompts achieve comparable performance in text-based misinformation detection but exhibit notably constrained capabilities in comprehending propagation structure compared to existing models in propagation-based misinformation detection.""",2023-11-21T16:03:51Z
HierSpeech++: Bridging the Gap between Semantic and Acoustic Representation of Speech by Hierarchical Variational Inference for Zero-shot Speech Synthesis,Yes.,3.,"""they require a large-scale data and possess the same limitations as previous autoregressive speech models, including slow inference speed and lack of robustness.""",2023-11-21T09:07:11Z
Advancing Transformer Architecture in Long-Context Large Language Models: A Comprehensive Survey,Yes.,5.,"""current LLMs are predominantly pretrained on short text snippets, which compromises their effectiveness in processing the long-context prompts that are frequently encountered in practical scenarios."" and ""We first delineate and analyze the problems of handling long-context input and output with the current Transformer-based models.""",2023-11-21T04:59:17Z
"Adapting LLMs for Efficient, Personalized Information Retrieval: Methods and Implications",Yes.,4.,"""A notable challenge, model hallucination-where the model yields inaccurate or misinterpreted data-is addressed alongside other model-specific hurdles.""",2023-11-21T02:01:01Z
Enabling On-Device Large Language Model Personalization with Self-Supervised Data Selection and Synthesis,Yes.,3.,"""user-generated data usually contains sensitive and private information,"" and ""the storage of edge devices is usually too limited to enable large-scale fine-tuning with full user-generated data.""",2023-11-21T01:34:02Z
On the Potential and Limitations of Few-Shot In-Context Learning to Generate Metamorphic Specifications for Tax Preparation Software,Yes.,3.,"""We perform a systematic analysis on the potential and limitations of in-context learning with Large Language Models(LLMs) for this task.""",2023-11-20T18:12:28Z
FinanceBench: A New Benchmark for Financial Question Answering,,,,2023-11-20T17:28:02Z
LLMs as Visual Explainers: Advancing Image Classification with Evolving Visual Descriptions,Yes.,3.,"""their outputs often suffer from ambiguity and inaccuracy. We attribute this to two primary factors",2023-11-20T16:37:45Z
Evil Geniuses: Delving into the Safety of LLM-based Agents,Yes.,4.,"""Extensive evaluation and discussion reveal that these agents are less robust, prone to more harmful behaviors, and capable of generating stealthier content than LLMs, highlighting significant safety challenges and guiding future research.""",2023-11-20T15:50:09Z
System 2 Attention (is something you might need too),Yes.,5.,"""Soft attention in Transformer-based Large Language Models (LLMs) is susceptible to incorporating irrelevant information from the context into its latent representations, which adversely affects next token generations.""",2023-11-20T15:04:50Z
Towards Robust Text Retrieval with Progressive Learning,Yes.,4.,"""Retrieval augmentation has become an effective solution to empower large language models (LLMs) with external and verified knowledge sources from the database, which overcomes the limitations and hallucinations of LLMs in handling up-to-date and domain-specific information.""",2023-11-20T11:44:01Z
Refactoring Programs Using Large Language Models with Few-Shot Examples,Yes.,2.,"""unnecessary behaviors such as deleting or translating comments are also observed.""",2023-11-20T11:43:45Z
Incorporating LLM Priors into Tabular Learners,Yes.,3.,"""addressing LLMs challenges like data serialization sensitivity and biases.""",2023-11-20T09:27:09Z
Adapt in Contexts: Retrieval-Augmented Domain Adaptation via In-Context Learning,Yes.,3.,"""However, in-domain demonstrations are not always readily available in real scenarios, leading to cross-domain in-context learning. Besides, LLMs are still facing challenges in long-tail knowledge in unseen and unfamiliar domains.""",2023-11-20T06:06:20Z
Token-Level Adversarial Prompt Detection Based on Perplexity Measures and Contextual Information,Yes.,5.,"""these models are susceptible to adversarial prompt attacks,"" and ""this vulnerability to adversarial prompts underscores a significant concern regarding the robustness and reliability of LLMs.""",2023-11-20T03:17:21Z
A Security Risk Taxonomy for Large Language Models,Yes.,5.,"""The potential for exploitation by malicious actors, ranging from disinformation to data breaches and reputation damage, is substantial."" and ""Our work proposes a taxonomy of security risks along the user-model communication pipeline, explicitly focusing on prompt-based attacks on LLMs.""",2023-11-19T20:22:05Z
Zero-Shot Question Answering over Financial Documents using Large Language Models,Yes.,3.,"""While LLMs have exhibited remarkable performance on various natural language and reasoning tasks, complex reasoning problems often rely on few-shot prompts that require carefully crafted examples."" and ""mitigating the limitations of LLM in performing accurate arithmetic calculations.""",2023-11-19T16:23:34Z
TPTU-v2: Boosting Task Planning and Tool Usage of Large Language Model-based Agents in Real-world Systems,,,,2023-11-19T12:37:30Z
Rethinking Large Language Models in Mental Health Applications,Yes.,5.,"""It discusses the instability of generative models for prediction and the potential for generating hallucinatory outputs, underscoring the need for ongoing audits and evaluations to maintain their reliability and dependability.""",2023-11-19T08:40:01Z
Leveraging Generative AI for Clinical Evidence Summarization Needs to Ensure Trustworthiness,Yes.,3.,"""Recent advancements in generative AI, exemplified by large language models, hold promise in facilitating the arduous task. However, developing accountable, fair, and inclusive models remains a complicated undertaking.""",2023-11-19T03:29:45Z
Few-Shot Classification & Segmentation Using Large Language Models Agent,Yes.,1.,"""We introduce a method that utilises large language models (LLM) as an agent to address the FS-CS problem in a training-free manner.""",2023-11-19T00:33:41Z
Visual AI and Linguistic Intelligence Through Steerability and Composability,Yes.,5.,"""The research presents a series of 14 creatively and constructively diverse tasks, ranging from AI Lego Designing to AI Satellite Image Analysis, designed to test the limits of current LLMs in contexts that previously proved difficult without extensive memory and contextual understanding."" and ""Tasks such as 'AI Genetic Programmer'",2023-11-18T22:01:33Z
A Principled Framework for Knowledge-enhanced Large Language Model,Yes.,5.,"""Large Language Models (LLMs) are versatile, yet they often falter in tasks requiring deep and reliable reasoning due to issues like hallucinations, limiting their applicability in critical scenarios.""",2023-11-18T18:10:02Z
(Why) Is My Prompt Getting Worse? Rethinking Regression Testing for Evolving LLM APIs,Yes.,5.,"""LLM APIs are often updated silently and scheduled to be deprecated, forcing users to continuously adapt to evolving models. This can cause performance regression and affect prompt design choices,"" and ""regression testing LLMs requires fundamental changes to traditional testing approaches, due to different correctness notions, prompting brittleness, and non-determinism in LLM APIs.""",2023-11-18T17:11:12Z
Journey of Hallucination-minimized Generative AI Solutions for Financial Decision Makers,Yes.,5.,"""One major limitation of the currently evolving family of LLMs is 'hallucinations', wherein inaccurate responses are reported as factual. Hallucinations are primarily caused by biased training data, ambiguous prompts and inaccurate LLM parameters, and they majorly occur while combining mathematical facts with language-based context.""",2023-11-18T03:55:59Z
An Embodied Generalist Agent in 3D World,Yes.,3.,"""However, a significant challenge remains as these models exhibit limited ability in understanding and interacting with the 3D world.""",2023-11-18T01:21:38Z
Distilling and Retrieving Generalizable Knowledge for Robot Manipulation via Language Corrections,Yes.,1.,"""a large language model (LLM)-based system that can respond to arbitrary forms of language feedback, distill generalizable knowledge from corrections, and retrieve relevant past experiences based on textual and visual similarity for improving performance in novel settings.""",2023-11-17T18:00:20Z
A Self-enhancement Approach for Domain-specific Chatbot Training via Knowledge Mining and Digest,Yes.,3.,"""Large Language Models (LLMs), despite their great power in language generation, often encounter challenges when dealing with intricate and knowledge-demanding queries in specific domains.""",2023-11-17T16:09:10Z
TaCo: Enhancing Cross-Lingual Transfer for Low-Resource Languages in LLMs through Translation-Assisted Chain-of-Thought Processes,Yes.,3.,"""Creating multilingual LLMs poses a significant challenge. Pretraining or fine-tuning LLMs to adopt new languages is evidently very costly. Furthermore, there exist limitations concerning benchmark datasets and the metrics used to measure model performance in multilingual settings.""",2023-11-17T06:55:32Z
DRESS: Instructing Large Vision-Language Models to Align and Interact with Humans via Natural Language Feedback,Yes.,5.,"""First, prior LVLMs generally rely only on the instruction finetuning stage to enhance alignment with human preferences. Without incorporating extra feedback, they are still prone to generate unhelpful, hallucinated, or harmful responses. Second, while the visual instruction",2023-11-16T18:37:29Z
"ChatGPT-3.5, ChatGPT-4, Google Bard, and Microsoft Bing to Improve Health Literacy and Communication in Pediatric Populations and Beyond",Yes.,3.,"""LLMs face challenges in crafting outputs below a sixth-grade reading level.""",2023-11-16T18:30:14Z
Hijacking Large Language Models via Adversarial In-Context Learning,Yes.,5.,"""ICL suffers from instability with the choice and arrangement of examples. Additionally, crafted adversarial attacks pose a notable threat to the robustness of ICL.""",2023-11-16T15:01:48Z
"Which Modality should I use -- Text, Motif, or Image? : Understanding Graphs with Large Language Models",Yes.,5.,"""despite their advancements in various fields using large text corpora, face limitations in encoding entire graphs due to context size constraints."" and ""outlines the existing challenges and potential future developments for LLMs in graph understanding and reasoning tasks.""",2023-11-16T12:45:41Z
Leveraging LLMs in Scholarly Knowledge Graph Question Answering,Yes.,1.,"""This paper presents a scholarly Knowledge Graph Question Answering (KGQA) that answers bibliographic natural language questions by leveraging a large language model (LLM) in a few-shot manner.""",2023-11-16T12:13:49Z
ML-Bench: Large Language Models Leverage Open-source Libraries for Machine Learning Tasks,Yes.,5.,"""a considerable divide exists between these benchmark achievements and their practical applicability, primarily attributed to real-world programming's reliance on pre-existing libraries"" and ""GPT-4 exhibits remarkable improvement over other LLMs, it manages to accomplish only 39.73% of the tasks, leaving a huge",2023-11-16T12:03:21Z
FollowEval: A Multi-Dimensional Benchmark for Assessing the Instruction-Following Capability of Large Language Models,Yes.,5.,"""We have evaluated various LLMs using the FollowEval benchmark and found that their performance significantly lags behind that of humans. This highlights the considerable room for improvement in the instruction-following ability of these models.""",2023-11-16T11:53:31Z
Cognitive Overload: Jailbreaking Large Language Models with Overloaded Logical Thinking,Yes.,5.,"""we analyze the safety vulnerability of LLMs in the face of (1) multilingual cognitive overload, (2) veiled expression, and (3) effect-to-cause reasoning.""",2023-11-16T11:52:22Z
MedAgents: Large Language Models as Collaborators for Zero-shot Medical Reasoning,Yes.,3.,"""Large language models (LLMs), despite their remarkable progress across various general domains, encounter significant barriers in medicine and healthcare. This field faces unique challenges such as domain-specific terminologies and reasoning over specialized knowledge.""",2023-11-16T11:47:58Z
The Curious Decline of Linguistic Diversity: Training Language Models on Synthetic Text,Yes.,5.,"""Our findings reveal a marked decrease in the diversity of the models' outputs through successive iterations. This trend underscores the potential risks of training LLMs on predecessor-generated text, particularly concerning the preservation of linguistic richness.""",2023-11-16T11:31:50Z
DocMath-Eval: Evaluating Numerical Reasoning Capabilities of LLMs in Understanding Long Documents with Tabular Data,Yes.,5.,"""We found that, although the current best-performing system (i.e., GPT-4), can perform well on simple problems such as calculating the rate of increase in a financial metric within a short document context, it significantly lags behind human experts in more complex problems grounded in longer contexts.""",2023-11-16T11:30:53Z
Neuro-Symbolic Integration Brings Causal and Reliable Reasoning Proofs,Yes.,5.,"""these proofs are not ensured to be causal and reliable due to the inherent defects of LLMs.""",2023-11-16T11:26:21Z
How Far Can We Extract Diverse Perspectives from Large Language Models?,Yes.,3.,"""However, the extent of LLMs' capability to generate diverse perspectives on subjective topics remains an unexplored question.""",2023-11-16T11:23:38Z
Interpreting User Requests in the Context of Natural Language Standing Instructions,Yes.,3.,"""Our results demonstrate the challenges in identifying the relevant standing instructions and their interpretation into API calls.""",2023-11-16T11:19:26Z
Investigating Data Contamination in Modern Benchmarks for Large Language Models,Yes.,5.,"""Recent observations have underscored a disparity between the inflated benchmark scores and the actual performance of LLMs, raising concerns about potential contamination of evaluation benchmarks."" and ""We hope these results underscore the need for more robust evaluation methodologies and benchmarks in the field.""",2023-11-16T11:03:04Z
Video-LLaVA: Learning United Visual Representation by Alignment Before Projection,Yes.,3.,"""However, due to the lack of unified tokenization for images and videos, namely misalignment before projection, it becomes challenging for a Large Language Model (LLM) to learn multi-modal interactions from several poor projection layers.""",2023-11-16T10:59:44Z
Test-time Backdoor Mitigation for Black-Box Large Language Models with Defensive Demonstrations,Yes.,2.,"""Existing studies in backdoor defense have predominantly focused on the training phase, overlooking the critical aspect of testing time defense.""",2023-11-16T10:38:43Z
Graph-Guided Reasoning for Multi-Hop Question Answering in Large Language Models,Yes.,4.,"""We analyze the reasoning paths generated by CoT and find two issues in multi-step reasoning",2023-11-16T10:36:08Z
How Does Calibration Data Affect the Post-training Pruning and Quantization of Large Language Models?,Yes.,3.,"""However, no prior work has systematically investigated how the calibration data impacts the effectiveness of model compression methods.""",2023-11-16T10:30:00Z
GEO: Generative Engine Optimization,Yes.,3.,"""Given the black-box and fast-moving nature of Generative Engines, content creators have little to no control over when and how their content is displayed.""",2023-11-16T10:06:09Z
MOKA: Moral Knowledge Augmentation for Moral Event Extraction,Yes.,3.,"""insufficient moral reasoning capability in most existing NLP systems, where LLMs are no exception.""",2023-11-16T10:04:49Z
Examining LLMs' Uncertainty Expression Towards Questions Outside Parametric Knowledge,Yes.,5.,"""we observe that most LLMs fail to consistently refuse or express uncertainty towards questions outside their parametric knowledge,"" and ""LLMs' uncertainty expression does not always stay consistent with the perceived confidence of their textual outputs.""",2023-11-16T10:02:40Z
Aligning with Whom? Large Language Models Have Gender and Racial Biases in Subjective NLP Tasks,Yes.,5.,"""Our results suggest that LLMs hold gender and racial biases for subjective NLP tasks and that demographic-infused prompts alone may be insufficient to mitigate such effects.""",2023-11-16T10:02:24Z
"OVM, Outcome-supervised Value Models for Planning in Mathematical Reasoning",Yes.,3.,"""Large language models (LLMs) often struggle with maintaining accuracy throughout multiple reasoning steps, especially in mathematical reasoning where an error in earlier steps can propagate to subsequent ones and it ultimately leading to an incorrect answer.""",2023-11-16T09:56:28Z
Large Language Model Inference with Lexical Shortlisting,Yes.,3.,"""Large language model (LLM) inference is computation and memory intensive,"" and ""we also identify the drawbacks of such vocabulary selection methods and propose avenues for future research.""",2023-11-16T09:35:50Z
Towards Autonomous Hypothesis Verification via Language Models with Minimal Guidance,Yes.,3.,"""While this is a promising result, we also found that none of the verifications were flawless, and there remain significant challenges in achieving autonomous, human-level research using only generic instructions.""",2023-11-16T09:34:23Z
Deceptive Semantic Shortcuts on Reasoning Chains: How Far Can Models Go without Hallucination?,Yes.,5.,"""Despite the recent advancement in large language models (LLMs) and their high performances across numerous benchmarks, recent research has unveiled that LLMs suffer from hallucinations and unfaithful reasoning."" and ""We find that existing LLMs lack the necessary capabilities to follow correct reasoning paths and resist the attempt of greedy shortcuts.""",2023-11-16T09:27:36Z
BLT: Can Large Language Models Handle Basic Legal Text?,Yes.,5.,"""We find that the best publicly available LLMs like GPT-4, Claude, and {PaLM 2} currently perform poorly at basic legal text handling."" and ""LLMs' poor performance on this benchmark casts into doubt their reliability as-is for legal practice.""",2023-11-16T09:09:22Z
Inducing Political Bias Allows Language Models Anticipate Partisan Reactions to Controversies,Yes.,3.,"""Our findings reveal the model's effectiveness in capturing emotional and moral nuances, albeit with some challenges in stance detection, highlighting the intricacies and potential for refinement in NLP tools for politically sensitive contexts.""",2023-11-16T08:57:53Z
R-Tuning: Teaching Large Language Models to Refuse Unknown Questions,Yes.,5.,"""A predominant issue is the propensity for these models to generate non-existent facts, a concern termed hallucination."" and ""previous instruction tuning methods force the model to complete a sentence no matter whether the model knows the knowledge or not.""",2023-11-16T08:45:44Z
Improving the Generation Quality of Watermarked Large Language Models via Word Importance Scoring,Yes.,3.,"""Token-level watermarking inserts watermarks in the generated texts by altering the token probability distributions with a private random number generator seeded by its prefix tokens. However, this watermarking algorithm alters the logits during generation, which can lead to a downgraded text quality if it chooses to promote tokens that are less relevant given the input.""",2023-11-16T08:36:00Z
The Wisdom of Partisan Crowds: Comparing Collective Intelligence in Humans and LLM-based Agents,Yes.,3.,"""We then identify several factors that interfere with convergence, including the use of chain-of-thought prompt and lack of details in personas.""",2023-11-16T08:30:15Z
Structured Chemistry Reasoning with Large Language Models,Yes.,5.,"""Large Language Models (LLMs) excel in diverse areas, yet struggle with complex scientific reasoning, especially in the field of chemistry."" and ""even advanced LLMs, like GPT-4, can fail easily in different ways."" and ""the errors often stem not from a lack of domain knowledge within the LLMs, but rather from the absence of an effective reasoning structure that",2023-11-16T08:20:36Z
On the Exploitability of Reinforcement Learning with Human Feedback for Large Language Models,Yes.,5.,"""Despite its advantages, RLHF relies on human annotators to rank the text, which can introduce potential security vulnerabilities if any adversarial annotator (i.e., attackers) manipulates the ranking score by up-ranking any malicious text to steer the LLM adversarially."" and ""Our",2023-11-16T07:48:45Z
Automatic Engineering of Long Prompts,Yes.,2.,"""However, these prompts can be lengthy, often comprising hundreds of lines and thousands of tokens, and their design often requires considerable human effort.""",2023-11-16T07:42:46Z
Bergeron: Combating Adversarial Attacks through a Conscience-Based Alignment Framework,Yes.,4.,"""modern methods of alignment still fail to fully prevent harmful responses when models are deliberately attacked"" and ""These attacks can trick seemingly aligned models into giving manufacturing instructions for dangerous materials, inciting violence, or recommending other immoral acts.""",2023-11-16T07:31:18Z
CRISPR: Eliminating Bias Neurons from an Instruction-following Language Model,Yes.,4.,"""Large language models (LLMs) executing tasks through instruction-based prompts often face challenges stemming from distribution differences between user instructions and training instructions. This leads to distractions and biases, especially when dealing with inconsistent dynamic labels.""",2023-11-16T07:16:55Z
Knowledge Plugins: Enhancing Large Language Models for Domain-Specific Recommendations,Yes.,3.,"""when applied to specific task domains, an LLM pre-trained on a general-purpose corpus may exhibit a deficit or inadequacy in two types of domain-specific knowledge... The absence or inadequacy of such knowledge impacts the performance of the LLM.""",2023-11-16T07:09:38Z
Simulating Opinion Dynamics with Networks of LLM-based Agents,Yes.,4.,"""This bias limits their utility for understanding resistance to consensus views on issues like climate change."" and ""These insights highlight the promise and limitations of LLM agents in this domain and suggest a path forward",2023-11-16T07:01:48Z
Self-Contradictory Reasoning Evaluation and Detection,Yes.,5.,"""We find that LLMs often contradict themselves when performing reasoning tasks that involve contextual information understanding or commonsense"" and ""Our results indicate that the current LLMs lack robustness necessary for reliable reasoning and we emphasize the urgent need for establishing best practices in comprehensive reasoning evaluations beyond accuracy-based metrics.""",2023-11-16T06:22:17Z
Language Models (Mostly) Do Not Consider Emotion Triggers When Predicting Emotion,Yes.,3.,"""Our analysis reveals that emotion triggers are largely not considered salient features for emotion prediction models, instead there is intricate interplay between various features and the task of emotion detection.""",2023-11-16T06:20:13Z
LongBoX: Evaluating Transformers on Long-Sequence Clinical Tasks,Yes.,5.,"""Assessing these models on long sequences is crucial since prior work in the general domain has demonstrated performance degradation of LLMs on longer texts."" and ""Preliminary experiments reveal that both medical LLMs (e.g., BioGPT) and strong general domain LLMs (e.g., FLAN-T5) struggle on this benchmark.""",2023-11-16T04:57:49Z
Prompt-based Pseudo-labeling Strategy for Sample-Efficient Semi-Supervised Extractive Summarization,Yes.,1.,"""we propose a prompt-based pseudo-labeling strategy with LLMs that picks unlabeled examples with more accurate pseudo-labels than using just the classifier's probability outputs.""",2023-11-16T04:29:41Z
Leveraging Code to Improve In-context Learning for Semantic Parsing,Yes.,3.,"""learning to parse to rare domain-specific languages (DSLs) from just a few demonstrations is challenging, limiting the performance of even the most capable LLMs.""",2023-11-16T02:50:06Z
One Size Does Not Fit All: Customizing Open-Domain Procedures,Yes.,1.,"""Our goal is to measure and improve an LLM's ability to perform such customization.""",2023-11-16T02:25:36Z
Stealthy and Persistent Unalignment on Large Language Models via Backdoor Injections,Yes.,3.,"""such alignments are often vulnerable",2023-11-15T23:52:05Z
MMC: Advancing Multimodal Chart Understanding with Large-scale Instruction Tuning,Yes.,4.,"""Extensive experiments on MMC-Benchmark reveal the limitations of existing LMMs on correctly interpreting charts, even for the most recent GPT-4V model.""",2023-11-15T23:36:42Z
How Trustworthy are Open-Source LLMs? An Assessment under Malicious Demonstrations Shows their Vulnerabilities,Yes.,5.,"""However, there is still a limited understanding of their trustworthiness. Deploying these models at scale without sufficient trustworthiness can pose significant risks, highlighting the need to uncover these issues promptly."" and ""scrutinizing them across eight different aspects including toxicity, stereotypes, ethics, hallucination, fairness, sycophancy, privacy, and robustness against adversarial demonstrations.""",2023-11-15T23:33:07Z
Backdoor Activation Attack: Attack Large Language Models using Activation Steering for Safety-Alignment,Yes.,5.,"""the vulnerability of their safety alignment has not been extensively studied"" and ""Existing attack methods on LLMs often rely on poisoned training data or the injection of malicious prompts"" and ""Additionally, these models often demand substantial computational resources for implementation, making them less practical for real-world applications.""",2023-11-15T23:07:40Z
When Large Language Models contradict humans? Large Language Models' Sycophantic Behaviour,Yes.,5.,"""the suggestibility transmitted through human feedback increases the inclination to produce responses that correspond to the user's beliefs or misleading prompts as opposed to true facts, a behaviour known as sycophancy. This phenomenon decreases the bias, robustness, and, consequently, their reliability.""",2023-11-15T22:18:33Z
LOKE: Linked Open Knowledge Extraction for Automated Knowledge Graph Construction,Yes.,1.,"""The advent of Large Language Models (LLMs), especially the commercially available OpenAI models, have reset expectations for what is possible with deep learning models and have created a new field called prompt engineering.""",2023-11-15T20:57:44Z
Investigating Hallucinations in Pruned Large Language Models for Abstractive Summarization,Yes.,5.,"""Despite the remarkable performance of generative large language models (LLMs) on abstractive summarization, they face two significant challenges",2023-11-15T19:49:24Z
Improving fit to human reading times via temperature-scaled surprisal,Yes.,3.,"""In general, these studies have implicitly assumed that the probability scores from LLMs are accurate, ignoring the discrepancies between human cognition and LLMs from this standpoint.""",2023-11-15T19:34:06Z
Symbol-LLM: Towards Foundational Symbol-centric Interface For Large Language Models,Yes.,4.,"""Although Large Language Models (LLMs) demonstrate remarkable ability in processing and generating human-like text, they do have limitations when it comes to comprehending and expressing world knowledge that extends beyond the boundaries of natural language (e.g., chemical molecular formula).""",2023-11-15T18:59:56Z
Mind's Mirror: Distilling Self-Evaluation Capability and Comprehensive Thinking from Large Language Models,Yes.,3.,"""the massive scale and computational demands of these models present formidable challenges when considering their practical deployment in resource-constrained environments"" and ""there is a risk that distilled SLMs may still inherit flawed reasoning and hallucinations from LLMs.""",2023-11-15T18:56:23Z
Never Lost in the Middle: Improving Large Language Models via Attention Strengthening Question Answering,Yes.,5.,"""they are struggling to seek correct information in long contexts. The 'lost in the middle' problem challenges most LLMs, referring to the dramatic decline in accuracy when correct information is located in the middle.""",2023-11-15T18:42:44Z
Towards Verifiable Text Generation with Symbolic References,Yes.,5.,"""However they remain vulnerable to hallucinations, and thus their outputs generally require manual human verification for high-stakes applications, which can be time-consuming and difficult.""",2023-11-15T18:28:29Z
Benchmarking Generation and Evaluation Capabilities of Large Language Models for Instruction Controllable Summarization,Yes.,5.,"""our study reveals that instruction controllable text summarization remains a challenging task for LLMs, since (1) all LLMs evaluated still make factual and other types of errors in their summaries; (2) all LLM-based evaluation methods cannot achieve a strong alignment with human annotators when judging the quality of candidate summaries; (3) different LLMs show large performance",2023-11-15T18:25:26Z
ContraDoc: Understanding Self-Contradictions in Documents with Large Language Models,Yes.,5.,"""While GPT4 performs the best and can outperform humans on this task, we find that it is still unreliable and struggles with self-contradictions that require more nuance and context.""",2023-11-15T18:23:17Z
AbsPyramid: Benchmarking the Abstraction Ability of Language Models with a Unified Entailment Graph,Yes.,5.,"""Experimental results demonstrate that current LLMs face challenges comprehending abstraction knowledge in zero-shot and few-shot settings.""",2023-11-15T18:11:23Z
CLEAN-EVAL: Clean Evaluation on Contaminated Large Language Models,Yes.,3.,"""However, genuinely assessing the capabilities of these LLMs has become a challenging and critical issue due to potential data contamination,"" and ""Our experiments illustrate that Clean-Eval substantially restores the actual evaluation results on contaminated LLMs under both few-shot learning and fine-tuning scenarios.""",2023-11-15T17:50:30Z
Temporal Knowledge Question Answering via Abstract Reasoning Induction,Yes.,5.,"""In this paper, we tackle the significant challenge of temporal knowledge reasoning in Large Language Models (LLMs), an area where such models frequently encounter difficulties. These difficulties often result in the generation of misleading or incorrect information, primarily due to their limited capacity to process evolving factual knowledge and complex temporal logic.""",2023-11-15T17:46:39Z
Jailbreaking GPT-4V via Self-Adversarial Attacks with System Prompts,Yes.,5.,"""This finding indicates potential exploitable security risks in MLLMs"" and ""Results show that appropriately designed system prompts can significantly reduce jailbreak success rates.""",2023-11-15T17:17:39Z
Ever: Mitigating Hallucination in Large Language Models through Real-Time Verification and Rectification,Yes.,5.,"""Large Language Models (LLMs) have demonstrated remarkable proficiency in generating fluent text. However, they often encounter the challenge of generating inaccurate or hallucinated content.""",2023-11-15T17:04:56Z
Does Pre-trained Language Model Actually Infer Unseen Links in Knowledge Graph Completion?,Yes.,5.,"""This approach is problematic because building KGC models aims to infer unseen links between entities. However, conventional evaluations in KGC do not consider inference and memorization abilities separately. Thus, a PLM-based KGC method, which achieves high performance in current KGC evaluations, may be ineffective in practical applications.""",2023-11-15T16:56:49Z
MAVEN-Arg: Completing the Puzzle of All-in-One Event Understanding Dataset with Event Argument Annotation,Yes.,2.,"""Experiments indicate that MAVEN-Arg is quite challenging for both fine-tuned EAE models and proprietary large language models (LLMs).""",2023-11-15T16:52:14Z
Defending Large Language Models Against Jailbreaking Attacks Through Goal Prioritization,Yes.,5.,"""Large Language Models (LLMs) continue to advance in their capabilities, yet this progress is accompanied by a growing array of safety risks."" and ""we point out a pivotal factor contributing to the success of jailbreaks",2023-11-15T16:42:29Z
Social Bias Probing: Fairness Benchmarking for Language Models,Yes.,4.,"""Large language models have been shown to encode a variety of social biases, which carries the risk of downstream harms."" and ""When comparing our methodology with prior work, we demonstrate that biases within language models are more nuanced than previously acknowledged.""",2023-11-15T16:35:59Z
How Multilingual is Multilingual LLM?,Yes.,3.,"""Large Language Models (LLMs), trained predominantly on extensive English data, often exhibit limitations when applied to other languages.""",2023-11-15T16:13:14Z
How Well Do Large Language Models Truly Ground?,Yes.,5.,"""Reliance on the inherent knowledge of Large Language Models (LLMs) can cause issues such as hallucinations, lack of control, and difficulties in integrating variable knowledge.""",2023-11-15T16:11:27Z
GRASP: A novel benchmark for evaluating language GRounding And Situated Physics understanding in multimodal language models,Yes.,5.,"""Our evaluation reveals significant shortcomings in the language grounding and intuitive physics capabilities of these models."" and ""These identified limitations underline the importance of using benchmarks like GRASP to monitor the progress of future models in developing these competencies.""",2023-11-15T15:38:28Z
Factcheck-GPT: End-to-End Fine-Grained Document-Level Fact-Checking and Correction of LLM Output,Yes.,5.,"""The increased use of large language models (LLMs) across a variety of real-world applications calls for mechanisms to verify the factual accuracy of their outputs."" and ""Preliminary experiments show that FacTool, FactScore and Perplexity.ai are struggling to identify",2023-11-15T14:41:57Z
When does In-context Learning Fall Short and Why? A Study on Specification-Heavy Tasks,Yes.,5.,"""ICL falls short of handling specification-heavy tasks, which are tasks with complicated and extensive task specifications,"" and ""three primary reasons",2023-11-15T14:26:30Z
Enabling Large Language Models to Learn from Rules,Yes.,3.,"""However, this learning paradigm may not well learn those complicated rules, especially when the training examples are limited.""",2023-11-15T11:42:41Z
Llamas Know What GPTs Don't Show: Surrogate Models for Confidence Estimation,Yes.,5.,"""large language models (LLMs) should signal low confidence on examples where they are incorrect, instead of misleading the user."" and ""state-of-the-art LLMs such as GPT-4 and Claude-v1.3 do not provide access to these probabilities.""",2023-11-15T11:27:44Z
Disinformation Capabilities of Large Language Models,Yes.,4.,"""Automated disinformation generation is often listed as an important risk associated with large language models (LLMs).""",2023-11-15T10:25:30Z
MAP's not dead yet: Uncovering true language model modes by conditioning away degeneracy,Yes.,5.,"""degenerate modes can even occur in the absence of any model error, due to contamination of the training data"" and ""the modes of the LLaMA models are still degenerate, showing that improvements in modeling have not fixed this issue.""",2023-11-15T09:38:53Z
"StrategyLLM: Large Language Models as Strategy Generators, Executors, Optimizers, and Evaluators for Problem Solving",Yes.,3.,"""Most existing chain-of-thought (CoT) prompting methods suffer from the issues of generalizability and consistency, as they often rely on instance-specific solutions that may not be applicable to other cases and lack task-level consistency in their reasoning steps.""",2023-11-15T09:18:09Z
Auto-ICL: In-Context Learning without Human Supervision,Yes.,3.,"""Despite this, LLMs are heavily reliant on well-structured prompts to function efficiently within the realm of In-Context Learning.""",2023-11-15T07:37:28Z
Thread of Thought Unraveling Chaotic Contexts,Yes.,5.,"""they encounter difficulties when confronted with chaotic contexts (e.g., distractors rather than long irrelevant context), leading to the inadvertent omission of certain details within the chaotic context.""",2023-11-15T06:54:44Z
Enhancing Emergency Decision-making with Knowledge Graphs and Large Language Models,Yes.,4.,"""However, the utilization of LLM directly would inevitably introduce unreliable output for its inherent issue of hallucination and poor reasoning skills.""",2023-11-15T06:48:50Z
Decomposing Uncertainty for Large Language Models through Input Clarification Ensembling,Yes.,3.,"""Performing uncertainty decomposition for large language models (LLMs) is an important step toward improving the reliability, trustworthiness, and interpretability of LLMs, but this research task is very challenging and remains unresolved."" and ""The existing canonical method, Bayesian Neural Network (BNN), cannot be applied to LLMs, because BNN requires training and ensembling multiple variants of",2023-11-15T05:58:35Z
PLUG: Leveraging Pivot Language in Cross-Lingual Instruction Tuning,Yes.,3.,"""Despite the success in high-resource languages, its application in lower-resource ones faces challenges due to the imbalanced foundational abilities of LLMs across different languages, stemming from the uneven language distribution in their pre-training data.""",2023-11-15T05:28:07Z
Comparing Generalization in Learning with Limited Numbers of Exemplars: Transformer vs. RNN in Attractor Dynamics,Yes.,3.,"""Our simulation results suggest that under conditions of limited data availability, Transformer's GIL abilities are markedly inferior to those of RNN.""",2023-11-15T00:37:49Z
Navigating the Ocean of Biases: Political Bias Attribution in Language Models via Causal Structures,Yes.,4.,"""we undertake an exploration of decision-making processes and inherent biases within LLMs"" and ""We discuss the consequences of our findings for human-AI alignment and bias mitigation.""",2023-11-15T00:02:25Z
Are You Sure? Challenging LLMs Leads to Performance Drops in The FlipFlop Experiment,Yes.,5.,"""A systematic study of ten LLMs on seven classification tasks reveals that models flip their answers on average 46% of the time and that all models see a deterioration of accuracy between their first and final prediction, with an average drop of 17% (the FlipFlop effect).""",2023-11-14T23:40:22Z
CodeScope: An Execution-based Multilingual Multitask Multidimensional Benchmark for Evaluating LLMs on Code Understanding and Generation,Yes.,4.,"""existing benchmarks for evaluating the code understanding and generation capacities of LLMs suffer from severe limitations."" and ""most benchmarks are deficient as they focus on a narrow range of popular programming languages and specific tasks"" and ""most benchmarks also fail to",2023-11-14T23:18:52Z
GLiNER: Generalist Model for Named Entity Recognition using Bidirectional Transformer,,,,2023-11-14T20:39:12Z
"LLMs cannot find reasoning errors, but can correct them!",Yes.,5.,"""recent attempts to self-correct logical or reasoning errors often cause correct answers to become incorrect, resulting in worse performances overall"" and ""demonstrate that LLMs generally struggle with finding logical mistakes.""",2023-11-14T20:12:38Z
Selecting Shots for Demographic Fairness in Few-Shot Learning with Large Language Models,Yes.,4.,"""while fairness evaluations have become a standard for supervised methods, little is known about the fairness of LLMs as prediction systems"" and ""We discuss how future work can include LLM fairness evaluations.""",2023-11-14T19:02:03Z
Fine-tuning Language Models for Factuality,Yes.,5.,"""Yet language models are prone to making convincing but factually inaccurate claims, often referred to as 'hallucinations.' These errors can inadvertently spread misinformation or harmfully perpetuate misconceptions.""",2023-11-14T18:59:15Z
Towards Open-Ended Visual Recognition with Large Language Model,Yes.,3.,"""However, it is worth noting that these open-vocabulary recognition models still exhibit limitations in practical applications. On one hand, they rely on the provision of class names during testing, where the recognition performance heavily depends on this predefined set of semantic classes by users. On the other hand, when training with multiple datasets, human intervention is required to alleviate the label definition conflict between them.""",2023-11-14T18:59:01Z
Are Large Language Models Temporally Grounded?,Yes.,5.,"""Generally, we find that LLMs lag significantly behind both human performance as well as small-scale, specialised LMs. In-context learning, instruction tuning, and chain-of-thought prompting reduce this gap only to a limited degree. Crucially, LLMs struggle the most with self-consistency, displaying incoherent behaviour in at least 27.23% of their predictions.",2023-11-14T18:57:15Z
On What Basis? Predicting Text Preference Via Structured Comparative Reasoning,Yes.,3.,"""large language models (LLMs) often demonstrate inconsistencies in their reasoning"" and ""they struggle to consistently distinguish the similarities and differences of complex texts.""",2023-11-14T18:51:38Z
SimpleSafetyTests: a Test Suite for Identifying Critical Safety Risks in Large Language Models,Yes.,5.,"""However, without proper steering and safeguards, LLMs will readily follow malicious instructions, provide unsafe advice, and generate toxic content."" and ""We test 11 open-access and open-source LLMs and four closed-source LLMs, and find critical safety weaknesses.""",2023-11-14T18:33:43Z
GPT-4V(ision) Unsuitable for Clinical Care and Education: A Clinician-Evaluated Assessment,Yes.,5.,"""Although GPT-4V is able to identify and explain medical images, its diagnostic accuracy and clinical decision-making abilities are poor, posing risks to patient safety.""",2023-11-14T17:06:09Z
Extrinsically-Focused Evaluation of Omissions in Medical Summarization,Yes.,4.,"""Generative large language models (LLMs) have shown to be robust summarizers, yet traditional metrics struggle to capture resulting performance (Goyal et al, 2022) in more powerful LLMs."" and ""especially given the potential for LLMs to omit important information in the resulting summary.""",2023-11-14T16:46:15Z
A Survey of Confidence Estimation and Calibration in Large Language Models,Yes.,4.,"""Despite their impressive performance, they can be unreliable due to factual errors in their generations."" and ""we outline the challenges and we summarize recent technical advancements for LLM confidence estimation and calibration.""",2023-11-14T16:43:29Z
How Well Do Large Language Models Understand Syntax? An Evaluation by Asking Natural Language Questions,Yes.,5.,"""Experiments conducted on 24 LLMs suggest that most have a limited grasp of syntactic knowledge, exhibiting notable discrepancies across different syntactic knowledge points."" and ""simply increasing the number of training tokens may not be the `silver bullet' for improving the comprehension ability of LLM",2023-11-14T16:30:36Z
A Wolf in Sheep's Clothing: Generalized Nested Jailbreak Prompts can Fool Large Language Models Easily,Yes.,5.,"""Exploring jailbreak prompts can help to better reveal the weaknesses of LLMs and further steer us to secure them."" and ""Our study also reveals the inadequacy of current defense methods in safeguarding LLMs.""",2023-11-14T16:02:16Z
Self-Evolved Diverse Data Sampling for Efficient Instruction Tuning,Yes.,2.,"""Enhancing the instruction-following ability of Large Language Models (LLMs) primarily demands substantial instruction-tuning datasets. However, the sheer volume of these imposes a considerable computational burden and annotation cost.""",2023-11-14T14:10:40Z
Vision-Language Instruction Tuning: A Review and Analysis,Yes.,3.,"""we discuss the current challenges and future research directions of VLIT, providing insights for the continuous development of this field.""",2023-11-14T14:02:32Z
"MechAgents: Large language model multi-agent collaborations can solve mechanics problems, generate new data, and integrate knowledge",Yes.,2.,"""they often lack physical intuition since knowledge is baked into the parametric complement through training, offering less flexibility when it comes to incorporating mathematical or physical insights.""",2023-11-14T13:49:03Z
Ask One More Time: Self-Agreement Improves Reasoning of Language Models in (Almost) All Scenarios,Yes.,3.,"""To address this shortcoming, ensemble-optimization tries to obtain multiple reasoning paths to get the final answer assembly. However, current ensemble-optimization methods either simply employ rule-based post-processing such as \textit{self-consistency}, or train an additional model",2023-11-14T13:30:54Z
RECALL: A Benchmark for LLMs Robustness against External Counterfactual Knowledge,Yes.,5.,"""Evaluation results show that existing LLMs are susceptible to interference from unreliable external knowledge with counterfactual information, and simple intervention methods make limited contributions to the alleviation of this issue.""",2023-11-14T13:24:19Z
Insights into Classifying and Mitigating LLMs' Hallucinations,Yes.,5.,"""However, LLMs are not exempt from drawbacks. One of the most concerning aspects regards the emerging problematic phenomena known as 'Hallucinations'. They manifest in text generation systems, particularly in question-answering systems reliant on LLMs, potentially resulting in false or misleading information propagation.""",2023-11-14T12:30:28Z
Carpe Diem: On the Evaluation of World Knowledge in Lifelong Language Models,Yes.,5.,"""the dynamic nature of knowledge presents challenges for language models that are trained on static data, leading to outdated encoded information,"" and ""we uncover that existing continual learning baselines have difficulty in updating and forgetting outdated knowledge,"" and ""the models fail to learn updated knowledge due to the small weight gradient,"" and ""the models struggle mostly on providing numerical or temporal answers to questions asking for updated knowledge",2023-11-14T12:12:02Z
Empowering Multi-step Reasoning across Languages via Tree-of-Thoughts,Yes.,3.,"""the ability to deliver multi-step reasoning remains limited to English due to the imbalance in the distribution of the pre-training data, making the other languages a barrier.""",2023-11-14T11:49:43Z
Adversarial Preference Optimization,Yes.,3.,"""However, in practice, continuously updating LLMs raises a distribution gap between model-generated samples and human-preferred responses, which hinders model fine-tuning efficiency.""",2023-11-14T10:10:31Z
TempTabQA: Temporal Question Answering for Semi-Structured Tables,Yes.,3.,"""We observe that even the top-performing LLMs lag behind human performance by more than 13.5 F1 points.""",2023-11-14T08:57:01Z
How good are Large Language Models on African Languages?,Yes.,5.,"""Our results suggest that all LLMs produce below-par performance on African languages, and there is a large gap in performance compared to high-resource languages like English most tasks.""",2023-11-14T08:10:14Z
A Closer Look at the Self-Verification Abilities of Large Language Models in Logical Reasoning,Yes.,5.,"""Despite significant advancements made by large language models (LLMs), they still struggle with complex logical reasoning problems."" and ""Our main findings suggest that existing LLMs could struggle to identify fallacious reasoning steps accurately and may fall short of guaranteeing the validity of self-verification",2023-11-14T07:13:10Z
Can Knowledge Graphs Reduce Hallucinations in LLMs? : A Survey,Yes.,5.,"""The contemporary LLMs are prone to producing hallucinations, stemming mainly from the knowledge gaps within the models. To address this critical limitation, researchers employ diverse strategies to augment the LLMs by incorporating external knowledge, aiming to reduce hallucinations and enhance reasoning accuracy.""",2023-11-14T05:21:57Z
Instruction-Following Evaluation for Large Language Models,Yes.,3.,"""Human evaluations are expensive, slow, and not objectively reproducible, while LLM-based auto-evaluation is potentially biased or limited by the ability of the evaluator LLM.""",2023-11-14T05:13:55Z
Fair Abstractive Summarization of Diverse Perspectives,Yes.,4.,"""current work in summarization metrics and Large Language Models (LLMs) evaluation has not explored fair abstractive summarization"" and ""Experiments show that both the model-generated and the human-written reference summaries suffer from low fairness.""",2023-11-14T03:38:55Z
LLatrieval: LLM-Verified Retrieval for Verifiable Generation,Yes.,3.,"""However, the widely used retrievers become the bottleneck of the entire pipeline and limit the overall performance. Their capabilities are usually inferior to LLMs since they often have much fewer parameters than the large language model and have not been demonstrated to scale well to the size of LLMs.""",2023-11-14T01:38:02Z
Enabling High-Level Machine Reasoning with Cognitive Neuro-Symbolic Systems,Yes.,5.,"""Large Language Models have recently become popular by demonstrating remarkable fluency in conversing with humans, but they still make trivial mistakes when probed for commonsense competence.""",2023-11-13T21:20:17Z
On The Truthfulness of 'Surprisingly Likely' Responses of Large Language Models,Yes.,1.,"""We investigate the relevance of a similar criterion for responses of LLMs.""",2023-11-13T19:21:25Z
MART: Improving LLM Safety with Multi-round Automatic Red-Teaming,Yes.,4.,"""Red-teaming is a common practice for mitigating unsafe behaviors in Large Language Models (LLMs), which involves thoroughly assessing LLMs to identify potential flaws and addressing them with responsible and accurate responses.""",2023-11-13T19:13:29Z
Using Natural Language Explanations to Improve Robustness of In-context Learning for Natural Language Inference,Yes.,3.,"""However, the existing literature shows that ICL encounters performance deterioration when exposed to adversarial inputs.""",2023-11-13T18:49:13Z
GPT-4V(ision) as A Social Media Analysis Engine,Yes.,5.,"""Despite the overall impressive capacity of GPT-4V in the social media domain, there remain notable challenges. GPT-4V struggles with tasks involving multilingual social multimedia comprehension and has difficulties in generalizing to the latest trends in social media. Additionally, it exhibits a tendency to generate erroneous information in the context",2023-11-13T18:36:50Z
It's Not Easy Being Wrong: Large Language Models Struggle with Process of Elimination Reasoning,Yes.,5.,"""We find that the strategy of PoE always underperforms the strategy of choosing the correct answer. The agreement of these strategies is also lower than the self-consistency of each strategy.""",2023-11-13T18:18:22Z
A Step Closer to Comprehensive Answers: Constrained Multi-Stage Question Decomposition with Large Language Models,Yes.,5.,"""While large language models exhibit remarkable performance in the Question Answering task, they are susceptible to hallucinations. Challenges arise when these models grapple with understanding multi-hop relations in complex questions or lack the necessary knowledge for a comprehensive response.""",2023-11-13T17:28:03Z
InCA: Rethinking In-Car Conversational System Assessment Leveraging Large Language Models,Yes.,3.,"""The unique demands of these systems, where answers may relate to driver or car safety and are confined within the car domain, highlight the limitations of current metrics.""",2023-11-13T17:02:06Z
Are We Falling in a Middle-Intelligence Trap? An Analysis and Mitigation of the Reversal Curse,Yes.,5.,"""Recent studies have highlighted a phenomenon in large language models (LLMs) known as 'the reversal curse,' in which the order of knowledge entities in the training data biases the models' comprehension."" and ""We hope that more attention can be focused on exploring and addressing these inherent weaknesses of the current LLMs, in order to achieve a higher level of intelligence.""",2023-11-13T17:01:12Z
On Measuring Faithfulness or Self-consistency of Natural Language Explanations,Yes.,5.,"""But an LLM could make up reasonably sounding explanations that are unfaithful to its underlying reasoning.""",2023-11-13T16:53:51Z
Story-to-Motion: Synthesizing Infinite and Controllable Character Animation from Long Text,Yes.,1.,"""We leverage contemporary Large Language Models to act as a text-driven motion scheduler to extract a series of (text, position, duration) pairs from long text.""",2023-11-13T16:22:38Z
Think Before You Speak: Cultivating Communication Skills of Large Language Models via Inner Monologue,Yes.,5.,"""However, LLMs still lack a crucial ability",2023-11-13T16:19:42Z
AMBER: An LLM-free Multi-dimensional Benchmark for MLLMs Hallucination Evaluation,Yes.,4.,"""current Multi-modal Large Language Models (MLLMs) encounter the significant challenge of hallucinations, which may lead to harmful consequences.""",2023-11-13T15:25:42Z
Assessing Logical Puzzle Solving in Large Language Models: Insights from a Minesweeper Case Study,Yes.,5.,"""Despite these advancements, it remains an open question whether LLMs are fundamentally capable of reasoning and planning, or if they primarily rely on recalling and synthesizing information from their training data."" and ""Our experiments, including trials with the advanced GPT-4 model, indicate that while LLMs possess the foundational abilities required for this task, they struggle to integrate these into a coherent,",2023-11-13T15:11:26Z
LM-Polygraph: Uncertainty Estimation for Language Models,Yes.,5.,"""However, a significant challenge arises as these models often 'hallucinate', i.e., fabricate facts without providing users an apparent means to discern the veracity of their statements.""",2023-11-13T15:08:59Z
Do large language models and humans have similar behaviors in causal inference with script knowledge?,Yes.,4.,"""Our experiments show that 1) only recent LLMs, like GPT-3 or Vicuna, correlate with human behavior in the $\neg A \rightarrow B$ condition. 2) Despite this correlation, all models still fail to predict that $nil \rightarrow B$ is less",2023-11-13T13:05:15Z
What Large Language Models Bring to Text-rich VQA?,Yes.,3.,"""we focus on investigating the advantages and bottlenecks of LLM-based approaches in addressing this problem"" and ""The bottleneck for LLM to address text-rich VQA problems may primarily lie in visual part.""",2023-11-13T12:52:29Z
In Search of the Long-Tail: Systematic Generation of Long-Tail Inferential Knowledge via Logical Rule Guided Search,Yes.,5.,"""Recent works evaluating LLMs note a marked performance drop on input data from the low-probability distribution, i.e., the longtail."" and ""LINK effectively generates data in the longtail distribution that zero-shot prompted LLMs are unable to reach,"" and ""find that model performances drop by as high as 5% in the long-tail distribution compared to head distribution.""",2023-11-13T10:56:59Z
Exploring the Factual Consistency in Dialogue Comprehension of Large Language Models,Yes.,5.,"""on average, 26.8% of the summaries generated by LLMs contain factual inconsistency. Even ChatGPT, the strongest model evaluated, has such errors in 16% of its summaries. For answering the factual questions, which is more challenging, the average error rate of all",2023-11-13T09:32:12Z
Can LLMs Patch Security Issues?,Yes.,3.,"""Nonetheless, similar to human developers, these models might generate code that contains security vulnerabilities and flaws.""",2023-11-13T08:54:37Z
WaterBench: Towards Holistic Evaluation of Watermarks for Large Language Models,Yes.,3.,"""we observe the common struggles for current methods on maintaining the generation quality.""",2023-11-13T08:09:01Z
Towards the Law of Capacity Gap in Distilling Language Models,Yes.,4.,"""it is still a pain distilling LMs when a large capacity gap is exhibited between the teacher and the student LMs,"" and ""the curse of capacity gap can be only partly yet not fully lifted as indicated in previous studies.""",2023-11-13T03:36:18Z
ExpNote: Black-box Large Language Models are Better Task Solvers with Experience Notebook,Yes.,4.,"""However, LLMs still fail in many specific tasks although understand the task instruction.""",2023-11-13T02:31:16Z
SELF-EXPLAIN: Teaching Large Language Models to Reason Complex Questions by Themselves,Yes.,3.,"""such chain-of-thought examples are expensive to craft, especially for professional domains, and can have high variance depending on human annotators.""",2023-11-12T23:14:43Z
Assessing the Interpretability of Programmatic Policies with Large Language Models,Yes.,1.,"""we introduce a novel metric that uses large-language models (LLM) to assess the interpretability of programmatic policies.""",2023-11-12T22:43:26Z
Flames: Benchmarking Value Alignment of LLMs in Chinese,Yes.,5.,"""Current benchmarks, however, fall short of effectively uncovering safety vulnerabilities in LLMs,"" and ""there is still a significant gap in LLMs' deeper alignment with human values and achieving genuine harmlessness,"" and ""all the evaluated LLMs demonstrate relatively poor performance on Flames, particularly in the safety and fairness dimensions.""",2023-11-12T17:18:21Z
Can Large Language Models Augment a Biomedical Ontology with missing Concepts and Relations?,Yes.,1.,"""Here, we explore the potential of large language models (LLM) to expand an existing ontology in a semi-automated fashion.""",2023-11-12T14:20:55Z
Evaluating the Efficacy of Interactive Language Therapy Based on LLM for High-Functioning Autistic Adolescent Psychological Counseling,Yes.,3.,"""challenges in achieving the depth of personalization and emotional understanding characteristic of human therapists were noted.""",2023-11-12T07:55:39Z
Are LLMs Rigorous Logical Reasoner? Empowering Natural Language Proof Generation with Contrastive Stepwise Decoding,Yes.,5.,"""Nonetheless, logical reasoning that involves proof planning, specifically those that necessitate the validation of explanation accuracy, continues to present stumbling blocks."" and ""Our analysis reveals that LLMs still struggle to navigate complex reasoning chains, which demand the meticulous linkage of premises",2023-11-12T05:12:49Z
Trusted Source Alignment in Large Language Models,Yes.,2.,"""Large language models (LLMs) are trained on web-scale corpora that inevitably include contradictory factual information from sources of varying reliability.""",2023-11-12T00:25:25Z
Intentional Biases in LLM Responses,Yes.,3.,"""We find that the guardrails in the GPT-4 mixture of experts models with a supervisor, while useful in assuring AI alignment in general, are detrimental in trying to construct personas with a variety of uncommon viewpoints.""",2023-11-11T19:59:24Z
BizBench: A Quantitative Reasoning Benchmark for Business and Finance,Yes.,3.,"""We demonstrate that the current bottleneck in performance is due to LLMs' limited business and financial understanding, highlighting the value of a challenging benchmark for quantitative reasoning within this domain.""",2023-11-11T16:16:11Z
Zero-Shot Cross-Lingual Sentiment Classification under Distribution Shift: an Exploratory Study,Yes.,3.,"""The brittleness of finetuned language model performance on out-of-distribution (OOD) test samples in unseen domains has been well-studied for English, yet is unexplored for multi-lingual models."" and ""Results echo the OOD performance decline observed in the",2023-11-11T11:56:56Z
CompCodeVet: A Compiler-guided Validation and Enhancement Approach for Code Dataset,Yes.,5.,"""However, even models with billions of parameters face challenges in tasks demanding multi-step reasoning. Code generation and comprehension, especially in C and C++, emerge as significant challenges. ...they struggle with rectifying non-compilable C and C++ code. ...This approach, however, retains the limitations",2023-11-11T08:21:52Z
Knowledgeable Preference Alignment for LLMs in Domain-specific Question Answering,Yes.,3.,"""the model needs to utilize domain knowledge properly to generate reliable answers. These two issues are the two major difficulties in the LLM application as vanilla fine-tuning can not adequately address them.""",2023-11-11T07:56:40Z
Distilling Large Language Models using Skill-Occupation Graph Context for HR-Related Tasks,Yes.,2.,"""their real-world adoption faces challenges due to absence of comprehensive benchmarks for various HR tasks, and lack of smaller models with competitive capabilities.""",2023-11-10T20:25:42Z
ChatGPT Exhibits Gender and Racial Biases in Acute Coronary Syndrome Management,Yes.,5.,"""a leading barrier to the deployment of Artificial Intelligence (AI) and in particular LLMs has been concern for embedded gender and racial biases."" and ""we evaluate whether a leading LLM, ChatGPT 3.5, exhibits gender and racial bias in clinical management of acute coronary syndrome (ACS).""",2023-11-10T19:59:36Z
Language Models can be Logical Solvers,Yes.,3.,"""Despite their impressive performance, any parsing errors will inevitably result in the failure of the execution of the external logical solver and no answer to the logical questions.""",2023-11-10T16:23:50Z
Making LLMs Worth Every Penny: Resource-Limited Text Classification in Banking,Yes.,2.,"""However, the performance-cost trade-offs of these methods remain underexplored, a critical concern for budget-limited organizations.""",2023-11-10T15:10:36Z
Practical Membership Inference Attacks against Fine-tuned Large Language Models via Self-prompt Calibration,Yes.,3.,"""Existing MIAs designed for LMs can be classified into two categories",2023-11-10T13:55:05Z
ChiMed-GPT: A Chinese Medical Large Language Model with Full Training Regime and Better Alignment to Human Preferences,Yes.,5.,"""most medical LLMs are trained only with supervised fine-tuning (SFT), even though it efficiently empowers LLMs to understand and respond to medical instructions but is ineffective in learning domain knowledge and aligning with human preference. Another engineering barrier that prevents current medical LLM from better text processing ability is their restricted context length (e.g., 2,048 tokens), making it",2023-11-10T12:25:32Z
How to Bridge the Gap between Modalities: A Comprehensive Survey on Multimodal Large Language Model,Yes.,4.,"""MLLMs still face challenges in processing the semantic gap in multimodality, which may lead to erroneous generation, posing potential risks to society."" and ""Choosing the appropriate modality alignment method is crucial, as improper methods might require more parameters with limited performance improvement.""",2023-11-10T09:51:24Z
"Trends in Integration of Knowledge and Large Language Models: A Survey and Taxonomy of Methods, Benchmarks, and Applications",Yes.,4.,"""Large language models (LLMs) exhibit superior performance on various natural language tasks, but they are susceptible to issues stemming from outdated data and domain-specific limitations.""",2023-11-10T05:24:04Z
Watermarking Vision-Language Pre-trained Models for Multi-modal Embedding as a Service,Yes.,3.,"""existing studies indicate that EaaS is vulnerable to model extraction attacks that induce great loss for the owners of VLPs"" and ""A major solution of watermarking model for EaaS implants a backdoor in the model by inserting verifiable trigger embeddings into texts, but it is only applicable for large language models and is unrealistic due to data and model privacy.""",2023-11-10T04:27:27Z
Tamil-Llama: A New Tamil Language Model Based on Llama 2,Yes.,3.,"""However, a prevailing limitation is the underrepresentation of languages like Tamil in these cutting-edge models, leading to suboptimal performance in diverse linguistic contexts.""",2023-11-10T03:02:39Z
Hallucination-minimized Data-to-answer Framework for Financial Decision-makers,Yes.,5.,"""scaling such prototypes to robust products with minimized hallucinations or fake responses still remains an open challenge, especially in niche data-table heavy domains such as financial decision making.""",2023-11-09T22:53:52Z
