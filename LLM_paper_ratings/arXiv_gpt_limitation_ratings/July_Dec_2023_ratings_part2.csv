Title,Talks about LLMs,Rate,Evidence,Published
Efficiently Adapting Pretrained Language Models To New Languages,Yes.,4.,"""Recent large language models (LLM) exhibit sub-optimal performance on low-resource languages, as the training data of these models is usually dominated by English and other high-resource languages."" and ""naively adapting to new languages leads to catastrophic forgetting and poor tokenizer efficiency.""",2023-11-09T20:59:08Z
Long-Horizon Dialogue Understanding for Role Identification in the Game of Avalon with Large Language Models,Yes.,5.,"""Such complex tasks pose challenges for current Large Language Models (LLM) as deception and persuasion can easily mislead them, especially in long-horizon multi-party dialogues."" and ""We find that even current state-of-the-art LLMs do not reach human performance, making our dataset",2023-11-09T20:04:08Z
Conversational AI Threads for Visualizing Multidimensional Datasets,Yes.,3.,"""We surfaced the strengths and weaknesses of LLM-driven analytic chatbots, finding that they fell short in supporting progressive visualization refinements.""",2023-11-09T18:47:46Z
Zero-Shot Goal-Directed Dialogue via RL on Imagined Conversations,Yes.,3.,"""LLMs trained with supervised fine-tuning or 'single-step' RL, as with standard RLHF, might struggle which tasks that require such goal-directed behavior, since they are not trained to optimize for overall conversational outcomes after multiple turns of interaction.""",2023-11-09T18:45:16Z
Removing RLHF Protections in GPT-4 via Fine-Tuning,Yes.,5.,"""fine-tuning can remove RLHF protections"" and ""Our results show the need for further research on protections on LLMs.""",2023-11-09T17:54:59Z
Technical Report: Large Language Models can Strategically Deceive their Users when Put Under Pressure,Yes.,5.,"""Large Language Models, trained to be helpful, harmless, and honest, can display misaligned behavior and strategically deceive their users about this behavior without being instructed to do so.""",2023-11-09T17:12:44Z
Do personality tests generalize to Large Language Models?,Yes.,5.,"""LLMs' responses to personality tests systematically deviate from typical human responses,"" and ""reverse-coded items (e.g. 'I am introverted' vs 'I am extraverted') are often both answered affirmatively by LLMs,"" and ""variation across different prompts designed to 'steer' LLMs to simulate particular personality types does not follow the clear separation",2023-11-09T11:54:01Z
BeLLM: Backward Dependency Enhanced Large Language Model for Sentence Embeddings,Yes.,3.,"""Existing LLMs mainly adopted autoregressive architecture without explicit backward dependency modeling.""",2023-11-09T11:53:52Z
Chain of Images for Intuitively Reasoning,Yes.,3.,"""current Large Language Models (LLMs) do not utilize such visual intuition to help their thinking. Even the most advanced version language models (e.g., GPT-4V and LLaVA) merely align images into textual space, which means their reasoning processes remain purely verbal.""",2023-11-09T11:14:51Z
"A Survey on Hallucination in Large Language Models: Principles, Taxonomy, Challenges, and Open Questions",Yes.,5.,"""LLMs exhibit a critical tendency to produce hallucinations, resulting in content that is inconsistent with real-world facts or user inputs."" and ""This phenomenon poses substantial challenges to their practical deployment and raises concerns over the reliability of LLMs in real-world scenarios.""",2023-11-09T09:25:37Z
Prompt Engineering a Prompt Engineer,Yes.,3.,"""we argue that their potential is limited due to insufficient guidance for complex reasoning in the meta-prompt.""",2023-11-09T08:00:32Z
Characterizing Large Language Models as Rationalizers of Knowledge-intensive Tasks,Yes.,3.,"""Although LLMs-generated rationales were preferable, further improvements in conciseness and novelty are required."" and ""how rationalization of incorrect model predictions erodes humans' trust in LLM-generated rationales.""",2023-11-09T01:04:44Z
"Frontier Language Models are not Robust to Adversarial Arithmetic, or ""What do I need to say so you agree 2+2=5?",Yes.,5.,"""Even in the simple setting of 1-digit addition problems, it is easy to find adversarial prompts that make all tested models (including PaLM2, GPT4, Claude2) misbehave, and",2023-11-08T19:07:10Z
How Abstract Is Linguistic Generalization in Large Language Models? Experiments with Argument Structure,Yes.,5.,"""However, LLMs fail at generalizations between related contexts that have not been observed during pre-training, but which instantiate more abstract, but well-attested structural generalizations (e.g., between the active object and passive subject of an arbitrary verb). Instead, in this case, LLMs show a bias to generalize based on linear order. This finding points to a limitation",2023-11-08T18:58:43Z
Bias Runs Deep: Implicit Reasoning Biases in Persona-Assigned LLMs,Yes.,5.,"""Our study covers 24 reasoning datasets, 4 LLMs, and 19 diverse personas"" and ""Our experiments unveil that LLMs harbor deep rooted bias against various socio-demographics underneath a veneer of fairness.""",2023-11-08T18:52:17Z
SEMQA: Semi-Extractive Multi-Source Question Answering,Yes.,3.,"""Yet, attributing and verifying their generated abstractive answers can be difficult, and automatically evaluating their accuracy remains an ongoing challenge."" and ""Experimenting with several LLMs in various settings, we find this task to be surprisingly challenging.""",2023-11-08T18:46:32Z
Rethinking Benchmark and Contamination for Language Models with Rephrased Samples,,,,2023-11-08T17:35:20Z
Multi-label and Multi-target Sampling of Machine Annotation for Computational Stance Detection,Yes.,3.,"""while large language models show strong potential as an alternative to human annotators, their sensitivity to task-specific instructions and their intrinsic biases pose intriguing yet unique challenges in machine annotation.""",2023-11-08T06:54:34Z
LooGLE: Can Long-Context Language Models Understand Long Contexts?,Yes.,5.,"""LLMs excelled in short dependency tasks like short question-answering and cloze tasks but struggled with more intricate long dependency tasks"" and ""strategies for extending context window length had limited impact on long context understanding.""",2023-11-08T01:45:37Z
Watermarks in the Sand: Impossibility of Strong Watermarking for Generative Models,Yes.,1.,"The paper discusses watermarking schemes for generative models, including large language models, but does not mention any explicit limitations of the language models themselves in the abstract.",2023-11-07T22:52:54Z
Evaluating the Effectiveness of Retrieval-Augmented Large Language Models in Scientific Document Reasoning,Yes.,5.,"""LLMs often provide seemingly plausible but not factual information, often referred to as hallucinations."" and ""Our findings suggest that models justify predictions in science tasks with fabricated evidence and leveraging scientific corpus as pretraining data does not alleviate the risk of evidence fabrication.""",2023-11-07T21:09:57Z
Identifying and Mitigating Vulnerabilities in LLM-Integrated Applications,Yes.,4.,"""LLM-integrated applications also introduce new attack surfaces,"" and ""Successful exploits of the identified vulnerabilities result in the users receiving responses tailored to the intent of a threat initiator,"" and ""our empirical results show that the threats can effectively bypass the restrictions and moderation policies of OpenAI, resulting in users receiving responses that contain bias, toxic content, privacy risk, and disinformation.""",2023-11-07T20:13:05Z
Exploring Recommendation Capabilities of GPT-4V(ision): A Preliminary Case Study,,,,2023-11-07T18:39:10Z
Prompt Cache: Modular Attention Reuse for Low-Latency Inference,Yes.,1.,"""We present Prompt Cache, an approach for accelerating inference for large language models (LLM) by reusing attention states across different LLM prompts.""",2023-11-07T18:17:05Z
Enhancing LLM Intelligence with ARM-RAG: Auxiliary Rationale Memory for Retrieval Augmented Generation,Yes.,5.,"""However, unlike humans, frozen LLMs do not improve over time; they neither acquire new knowledge nor learn from their successes or failures."" and ""However, these methods have the drawback of requiring substantial data and computational resources to retrain existing models.""",2023-11-07T18:03:23Z
Unveiling Safety Vulnerabilities of Large Language Models,Yes.,5.,"""As large language models become more prevalent, their possible harmful or inappropriate responses are a cause for concern."" and ""We assess the efficacy of our dataset by analyzing the vulnerabilities of various models when subjected to it.""",2023-11-07T16:50:33Z
Do LLMs exhibit human-like response biases? A case study in survey design,Yes.,5.,"""One widely-cited barrier to the adoption of LLMs as proxies for humans in subjective tasks is their sensitivity to prompt wording"" and ""Our comprehensive evaluation of nine models shows that popular open and commercial LLMs generally fail to reflect human-like behavior, particularly in models that have undergone RLHF.""",2023-11-07T15:40:43Z
Beyond Imitation: Leveraging Fine-grained Quality Signals for Alignment,Yes.,3.,"""A major limitation of SFT is that it essentially does imitation learning, which cannot fully understand what are the expected behaviors.""",2023-11-07T15:36:40Z
Reinforcement Learning Fine-tuning of Language Models is Biased Towards More Extractable Features,Yes.,3.,"""During this stage, models may be guided by their inductive biases to rely on simpler features which may be easier to extract, at a cost to robustness and generalisation.""",2023-11-07T15:00:39Z
Benefits and Harms of Large Language Models in Digital Mental Health,Yes.,4.,"""This article presents contemporary perspectives on the opportunities and risks posed by LLMs in the design, development, and implementation of digital mental health tools.""",2023-11-07T14:11:10Z
Input Reconstruction Attack against Vertical Federated Large Language Models,Yes.,5.,"""privacy concerns limit their usage in real-life businesses"" and ""we demonstrate that in LLMs, VFL fails to protect the user input since it is simple and cheap to reconstruct the input from the intermediate embeddings.""",2023-11-07T09:39:22Z
Leveraging Large Language Models for Automated Proof Synthesis in Rust,Yes.,3.,"""However, LLMs lack the ability to retain and propagate context information, a strength of traditional static analysis.""",2023-11-07T05:47:47Z
Leveraging Structured Information for Explainable Multi-hop Question Answering and Reasoning,Yes.,3.,"""However, several challenges still remain",2023-11-07T05:32:39Z
A Survey of Large Language Models Attribution,Yes.,4.,"""issues like ambiguous knowledge reservoirs, inherent biases, and the drawbacks of excessive attribution can hinder the effectiveness of these systems.""",2023-11-07T05:20:09Z
Quantifying Uncertainty in Natural Language Explanations of Large Language Models,Yes.,5.,"""However, there is no certainty whether these explanations are reliable and reflect the LLMs behavior."" and ""Our study provides insights into the challenges and opportunities of quantifying uncertainty in LLM explanations, contributing to the broader discussion of the trustworthiness of foundation models.""",2023-11-06T21:14:40Z
Scalable and Transferable Black-Box Jailbreaks for Language Models via Persona Modulation,Yes.,4.,"""Despite efforts to align large language models to produce harmless responses, they are still vulnerable to jailbreak prompts that elicit unrestricted behaviour."" and ""Our work reveals yet another vulnerability in commercial large language models and highlights the need for more comprehensive safeguards.""",2023-11-06T18:55:18Z
ProPath: Disease-Specific Protein Language Model for Variant Pathogenicity,Yes.,3.,"""However, these VEPs are not disease-specific, limiting their adaptation at point-of-care.""",2023-11-06T18:43:47Z
DAIL: Data Augmentation for In-Context Learning via Self-Paraphrase,Yes.,2.,"""However, ICL requires high-quality annotated demonstrations which might not be available in real-world scenarios.""",2023-11-06T18:12:55Z
Unraveling Downstream Gender Bias from Large Language Models: A Study on AI Educational Writing Assistance,Yes.,4.,"""Despite their potential, LLMs are known to harbor inherent biases which may negatively impact learners.""",2023-11-06T18:01:34Z
Ziya2: Data-centric Learning is All LLMs Need,Yes.,3.,"""the development of LLMs still faces several issues, such as high cost of training models from scratch, and continual pre-training leading to catastrophic forgetting, etc."" and ""an important yet practical limitation is that many studies overly pursue enlarging model sizes without comprehensively analyzing and optimizing the use of pre-training data in their learning process, as well as appropriate organization and leveraging of such data",2023-11-06T17:49:34Z
Holistic Analysis of Hallucination in GPT-4V(ision): Bias and Interference Challenges,Yes.,5.,"""This benchmark is designed to evaluate and shed light on the two common types of hallucinations in visual language models",2023-11-06T17:26:59Z
Instructed Language Models with Retrievers Are Powerful Entity Linkers,Yes.,5.,"""Yet the generative nature still makes the generated content suffer from hallucinations, thus unsuitable for entity-centric tasks like entity linking (EL) requiring precise entity predictions over a large knowledge base."" and ""reaffirming that the EL task remains a persistent hurdle for general LLMs.""",2023-11-06T16:38:51Z
ALYMPICS: LLM Agents Meet Game Theory -- Exploring Strategic Decision-Making with AI Agents,Yes.,1.,"""Our findings not only expand the understanding of LLM agents' proficiency in emulating human strategic behavior but also highlight their potential in advancing game theory knowledge.""",2023-11-06T16:03:46Z
DeepInception: Hypnotize Large Language Model to Be Jailbreaker,Yes.,5.,"""Despite remarkable success in various applications, large language models (LLMs) are vulnerable to adversarial jailbreaks that make the safety guardrails void."" and ""Our investigation appeals to people to pay more attention to the safety aspects of LLMs and develop a stronger defense against their misuse risks.""",2023-11-06T15:29:30Z
Zero-shot Bilingual App Reviews Mining with Large Language Models,Yes.,1.,"""In this work, we propose Mini-BAR, a tool that integrates large language models (LLMs) to perform zero-shot mining of user reviews in both English and French.""",2023-11-06T12:36:46Z
LitSumm: Large language models for literature summarisation of non-coding RNAs,Yes.,2.,"""We demonstrate that high-quality, factually accurate summaries with accurate references can be automatically generated from the literature using a commercial LLM and a chain of prompts and checks. Manual assessment was carried out for a subset of summaries, with the majority being rated extremely high quality. We also applied the",2023-11-06T12:22:19Z
Can LLMs Follow Simple Rules?,Yes.,5.,"""Our evaluations of proprietary and open models show that almost all current models struggle to follow scenario rules, even on straightforward test cases.""",2023-11-06T08:50:29Z
Tailoring Self-Rationalizers with Multi-Reward Distillation,Yes.,3.,"""prior work 1) suggests that useful self-rationalization is emergent only at significant scales (e.g., 175B parameter GPT-3);"" and ""focuses largely on downstream performance, ignoring the semantics of the rationales themselves, e.g., are they faithful, true, and helpful for humans?""",2023-11-06T00:20:11Z
On the Intersection of Self-Correction and Trust in Language Models,Yes.,4.,"""However, their complexity and lack of transparency have raised several trustworthiness concerns, including the propagation of misinformation and toxicity."" and ""Interestingly, our study also uncovers instances of 'self-doubt' in LLMs during the self-correction process, introducing a new set of challenges that need to be addressed.""",2023-11-06T00:04:12Z
Assessing the Promise and Pitfalls of ChatGPT for Automated Code Generation,Yes.,3.,"""The key findings reveal ChatGPT's strengths in crafting concise, efficient code with advanced constructs, showcasing strengths in data analysis tasks (93.1% accuracy) but limitations in visual-graphical challenges.""",2023-11-05T12:56:40Z
FloodBrain: Flood Disaster Reporting by Web-based Retrieval Augmented Generation with an LLM,Yes.,5.,"""LLMs are constrained by the knowledge within their training data and are prone to generating inaccurate, or 'hallucinated', information.""",2023-11-05T08:34:26Z
Accelerating Reinforcement Learning of Robotic Manipulations via Feedback from Large Language Models,Yes.,3.,"""Nevertheless, they are not designed to directly control low-level robotic motions, as their pretraining is based on vast internet data rather than specific robotics data.""",2023-11-04T11:21:38Z
Narrowing the Gap between Zero- and Few-shot Machine Translation by Matching Styles,Yes.,4.,"""Large language models trained primarily in a monolingual setting have demonstrated their ability to generalize to machine translation using zero- and few-shot examples with in-context learning. However, even though zero-shot translations are relatively good, there remains a discernible gap comparing their performance with the few-shot setting.""",2023-11-04T03:18:45Z
LLMs-augmented Contextual Bandit,Yes.,1.,"""In this paper, we propose a novel integration of large language models (LLMs) with the contextual bandit framework.""",2023-11-03T23:12:57Z
Tell Your Model Where to Attend: Post-hoc Attention Steering for LLMs,Yes.,1.,"""Existing methods, however, are constrained to process plain text and do not support such a mechanism.""",2023-11-03T22:56:43Z
An Interdisciplinary Outlook on Large Language Models for Scientific Research,Yes.,5.,"""we articulate the challenges LLMs face, including their reliance on extensive and sometimes biased datasets, and the potential ethical dilemmas stemming from their use.""",2023-11-03T19:41:09Z
An Introduction to Natural Language Processing Techniques and Framework for Clinical Implementation in Radiation Oncology,Yes.,4.,"""However, these LLMs are prone to many errors such as hallucinations, biases, and ethical violations, which necessitate rigorous evaluation and validation before clinical deployment.""",2023-11-03T19:32:35Z
The Alignment Problem in Context,Yes.,5.,"""large language models remain vulnerable to adversarial attacks that can reliably elicit unsafe behaviour"" and ""the alignment problem is not only unsolved for current AI systems, but may be intrinsically difficult to solve without severely undermining their capabilities.""",2023-11-03T17:57:55Z
Grounded Intuition of GPT-Vision's Abilities with Scientific Images,Yes.,3.,"""GPT-Vision has impressed us on a range of vision-language tasks, but it comes with the familiar new challenge",2023-11-03T17:53:43Z
Post Turing: Mapping the landscape of LLM Evaluation,Yes.,3.,"""introduction of well-defined and standardized evaluation methodologies remains a crucial challenge"" and ""traditional evaluation proxies, such as the Turing test, have become less reliable.""",2023-11-03T17:24:50Z
Hint-enhanced In-Context Learning wakes Large Language Models up for knowledge-intensive tasks,Yes.,4.,"""However, under the standard ICL setting, LLMs may sometimes neglect query-related information in demonstrations, leading to incorrect predictions.""",2023-11-03T14:39:20Z
Comprehensive Assessment of Toxicity in ChatGPT,Yes.,4.,"""The emerging large language models (LLMs), such as ChatGPT, can potentially further accentuate this threat."" and ""Previous works have discovered that ChatGPT can generate toxic responses using carefully crafted inputs.""",2023-11-03T14:37:53Z
Sentiment Analysis through LLM Negotiations,Yes.,3.,"""This framework suffers the key disadvantage that the single-turn output generated by a single LLM might not deliver the perfect decision, just as humans sometimes need multiple attempts to get things right.""",2023-11-03T12:35:29Z
Large Language Models to the Rescue: Reducing the Complexity in Scientific Workflow Development Using ChatGPT,Yes.,3.,"""Our results indicate that LLMs efficiently interpret workflows but achieve lower performance for exchanging components or purposeful workflow extensions. We characterize their limitations in these challenging scenarios and suggest future research directions.""",2023-11-03T10:28:53Z
AFPQ: Asymmetric Floating Point Quantization for LLMs,Yes.,3.,"""Large language models (LLMs) show great performance in various tasks, but face deployment challenges from limited memory capacity and bandwidth.""",2023-11-03T09:07:09Z
TCM-GPT: Efficient Pre-training of Large Language Models for Domain Adaptation in Traditional Chinese Medicine,Yes.,3.,"""However, the application of these general models to specific domains often yields suboptimal results, primarily due to challenges like lack of domain knowledge, unique objectives, and computational efficiency.""",2023-11-03T08:54:50Z
PPTC Benchmark: Evaluating Large Language Models for PowerPoint Task Completion,Yes.,5.,"""The results show that GPT-4 outperforms other LLMs with 75.1% accuracy in single-turn dialogue testing but faces challenges in completing entire sessions, achieving just 6% session accuracy. We find three main error causes in our benchmark",2023-11-03T08:06:35Z
FinGPT: Large Generative Models for a Small Language,Yes.,4.,"""LLM work tends to focus on languages where nearly unlimited data is available for pretraining.""",2023-11-03T08:05:04Z
Proto-lm: A Prototypical Network-Based Framework for Built-in Interpretability in Large Language Models,Yes.,4.,"""Large Language Models (LLMs) have significantly advanced the field of Natural Language Processing (NLP), but their lack of interpretability has been a major concern. Current methods for interpreting LLMs are post hoc, applied after inference time, and have limitations such",2023-11-03T05:55:32Z
Successor Features for Efficient Multisubject Controlled Text Generation,Yes.,5.,"""While large language models (LLMs) have achieved impressive performance in generating fluent and realistic text, controlling the generated text so that it exhibits properties such as safety, factuality, and non-toxicity remains challenging.""",2023-11-03T00:17:08Z
Preserving the knowledge of long clinical texts using aggregated ensembles of large language models,Yes.,4.,"""applying large language models, such as BERT-based models, to clinical texts poses two major challenges",2023-11-02T19:50:02Z
Divergent Token Metrics: Measuring degradation to prune away LLM components -- and optimize quantization,Yes.,3.,"""However, their ever-increasing size has raised concerns about their effective deployment and the need for LLM compression.""",2023-11-02T18:55:53Z
GPT-4V(ision) as a Generalist Evaluator for Vision-Language Tasks,Yes.,2.,"""Despite limitations like restricted visual clarity grading and real-world complex reasoning, its ability to provide human-aligned scores enriched with detailed explanations is promising for universal automatic evaluator.""",2023-11-02T16:11:09Z
"The Effect of Scaling, Retrieval Augmentation and Form on the Factual Consistency of Language Models",Yes.,5.,"""Large Language Models (LLMs) make natural interfaces to factual knowledge, but their usefulness is limited by their tendency to deliver inconsistent answers to semantically equivalent questions.""",2023-11-02T15:20:11Z
FlashDecoding++: Faster Large Language Model Inference on GPUs,Yes.,5.,"""However, the following challenges still remain unsolved in accelerating LLM inference",2023-11-02T14:57:03Z
Expressive TTS Driven by Natural Language Prompts Using Few Human Annotations,Yes.,1.,"""Our approach utilizes a large language model (LLM) to transform expressive TTS into a style retrieval task.""",2023-11-02T14:20:37Z
CRUSH4SQL: Collective Retrieval Using Schema Hallucination For Text2SQL,Yes.,1.,"""First, we instruct an LLM to hallucinate a minimal DB schema deemed adequate to answer the query.""",2023-11-02T12:13:52Z
Revisiting the Knowledge Injection Frameworks,Yes.,4.,"""However, how to adapt these LLMs to better suit the vertical domain-specific tasks by utilizing external knowledge remains not completely solved."" and ""we identify a pivotal problem in this work ubiquitously. Simply put, we find that injecting unaligned (i.e., random) knowledge tuple into the LLMs achieves comparable (and sometimes better) results than the aligned knowledge being injected.""",2023-11-02T11:18:16Z
ChineseWebText: Large-scale High-quality Chinese Web Text Extracted with Effective Evaluation Model,,,,2023-11-02T11:13:51Z
Making Harmful Behaviors Unlearnable for Large Language Models,Yes.,3.,"""the powerful learning ability of LLMs not only enables them to acquire new tasks but also makes them susceptible to learning undesired behaviors.""",2023-11-02T09:18:21Z
LLM4Drive: A Survey of Large Language Models for Autonomous Driving,Yes.,2.,"""This study evaluates the current state of technological advancements, distinctly outlining the principal challenges and prospective directions for the field.""",2023-11-02T07:23:33Z
Learn to Refuse: Making Large Language Models More Controllable and Reliable through Knowledge Scope Limitation and Refusal Mechanism,Yes.,5.,"""these models are not flawless and often produce responses that contain errors or misinformation. These inaccuracies, commonly referred to as hallucinations, render LLMs unreliable and even unusable in many scenarios.""",2023-11-02T07:20:49Z
Tensor Trust: Interpretable Prompt Injection Attacks from an Online Game,Yes.,5.,"""While Large Language Models (LLMs) are increasingly being used in real-world applications, they remain vulnerable to prompt injection attacks",2023-11-02T06:13:36Z
POS: A Prompts Optimization Suite for Augmenting Text-to-Video Generation,Yes.,,,2023-11-02T02:33:09Z
M2T2: Multi-Task Masked Transformer for Object-centric Pick and Place,Yes.,3.,"""These generic models are able to interpret complex tasks using language commands, but they often have difficulties generalizing to out-of-distribution objects due to the inability of low-level action primitives.""",2023-11-02T01:42:52Z
Task-Agnostic Low-Rank Adapters for Unseen English Dialects,,,,2023-11-02T01:17:29Z
Generate and Pray: Using SALLMS to Evaluate the Security of LLM Generated Code,Yes.,5.,"""Although LLMs can help developers to be more productive, prior empirical studies have shown that LLMs can generate insecure code."" and ""existing datasets used to evaluate Large Language Models (LLMs) do not adequately represent genuine software engineering tasks sensitive to security."" and ""existing evaluation metrics primarily focus on the functional correctness of the generated code while ignoring security considerations.""",2023-11-01T22:46:31Z
Pretraining Data Mixtures Enable Narrow Model Selection Capabilities in Transformer Models,Yes.,5.,"""However when presented with tasks or functions which are out-of-domain of their pretraining data, we demonstrate various failure modes of transformers and degradation of their generalization for even simple extrapolation tasks.""",2023-11-01T21:41:08Z
SAGE: Smart home Agent with Grounded Execution,Yes.,4.,"""LLMs, however, lack specific knowledge about the user and their home limit their potential impact.""",2023-11-01T18:36:28Z
Unleashing the Creative Mind: Language Model As Hierarchical Policy For Improved Exploration on Challenging Problem Solving,Yes.,3.,"""Large Language Models (LLMs) have achieved tremendous progress, yet they still often struggle with challenging reasoning problems.""",2023-11-01T17:52:15Z
Improving Interpersonal Communication by Simulating Audiences with Language Models,Yes.,1.,"""we explore how we can leverage Large Language Model (LLM) simulations to help us communicate better.""",2023-11-01T17:44:50Z
Attention Alignment and Flexible Positional Embeddings Improve Transformer Length Extrapolation,Yes.,3.,"""However, T5 suffers from the dispersed attention issue",2023-11-01T17:43:35Z
Are Large Language Models Reliable Judges? A Study on the Factuality Evaluation Capabilities of LLMs,Yes.,5.,"""Contrary to initial expectations, our results indicate a lack of significant correlations between factuality metrics and human evaluations, specifically for GPT-4 and PaLM-2. Notable correlations were only observed with GPT-3.5 across two factuality subcategories. These consistent findings across various factual error categories suggest a fundamental limitation in the current LLMs' capability to accurately gauge factual",2023-11-01T17:42:45Z
Crosslingual Retrieval Augmented In-context Learning for Bangla,Yes.,5.,"""The promise of Large Language Models (LLMs) in Natural Language Processing has often been overshadowed by their limited performance in low-resource languages such as Bangla.""",2023-11-01T15:32:50Z
Can Large Language Models Design Accurate Label Functions?,,,,2023-11-01T15:14:46Z
Probing Explicit and Implicit Gender Bias through LLM Conditional Text Generation,Yes.,5.,"""Large Language Models (LLMs) can generate biased and toxic responses."", ""all tested LLMs exhibit explicit and/or implicit gender bias, even when explicit gender stereotypes are absent in the inputs.""",2023-11-01T05:31:46Z
Instructive Decoding: Instruction-Tuned Large Language Models are Self-Refiner from Noisy Instructions,Yes.,3.,"""While instruction-tuned language models have demonstrated impressive zero-shot generalization, these models often struggle to generate accurate responses when faced with instructions that fall outside their training set.""",2023-11-01T02:31:35Z
Is GPT Powerful Enough to Analyze the Emotions of Memes?,Yes.,5.,"""Despite GPT's remarkable progress, our findings underscore the challenges faced by these models in handling subjective tasks, which are rooted in their inherent limitations including contextual understanding, interpretation of implicit meanings, and data biases.""",2023-11-01T01:57:48Z
Can Large Language Models Capture Public Opinion about Global Warming? An Empirical Assessment of Algorithmic Fidelity and Bias,Yes.,4.,"""The findings indicate that LLMs can effectively capture presidential voting behaviors but encounter challenges in accurately representing global warming perspectives when relevant covariates are not included."" and ""disparities emerge in LLM estimations of the views of certain groups, with LLMs tending to underestimate worry about global warming among Black Americans."" and ""these results underscore the importance of meticulous conditioning, model",2023-11-01T01:32:59Z
ChatGPT-Powered Hierarchical Comparisons for Image Classification,Yes.,2.,"""However, biases in CLIP lead to similar descriptions for distinct but related classes, prompting our novel image classification framework via hierarchical comparisons.""",2023-11-01T00:26:40Z
The Alignment Ceiling: Objective Mismatch in Reinforcement Learning from Human Feedback,Yes.,5.,"""Notable manifestations of models trained with imperfect RLHF systems are those that are prone to refusing basic requests for safety reasons or appearing lazy in generations.""",2023-10-31T21:52:41Z
BadLlama: cheaply removing safety fine-tuning from Llama 2-Chat 13B,Yes.,5.,"""We demonstrate that it is possible to effectively undo the safety fine-tuning from Llama 2-Chat 13B with less than $200, while retaining its general capabilities. Our results demonstrate that safety-fine tuning is ineffective at preventing misuse when model weights are",2023-10-31T19:45:15Z
BERTwich: Extending BERT's Capabilities to Model Dialectal and Noisy Text,Yes.,5.,"""language models like BERT deteriorate in the face of dialect variation or noise.""",2023-10-31T19:44:50Z
Filter bubbles and affective polarization in user-personalized large language model outputs,Yes.,5.,"""These results illustrate that personalizing LLMs based on user demographics carry the same risks of affective polarization and filter bubbles that have been seen in other personalized internet technologies. This 'failure mode' should be monitored closely as there are more attempts to monetize and personalize these models.""",2023-10-31T18:19:28Z
LoRA Fine-tuning Efficiently Undoes Safety Training in Llama 2-Chat 70B,Yes.,5.,"""We explore the robustness of safety training in language models by subversively fine-tuning the public weights of Llama 2-Chat."" and ""While there is considerable uncertainty about the scope of risks from current models, it is likely that future models will have significantly more dangerous capabilities, including the ability to hack into critical infrastructure, create dangerous bio-weapons, or autonomously replicate",2023-10-31T16:55:06Z
Zero-Shot Medical Information Retrieval via Knowledge Graph Embedding,Yes.,2.,"""This paper introduces MedFusionRank, a novel approach to zero-shot medical information retrieval (MIR) that combines the strengths of pre-trained language models and statistical methods while addressing their limitations.""",2023-10-31T16:26:33Z
Unleashing the Power of Pre-trained Language Models for Offline Reinforcement Learning,Yes.,1.,"""Given recent advances in Large Language Models (LLMs) and their few-shot learning prowess, this paper introduces $\textbf{La}$nguage Models for $\textbf{Mo}$tion Control ($\textbf{LaMo}$), a general framework based on Decision Transformers to effectively use pre-trained Language Models (LMs) for offline RL.""",2023-10-31T16:24:17Z
Breaking the Token Barrier: Chunking and Convolution for Efficient Long Text Classification with BERT,Yes.,5.,"""these models are limited to a maximum token limit of 512 tokens. Consequently, this makes it non-trivial to apply it in a practical setting with long input.""",2023-10-31T15:41:08Z
LLMs may Dominate Information Access: Neural Retrievers are Biased Towards LLM-Generated Texts,Yes.,5.,"""IR systems in the LLMs era are facing a new challenge",2023-10-31T14:42:23Z
FollowBench: A Multi-level Fine-grained Constraints Following Benchmark for Large Language Models,Yes.,4.,"""By evaluating ten closed-source and open-source popular LLMs on FollowBench, we highlight the weaknesses of LLMs in instruction following and point towards potential avenues for future work.""",2023-10-31T12:32:38Z
InstructCoder: Instruction Tuning Large Language Models for Code Editing,Yes.,3.,"""Evaluated on a novel human-written execution-based benchmark dubbed EditEval, we found current models often struggle to fulfill the instructions.""",2023-10-31T10:15:35Z
Interactive Multi-fidelity Learning for Cost-effective Adaptation of Language Model with Sparse Human Supervision,Yes.,3.,"""However, their suitability for domain-specific tasks, is limited due to their immense scale at deployment, susceptibility to misinformation, and more importantly, high data annotation costs.""",2023-10-31T03:39:23Z
Integrating Summarization and Retrieval for Enhanced Personalization via Large Language Models,Yes.,3.,"""retrieval-based methods are limited by potential information loss, lack of more profound user understanding, and cold-start challenges.""",2023-10-30T23:40:41Z
The Expressibility of Polynomial based Attention Scheme,Yes.,5.,"""the quadratic complexity of attention in transformer architectures poses a challenge when scaling up these models for processing long textual contexts. This issue makes it impractical to train very large models on lengthy texts or use them efficiently during inference.""",2023-10-30T22:16:18Z
Synthetic Imitation Edit Feedback for Factual Alignment in Clinical Summarization,Yes.,5.,"""community concerns about these models' hallucination issues continue to rise. LLMs sometimes generate factually hallucinated summaries, which can be extremely harmful in the clinical domain NLP tasks (e.g., clinical note summarization), where factually incorrect statements can lead to critically erroneous diagnoses.""",2023-10-30T21:33:22Z
Chain-of-Thought Embeddings for Stance Detection on Social Media,Yes.,3.,"""Stance detection on social media is challenging for Large Language Models (LLMs), as emerging slang and colloquial language in online conversations often contain deeply implicit stance labels."" and ""However, COT prompting still struggles with implicit stance identification. This challenge arises because many samples are initially challenging to comprehend before a",2023-10-30T17:18:10Z
Collaborative Evaluation: Exploring the Synergy of Large Language Models and Humans for Open-ended Generation Evaluation,Yes.,4.,"""However, both humans and LLMs have limitations, i.e., inherent subjectivity and unreliable judgments, particularly for open-ended tasks that require adaptable metrics tailored to diverse task requirements.""",2023-10-30T17:04:35Z
Adversarial Attacks and Defenses in Large Language Models: Old and New Threats,Yes.,4.,"""substantial challenges associated with an impending adversarial arms race in natural language processing, specifically with closed-source Large Language Models (LLMs), such as ChatGPT, Google Bard, or Anthropic's Claude"" and ""we identify embedding space attacks on LLMs as another viable threat model for the purposes of generating malicious content in open-sourced models.""",2023-10-30T17:01:02Z
Evaluating Large Language Models: A Comprehensive Survey,Yes.,5.,"""LLMs also present potential risks. They could suffer from private data leaks or yield inappropriate, harmful, or misleading content. Additionally, the rapid progress of LLMs raises concerns about the potential emergence of superintelligent systems without adequate safeguards.""",2023-10-30T17:00:52Z
Explaining Tree Model Decisions in Natural Language for Network Intrusion Detection,Yes.,1.,"""In this work, we explore the use of large language models (LLMs) to provide explanations and additional background knowledge for decision tree NID systems.""",2023-10-30T15:40:34Z
MiLe Loss: a New Loss for Mitigating the Bias of Learning Difficulties in Generative Language Models,Yes.,3.,"""existing generative language models generally neglect an inherent challenge in text corpus during training, i.e., the imbalance between frequent tokens and infrequent ones. It can lead a language model to be dominated by common and easy-to-learn tokens, thereby overlooking the infrequent and difficult-to-learn ones.""",2023-10-30T13:33:21Z
Improving Factual Consistency of Text Summarization by Adversarially Decoupling Comprehension and Embellishment Abilities of LLMs,Yes.,5.,"""they often generate summaries that are factually inconsistent with original articles, known as 'hallucinations' in text generation."" and ""current LLMs make fewer silly mistakes but more sophisticated ones, such as imposing cause and effect, adding false details, overgeneralizing, etc.""",2023-10-30T08:40:16Z
M4LE: A Multi-Ability Multi-Range Multi-Task Multi-Domain Long-Context Evaluation Benchmark for Large Language Models,Yes.,5.,"""Our results reveal that",2023-10-30T03:11:30Z
"From Chatbots to PhishBots? -- Preventing Phishing scams created using ChatGPT, Google Bard and Claude",Yes.,4.,"""However, their effectiveness and accessibility also render them susceptible to abuse for generating malicious content, including phishing attacks.""",2023-10-29T22:52:40Z
MILL: Mutual Verification with Large Language Models for Zero-Shot Query Expansion,Yes.,3.,"""Generation-based methods, utilizing large language models (LLMs), generally lack corpus-specific knowledge and entail high fine-tuning costs.""",2023-10-29T16:04:10Z
Are NLP Models Good at Tracing Thoughts: An Overview of Narrative Understanding,Yes.,3.,"""Although large language models (LLMs) excel in generating grammatically coherent text, their ability to comprehend the author's thoughts remains uncertain. This limitation hinders the practical applications of narrative understanding.""",2023-10-28T18:47:57Z
N-Critics: Self-Refinement of Large Language Models with Ensemble of Critics,Yes.,5.,"""We propose a self-correction mechanism for Large Language Models (LLMs) to mitigate issues such as toxicity and fact hallucination."" and ""enhance trustworthiness by addressing fairness, bias, and robustness concerns.""",2023-10-28T11:22:22Z
Large Language Models Are Better Adversaries: Exploring Generative Clean-Label Backdoor Attacks Against Text Classifiers,Yes.,1.,"""Our attack, LLMBkd, leverages language models to automatically insert diverse style-based triggers into texts.""",2023-10-28T06:11:07Z
LLMs-Healthcare : Current Applications and Challenges of Large Language Models in various Medical Specialties,Yes.,3.,"""Throughout our analysis, we explore the challenges and opportunities associated with integrating LLMs in healthcare, recognizing their potential across various medical specialties despite existing limitations.""",2023-10-28T01:01:30Z
On the Automatic Generation and Simplification of Children's Stories,Yes.,5.,"""We find that, in spite of the growing capabilities of LLMs, they do not yet possess the ability to limit their vocabulary to levels appropriate for younger age groups."" and ""while the strongest-performing current lexical simplification models do not perform as well on material designed for children due to their reliance on large language models",2023-10-27T21:31:34Z
PeTailor: Improving Large Language Model by Tailored Chunk Scorer in Biomedical Triple Extraction,Yes.,1.,"""While current unified information extraction models showcase state-of-the-art performance, they face challenges in understanding relationships between entities within intricate biomedical sentences.""",2023-10-27T20:15:23Z
T5 meets Tybalt: Author Attribution in Early Modern English Drama Using Large Language Models,Yes.,3.,"""LLMs are able to accurately predict the author of surprisingly short passages but are also prone to confidently misattribute texts to specific authors."" and ""we see indications that the presence of certain authors in the model's pre-training data affects predictive results in ways that are difficult to assess.""",2023-10-27T20:04:57Z
Entity Embeddings : Perspectives Towards an Omni-Modality Era for Large Language Models,Yes.,2.,"""Such a formulation has the potential to overcome the cognitive and computational limitations of current models.""",2023-10-27T17:04:10Z
ArcheType: A Novel Framework for Open-Source Column Type Annotation using Large Language Models,Yes.,3.,"""Existing deep-learning approaches to semantic column type annotation (CTA) have important shortcomings",2023-10-27T15:31:22Z
DELPHI: Data for Evaluating LLMs' Performance in Handling Controversial Issues,Yes.,4.,"""This dataset presents challenges concerning knowledge recency, safety, fairness, and bias.""",2023-10-27T13:23:02Z
NLP Evaluation in trouble: On the Need to Measure LLM Data Contamination for each Benchmark,Yes.,5.,"""Contamination causes an overestimation of the performance of a contaminated model in a target benchmark and associated task with respect to their non-contaminated counterparts. The consequences can be very harmful, with wrong scientific conclusions being published while other correct ones are discarded.""",2023-10-27T09:48:29Z
SOUL: Towards Sentiment and Opinion Understanding of Language,Yes.,5.,"""Experimental results indicate that SOUL is a challenging task for both small and large language models, with a performance gap of up to 27% when compared to human performance. Furthermore, evaluations conducted with both human experts and GPT-4 highlight the limitations of the small language model in generating reasoning-based justifications.""",2023-10-27T06:48:48Z
Knowing What LLMs DO NOT Know: A Simple Yet Effective Self-Detection Method,Yes.,5.,"""recent literature reveals that LLMs generate nonfactual responses intermittently, which impedes the LLMs' reliability for further utilization.""",2023-10-27T06:22:14Z
Natural Language Interfaces for Tabular Data Querying and Visualization: A Survey,Yes.,3.,"""This includes a deep dive into the influence of LLMs, highlighting their strengths, limitations, and potential for future improvements.""",2023-10-27T05:01:20Z
Can LLMs Keep a Secret? Testing Privacy Implications of Language Models via Contextual Integrity Theory,Yes.,5.,"""Our experiments show that even the most capable models such as GPT-4 and ChatGPT reveal private information in contexts that humans would not, 39% and 57% of the time, respectively. This leakage persists even when we employ privacy-inducing prompts or chain-of-thought reasoning.""",2023-10-27T04:15:30Z
"""You Are An Expert Linguistic Annotator"": Limits of LLMs as Analyzers of Abstract Meaning Representation",Yes.,5.,"""we examine the successes and limitations of the GPT-3, ChatGPT, and GPT-4 models in analysis of sentence meaning structure"" and ""model outputs are prone to frequent and major errors, and holistic analysis of parse acceptability shows that even with few-shot demonstrations, models have virtually 0% success in producing fully accurate parses.""",2023-10-26T21:47:59Z
Evaluation of large language models using an Indian language LGBTI+ lexicon,Yes.,4.,"""Our qualitative analysis shows that the three LLMs we experiment on are unable to detect underlying hateful content. Similarly, we observe limitations in using machine translation as means to evaluate natural language understanding in languages other than English.""",2023-10-26T21:32:24Z
A Framework for Automated Measurement of Responsible AI Harms in Generative AI Applications,Yes.,4.,"""We use this framework to run through several case studies investigating how different LLMs may violate a range of RAI-related principles.""",2023-10-26T19:45:06Z
Salespeople vs SalesBot: Exploring the Role of Educational Value in Conversational Recommender Systems,Yes.,5.,"""revealing that although SalesBot approaches professional performance in terms of fluency and informativeness, it lags behind in recommendation quality. We emphasize the distinct limitations both face in providing truthful information, highlighting the challenges of ensuring faithfulness in the CRS context.""",2023-10-26T19:44:06Z
Outlier Dimensions Encode Task-Specific Knowledge,Yes.,3.,"""Previous works have argued that although ablating these outlier dimensions in LLM representations hurts downstream performance, outlier dimensions are detrimental to the representational quality of embeddings.""",2023-10-26T18:22:13Z
Proving Test Set Contamination in Black Box Language Models,Yes.,5.,"""Large language models are trained on vast amounts of internet data, prompting concerns and speculation that they have memorized public benchmarks."" and ""Our test flags potential contamination whenever the likelihood of a canonically ordered benchmark dataset is significantly higher than the likelihood after shuffling the examples.""",2023-10-26T17:43:13Z
An Open Source Data Contamination Report for Large Language Models,Yes.,4.,"""Data contamination in model evaluation has become increasingly prevalent with the growing popularity of large language models."" and ""Performance analysis of large language models indicates that data contamination does not necessarily lead to increased model metrics.""",2023-10-26T17:11:42Z
Can large language models replace humans in the systematic review process? Evaluating GPT-4's efficacy in screening and extracting data from peer-reviewed and grey literature in multiple languages,,,,2023-10-26T16:18:30Z
Improving Zero-shot Reader by Reducing Distractions from Irrelevant Documents in Open-Domain Question Answering,Yes.,4.,"""LLMs are distracted due to irrelevant documents in the retrieved set and the overconfidence of the generated answers when they are exploited as zero-shot readers.""",2023-10-26T15:45:12Z
Sliceformer: Make Multi-head Attention as Simple as Sorting in Discriminative Tasks,No.,1.,The abstract discusses the Transformer model and its multi-head attention mechanism but does not specifically mention language models (LLMs or LMs).,2023-10-26T14:43:07Z
ToxicChat: Unveiling Hidden Challenges of Toxicity Detection in Real-World User-AI Conversation,Yes.,3.,"""Our systematic evaluation of models trained on existing toxicity datasets has shown their shortcomings when applied to this unique domain of ToxicChat.""",2023-10-26T13:35:41Z
Cultural Adaptation of Recipes,Yes.,3.,"""While GPT-4 exhibits impressive abilities in adapting Chinese recipes into English, it still lags behind human expertise when translating English recipes into Chinese.""",2023-10-26T12:39:20Z
Symbolic Planning and Code Generation for Grounded Dialogue,Yes.,5.,"""LLMs have had limited applicability in grounded task-oriented dialogue as they are difficult to steer toward task objectives and fail to handle novel grounding.""",2023-10-26T04:22:23Z
Incorporating Probing Signals into Multimodal Machine Translation via Visual Question-Answering Pairs,Yes.,1.,"""Using Large Language Models (LLMs), we explicitly model the probing signal in MMT to convert it into VQA-style data to create the Multi30K-VQA dataset.""",2023-10-26T04:13:49Z
FLEEK: Factual Error Detection and Correction with Evidence Retrieved from External Knowledge,Yes.,5.,"""LLMs' inability to attribute their claims to external knowledge and their tendency to hallucinate makes it difficult to rely on their responses.""",2023-10-26T03:28:30Z
math-PVS: A Large Language Model Framework to Map Scientific Publications to PVS Theories,Yes.,3.,"""Despite their current limitations in logic and mathematical tasks,"" and ""Given the noted reasoning shortcomings of LLMs.""",2023-10-25T23:54:04Z
BOOST: Harnessing Black-Box Control to Boost Commonsense in LMs' Generation,Yes.,3.,"""However, amidst their successes, a crucial issue persists",2023-10-25T23:32:12Z
Improving Few-shot Generalization of Safety Classifiers via Data Augmented Parameter-Efficient Fine-Tuning,Yes.,3.,"""We demonstrate that existing few-shot techniques do not perform well in this setting,"" and ""new safety issues and policies emerge, to which existing safety classifiers do not generalize well.""",2023-10-25T19:57:07Z
LLM-FP4: 4-Bit Floating-Point Quantized Transformers,Yes.,1.,"""We propose LLM-FP4 for quantizing both weights and activations in large language models (LLMs) down to 4-bit floating-point values, in a post-training manner.""",2023-10-25T17:59:32Z
Can GPT models Follow Human Summarization Guidelines? Evaluating ChatGPT and GPT-4 for Dialogue Summarization,Yes.,5.,"""Our findings indicate that GPT models often produce lengthy summaries and deviate from human summarization guidelines."" and ""The results reveal that GPT models exhibit unique stylistic tendencies in their summaries."" and ""While BERTScores did not dramatically decrease for GPT outputs suggesting semantic similarity to human references and specialised pre-trained models, ROUGE scores reveal grammatical and lexical disparities between GPT-generated and human-written summaries",2023-10-25T17:39:07Z
Exploring OCR Capabilities of GPT-4V(ision) : A Quantitative and In-depth Evaluation,Yes.,5.,"""The evaluation reveals that GPT-4V performs well in recognizing and understanding Latin contents, but struggles with multilingual scenarios and complex tasks. Specifically, it showed limitations when dealing with non-Latin languages and complex tasks such as handwriting mathematical expression recognition, table structure recognition, and end-to-end semantic entity recognition and pair extraction from document image.""",2023-10-25T17:38:55Z
Detecting Pretraining Data from Large Language Models,Yes.,4.,"""the data used to train them is rarely disclosed"" and ""it includes potentially problematic text such as copyrighted materials, personally identifiable information, and test data for widely reported reference benchmarks.""",2023-10-25T17:21:23Z
SuperHF: Supervised Iterative Learning from Human Feedback,Yes.,5.,"""While large language models demonstrate remarkable capabilities, they often present challenges in terms of safety, alignment with human values, and stability during training.""",2023-10-25T16:52:00Z
HI-TOM: A Benchmark for Evaluating Higher-Order Theory of Mind Reasoning in Large Language Models,Yes.,5.,"""Our experimental evaluation using various Large Language Models (LLMs) indicates a decline in performance on higher-order ToM tasks, demonstrating the limitations of current LLMs. We conduct a thorough analysis of different failure cases of LLMs, and share our thoughts on the implications of our findings on the future of NLP.""",2023-10-25T16:41:15Z
Exploring Large Language Models for Code Explanation,Yes.,1.,"""This study specifically delves into the task of generating natural-language summaries for code snippets, using various LLMs.""",2023-10-25T14:38:40Z
Tailoring Personality Traits in Large Language Models via Unsupervisedly-Built Personalized Lexicons,Yes.,3.,"""Previous methods either relied on fine-tuning LLMs on specific corpora or necessitated manually crafted prompts to elicit specific personalities from LLMs. However, the former approach is inefficient and costly, while the latter cannot precisely manipulate personality traits at a fine-grained level",2023-10-25T12:16:33Z
"R$^3$ Prompting: Review, Rephrase and Resolve for Chain-of-Thought Reasoning in Large Language Models under Noisy Context",Yes.,4.,"""the dilemma for LLMs to produce inaccurate results under the noisy context has not been fully investigated.""",2023-10-25T10:34:02Z
An Early Evaluation of GPT-4V(ision),Yes.,5.,"""Our experimental results reveal the ability and limitations of GPT-4V"" and ""GPT-4V exhibits impressive performance on English visual-centric benchmarks but fails to recognize simple Chinese texts in the images; (2) GPT-4V shows inconsistent refusal behavior when answering questions related to sensitive traits such as gender, race, and age; (3) GPT-4V obtains worse results",2023-10-25T10:33:17Z
Improving Diversity of Demographic Representation in Large Language Models via Collective-Critiques and Self-Voting,Yes.,4.,"""A crucial challenge for generative large language models (LLMs) is diversity",2023-10-25T10:17:17Z
OccuQuest: Mitigating Occupational Bias for Inclusive Large Language Models,Yes.,4.,"""existing instruction-tuning datasets suffer from occupational bias",2023-10-25T10:06:17Z
CLEX: Continuous Length Extrapolation for Large Language Models,,,,2023-10-25T08:13:02Z
Graph Agent: Explicit Reasoning Agent for Graphs,Yes.,1.,"""In this paper, we introduce the Graph Agent (GA), an intelligent agent methodology of leveraging large language models (LLMs), inductive-deductive reasoning modules, and long-term memory for knowledge graph reasoning tasks.""",2023-10-25T07:20:16Z
Multiple Key-value Strategy in Recommendation Systems Incorporating Large Language Model,Yes.,3.,"""Since we adopt multiple key-value strategies, LLM is hard to learn well among these keys.""",2023-10-25T06:49:19Z
"Evaluating, Understanding, and Improving Constrained Text Generation for Large Language Models",Yes.,3.,"""However, integrating intricate constraints into neural text generation, due to LLMs' opacity, remains challenging."" and ""Results illuminate LLMs' capacity and deficiency to incorporate constraints.""",2023-10-25T03:58:49Z
Enhancing Large Language Models for Secure Code Generation: A Dataset-driven Study on Vulnerability Mitigation,Yes.,5.,"""Our experimental results reveal that existing models often overlook security concerns during code generation, leading to the generation of vulnerable code. To address this, we propose effective approaches to mitigate the security vulnerabilities and enhance the overall robustness of code generated by LLMs. Moreover, our study identifies",2023-10-25T00:32:56Z
ConDefects: A New Dataset to Address the Data Leakage Concern for LLM-based Fault Localization and Program Repair,Yes.,2.,"""The code in existing widely-adopted benchmarks for these tasks was written before the bloom of LLMs and may be included in the training data of existing popular LLMs, thereby suffering from the threat of data leakage, leading to misleadingly optimistic performance metrics.""",2023-10-25T00:06:02Z
Knowledge Editing for Large Language Models: A Survey,Yes.,4.,"""Nevertheless, one major drawback of LLMs is their substantial computational cost for pre-training due to their unprecedented amounts of parameters. The disadvantage is exacerbated when new knowledge frequently needs to be introduced into the pre-trained model.""",2023-10-24T22:18:13Z
Clinfo.ai: An Open-Source Retrieval-Augmented Large Language Model System for Answering Medical Questions using Scientific Literature,Yes.,2.,"""While several closed-source summarization tools based on large language models (LLMs) now exist, rigorous and systematic evaluations of their outputs are lacking. Furthermore, there is a paucity of high-quality datasets and appropriate benchmark tasks with which to evaluate these tools",2023-10-24T19:43:39Z
Can You Follow Me? Testing Situational Understanding in ChatGPT,Yes.,5.,"""Previous works have identified certain SU limitations in non-chatbot Large Language models (LLMs),"" and ""despite the fundamental simplicity of the task, the model's performance reflects an inability to retain correct environment states across time,"" and ""performance degradation is largely because ChatGPT has non-persistent in-context memory (although it can access the full dialogue history) and it is susceptible to halluc",2023-10-24T19:22:01Z
Locally Differentially Private Document Generation Using Zero Shot Prompting,Yes.,2.,"""Numerous studies have highlighted the privacy risks associated with pretrained large language models.""",2023-10-24T18:25:13Z
Ignore This Title and HackAPrompt: Exposing Systemic Vulnerabilities of LLMs through a Global Scale Prompt Hacking Competition,Yes.,5.,"""These deployments are vulnerable to prompt injection and jailbreaking (collectively, prompt hacking), in which models are manipulated to ignore their original instructions and follow potentially malicious ones.""",2023-10-24T18:18:11Z
MuSR: Testing the Limits of Chain-of-thought with Multistep Soft Reasoning,Yes.,5.,"""While large language models (LLMs) equipped with techniques like chain-of-thought prompting have demonstrated impressive capabilities, they still fall short in their ability to reason robustly in complex settings.""",2023-10-24T17:59:20Z
What's Left? Concept Grounding with Logic-Enhanced Foundation Models,Yes.,3.,"""However, they operate in limited domains, such as 2D images, not fully exploiting the generalization of language",2023-10-24T17:50:20Z
Towards Perceiving Small Visual Details in Zero-shot Visual Question Answering with Multimodal LLMs,Yes.,5.,"""it is important to investigate their limitations in dealing with different image and question properties."" and ""we show that their zero-shot accuracy in answering visual questions is very sensitive to the size of the visual subject of the question, declining up to 46% with size.""",2023-10-24T17:48:04Z
Mixture of Tokens: Efficient LLMs through Cross-Example Aggregation,Yes.,2.,"""their application carries notable drawbacks"" and ""The operation of matching experts and tokens is discrete, which makes MoE models prone to issues like training instability and uneven expert utilization.""",2023-10-24T16:03:57Z
NoteChat: A Dataset of Synthetic Doctor-Patient Conversations Conditioned on Clinical Notes,Yes.,1.,"""We introduce NoteChat, a novel cooperative multi-agent framework leveraging Large Language Models (LLMs) to generate patient-physician dialogues.""",2023-10-24T15:59:43Z
Representation Learning with Large Language Models for Recommendation,Yes.,3.,"""challenges such as scalability issues, limitations in text-only reliance, and prompt input constraints need to be addressed for effective implementation in practical recommender systems.""",2023-10-24T15:51:13Z
This is not a Dataset: A Large Negation Benchmark to Challenge Large Language Models,Yes.,5.,"""Although large language models (LLMs) have apparently acquired a certain level of grammatical knowledge and the ability to make generalizations, they fail to interpret negation, a crucial step in Natural Language Processing"" and ""Our findings show that, while LLMs are proficient at classifying affirmative sentences, they struggle with negative sentences and lack a deep understanding of negation, often relying on",2023-10-24T15:38:21Z
E-Sparse: Boosting the Large Language Model Inference through Entropy-based N:M Sparsity,Yes.,3.,"""Traditional pruning methods are known to be challenging to work in Large Language Models (LLMs) for Generative AI because of their unaffordable training process and large computational demands.""",2023-10-24T15:27:15Z
BianQue: Balancing the Questioning and Suggestion Ability of Health LLMs with Multi-turn Health Conversations Polished by ChatGPT,Yes.,5.,"""However, the limited information provided by users during single turn results in inadequate personalization and targeting of the generated suggestions, which requires users to independently select the useful part. It is mainly caused by the missing ability to engage in multi-turn questioning.""",2023-10-24T14:57:34Z
SoK: Memorization in General-Purpose Large Language Models,Yes.,5.,"""This is often desirable since it is necessary for performing tasks such as question answering, and therefore an important part of learning, but also brings a whole array of issues, from privacy and security to copyright and beyond.""",2023-10-24T14:25:53Z
Self-Guard: Empower the LLM to Safeguard Itself,Yes.,5.,"""The jailbreak attack can bypass the safety measures of a Large Language Model (LLM), generating harmful content... safety training has constraints in its ability to adapt to new attack types and often leads to a drop in model performance. Safeguards have proven to be of limited help.""",2023-10-24T14:08:26Z
Unnatural language processing: How do language models handle machine-generated prompts?,Yes.,5.,"""We use machine-generated prompts to probe how models respond to input that is not composed of natural language expressions."" and ""Even when producing a similar output, machine-generated and human prompts trigger different response patterns through the network processing pathways, including different perplexities, different attention and output entropy distributions, and different unit activation profiles.""",2023-10-24T13:32:20Z
Generative Language Models Exhibit Social Identity Biases,Yes.,4.,"""The surge in popularity of large language models has given rise to concerns about biases that these models could learn from humans."" and ""Our findings suggest that modern language models exhibit fundamental social identity biases and that such biases can be mitigated by curating training data.""",2023-10-24T13:17:40Z
Improving generalization in large language models by learning prefix subspaces,Yes.,3.,"""Their considerable number of parameters makes it difficult to train several models jointly, and second, their deterministic parameter initialization schemes make them unfit for the subspace method as originally proposed.""",2023-10-24T12:44:09Z
Guiding LLM to Fool Itself: Automatically Manipulating Machine Reading Comprehension Shortcut Triggers,Yes.,5.,"""the use of shortcuts, mechanisms triggered by features spuriously correlated to the true label, has emerged as a potential threat to their reliability"" and ""Our findings highlight inherent vulnerabilities of LLMs to shortcut manipulations.""",2023-10-24T12:37:06Z
Integrating Language Models into Direct Speech Translation: An Inference-Time Solution to Control Gender Inflection,Yes.,3.,"""The existing solutions to do so, though effective, are hardly feasible in practice as they involve dedicated model re-training on gender-labeled ST data.""",2023-10-24T11:55:16Z
Large Language Models are Temporal and Causal Reasoners for Video Question Answering,Yes.,3.,"""such priors often cause suboptimal results on VideoQA by leading the model to over-rely on questions, $\textit{i.e.}$, $\textit{linguistic bias}$, while ignoring visual content. This is also known as ‘ungrounded guesses’ or ‘hallucinations’.""",2023-10-24T11:44:39Z
Failures Pave the Way: Enhancing Large Language Models through Tuning-free Rule Accumulation,Yes.,5.,"""However, due to their inability to capture relationships among samples, these frozen LLMs inevitably keep repeating similar mistakes.""",2023-10-24T11:40:34Z
Prevalence and prevention of large language model use in crowd work,Yes.,4.,"""LLM use yields high-quality but homogeneous responses, which may harm research concerned with human (rather than model) behavior and degrade future models trained with crowdsourced data"" and ""preventing LLM use may be at odds with obtaining high-quality responses; e.g., when requesting workers not to use L",2023-10-24T09:52:09Z
A Survey on Detection of LLMs-Generated Content,Yes.,2.,"""We aim to provide a detailed overview of existing detection strategies and benchmarks, scrutinizing their differences and identifying key challenges and prospects in the field, advocating for more adaptable and robust models to enhance detection accuracy.""",2023-10-24T09:10:26Z
TCRA-LLM: Token Compression Retrieval Augmented Large Language Model for Inference Cost Reduction,Yes.,3.,"""One problem of deploying commercial retrieval-augmented LLMs is the cost due to the additionally retrieved context that largely increases the input token size of the LLMs.""",2023-10-24T06:56:38Z
SteloCoder: a Decoder-Only LLM for Multi-Language to Python Code Translation,Yes.,2.,"""However, there is still a need for improvement in code translation functionality with efficient training techniques.""",2023-10-24T06:04:28Z
KITAB: Evaluating LLMs on Constraint Satisfaction for Information Retrieval,Yes.,5.,"""Motivated by rising concerns around factual incorrectness and hallucinations of LLMs,"" and ""Results show that in the absence of context, models exhibit severe limitations as measured by irrelevant information, factual errors, and incompleteness, many of which exacerbate as information popularity decreases.""",2023-10-24T04:40:38Z
The Janus Interface: How Fine-Tuning in Large Language Models Amplifies the Privacy Risks,Yes.,5.,"""security and privacy challenges also emerged. Foremost among these is the potential inadvertent accrual of Personal Identifiable Information (PII) during web-based data acquisition, posing risks of unintended PII disclosure,"" and ""Our findings indicate that, with a trivial fine-tuning outlay, LLMs such as GPT-3.5 can transition from being impermeable to PII",2023-10-24T02:48:19Z
FANToM: A Benchmark for Stress-testing Machine Theory of Mind in Interactions,Yes.,5.,"""We show that FANToM is challenging for state-of-the-art LLMs, which perform significantly worse than humans even with chain-of-thought reasoning or fine-tuning.""",2023-10-24T00:24:11Z
GPT-4 as an Effective Zero-Shot Evaluator for Scientific Figure Captions,Yes.,1.,"""This paper investigates using large language models (LLMs) as a cost-effective, reference-free method for evaluating figure captions.""",2023-10-23T23:24:57Z
DoGE: Domain Reweighting with Generalization Estimation,Yes.,3.,"""Despite its importance, recent LLMs still rely on heuristics and trial and error to increase or reduce the influence of data-domains.""",2023-10-23T22:51:58Z
Irreducible Curriculum for Language Model Pretraining,Yes.,3.,"""Automatic data selection and curriculum design for training large language models is challenging,"" and ""It is difficult to apply traditional datapoint selection methods on large language models",2023-10-23T22:41:33Z
EpiK-Eval: Evaluation for Language Models as Epistemic Models,Yes.,5.,"""Evaluations across various LLMs reveal significant weaknesses in this domain.""",2023-10-23T21:15:54Z
"Why LLMs Hallucinate, and How to Get (Evidential) Closure: Perceptual, Intensional, and Extensional Learning for Faithful Natural Language Generation",Yes.,5.,"""We show that LLMs hallucinate because their output is not constrained to be synonymous with claims for which they have evidence",2023-10-23T20:35:52Z
Moral Foundations of Large Language Models,Yes.,4.,"""they may reflect the biases that are present in such corpora"" and ""illustrate the potential risks and unintended consequences of LLMs assuming a particular moral stance.""",2023-10-23T20:05:37Z
Towards Possibilities & Impossibilities of AI-generated Text Detection: A Survey,,,,2023-10-23T18:11:32Z
Verb Conjugation in Transformers Is Determined by Linear Encodings of Subject Number,Yes.,1.,"""Deep architectures such as Transformers are sometimes criticized for having uninterpretable 'black-box' representations.""",2023-10-23T17:53:47Z
"S3Eval: A Synthetic, Scalable, Systematic Evaluation Suite for Large Language Models",Yes.,5.,"""it becomes more challenging to evaluate whether they have acquired certain capabilities, since the length of text (e.g., 200K tokens) they can process far exceeds what humans can reliably assess in a reasonable duration."" and ""experimental results have shown that it poses significant challenges for all existing LLMs.""",2023-10-23T17:52:06Z
Causal Inference Using LLM-Guided Discovery,Yes.,3.,"""Acknowledging LLMs' limitations, we also study possible techniques to integrate LLMs with established causal discovery algorithms, including constraint-based and score-based methods, to enhance their performance.""",2023-10-23T17:23:56Z
Federated Learning of Large Language Models with Parameter-Efficient Prompt Tuning and Adaptive Optimization,Yes.,3.,"""the training process of Large Language Models (LLMs) generally incurs the update of significant parameters, which limits the applicability of FL techniques to tackle the LLMs in real scenarios."" and ""the decentralized data is generally non-Independent and Identically Distributed (non-IID), which",2023-10-23T16:37:59Z
Did the Neurons Read your Book? Document-level Membership Inference for Large Language Models,Yes.,3.,"""questions are starting to be raised about the dataset(s) they learned from. These questions range from potential bias or misinformation LLMs could retain from their training data to questions of copyright and fair use of human-generated text.""",2023-10-23T15:00:46Z
Towards LLM-driven Dialogue State Tracking,Yes.,5.,"""Despite its impressive performance, ChatGPT has significant limitations including its closed-source nature, request restrictions, raising data privacy concerns, and lacking local deployment capabilities.""",2023-10-23T14:15:28Z
Assessing Step-by-Step Reasoning against Lexical Negation: A Case Study on Syllogism,Yes.,5.,"""We observed that dozens of modern LLMs were not robust against lexical negation (e.g., plausible ->implausible) when performing CoT-style reasoning, and the results highlight unique limitations in each LLM family.""",2023-10-23T12:40:41Z
Contextual Refinement of Translations: Large Language Models for Sentence and Document-Level Post-Editing,Yes.,3.,"""Surprisingly, our initial experiments find that fine-tuning for translation purposes even led to performance degradation.""",2023-10-23T12:22:15Z
ALCUNA: Large Language Models Meet New Knowledge,Yes.,5.,"""We benchmark several LLMs, reveals that their performance in face of new knowledge is not satisfactory, particularly in reasoning between new and internal knowledge.""",2023-10-23T11:40:05Z
Analyzing Multilingual Competency of LLMs in Multi-Turn Instruction Following: A Case Study of Arabic,Yes.,2.,"""there is a lack of comprehensive evaluation of their abilities in responding to multi-turn instructions in less-commonly tested languages like Arabic.""",2023-10-23T11:40:04Z
Cross-lingual Prompting: Improving Zero-shot Chain-of-Thought Reasoning across Languages,Yes.,2.,"""Despite the success of zero-shot CoT, the existing zero-shot prompting techniques remain limited to a single language, making it challenging to generalize to other languages and hindering global development.""",2023-10-23T10:56:03Z
Evaluating the Knowledge Base Completion Potential of GPT,Yes.,5.,"""We find that, despite their size and capabilities, models like GPT-3, ChatGPT and GPT-4 do not achieve fully convincing results on this task.""",2023-10-23T10:15:13Z
"A Survey on LLM-generated Text Detection: Necessity, Methods, and Future Directions",Yes.,4.,"""We also delve into prevalent datasets, elucidating their limitations and developmental requirements. Furthermore, we analyze various LLM-generated text detection paradigms, shedding light on challenges like out-of-distribution problems, potential attacks, and data ambiguity.""",2023-10-23T09:01:13Z
Establishing Vocabulary Tests as a Benchmark for Evaluating Large Language Models,Yes.,4.,"""We evaluate seven LLMs using two vocabulary test formats across two languages and uncover surprising gaps in their lexical knowledge.""",2023-10-23T08:45:12Z
Reasoning about Ambiguous Definite Descriptions,Yes.,3.,"""But no resources exist to evaluate how well Large Language Models can use explicit reasoning to resolve ambiguity in language."" and ""We find this to be a challenging task for recent LLMs.""",2023-10-23T07:52:38Z
Conversational Recommender System and Large Language Model Are Made for Each Other in E-commerce Pre-sales Dialogue,Yes.,3.,"""Large language models (LLMs) generate responses that mimic pre-sales dialogues after fine-tuning, but lack domain-specific knowledge for accurate recommendations.""",2023-10-23T07:00:51Z
Confronting LLMs with Traditional ML: Rethinking the Fairness of Large Language Models in Tabular Classifications,Yes.,5.,"""LLMs have been shown to exhibit harmful social biases that reflect the stereotypes and inequalities present in society,"" ""LLMs tend to inherit social biases from their training data which significantly impact their fairness in tabular classification tasks,"" and ""the fairness metric gap between different subgroups is still larger than that in traditional machine learning models.""",2023-10-23T06:31:28Z
Large Search Model: Redefining Search Stack in the Era of LLMs,Yes.,2.,"""we present a series of proof-of-concept experiments and discuss the potential challenges associated with implementing this approach within real-world search systems.""",2023-10-23T05:52:09Z
"Language Models Hallucinate, but May Excel at Fact Verification",Yes.,5.,"""Nevertheless, LLMs frequently 'hallucinate,' resulting in non-factual outputs. Our carefully-designed human evaluation substantiates the serious hallucination issue, revealing that even GPT-3.5 produces factual outputs less than 25% of the time.""",2023-10-23T04:39:01Z
The Skipped Beat: A Study of Sociopragmatic Understanding in LLMs for 64 Languages,Yes.,5.,"""Our comprehensive analysis reveals that existing open-source instruction tuned LLMs still struggle to understand SM across various languages, performing close to a random baseline in some cases. We also find that although ChatGPT outperforms many LLMs, it still falls behind task",2023-10-23T04:22:44Z
Evaluating Large Language Models on Controlled Generation Tasks,Yes.,5.,"""We conclude that large language models struggle at meeting fine-grained hard constraints.""",2023-10-23T03:48:24Z
QUDEVAL: The Evaluation of Questions Under Discussion Discourse Parsing,Yes.,3.,"""Using QUDeval, we show that satisfying all constraints of QUD is still challenging for modern LLMs, and that existing evaluation metrics poorly approximate parser quality.""",2023-10-23T03:03:58Z
Retrieval-Augmented Chain-of-Thought in Semi-structured Domains,Yes.,5.,"""their inability to handle very long inputs/contexts is well known.""",2023-10-22T22:45:14Z
Large Language Models are biased to overestimate profoundness,Yes.,5.,"""LLMs systematically overestimate the profoundness of nonsensical statements,"" and ""provides insights into the potential biases induced by Reinforcement Learning from Human Feedback (RLHF), inducing an increase in the bias to overestimate the profoundness of statements.""",2023-10-22T21:33:50Z
Monte Carlo Thought Search: Large Language Model Querying for Complex Scientific Reasoning in Catalyst Design,Yes.,1.,"""While large language models (LLM) have demonstrated novel capabilities for chemistry through complex instruction following capabilities and high quality reasoning, a goal-driven combinatorial search using LLMs has not been explored in detail.""",2023-10-22T21:29:33Z
Towards Harmful Erotic Content Detection through Coreference-Driven Contextual Analysis,Yes.,4.,"""Ethical restrictions prohibit large language models (LLMs) from analyzing and classifying harmful erotics, let alone generating them to create synthetic datasets for other neural models.""",2023-10-22T15:19:04Z
Chainpoll: A high efficacy method for LLM hallucination detection,Yes.,5.,"""hallucinations - incorrect or unfounded claims - are still prevalent,"" and ""we assessed tasks and datasets from previous hallucination detection studies and observed that many are not suitable for the potent LLMs currently in use.""",2023-10-22T14:45:14Z
Language Model Unalignment: Parametric Red-Teaming to Expose Hidden Harms and Biases,Yes.,5.,"""Bypassing the guardrails uncovers hidden harmful information and biases in the model that are left untreated or newly introduced by its safety training,"" and ""Unalignment exposes inherent biases in safety-aligned models such as CHATGPT and LLAMA-2-CHAT where the model's responses are strongly biased and opinionated 64% of the time.""",2023-10-22T13:55:46Z
NERetrieve: Dataset for Next Generation Named Entity Recognition and Retrieval,Yes.,3.,"""the capabilities provided by LLMs are not the end of NER research, but rather an exciting beginning."" and ""We show that all of these are far from being solved.""",2023-10-22T12:23:00Z
From Static to Dynamic: A Continual Learning Framework for Large Language Models,Yes.,4.,"""However, this complexity also presents challenges, making LLMs difficult to train and inhibiting their ability to continuously assimilate new knowledge, which may lead to inaccuracies in their outputs.""",2023-10-22T10:18:53Z
CXR-LLAVA: a multimodal large language model for interpreting chest X-ray images,Yes.,3.,"""This study highlights the significant potential of multimodal LLMs for CXR interpretation, while also acknowledging the performance limitations.""",2023-10-22T06:22:37Z
PromptCBLUE: A Chinese Prompt Tuning Benchmark for the Medical Domain,Yes.,2.,"""most current benchmarks",2023-10-22T02:20:38Z
Learning Reward for Physical Skills using Large Language Model,Yes.,3.,"""the direct application of LLMs for proposing reward functions has its limitations such as numerical instability and inability to incorporate the environment feedback.""",2023-10-21T19:10:06Z
MOELoRA: An MOE-based Parameter Efficient Fine-Tuning Method for Multi-task Medical Applications,Yes.,4.,"""However, two issues arise during fine-tuning LLMs for medical applications. The first is the problem of task variety, where there are numerous distinct tasks in real-world medical scenarios. This diversity often results in suboptimal fine-tuning due to data imbalance and seesawing problems. Additionally, the high cost of fine-tuning can be prohibitive, impeding the application of",2023-10-21T17:18:09Z
Beyond Accuracy: Evaluating Self-Consistency of Code Large Language Models with IdentityChain,Yes.,5.,"""We study eleven Code LLMs and show that they fail to preserve self-consistency, which is indeed a distinct aspect from conventional accuracy. Furthermore, we show that IdentityChain can be used as a model debugging tool to expose weaknesses of Code LLMs by demonstrating three major weaknesses that",2023-10-21T16:14:56Z
LLM-Prop: Predicting Physical And Electronic Properties Of Crystalline Solids From Their Text Descriptions,Yes.,1.,"""We then propose LLM-Prop, a method that leverages the general-purpose learning capabilities of large language models (LLMs) to predict the physical and electronic properties of crystals from their text descriptions.""",2023-10-21T14:49:58Z
On Bilingual Lexicon Induction with Large Language Models,,,,2023-10-21T12:43:27Z
GEMBA-MQM: Detecting Translation Quality Error Spans with GPT-4,Yes.,3.,"""we advise caution when using it in academic works to demonstrate improvements over other methods due to its dependence on the proprietary, black-box GPT model.""",2023-10-21T12:30:33Z
HateRephrase: Zero- and Few-Shot Reduction of Hate Intensity in Online Posts using Large Language Models,Yes.,3.,"""We also perform human evaluations and interestingly, find that the rephrasings generated by GPT-3.5 outperform even the human-generated ground-truth rephrasings in the dataset. We also conduct detailed ablation studies to investigate why LLM",2023-10-21T12:18:29Z
Ensemble-Instruct: Generating Instruction-Tuning Data with a Heterogeneous Mixture of LMs,Yes.,3.,"""One limitation of these approaches is that they resort to very large language models (around 175B parameters) that are also proprietary and non-public.""",2023-10-21T10:21:17Z
Copyright Violations and Large Language Models,,,,2023-10-20T19:14:59Z
Long-Form Speech Translation through Segmentation with Finite-State Decoding Constraints on Large Language Models,Yes.,3.,"""We overcome the tendency of hallucination in LLMs by incorporating finite-state constraints during decoding; these eliminate invalid outputs without requiring additional training.""",2023-10-20T17:31:39Z
Let's Synthesize Step by Step: Iterative Dataset Synthesis with Large Language Models by Extrapolating Errors from Small Models,Yes.,3.,"""However, a key challenge in data synthesis is that the synthesized dataset often suffers from a large distributional discrepancy from the real task data distribution.""",2023-10-20T17:14:25Z
Benchmarking and Improving Text-to-SQL Generation under Ambiguity,Yes.,3.,"""We evaluate several Text-to-SQL systems and decoding algorithms, including those employing state-of-the-art LLMs, and find them to be far from this ideal.""",2023-10-20T17:00:53Z
BotChat: Evaluating LLMs' Capabilities of Having Multi-Turn Dialogues,Yes.,4.,"""other LLMs struggle to generate multi-turn dialogues of satisfactory quality due to poor instruction-following capability, tendency to generate lengthy utterances, or limited general capability.""",2023-10-20T16:53:51Z
Three Questions Concerning the Use of Large Language Models to Facilitate Mathematics Learning,Yes.,5.,"""Apart from generating the wrong reasoning processes, LLMs can misinterpret the meaning of the question, and also exhibit difficulty in understanding the given questions' rationales when attempting to correct students' answers.""",2023-10-20T16:05:35Z
A Simple Baseline for Knowledge-Based Visual Question Answering,Yes.,2.,"""A common limitation of such approaches is that they consist of relatively complicated pipelines and often heavily rely on accessing GPT-3 API.""",2023-10-20T15:08:17Z
Self-prompted Chain-of-Thought on Large Language Models for Open-domain Multi-hop Reasoning,Yes.,3.,"""existing automated methods lack of quality assurance, while manual approaches suffer from limited scalability and poor diversity, hindering the capabilities of LLMs.""",2023-10-20T14:51:10Z
The Perils & Promises of Fact-checking with Large Language Models,Yes.,3.,"""Understanding the capacities and limitations of LLMs in fact-checking tasks is therefore essential for ensuring the health of our information ecosystem."" and ""While LLMs show promise in fact-checking, caution is essential due to inconsistent accuracy.""",2023-10-20T14:49:47Z
She had Cobalt Blue Eyes: Prompt Testing to Create Aligned and Sustainable Language Models,Yes.,4.,"""Recent events indicate ethical concerns around conventionally trained LLMs, leading to overall unsafe user experiences."" and ""The assessment presented in this paper highlights a gap between societal alignment and the capabilities of current LLMs.""",2023-10-20T14:18:40Z
Teaching Language Models to Self-Improve through Interactive Demonstrations,Yes.,3.,"""this ability has been shown to be absent and difficult to learn for smaller models, thus widening the performance gap between state-of-the-art LLMs and more cost-effective and faster ones.""",2023-10-20T14:11:04Z
Steering Large Language Models for Machine Translation with Finetuning and In-Context Learning,Yes.,5.,"""current LLM-based MT systems are brittle",2023-10-20T12:29:51Z
Self-Consistency of Large Language Models under Ambiguity,Yes.,5.,"""Large language models (LLMs) that do not give consistent answers across contexts are problematic when used for tasks with expectations of consistency,"" and ""we find that models are uncalibrated when judging their own consistency, with models displaying both over- and under-confidence.""",2023-10-20T11:57:56Z
POSQA: Probe the World Models of LLMs with Size Comparisons,Yes.,5.,"""We show that even the largest LLMs today perform poorly under the zero-shot setting,"" and ""Our results show that real-world understanding that LLMs shaped from textual data can be vulnerable to deception and confusion by the surface form of prompts, which makes it less aligned with human behaviours.""",2023-10-20T10:05:01Z
Challenges and Contributing Factors in the Utilization of Large Language Models (LLMs),Yes.,5.,"""This review initially explores the issue of domain specificity, where LLMs may struggle to provide precise answers to specialized questions within niche fields. The problem of knowledge forgetting arises as these LLMs might find it hard to balance old and new information. The knowledge repetition phenomenon reveals that sometimes LLMs might deliver overly mechanized responses, lacking depth and originality. Furthermore, knowledge illusion describes",2023-10-20T08:13:36Z
Democratizing Reasoning Ability: Tailored Learning from Large Language Model,Yes.,3.,"""Large language models (LLMs) exhibit impressive emergent abilities in natural language processing, but their democratization is hindered due to huge computation requirements and closed-source nature.""",2023-10-20T07:50:10Z
Test-Time Self-Adaptive Small Language Models for Question Answering,Yes.,3.,"""they might be suboptimal on specific tasks due to their limited capacity to transfer and adapt knowledge to target tasks.""",2023-10-20T06:49:32Z
MoqaGPT : Zero-Shot Multi-modal Open-domain Question Answering with Large Language Model,Yes.,3.,"""Even Large Language Models (LLMs) like GPT-4 fall short in this task.""",2023-10-20T04:09:36Z
Steve-Eye: Equipping LLM-based Embodied Agents with Visual Perception in Open Worlds,Yes.,5.,"""However, these efforts tend to overlook the visual richness of open worlds, rendering the entire interactive process akin to 'a blindfolded text-based game.' Consequently, LLM-based agents frequently encounter challenges in intuitively comprehending their surroundings and producing responses that are easy to understand.""",2023-10-20T03:22:05Z
Towards Robust Pruning: An Adaptive Knowledge-Retention Pruning Strategy for Language Models,Yes.,3.,"""existing methods struggle to enhance robustness against adversarial attacks when continually increasing model sparsity and require a retraining process.""",2023-10-19T23:02:29Z
Auto-Instruct: Automatic Instruction Generation and Ranking for Black-Box Language Models,Yes.,3.,"""Unfortunately, the performance of LLMs is greatly influenced by the quality of these instructions, and manually writing effective instructions for each task is a laborious and subjective process.""",2023-10-19T19:52:55Z
CLAIR: Evaluating Image Captions with Large Language Models,Yes.,1.,"""we propose CLAIR, a novel method that leverages the zero-shot language modeling capabilities of large language models (LLMs) to evaluate candidate captions.""",2023-10-19T17:59:01Z
Luminate: Structured Generation and Exploration of Design Space with Large Language Models for Human-AI Co-Creation,Yes.,3.,"""We argue that current interaction paradigms fall short, guiding users towards rapid convergence on a limited set of ideas, rather than empowering them to explore the vast latent design space in generative models.""",2023-10-19T17:53:14Z
StoryAnalogy: Deriving Story-level Analogies from Large Language Models to Unlock Analogical Understanding,Yes.,5.,"""Interestingly, we find that the analogy identification tasks are incredibly difficult not only for sentence embedding models but also for the recent large language models (LLMs) such as ChatGPT and LLaMa.""",2023-10-19T16:29:23Z
Probing LLMs for hate speech detection: strengths and vulnerabilities,Yes.,4.,"""we further provide a typology of the error cases where these large language models fail to (i) classify and (ii) explain the reason for the decisions they take. Such vulnerable points automatically constitute 'jailbreak' prompts for these models and industry scale safeguard techniques need to be developed to make the models robust against such prompts.""",2023-10-19T16:11:02Z
AgentTuning: Enabling Generalized Agent Abilities for LLMs,Yes.,3.,"""However, they are far inferior to commercial models such as ChatGPT and GPT-4 when acting as agents to tackle complex tasks in the real world.""",2023-10-19T15:19:53Z
Prompt Injection Attacks and Defenses in LLM-Integrated Applications,Yes.,4.,"""Multiple recent works showed that LLM-Integrated Applications are vulnerable to prompt injection attacks, in which an attacker injects malicious instruction/data into the input of those applications such that they produce results as the attacker desires.""",2023-10-19T15:12:09Z
Are Structural Concepts Universal in Transformer Language Models? Towards Interpretable Cross-Lingual Generalization,Yes.,4.,"""However, the transfer is not equally successful for all languages, especially for low-resource ones, which poses an ongoing challenge.""",2023-10-19T14:50:51Z
Safe RLHF: Safe Reinforcement Learning from Human Feedback,Yes.,4.,"""the inherent tension between the objectives of helpfulness and harmlessness presents a significant challenge during LLM training"" and ""We formalize the safety concern of LLMs as an optimization task of maximizing the reward function while satisfying specified cost constraints.""",2023-10-19T14:22:03Z
Exploring Large Language Models as a Source of Common-Sense Knowledge for Robots,Yes.,3.,"""Our experiments reveal limited effectiveness in the selective extraction of contextual action knowledge, suggesting that LLMs may not be sufficient on their own.""",2023-10-19T14:20:30Z
TabuLa: Harnessing Language Models for Tabular Data Synthesis,Yes.,3.,"""However, their long training time and limited re-usability on new tasks prevent them from replacing exiting tabular generative models."" and ""Through Tabula, we demonstrate the inherent limitation of employing pre-trained language models designed for natural language processing (NLP) in the context of tabular data synthesis.""",2023-10-19T13:50:56Z
Large Language Models Help Humans Verify Truthfulness -- Except When They Are Convincingly Wrong,Yes.,5.,"""However, they over-rely on the LLMs when the explanation is wrong."" and ""Taken together, our study highlights that natural language explanations by LLMs may not be a reliable replacement for reading the retrieved passages, especially in high-stakes settings where over-relying on wrong AI explanations could lead to critical consequences.""",2023-10-19T08:09:58Z
Product Attribute Value Extraction using Large Language Models,Yes.,3.,"""State-of-the-art attribute/value extraction methods based on pre-trained language models (PLMs), such as BERT, face two drawbacks (i) the methods require significant amounts of task-specific training data and (ii) the fine-tuned models have problems to generalize to attribute values that were not part of the training data.""",2023-10-19T07:39:00Z
Automatic Hallucination Assessment for Aligned Large Language Models via Transferable Adversarial Attacks,Yes.,5.,"""Our experimental results show that LLMs are likely to hallucinate in two categories of question-answering scenarios where (1) there are conflicts between knowledge given in the prompt and their parametric knowledge, or (2) the knowledge expressed in the prompt is complex.""",2023-10-19T06:37:32Z
Attack Prompt Generation for Red Teaming and Defending Large Language Models,Yes.,4.,"""Large language models (LLMs) are susceptible to red teaming attacks, which can induce LLMs to generate harmful content.""",2023-10-19T06:15:05Z
Not All Countries Celebrate Thanksgiving: On the Cultural Dominance in Large Language Models,Yes.,5.,"""This paper identifies a cultural dominance issue within large language models (LLMs) due to the predominant use of English data in model training"" and ""Our study emphasizes the need to critically examine cultural dominance and ethical consideration in their development and deployment.""",2023-10-19T05:38:23Z
Contrastive Learning for Inference in Dialogue,Yes.,5.,"""While recent large language models show remarkable advances in inference tasks, their performance in inductive reasoning, where not all information is present in the context, is far behind deductive reasoning.""",2023-10-19T04:49:36Z
"Know Where to Go: Make LLM a Relevant, Responsible, and Trustworthy Searcher",Yes.,5.,"""challenges arise in validating the reliability of generated results and the credibility of contributing sources, due to the limitations of traditional information retrieval algorithms and the LLM hallucination problem.""",2023-10-19T03:49:36Z
PoisonPrompt: Backdoor Attack on Prompt-based Large Language Models,Yes.,4.,"""However, the backdoor vulnerability, a serious security threat that can maliciously alter the victim model's normal predictions, has not been sufficiently explored for prompt-based LLMs.""",2023-10-19T03:25:28Z
Automated Repair of Declarative Software Specifications in the Era of Large Language Models,Yes.,5.,"""Our study revealed that while ChatGPT falls short in comparison to existing techniques, it was able to successfully repair bugs that no other technique could address. Our analysis also identified errors in ChatGPT's generated repairs, including improper operator usage, type errors, higher-order logic misuse, and relational arity mismatches. Additionally, we observed instances of hallucinations in ChatGPT-generated repairs and incons",2023-10-19T02:30:42Z
GPT-4 Doesn't Know It's Wrong: An Analysis of Iterative Prompting for Reasoning Problems,Yes.,5.,"""The study seems to indicate that (i) LLMs are bad at solving graph coloring instances (ii) they are no better at verifying a solution--and thus are not effective in iterative modes with LLMs critiquing LLM-generated solutions (iii) the correctness and content of the criticisms--whether by LLMs or external solvers--seems largely irrelevant to",2023-10-19T00:56:37Z
FactCHD: Benchmarking Fact-Conflicting Hallucination Detection,Yes.,5.,"""Despite their impressive generative capabilities, LLMs are hindered by fact-conflicting hallucinations in real-world applications."" and ""Experiments on different LLMs expose the shortcomings of current approaches in detecting factual errors accurately.""",2023-10-18T16:27:49Z
SPEED: Speculative Pipelined Execution for Efficient Decoding,Yes.,5.,"""Nevertheless, their application in real-time scenarios has been highly restricted due to the significant inference latency associated with these models. This is particularly pronounced due to the autoregressive nature of generative LLM inference, where tokens are generated sequentially since each token depends on all previous output tokens. It is therefore challenging to achieve any token-level parallelism, making inference extremely memory-bound.""",2023-10-18T16:07:01Z
LoHoRavens: A Long-Horizon Language-Conditioned Benchmark for Robotic Tabletop Manipulation,,,,2023-10-18T14:53:14Z
Improving Generalization of Alignment with Human Preferences through Group Invariant Learning,Yes.,3.,"""However, previous work shows that Reinforcement Learning (RL) often exploits shortcuts to attain high rewards and overlooks challenging samples. This focus on quick reward gains undermines both the stability in training and the model's ability to generalize to new, unseen data.""",2023-10-18T13:54:15Z
Emptying the Ocean with a Spoon: Should We Edit Models?,Yes.,5.,"""We call into question the recently popularized method of direct model editing as a means of correcting factual errors in LLM generations."" and ""We argue that direct model editing cannot be trusted as a systematic remedy for the disadvantages inherent to LLMs, and while it has proven potential in improving model explainability,",2023-10-18T13:38:03Z
The Curious Case of Hallucinatory (Un)answerability: Finding Truths in the Hidden States of Over-Confident Large Language Models,Yes.,5.,"""Large language models (LLMs) have been shown to possess impressive capabilities, while also raising crucial concerns about the faithfulness of their responses. A primary issue arising in this context is the management of (un)answerable queries by LLMs, which often results in hallucinatory behavior due to overconfidence.""",2023-10-18T11:01:09Z
Enhancing Genetic Improvement Mutations Using Large Language Models,Yes.,3.,"""We find that the number of patches passing unit tests is up to 75% higher with LLM-based edits than with standard Insert edits. Further, we observe that the patches found with LLMs are generally less diverse compared to standard edits.""",2023-10-18T10:24:14Z
Solving the multiplication problem of a large language model system using a graph-based method,Yes.,5.,"""The generative pre-trained transformer (GPT)-based chatbot software ChatGPT possesses excellent natural language processing capabilities but is inadequate for solving arithmetic problems, especially multiplication.""",2023-10-18T08:02:00Z
Telecom AI Native Systems in the Age of Generative AI -- An Engineering Perspective,Yes.,2.,"""Despite the enormous potential of FMs, ethical, regulatory, and operational challenges require careful consideration, especially in mission-critical telecom contexts.""",2023-10-18T07:55:54Z
MISAR: A Multimodal Instructional System with Augmented Reality,Yes.,1.,"""the potential of large language models (LLMs) in this landscape remains largely untapped.""",2023-10-18T04:15:12Z
SOTOPIA: Interactive Evaluation for Social Intelligence in Language Agents,Yes.,5.,"""We find that on this subset, GPT-4 achieves a significantly lower goal completion rate than humans and struggles to exhibit social commonsense reasoning and strategic communication skills.""",2023-10-18T02:27:01Z
Systematic Assessment of Factual Knowledge in Large Language Models,Yes.,4.,"""this approach has limitations regarding factual knowledge coverage,"" and ""We also find that LLMs performance depends on the instruction finetuning, domain and question complexity and is prone to adversarial context.""",2023-10-18T00:20:50Z
MAGNIFICo: Evaluating the In-Context Learning Ability of Large Language Models to Generalize to Novel Interpretations,Yes.,4.,"""Large Language Models (LLMs) have a knowledge cutoff and are costly to finetune repeatedly."" and ""our findings also highlight the need for further improvements, particularly when interpreting unfamiliar words or when composing multiple novel interpretations simultaneously in the same example."" and ""our analysis uncovers the semantic predispositions in LLMs and reveals the impact of recency bias for information presented in long",2023-10-18T00:02:38Z
Language Models as Zero-Shot Trajectory Generators,Yes.,3.,"""However, it is often assumed that LLMs do not possess sufficient knowledge to be used for the low-level trajectories themselves.""",2023-10-17T21:57:36Z
Automated Evaluation of Personalized Text Generation using Large Language Models,Yes.,2.,"""even though interesting new challenges still remain.""",2023-10-17T21:35:06Z
Personalized Soups: Personalized Large Language Model Alignment via Post-hoc Parameter Merging,Yes.,2.,"""While Reinforcement Learning from Human Feedback (RLHF) aligns Large Language Models (LLMs) with general, aggregate human preferences, it is suboptimal for learning diverse, individual perspectives.""",2023-10-17T20:22:13Z
"Self-RAG: Learning to Retrieve, Generate, and Critique through Self-Reflection",Yes.,5.,"""Despite their remarkable capabilities, large language models (LLMs) often produce responses containing factual inaccuracies due to their sole reliance on the parametric knowledge they encapsulate.""",2023-10-17T18:18:32Z
CoMPosT: Characterizing and Evaluating Caricature in LLM Simulations,Yes.,4.,"""there is growing concern that these LLM simulations are flattened caricatures of the personas that they aim to simulate, failing to capture the multidimensionality of people and perpetuating stereotypes.""",2023-10-17T18:00:25Z
Large Language Model Prediction Capabilities: Evidence from a Real-World Forecasting Tournament,Yes.,5.,"""GPT-4's probabilistic forecasts are significantly less accurate than the median human-crowd forecasts,"" and ""GPT-4 significantly underperforms in real-world predictive tasks compared to median human-crowd forecasts.""",2023-10-17T17:58:17Z
"Last One Standing: A Comparative Analysis of Security and Privacy of Soft Prompt Tuning, LoRA, and In-Context Learning",Yes.,4.,"""LLMs often require adaptation with private data, which poses privacy and security challenges."" and ""there is no silver bullet for privacy and security in LLM adaptation and each technique has different strengths and weaknesses.""",2023-10-17T17:03:00Z
DialogueLLM: Context and Emotion Knowledge-Tuned Large Language Models for Emotion Recognition in Conversations,Yes.,4.,"""Despite their remarkable performance in natural language generating (NLG), LLMs lack a distinct focus on the emotion understanding domain. As a result, using LLMs for emotion recognition may lead to suboptimal and inadequate precision. Another limitation of LLMs is that they are typically trained without leveraging multi-modal information.""",2023-10-17T16:15:34Z
Quantifying Language Models' Sensitivity to Spurious Features in Prompt Design or: How I learned to start worrying about prompt formatting,Yes.,5.,"""We find that several widely used open-source LLMs are extremely sensitive to subtle changes in prompt formatting in few-shot settings, with performance differences of up to 76 accuracy points when evaluated using LLaMA-2-13B.""",2023-10-17T15:03:30Z
Utilising a Large Language Model to Annotate Subject Metadata: A Case Study in an Australian National Research Data Catalogue,Yes.,3.,"""models based on in-context learning cannot acquire discipline-specific rules, resulting in lower performance in several categories. This limitation arises from the limited contextual information available for subject inference.""",2023-10-17T14:52:33Z
Generative error correction for code-switching speech recognition using large language models,,,,2023-10-17T14:49:48Z
Revealing the Unwritten: Visual Investigation of Beam Search Trees to Address Language Model Prompting Challenges,Yes.,4.,"""We identify several challenges associated with prompting large language models, categorized into data- and model-specific, linguistic, and socio-linguistic challenges.""",2023-10-17T13:20:16Z
Entity Matching using Large Language Models,Yes.,3.,"""Two major drawbacks of these models for entity matching are that (i) the models require significant amounts of task-specific training data and (ii) the fine-tuned models are not robust concerning out-of-distribution entities.""",2023-10-17T13:12:32Z
Watermarking LLMs with Weight Quantization,Yes.,1.,"""Abuse of large language models reveals high risks as large language models are being deployed at an astonishing speed.""",2023-10-17T13:06:59Z
The Quo Vadis of the Relationship between Language and Large Language Models,Yes.,4.,"""it is not clear that they are in a place to offer insights into the target system they seek to represent"" and ""the most important theoretical and empirical risks brought about by the adoption of scientific models that lack transparency.""",2023-10-17T10:54:24Z
H2O Open Ecosystem for State-of-the-art Large Language Models,Yes.,4.,"""However, they also pose many significant risks, such as the presence of biased, private, copyrighted or harmful text.""",2023-10-17T09:40:58Z
Learning from Red Teaming: Gender Bias Provocation and Mitigation in Large Language Models,Yes.,4.,"""These LLM-based chatbots encode the potential biases while retaining disparities that can harm humans during interactions.""",2023-10-17T08:56:04Z
Denevil: Towards Deciphering and Navigating the Ethical Values of Large Language Models via Instruction Learning,Yes.,4.,"""Large Language Models (LLMs) have made unprecedented breakthroughs, yet their increasing integration into everyday life might raise societal risks due to generated unethical content."" and ""We discovered that most models are essentially misaligned, necessitating further ethical value alignment.""",2023-10-17T07:42:40Z
Core Building Blocks: Next Gen Geo Spatial GPT Application,Yes.,1.,"""This paper proposes MapGPT which is a novel approach that integrates the capabilities of language models, specifically large language models (LLMs), with spatial data processing techniques.""",2023-10-17T06:59:31Z
Exploring Automatic Evaluation Methods based on a Decoder-based LLM for Text Generation,Yes.,5.,"""Experimental results show that compared to the tuned encoder-based models, the tuned decoder-based models perform poorly. The analysis of the causes for this suggests that the decoder-based models focus on surface word sequences and do not capture meaning. It is also revealed that in-context learning of very large decoder-based models such",2023-10-17T06:53:00Z
EXMODD: An EXplanatory Multimodal Open-Domain Dialogue dataset,Yes.,3.,"""Automatic data generation through large models is a cost-effective method, but for open-domain multimodal dialogue tasks, there are still three drawbacks",2023-10-17T03:28:29Z
Semantic-Aware Contrastive Sentence Representation Learning with Large Language Models,Yes.,2.,"""Unfortunately, acquiring sufficient high-quality labeled data can be both time-consuming and resource-intensive, leading researchers to focus on developing methods for learning unsupervised sentence representations.""",2023-10-17T03:21:43Z
NuclearQA: A Human-Made Benchmark for Language Models for the Nuclear Domain,Yes.,4.,"""Our experiments on state-of-the-art models suggest that even the best LLMs perform less than satisfactorily on our benchmark, demonstrating the scientific knowledge gap of existing LLMs.""",2023-10-17T01:27:20Z
Unlocking Emergent Modularity in Large Language Models,Yes.,3.,"""Despite the benefits of modularity, most Language Models (LMs) are still treated as monolithic models in the pre-train and fine-tune paradigm, with their emergent modularity locked and underutilized.""",2023-10-17T01:02:32Z
Fake News in Sheep's Clothing: Robust Fake News Detection Against LLM-Empowered Style Attacks,Yes.,3.,"""LLM-camouflaged fake news content leads to substantial performance degradation of state-of-the-art text-based detectors (up to 38% decrease in F1 Score), posing a significant challenge for automated detection in online ecosystems.""",2023-10-16T21:05:12Z
Vision and Language Navigation in the Real World via Online Visual Language Mapping,Yes.,1.,"""an LLMs-based instruction parser that converts the language instruction into a sequence of pre-defined macro-action descriptions.""",2023-10-16T20:44:09Z
Towards reducing hallucination in extracting information from financial reports using Large Language Models,Yes.,3.,"""extracting valuable insights from the Q\&A section has posed considerable challenges as the conventional methods such as detailed reading and note-taking lack scalability and are susceptible to human errors, and Optical Character Recognition (OCR) and similar techniques encounter difficulties in accurately processing unstructured transcript text, often missing subtle linguistic",2023-10-16T18:45:38Z
Bridging the Novice-Expert Gap via Models of Decision-Making: A Case Study on Remediating Math Mistakes,Yes.,2.,"""We evaluate state-of-the-art LLMs on our dataset and find that the expert's decision-making model is critical for LLMs to close the gap",2023-10-16T17:59:50Z
LLM Blueprint: Enabling Text-to-Image Generation with Complex and Detailed Prompts,Yes.,3.,"""The initial Global Scene Generation utilizes object layouts and background context to create an initial scene but often falls short in faithfully representing object characteristics as specified in the prompts. To address this limitation, we introduce an Iterative Refinement Scheme that iteratively evaluates and refines box-level content to align them with their textual descriptions, recomposing objects as needed to ensure consistency.""",2023-10-16T17:57:37Z
"""Mistakes Help Us Grow"": Facilitating and Evaluating Growth Mindset Supportive Language in Classrooms",Yes.,1.,"""We explore whether large language models (LLMs) can provide automated, personalized coaching to support teachers' use of GMSL.""",2023-10-16T17:56:07Z
BioPlanner: Automatic Evaluation of LLMs on Protocol Planning in Biology,Yes.,5.,"""However, LLMs can struggle with multi-step problems and long-term planning, which are crucial for designing scientific experiments.""",2023-10-16T17:54:20Z
Data Contamination Through the Lens of Time,Yes.,5.,"""Data contamination remains notoriously challenging to measure and mitigate,"" and ""we conduct the first thorough longitudinal analysis of data contamination in LLMs.""",2023-10-16T17:51:29Z
Factored Verification: Detecting and Reducing Hallucination in Summaries of Academic Papers,Yes.,5.,"""Hallucination plagues even frontier LLMs"" and ""We ask models to self-correct using Factored Critiques and find that this lowers the number of hallucinations to 0.49 for ChatGPT, 0.46 for GPT-4, and",2023-10-16T17:51:17Z
On Context Utilization in Summarization with Large Language Models,Yes.,5.,"""However, in question answering, language models exhibit uneven utilization of their input context. They tend to favor the initial and final segments, resulting in a U-shaped performance pattern concerning where the answer is located within the input. This bias raises concerns, particularly in summarization where crucial content may be dispersed throughout the source",2023-10-16T16:45:12Z
Metric Ensembles For Hallucination Detection,Yes.,2.,"""One of the most pressing problems related to generation of abstractive summaries is the need to reduce 'hallucinations,' information that was not included in the document being summarized, and which may be wholly incorrect.""",2023-10-16T15:17:22Z
Gaining Wisdom from Setbacks: Aligning Large Language Models via Mistake Analysis,Yes.,4.,"""This becomes particularly evident when LLMs inadvertently generate harmful or toxic content, either unintentionally or because of intentional inducement.""",2023-10-16T14:59:10Z
Stance Detection with Collaborative Role-Infused LLM-Based Agents,Yes.,4.,"""Despite their promising capabilities, LLMs encounter challenges when directly applied to stance detection. First, stance detection demands multi-aspect knowledge, from deciphering event-related terminologies to understanding the expression styles in social media platforms. Second, stance detection requires advanced reasoning to infer authors' implicit viewpoints, as stance are often subtly embedded rather than overtly stated in the text.""",2023-10-16T14:46:52Z
Large Language Model-Empowered Agents for Simulating Macroeconomic Activities,Yes.,1.,"""Large language models (LLMs) have recently gained prominence in offering autonomous human-like characteristics.""",2023-10-16T14:19:40Z
"Privacy in Large Language Models: Attacks, Defenses and Future Directions",Yes.,4.,"""unrestricted access to these models can also introduce potential malicious and unintentional privacy risks"" and ""Despite ongoing efforts to address the safety and privacy concerns associated with LLMs, the problem remains unresolved.""",2023-10-16T13:23:54Z
"Tabular Representation, Noisy Operators, and Impacts on Table Structure Understanding Tasks in LLMs",Yes.,5.,"""we introduce 8 noise operations inspired by real-world messy data and adversarial inputs, and show that such operations can impact LLM performance across formats for different structural understanding tasks.""",2023-10-16T12:51:24Z
Generative Calibration for In-context Learning,Yes.,5.,"""the performance is generally sensitive to various configurations of the prompt such as the choice or order of the training examples"" and ""such a paradox is mainly due to the label shift of the in-context model to the data distribution, in which LLMs shift the label marginal $p(y)$ while having a good label conditional $p(x|y)$.""",2023-10-16T10:45:02Z
Bongard-OpenWorld: Few-Shot Reasoning for Free-form Visual Concepts in the Real World,Yes.,3.,"""We further investigate to which extent the recently introduced Large Language Models (LLMs) and Vision-Language Models (VLMs) can solve our task, by directly probing VLMs, and combining VLMs and LLMs in an interactive reasoning scheme."" and ""However, none of these approaches manage to close the human-machine gap, as the best learner achieves 64",2023-10-16T09:19:18Z
Large Language Models Meet Open-World Intent Discovery and Recognition: An Evaluation of ChatGPT,Yes.,5.,"""Overall, ChatGPT exhibits consistent advantages under zero-shot settings, but is still at a disadvantage compared to fine-tuned models. More deeply, through a series of analytical experiments, we summarize and discuss the challenges faced by LLMs including clustering, domain-specific understanding, and cross-domain",2023-10-16T08:34:44Z
Theory of Mind for Multi-Agent Collaboration via Large Language Models,Yes.,5.,"""Our results reveal limitations in LLM-based agents' planning optimization due to systematic failures in managing long-horizon contexts and hallucination about the task state.""",2023-10-16T07:51:19Z
LoBaSS: Gauging Learnability in Supervised Fine-tuning Data,Yes.,1.,"""Supervised Fine-Tuning (SFT) serves as a crucial phase in aligning Large Language Models (LLMs) to specific task prerequisites.""",2023-10-16T07:26:24Z
Learning to Rank Context for Named Entity Recognition Using a Synthetic Dataset,Yes.,2.,"""While recent pre-trained transformer-based models can perform named entity recognition (NER) with great accuracy, their limited range remains an issue when applied to long documents such as whole novels.""",2023-10-16T06:53:12Z
On Generative Agents in Recommendation,Yes.,3.,"""We delve into both the capabilities and limitations of Agent4Rec, aiming to explore an essential research question",2023-10-16T06:41:16Z
JMedLoRA:Medical Domain Adaptation on Japanese Large Language Models using Instruction-tuning,Yes.,3.,"""While instruction-tuning is used to fine-tune some LLMs, its precise roles in domain adaptation remain unknown."" and ""highlighting the persisting limitations of Japanese-centric models.""",2023-10-16T05:28:28Z
Prompt Packer: Deceiving LLMs through Compositional Instruction with Hidden Attacks,Yes.,5.,"""Unfortunately, they remain the risk of generating harmful content like hate speech and criminal activities in practical applications."" and ""Our approach reveals the vulnerability of LLMs to such compositional instruction attacks that harbor underlying harmful intentions, contributing significantly to LLM security development.""",2023-10-16T05:19:25Z
FATE-LLM: A Industrial Grade Federated Learning Framework for Large Language Models,Yes.,5.,"""LLMs face two main challenges in real-world applications. One challenge is that training LLMs consumes vast computing resources, preventing LLMs from being adopted by small and medium-sized enterprises with limited computing resources. Another is that training LLM requires a large amount of high-quality data, which are often scattered among enterprises.""",2023-10-16T04:17:13Z
Improving Large Language Model Fine-tuning for Solving Math Problems,,,,2023-10-16T04:11:19Z
TRANSOM: An Efficient Fault-Tolerant System for Training LLMs,Yes.,3.,"""However, training LLMs with super-large-scale parameters requires large high-performance GPU clusters and long training periods lasting for months. Due to the inevitable hardware and software failures in large-scale clusters, maintaining uninterrupted and long-duration training is extremely challenging.""",2023-10-16T04:06:52Z
Can GPT-4V(ision) Serve Medical Applications? Case Studies on GPT-4V for Multimodal Medical Diagnosis,Yes.,5.,"""while GPT-4V demonstrates proficiency in distinguishing between medical image modalities and anatomy, it faces significant challenges in disease diagnosis and generating comprehensive reports. These findings underscore that while large multimodal models have made significant advancements in computer vision and natural language processing",2023-10-15T18:32:27Z
In-Context Learning with Iterative Demonstration Selection,Yes.,4.,"""However, the performance of ICL has been shown to be highly sensitive to the selection of few-shot demonstrations. Selecting the most suitable examples as context remains an ongoing challenge and an open problem.""",2023-10-15T16:40:19Z
Empower Text-Attributed Graphs Learning with Large Language Models (LLMs),Yes.,1.,"""Recently, the advent of Large Language Models (LLMs) has introduced their powerful capabilities in information retrieval and text generation, which can greatly enhance the text attributes of graph data.""",2023-10-15T16:04:28Z
ACES: Generating Diverse Programming Puzzles with Autotelic Language Models and Semantic Descriptors,Yes.,1.,"""With ACES (Autotelic Code Exploration via Semantic descriptors), we introduce a new autotelic generation method that leverages semantic descriptors produced by a large language model (LLM) to directly optimize for interesting diversity, as well as few-shot-based generation.""",2023-10-15T14:57:14Z
Assessing the Reliability of Large Language Model Knowledge,Yes.,5.,"""LLMs are typically evaluated using accuracy, yet this metric does not capture the vulnerability of LLMs to hallucination-inducing factors like prompt and context variability.""",2023-10-15T12:40:30Z
When can transformers reason with abstract symbols?,Yes.,5.,"""transformers fail to generalize as their embedding dimension increases"" and ""require astonishingly large quantities of training data.""",2023-10-15T06:45:38Z
Enhancing Conversational Search: Large Language Model-Aided Informative Query Rewriting,Yes.,1.,"""To overcome this limitation, we propose utilizing large language models (LLMs) as query rewriters, enabling the generation of informative query rewrites through well-designed instructions.""",2023-10-15T03:04:17Z
Configuration Validation with Large Language Models,,,,2023-10-15T00:50:27Z
DPZero: Private Fine-Tuning of Language Models without Backpropagation,Yes.,5.,"""The widespread practice of fine-tuning large language models (LLMs) on domain-specific data faces two major challenges in memory and privacy. First, as the size of LLMs continues to grow, the memory demands of gradient-based training methods via backpropagation become prohibitively high. Second, given the tendency of LLMs to memorize training data, it is important to protect",2023-10-14T18:42:56Z
Autonomous Tree-search Ability of Large Language Models,Yes.,5.,"""Large Language Models have excelled in remarkable reasoning capabilities with advanced prompting techniques, but they fall short on tasks that require exploration, strategic foresight, and sequential decision-making."" and ""there are several fundamental limitations of these approaches.""",2023-10-14T14:14:38Z
CarExpert: Leveraging Large Language Models for In-Car Conversational Question Answering,Yes.,5.,"""leveraging LLMs for domain-specific question answering suffers from severe limitations. The generated answer tends to hallucinate due to the training data collection time (when using off-the-shelf), complex user utterance and wrong retrieval (in retrieval-augmented generation). Furthermore, due to the lack of awareness about the domain and expected output, such LLMs may generate unexpected and unsafe",2023-10-14T08:46:24Z
Reward-Augmented Decoding: Efficient Controlled Text Generation With a Unidirectional Reward Model,Yes.,2.,"""While large language models have proven effective in a huge range of downstream applications, they often generate text that is problematic or lacks a desired attribute.""",2023-10-14T07:19:47Z
One-Shot Sensitivity-Aware Mixed Sparsity Pruning for Large Language Models,Yes.,3.,"""However, the enormous model sizes have hindered their practical use in real-world applications due to high inference latency.""",2023-10-14T05:43:09Z
A Setwise Approach for Effective and Highly Efficient Zero-shot Ranking with Large Language Models,Yes.,2.,"""Our study begins by thoroughly evaluating these existing approaches within a consistent experimental framework, considering factors like model size, token consumption, latency, among others.""",2023-10-14T05:20:02Z
Large Language Model Unlearning,Yes.,3.,"""removing harmful responses,"" ""erasing copyright-protected content as requested,"" and ""reducing hallucinations.""",2023-10-14T00:32:55Z
Dialogue Chain-of-Thought Distillation for Commonsense-aware Conversational Agents,Yes.,3.,"""Even for large language models (LLMs), the task of identifying and aggregating key evidence within a single hop presents a substantial challenge.""",2023-10-13T18:17:23Z
Ranking LLM-Generated Loop Invariants for Program Verification,Yes.,3.,"""Large Language Models (such as gpt-3.5 or gpt-4) are capable of synthesizing loop invariants for a class of programs in a 0-shot setting, yet require several samples to generate the correct invariants. This can lead to a large number of calls to a program verifier to establish an invariant.""",2023-10-13T18:13:52Z
User Inference Attacks on Large Language Models,Yes.,5.,"""We find that LLMs are susceptible to user inference across a variety of fine-tuning datasets, at times with near perfect attack success rates.""",2023-10-13T17:24:52Z
PromptRE: Weakly-Supervised Document-Level Relation Extraction via Prompting-Based Data Programming,Yes.,3.,"""Weakly-supervised document-level relation extraction faces significant challenges due to an imbalanced number 'no relation' instances and the failure of directly probing pretrained large language models for document relation extraction.""",2023-10-13T17:23:17Z
Table-GPT: Table-tuned GPT for Diverse Table Tasks,Yes.,5.,"""we observe that today's language models are still sub-optimal in many table-related tasks, likely because they are pre-trained predominantly on one-dimensional natural-language texts, whereas relational tables are two-dimensional objects.""",2023-10-13T17:20:56Z
"""Kelly is a Warm Person, Joseph is a Role Model"": Gender Biases in LLM-Generated Reference Letters",Yes.,5.,"""In this paper, we critically examine gender biases in LLM-generated reference letters. Drawing inspiration from social science findings, we design evaluation methods to manifest biases through 2 dimensions",2023-10-13T16:12:57Z
Explore-Instruct: Enhancing Domain-Specific Instruction Coverage through Active Exploration,Yes.,2.,"""existing data employed for such tuning often exhibit an inadequate coverage of individual domains, limiting the scope for nuanced comprehension and interactions within these areas.""",2023-10-13T15:03:15Z
Split-and-Denoise: Protect large language model inference with local differential privacy,Yes.,3.,"""the direct transmission of text to servers poses a largely unaddressed risk of privacy leakage.""",2023-10-13T14:17:33Z
Qilin-Med: Multi-stage Knowledge Injection Advanced Medical Large Language Model,Yes.,3.,"""Integrating large language models (LLMs) into healthcare presents potential but faces challenges. Directly pre-training LLMs for domains like medicine is resource-heavy and sometimes unfeasible. Sole reliance on Supervised Fine-tuning (SFT) can result in overconfident predictions and may not tap into domain specific insights.""",2023-10-13T13:17:03Z
KCTS: Knowledge-Constrained Tree Search Decoding with Token-Level Hallucination Detection,Yes.,5.,"""Large Language Models (LLMs) have demonstrated remarkable human-level natural language generation capabilities. However, their potential to generate misinformation, often called the hallucination problem, poses a significant risk to their deployment.""",2023-10-13T12:12:34Z
CodeChain: Towards Modular Code Generation Through Chain of Self-revisions with Representative Sub-modules,Yes.,3.,"""solving more complex and competitive programming tasks is still quite challenging for these models - possibly due to their tendency to generate solutions as monolithic code blocks instead of decomposing them into logical sub-tasks and sub-modules.""",2023-10-13T10:17:48Z
Embarrassingly Simple Text Watermarks,Yes.,3.,"""LLMs can generate texts that cannot be distinguished from human-written texts. This is a serious problem for the credibility of the text.""",2023-10-13T07:44:05Z
Dynamic Sparse No Training: Training-Free Fine-tuning for Sparse LLMs,Yes.,3.,"""The ever-increasing large language models (LLMs), though opening a potential path for the upcoming artificial general intelligence, sadly drops a daunting obstacle on the way towards their on-device deployment."" and ""network pruning appears to lag behind in the era of LLMs, due mostly to its costly",2023-10-13T07:38:52Z
SeqXGPT: Sentence-Level AI-Generated Text Detection,Yes.,2.,"""Widely applied large language models (LLMs) can generate human-like content, raising concerns about the abuse of LLMs.""",2023-10-13T07:18:53Z
Exploration with Principles for Diverse AI Supervision,Yes.,3.,"""This strong reliance on human oversight poses a significant hurdle to the advancement of AI innovation.""",2023-10-13T07:03:39Z
Large Language Models as Source Planner for Personalized Knowledge-grounded Dialogue,Yes.,3.,"""existing knowledge-grounded dialogue systems either focus on a single knowledge source or overlook the dependency between multiple sources of knowledge, which may result in generating inconsistent or even paradoxical responses.""",2023-10-13T03:38:38Z
Impact of Guidance and Interaction Strategies for LLM Use on Learner Performance and Perception,Yes.,2.,"""However, the challenge lies not only in establishing the efficacy of LLMs but also in discerning the nuances of interaction between learners and these models, which impact learners' engagement and results.""",2023-10-13T01:21:52Z
End-to-end Story Plot Generator,Yes.,3.,"""existing plot generators (e.g., DOC (Yang et al., 2022a)) require hundreds to thousands of calls to LLMs (e.g., OpenAI API) in the planning stage of the story plot, which is costly and takes at least several minutes. Moreover, the hard-wired nature of the method makes the pipeline non-differentiable, blocking fast",2023-10-13T00:49:59Z
"""Im not Racist but..."": Discovering Bias in the Internal Knowledge of Large Language Models",Yes.,4.,"""these models have been shown to harbor inherent societal biases, or stereotypes, which can adversely affect their performance in their many downstream applications.""",2023-10-13T00:03:37Z
Examining the Potential and Pitfalls of ChatGPT in Science and Engineering Problem-Solving,Yes.,5.,"""Analysis of the model's incorrect solutions revealed three distinct failure modes",2023-10-12T23:39:28Z
LoftQ: LoRA-Fine-Tuning-Aware Quantization for Large Language Models,Yes.,3.,"""it is common to observe a consistent gap in the performance on downstream tasks between full fine-tuning and quantization plus LoRA fine-tuning approach.""",2023-10-12T18:34:08Z
MemGPT: Towards LLMs as Operating Systems,Yes.,5.,"""Large language models (LLMs) have revolutionized AI, but are constrained by limited context windows, hindering their utility in tasks like extended conversations and document analysis.""",2023-10-12T17:51:32Z
Revisiting the Hypothesis: Do pretrained Transformers Learn In-Context by Gradient Descent?,Yes.,3.,"""We highlight the limiting assumptions in prior works that make their context considerably different from the practical context in which language models are trained.""",2023-10-12T17:32:09Z
LLM-augmented Preference Learning from Natural Language,Yes.,1.,"""Since Large Language Models (LLMs) are equipped to deal with larger context lengths and have much larger model sizes than the transformer-based model, we investigate their ability to classify comparative text directly.""",2023-10-12T17:17:27Z
Prometheus: Inducing Fine-grained Evaluation Capability in Language Models,Yes.,3.,"""using proprietary LLMs as an evaluator is unreliable due to the closed-source nature, uncontrolled versioning, and prohibitive costs.""",2023-10-12T16:50:08Z
Jailbreaking Black Box Large Language Models in Twenty Queries,Yes.,4.,"""However, the alignment of such models is vulnerable to adversarial jailbreaks, which coax LLMs into overriding their safety guardrails. The identification of these vulnerabilities is therefore instrumental in understanding inherent weaknesses and preventing future misuse.""",2023-10-12T15:38:28Z
Towards Better Evaluation of Instruction-Following: A Case-Study in Summarization,Yes.,3.,"""evaluating how well large language models (LLMs) follow user instructions remains an open problem"" and ""limited work on the correctness of these methods has been conducted.""",2023-10-12T15:07:11Z
Impact of Co-occurrence on Factual Knowledge of Large Language Models,Yes.,5.,"""Large language models (LLMs) often make factually incorrect responses despite their success in various applications."" and ""We show that co-occurrence bias remains despite scaling up model sizes or finetuning.""",2023-10-12T12:01:32Z
Large language models can replicate cross-cultural differences in personality,Yes.,3.,"""Our results show that GPT-4 replicated the cross-cultural differences for each factor. However, mean ratings had an upward bias and exhibited lower variation than in the human samples, as well as lower structural validity.""",2023-10-12T11:17:23Z
Who Wrote it and Why? Prompting Large-Language Models for Authorship Verification,Yes.,3.,"""Existing AV techniques, including traditional stylometric and deep learning approaches, face limitations in terms of data requirements and lack of explainability.""",2023-10-12T08:24:15Z
Can Large Language Models Really Improve by Self-critiquing Their Own Plans?,Yes.,5.,"""our findings reveal that self-critiquing appears to diminish plan generation performance, especially when compared to systems with external, sound verifiers and the LLM verifiers in that system produce a notable number of false positives, compromising the system's reliability.""",2023-10-12T08:22:37Z
QASiNa: Religious Domain Question Answering using Sirah Nabawiyah,Yes.,5.,"""The approach used by LLM to generate answers based on its own interpretation is similar to the concept of tafseer, LLM is neither an Islamic expert nor a human which is not permitted in Islam."" and ""The experiment indicate that Chat GPT tends to give excessive interpretations as evidenced by its higher Substring Match scores compared to EM and F1-Score, even after providing instruction and",2023-10-12T07:52:19Z
Promptor: A Conversational and Autonomous Prompt Generation Agent for Intelligent Text Entry Techniques,Yes.,2.,"""However, as deep learning-based language models become the norm for these advanced features, the necessity for data collection and model fine-tuning increases.""",2023-10-12T07:51:43Z
GameGPT: Multi-agent Collaborative Framework for Game Development,Yes.,4.,"""While many studies have pinpointed hallucination as a primary roadblock for deploying LLMs in production, we identify another concern",2023-10-12T06:31:43Z
Exploring Large Language Models for Multi-Modal Out-of-Distribution Detection,Yes.,3.,"""Indiscriminately using such knowledge causes catastrophic damage to OOD detection due to LLMs' hallucinations, as is observed by our analysis.""",2023-10-12T04:14:28Z
Effects of Human Adversarial and Affable Samples on BERT Generalization,No.,1.,"The abstract discusses BERT-based models and their generalization performance, but does not mention LLMs or their limitations.",2023-10-12T03:20:43Z
Synthetic Data Generation with Large Language Models for Text Classification: Potential and Limitations,,,,2023-10-11T19:51:13Z
GenTKG: Generative Forecasting on Temporal Knowledge Graph,Yes.,3.,"""However, challenges occur in the huge chasms between complex temporal graph data structure and sequential natural expressions LLMs can handle, and between the enormous data sizes of tKGs and heavy computation costs of finetuning LLMs.""",2023-10-11T18:27:12Z
Composite Backdoor Attacks Against Large Language Models,Yes.,3.,"""However, the untrustworthy third-party LLMs may covertly introduce vulnerabilities for downstream tasks."" and ""Our work highlights the necessity of increased security research on the trustworthiness of foundation LLMs.""",2023-10-11T17:21:03Z
Well Begun is Half Done: Generator-agnostic Knowledge Pre-Selection for Knowledge-Grounded Dialogue,Yes.,1.,"""knowledge selection before generation is a lightweight yet effective way to facilitate LLMs (e.g., ChatGPT) to generate more informative responses.""",2023-10-11T17:00:29Z
Mini-DALLE3: Interactive Text to Image by Prompting Large Language Models,Yes.,3.,"""However, a prevalent limitation persists in the effective communication with these popular T2I models, such as Stable Diffusion, using natural language descriptions. This typically makes an engaging image hard to obtain without expertise in prompt engineering with complex word compositions, magic tags, and annotations.""",2023-10-11T16:53:40Z
Evaluating Large Language Models at Evaluating Instruction Following,Yes.,3.,"""we discover that different evaluators (i.e., combinations of LLMs and prompts) exhibit distinct performance on LLMBar and even the highest-scoring ones have substantial room for improvement.""",2023-10-11T16:38:11Z
OpsEval: A Comprehensive IT Operations Benchmark Suite for Large Language Models,Yes.,3.,"""the performance of current LLMs in Ops tasks is yet to be determined"" and ""discussed findings related to various topics, including model quantification, QA evaluation, and hallucination issues.""",2023-10-11T16:33:29Z
"The Past, Present and Better Future of Feedback Learning in Large Language Models for Subjective Human Preferences and Values",Yes.,4.,"""it is unclear how to collect and incorporate feedback in a way that is efficient, effective and unbiased, especially for highly subjective human preferences and values,"" and ""we encourage a better future of feedback learning in LLMs by raising five unresolved conceptual and practical challenges.""",2023-10-11T16:18:13Z
In-Context Unlearning: Language Models as Few Shot Unlearners,Yes.,3.,"""Although unlearning is particularly relevant for LLMs in light of the copyright issues they raise, achieving precise unlearning is computationally infeasible for very large models."" and ""These algorithms crucially rely on access to the model parameters in order to update them, an assumption that may not hold in practice due to computational constraints or when the LLM is accessed via API.""",2023-10-11T15:19:31Z
"Survey on Factuality in Large Language Models: Knowledge, Retrieval and Domain-Specificity",Yes.,5.,"""We define the Factuality Issue as the probability of LLMs to produce content inconsistent with established facts,"" and ""highlighting the potential consequences and challenges posed by factual errors in LLM outputs.""",2023-10-11T14:18:03Z
Fast-ELECTRA for Efficient Pre-training,Yes.,2.,"""its potential is constrained by the training cost brought by the auxiliary model"" and ""This results in a substantial amount of training cost being expended in vain.""",2023-10-11T09:55:46Z
How Do Large Language Models Capture the Ever-changing World Knowledge? A Review of Recent Advances,Yes.,4.,"""Although large language models (LLMs) are impressive in solving various tasks, they can quickly be outdated after deployment. Maintaining their up-to-date status is a pressing concern in the current era.""",2023-10-11T09:46:32Z
Beyond Memorization: Violating Privacy Via Inference with Large Language Models,Yes.,5.,"""we present the first comprehensive study on the capabilities of pretrained LLMs to infer personal attributes from text,"" and ""common mitigations, i.e., text anonymization and model alignment, are currently ineffective at protecting user privacy against LLM inference.""",2023-10-11T08:32:46Z
Typing to Listen at the Cocktail Party: Text-Guided Target Speaker Extraction,Yes.,1.,"""Specifically, we propose a model named LLM-TSE, wherein a large language model (LLM) extracts useful semantic cues from the user's typed text input.""",2023-10-11T08:17:54Z
CoPAL: Corrective Planning of Robot Actions with Large Language Models,Yes.,1.,"""this study contributes to the field of Large Language Models (LLMs) applied to task and motion planning for robots.""",2023-10-11T07:39:42Z
CacheGen: KV Cache Compression and Streaming for Fast Language Model Serving,Yes.,3.,"""using long contexts poses a challenge for responsive LLM systems, as nothing can be generated until the whole context is processed by the LLM.""",2023-10-11T07:08:20Z
Adaptive Gating in Mixture-of-Experts based Language Models,Yes.,2.,"""Little is discussed in prior research on the trade-off between computation per token and model performance.""",2023-10-11T04:30:18Z
Online Speculative Decoding,Yes.,3.,"""Speculative decoding is a pivotal technique to accelerate the inference of large language models (LLMs) by employing a smaller draft model to predict the target model's outputs. However, its efficacy can be limited due to the low predictive accuracy of the draft model, particularly when faced with diverse text inputs and a significant capability gap between the draft and target models.""",2023-10-11T04:03:42Z
Syntax Error-Free and Generalizable Tool Use for LLMs via Finite-State Decoding,Yes.,4.,"""existing approaches either involve fine-tuning on tool demonstrations, which do not generalize to new tools without additional training, or providing tool documentation in context, limiting the number of tools. Both approaches often generate syntactically invalid tool calls.""",2023-10-10T23:37:53Z
Catastrophic Jailbreak of Open-source LLMs via Exploiting Generation,Yes.,5.,"""Finally, we propose an effective alignment method that explores diverse generation strategies, which can reasonably reduce the misalignment rate under our attack. Altogether, our study underscores a major failure in current safety evaluation and alignment procedures for open-source LLMs.""",2023-10-10T20:15:54Z
LLMs Killed the Script Kiddie: How Agents Supported by Large Language Models Change the Landscape of Network Threat Testing,Yes.,3.,"""However, the LLM's capabilities to deal with more complex networks, sophisticated vulnerabilities, and the sensitivity of prompts are open questions.""",2023-10-10T18:49:20Z
A Comparative Study of Transformer-based Neural Text Representation Techniques on Bug Triaging,Yes.,2.,"""However, the potential for using these techniques to improve upon prior approaches for automated bug triaging is not well studied or understood.""",2023-10-10T18:09:32Z
LongLLMLingua: Accelerating and Enhancing LLMs in Long Context Scenarios via Prompt Compression,Yes.,5.,"""In long context scenarios, large language models (LLMs) face three main challenges",2023-10-10T17:59:58Z
Generating and Evaluating Tests for K-12 Students with Language Model Simulations: A Case Study on Sentence Reading Efficiency,,,,2023-10-10T17:59:51Z
Teaching Language Models to Hallucinate Less with Synthetic Tasks,Yes.,5.,"""Large language models (LLMs) frequently hallucinate on abstractive summarization tasks such as document-based question-answering, meeting summarization, and clinical report generation, even though all necessary information is included in context.""",2023-10-10T17:57:00Z
The Geometry of Truth: Emergent Linear Structure in Large Language Model Representations of True/False Datasets,Yes.,4.,"""Large Language Models (LLMs) have impressive capabilities, but are also prone to outputting falsehoods."" and ""this line of work is controversial, with some authors pointing out failures of these probes to generalize in basic ways, among other conceptual issues.""",2023-10-10T17:54:39Z
Exploring Memorization in Fine-tuned Language Models,Yes.,5.,"""Large language models (LLMs) have shown great capabilities in various tasks but also exhibited memorization of training data, raising tremendous privacy and copyright concerns.""",2023-10-10T15:41:26Z
Benchmarking and Explaining Large Language Model-based Code Generation: A Causality-Centric Approach,Yes.,3.,"""the quality of the generated code is not guaranteed,"" and ""effectively evaluating and explaining the code generation capability of LLMs is inherently challenging, given the complexity of LLMs and the lack of transparency.""",2023-10-10T14:56:26Z
Automated clinical coding using off-the-shelf large language models,Yes.,3.,"""Unsupervised pre-training alone does not guarantee precise knowledge of the ICD ontology and specialist clinical coding task.""",2023-10-10T11:56:48Z
MetaAgents: Simulating Interactions of Human Behaviors for LLM-based Task-oriented Coordination via Collaborative Generative Agents,Yes.,4.,"""Despite this, their capacities to coordinate within task-oriented social contexts are under-explored."" and ""However, we also uncover limitations that hinder their effectiveness in more complex coordination tasks.""",2023-10-10T10:17:58Z
A New Benchmark and Reverse Validation Method for Passage-level Hallucination Detection,Yes.,5.,"""LLMs are apt to generate hallucinations, i.e., makeup incorrect text and unverified information, which can cause significant damage when deployed for mission-critical tasks.""",2023-10-10T10:14:59Z
Multilingual Jailbreak Challenges in Large Language Models,Yes.,5.,"""While large language models (LLMs) exhibit remarkable capabilities across a wide range of tasks, they pose potential safety concerns, such as the `jailbreak' problem, wherein malicious instructions can manipulate LLMs to exhibit undesirable behavior."" and ""The experimental results reveal that in the unintentional scenario, the rate of unsafe content increases as the availability of languages decreases. Specifically,",2023-10-10T09:44:06Z
Constructive Large Language Models Alignment with Diverse Feedback,Yes.,3.,"""current alignment methods often rely solely on singular forms of human feedback, such as preferences, annotated labels, or natural language critiques, overlooking the potential advantages of combining these feedback types. This limitation leads to suboptimal performance, even when ample training data is available.""",2023-10-10T09:20:14Z
Large Language Models for Propaganda Detection,Yes.,3.,"""Further, this study analyzes the potential and challenges of LLMs in complex tasks like propaganda detection.""",2023-10-10T08:46:10Z
Towards Mitigating Hallucination in Large Language Models via Self-Reflection,Yes.,5.,"""However, the practical deployment still faces challenges, notably the issue of 'hallucination', where models generate plausible-sounding but unfaithful or nonsensical information.""",2023-10-10T03:05:44Z
Model Tuning or Prompt Tuning? A Study of Large Language Models for Clinical Concept and Relation Extraction,Yes.,3.,"""When LLMs are frozen, small (i.e., 345 million parameters) LLMs have a big gap to be competitive with unfrozen models; scaling LLMs up to billions of parameters makes frozen LLMs competitive with unfrozen LLMs.""",2023-10-10T01:27:08Z
Compressing Context to Enhance Inference Efficiency of Large Language Models,Yes.,5.,"""However, they face challenges in managing long documents and extended conversations, due to significantly increased computational requirements, both in memory and inference time, and potential context truncation when the input exceeds the LLM's fixed context length.""",2023-10-09T23:03:24Z
Cost-Efficient Prompt Engineering for Unsupervised Entity Resolution,Yes.,3.,"""However, it is also well known that LLMs can pose risks,"" and ""Finally, we consider some limitations of LLMs when applied to ER.""",2023-10-09T21:57:07Z
OptiMUS: Optimization Modeling Using MIP Solvers and large language models,Yes.,1.,"""We introduce OptiMUS, a Large Language Model (LLM)-based agent designed to formulate and solve MILP problems from their natural language descriptions.""",2023-10-09T19:47:03Z
SALMON: Self-Alignment with Instructable Reward Models,Yes.,4.,"""a significant limitation of such an approach is its dependency on high-quality human annotations, making its application to intricate tasks challenging due to difficulties in obtaining consistent response demonstrations and in-distribution response preferences.""",2023-10-09T17:56:53Z
ViCor: Bridging Visual Understanding and Commonsense Reasoning with Large Language Models,Yes.,4.,"""However, we identify a challenge with VLMs' passive perception, which often misses crucial context information, leading to incorrect or uncertain reasoning by LLMs.""",2023-10-09T17:10:35Z
HyperAttention: Long-context Attention in Near-Linear Time,Yes.,4.,"""We present an approximate attention mechanism named HyperAttention to address the computational challenges posed by the growing complexity of long contexts used in Large Language Models (LLMs)."" and ""Recent work suggests that in the worst-case scenario, quadratic time is necessary unless the entries of the attention matrix are bounded or the matrix has low stable rank.""",2023-10-09T17:05:25Z
Improving Summarization with Human Edits,Yes.,1.,"""Existing works use human feedback to train large language models (LLMs) in general domain abstractive summarization and have obtained summary quality exceeding traditional likelihood training.""",2023-10-09T16:52:07Z
GraphLLM: Boosting Graph Reasoning Ability of Large Language Model,Yes.,4.,"""Despite this progress, a critical gap remains in empowering LLMs to proficiently understand and reason on graph data. Recent studies underscore LLMs' underwhelming performance on fundamental graph reasoning tasks.""",2023-10-09T16:42:00Z
SC-Safety: A Multi-round Open-ended Question Adversarial Safety Benchmark for Large Language Models in Chinese,Yes.,4.,"""they can also produce harmful content that negatively affects societal perceptions"" and ""Adversarial human-model interactions and conversations significantly increase the challenges compared to existing methods.""",2023-10-09T16:03:22Z
"A Survey of Large Language Models for Healthcare: from Data, Technology, and Applications to Accountability and Ethics",Yes.,4.,"""highlighting both the strengths and limitations"" and ""the unique concerns associated with deploying LLMs in Healthcare settings are investigated, particularly regarding fairness, accountability, transparency and ethics.""",2023-10-09T13:15:23Z
LAiW: A Chinese Legal Large Language Models Benchmark,Yes.,4.,"""current evaluations of these LLMs in LegalAI are defined by the experts of computer science, lacking consistency with the logic of legal practice, making it difficult to judge their practical capabilities"" and ""LLMs seem to be able to directly acquire complex legal application capabilities but perform poorly in some basic tasks, which may pose obstacles to their practical application and acceptance by legal experts.""",2023-10-09T11:19:55Z
Query and Response Augmentation Cannot Help Out-of-domain Math Reasoning Generalization,Yes.,5.,"""We also find that MuggleMath is weak in out-of-domain math reasoning generalization to MATH. This is attributed to the differences in query distribution between AugGSM8K and MATH which suggest that augmentation on a single benchmark could not help with overall math reasoning performance.""",2023-10-09T08:18:58Z
GROVE: A Retrieval-augmented Complex Story Generation Framework with A Forest of Evidence,Yes.,2.,"""Existing methods often rely on detailed prompts to guide LLMs to meet target conditions, which inadvertently restrict the creative potential of the generated stories.""",2023-10-09T03:55:55Z
SteerLM: Attribute Conditioned SFT as an (User-Steerable) Alternative to RLHF,Yes.,5.,"""RLHF faces inherent limitations stemming from a complex training setup and its tendency to align the model with implicit values that end users cannot control at run-time.""",2023-10-09T02:11:21Z
Negative Object Presence Evaluation (NOPE) to Measure Object Hallucination in Vision-Language Models,Yes.,5.,"""Object hallucination poses a significant challenge in vision-language (VL) models, often leading to the generation of nonsensical or unfaithful responses with non-existent objects."" and ""no VL model is immune to the vulnerability of object hallucination, as all models achieve accuracy",2023-10-09T01:52:27Z
Are Personalized Stochastic Parrots More Dangerous? Evaluating Persona Biases in Dialogue Systems,Yes.,5.,"""Recent advancements in Large Language Models empower them to follow freeform instructions, including imitating generic or specific demographic personas in conversations,"" and ""our study uncovers significant persona biases in dialogue systems.""",2023-10-08T21:03:18Z
Measuring reasoning capabilities of ChatGPT,Yes.,5.,"""I shall quantify the logical faults generated by ChatGPT when applied to reasoning tasks."" and ""A second output is the classification of reasoning faults conveyed by ChatGPT. This classification forms a basis for a taxonomy of reasoning faults generated by large language models.""",2023-10-08T20:18:50Z
MindfulDiary: Harnessing Large Language Model to Support Psychiatric Patients' Journaling,Yes.,3.,"""though their inherent complexity and low controllability have raised questions about their suitability in clinical settings.""",2023-10-08T17:00:04Z
Scaling Laws of RoPE-based Extrapolation,Yes.,2.,"""In this process, we also explain the origin of the RoPE-based extrapolation issue by critical dimension for extrapolation.""",2023-10-08T15:50:36Z
Loose lips sink ships: Mitigating Length Bias in Reinforcement Learning from Human Feedback,Yes.,5.,"""we have identified that the reward model often finds shortcuts to bypass its intended objectives, misleadingly assuming that humans prefer longer responses. The emergence of length bias often induces the model to favor longer outputs, yet it doesn't equate to an increase in helpful information within these outputs.""",2023-10-08T15:14:39Z
Factuality Challenges in the Era of Large Language Models,Yes.,5.,"""These incredibly useful, natural-sounding tools mark significant advances in natural language generation, yet they exhibit a propensity to generate false, erroneous, or misleading content -- commonly referred to as 'hallucinations.'"" and ""Moreover, LLMs can be exploited for malicious applications, such as generating false but credible-sounding",2023-10-08T14:55:02Z
Do Large Language Models Know about Facts?,Yes.,5.,"""Content generated by the LLMs can often exhibit inaccuracies or deviations from the truth, due to facts that can be incorrectly induced or become obsolete over time"" and ""Extensive experiments on different sizes and types of LLMs show that existing LLMs still lack factual knowledge and suffer from various spurious correlations.""",2023-10-08T14:26:55Z
Outlier Weighed Layerwise Sparsity (OWL): A Missing Secret Sauce for Pruning LLMs to High Sparsity,Yes.,3.,"""Large Language Models (LLMs), renowned for their remarkable performance across diverse domains, present a challenge when it comes to practical deployment due to their colossal model size.""",2023-10-08T14:22:58Z
On the Zero-Shot Generalization of Machine-Generated Text Detectors,Yes.,3.,"""While none of the detectors can generalize to all generators, we observe a consistent and interesting pattern that the detectors trained on data from a medium-size LLM can zero-shot generalize to the larger version.""",2023-10-08T13:49:51Z
An Investigation of LLMs' Inefficacy in Understanding Converse Relations,Yes.,5.,"""The results suggest that LLMs often resort to shortcut learning and still face challenges on our proposed benchmark.""",2023-10-08T13:45:05Z
MenatQA: A New Dataset for Testing the Temporal Comprehension and Reasoning Abilities of Large Language Models,Yes.,5.,"""The results show most LLMs fall behind smaller temporal reasoning models with different degree on these factors. In specific, LLMs show a significant vulnerability to temporal biases and depend heavily on the temporal information provided in questions.""",2023-10-08T13:19:52Z
Large Language Model (LLM) as a System of Multiple Expert Agents: An Approach to solve the Abstraction and Reasoning Corpus (ARC) Challenge,Yes.,1.,"""Using the flexibility of LLMs to be prompted to do various novel tasks using zero-shot, few-shot, context-grounded prompting, we explore the feasibility of using LLMs to solve the ARC Challenge.""",2023-10-08T12:37:28Z
Are Emily and Greg Still More Employable than Lakisha and Jamal? Investigating Algorithmic Hiring Bias in the Era of ChatGPT,Yes.,4.,"""this introduces issues of bias on protected attributes like gender, race and maternity status"" and ""We use contrastive input decoding on open-source LLMs to uncover potential sources of bias.""",2023-10-08T12:08:48Z
DialCoT Meets PPO: Decomposing and Exploring Reasoning Paths in Smaller Language Models,Yes.,3.,"""Chain-of-Thought (CoT) prompting has proven to be effective in enhancing the reasoning capabilities of Large Language Models (LLMs) with at least 100 billion parameters. However, it is ineffective or even detrimental when applied to reasoning tasks in Smaller Language Models (SLMs) with less than 10 billion parameters.""",2023-10-08T08:52:13Z
AvalonBench: Evaluating LLMs Playing the Game of Avalon,Yes.,3.,"""Notably, our evaluations based on AvalonBench highlight a clear capability gap. For instance, models like ChatGPT playing good-role got a win rate of 22.2% against rule-based bots playing evil, while good-role bot achieves 38.2% win rate in the same setting.""",2023-10-08T06:37:08Z
Walking Down the Memory Maze: Beyond Context Limit through Interactive Reading,Yes.,5.,"""However, this mechanism comes with a fundamental issue -- the predetermined context window is bound to be limited. Despite attempts to extend the context window through methods like extrapolating the positional embedding, using recurrence, or selectively retrieving essential parts of the long sequence, long-text understanding continues to be a challenge.""",2023-10-08T06:18:14Z
Revisiting Large Language Models as Zero-shot Relation Extractors,Yes.,3.,"""On the one hand, we analyze the drawbacks of existing RE prompts and attempt to incorporate recent prompt techniques such as chain-of-thought (CoT) to improve zero-shot RE.""",2023-10-08T06:17:39Z
Compresso: Structured Pruning with Collaborative Prompting Learns Compact Large Language Models,Yes.,3.,"""the massive size poses significant deployment challenges, particularly on resource-constrained hardware"" and ""existing LLM compression methods focus on quantization, pruning remains relatively unexplored due to the high cost of training-based approaches and data collection challenges.""",2023-10-08T05:16:28Z
Self-Knowledge Guided Retrieval Augmentation for Large Language Models,Yes.,3.,"""the knowledge stored in the parameters of LLMs could still be incomplete and difficult to update due to the computational costs"" and ""the retrieved knowledge does not always help and even has a negative impact on original responses occasionally.""",2023-10-08T04:22:33Z
Large Language Models Only Pass Primary School Exams in Indonesia: A Comprehensive Test on IndoMMLU,Yes.,5.,"""Our empirical evaluations show that GPT-3.5 only manages to pass the Indonesian primary school level, with limited knowledge of local Indonesian languages and culture.""",2023-10-07T21:49:38Z
Dual Grained Quantization: Efficient Fine-Grained Quantization for LLM,Yes.,4.,"""Large Language Models (LLMs) pose significant hardware challenges related to memory requirements and computational ability.""",2023-10-07T14:50:28Z
Critique Ability of Large Language Models,Yes.,5.,"""Critique is generally challenging for most LLMs, and this capability often emerges only when models are sufficiently large. (2) In particular, self-critique is especially difficult. Even top-performing LLMs struggle to achieve satisfactory performance. (3) Models tend to have lower critique accuracy on problems where they are most uncertain.""",2023-10-07T14:12:15Z
Improving the Reliability of Large Language Models by Leveraging Uncertainty-Aware In-Context Learning,Yes.,5.,"""However, these models often face the challenge of 'hallucination,' which undermines their reliability."" and ""Our aim is to improve the model's responses by filtering out answers with high uncertainty while considering the model's knowledge limitations.""",2023-10-07T12:06:53Z
Resprompt: Residual Connection Prompting Advances Multi-Step Reasoning in Large Language Models,Yes.,3.,"""Yet, the standard CoT is less effective in problems demanding multiple reasoning steps. This limitation arises from the complex reasoning process in multi-step problems",2023-10-07T08:56:28Z
Tree-GPT: Modular Large Language Model Expert System for Forest Remote Sensing Image Understanding and Interactive Analysis,Yes.,3.,"""Currently, LLMs are unable to extract or comprehend information from images and may generate inaccurate text due to a lack of domain knowledge, limiting their use in forestry data analysis.""",2023-10-07T06:12:39Z
Data-Centric Financial Large Language Models,Yes.,3.,"""Large language models (LLMs) show promise for natural language tasks but struggle when applied directly to complex domains like finance. LLMs have difficulty reasoning about and integrating all relevant information.""",2023-10-07T04:53:31Z
The Cost of Down-Scaling Language Models: Fact Recall Deteriorates before In-Context Learning,Yes.,5.,"""Reducing the model size by more than 30\% (via either scaling approach) significantly decreases the ability to recall facts seen in pre-training.""",2023-10-07T03:36:39Z
Label-free Node Classification on Graphs with Large Language Models (LLMS),Yes.,3.,"""Yet, they face challenges in efficiently processing structural data and suffer from high inference costs.""",2023-10-07T03:14:11Z
Confronting Reward Model Overoptimization with Constrained RLHF,Yes.,3.,"""Large language models are typically aligned with human preferences by optimizing reward models fitted to human feedback... Compounding this difficulty, because any RM is only a proxy for human evaluation, this process is vulnerable to overoptimization, wherein past a certain point, accumulating higher reward is associated with worse human ratings.""",2023-10-06T16:59:17Z
Amortizing intractable inference in large language models,Yes.,5.,"""This limits tractable querying of this knowledge to start-to-end autoregressive sampling. However, many tasks of interest -- including sequence continuation, infilling, and other forms of constrained generation -- involve sampling from intractable posterior distributions.""",2023-10-06T16:36:08Z
Ada-Instruct: Adapting Instruction Generators for Complex Reasoning,Yes.,3.,"""we found that in-context prompting cannot generate complex instructions with length ≥ 100 for tasks like code completion.""",2023-10-06T13:28:04Z
Keyword Augmented Retrieval: Novel framework for Information Retrieval integrated with speech interface,Yes.,5.,"""Retrieving answers in a quick and low cost manner without hallucinations from a combination of structured and unstructured data using Language models is a major hurdle. This is what prevents employment of Language models in knowledge retrieval automation."" and ""complete reliance on commercial large language models (LLMs) like GPT 3.5 etc. can be very costly.""",2023-10-06T12:44:04Z
Conversational Financial Information Retrieval Model (ConFIRM),Yes.,2.,"""regulated fields such as finance pose unique constraints, requiring domain-optimized frameworks.""",2023-10-06T12:31:05Z
Analysis of the Reasoning with Redundant Information Provided Ability of Large Language Models,Yes.,5.,"""Findings indicate that while these models achieved moderate success on standard QA benchmarks, their performance notably declines when assessed on RRIP tasks. The study not only highlights the limitations of current LLMs in handling redundant information but also suggests that future training of these models should focus on incorporating redundant information into the training data to increase the performance on RRIP tasks.""",2023-10-06T06:20:06Z
Enhancing Financial Sentiment Analysis via Retrieval Augmented Large Language Models,Yes.,5.,"""The discrepancy between the pre-training objective of LLMs and predicting the sentiment label can compromise their predictive performance. Furthermore, the succinct nature of financial news, often devoid of sufficient context, can significantly diminish the reliability of LLMs' sentiment analysis.""",2023-10-06T05:40:23Z
Reverse Chain: A Generic-Rule for LLMs to Master Multi-API Planning,Yes.,3.,"""Recognizing that most LLMs have limited tool-use capabilities, Reverse Chain limits LLMs to executing simple tasks, e.g., API Selection and Argument Completion.""",2023-10-06T05:20:18Z
From Text to Self: Users' Perceptions of Potential of AI on Interpersonal Communication and Self,Yes.,4.,"""However, the study also uncovers current limitations of AIMC tools, including verbosity, unnatural responses, and excessive emotional intensity. These shortcomings are further exacerbated by user concerns about inauthenticity and potential overreliance on the technology.""",2023-10-06T02:19:10Z
Quantized Transformer Language Model Implementations on Edge Devices,Yes.,5.,"""One of the major limitations of these large-scale models is that they cannot be deployed on resource-constrained devices due to their large model size and increased inference latency.""",2023-10-06T01:59:19Z
Chain of Natural Language Inference for Reducing Large Language Model Ungrounded Hallucinations,Yes.,5.,"""However, LLMs are prone to generate hallucinations that are not supported by the provided sources.""",2023-10-06T00:10:46Z
LLM-Coordination: Evaluating and Analyzing Multi-agent Coordination Abilities in Large Language Models,Yes.,4.,"""However, results on Coordination QA show a large room for improvement in the Theory of Mind reasoning and joint planning abilities of LLMs.""",2023-10-05T21:18:15Z
Simulating Social Media Using Large Language Models to Evaluate Alternative News Feed Algorithms,Yes.,1.,"""we argue that LLMs hold considerable potential to improve simulation research on social media and many other complex social settings.""",2023-10-05T18:26:06Z
HeaP: Hierarchical Policies for Web Actions using LLMs,Yes.,3.,"""However, teaching LLMs to perform tasks on the web presents fundamental challenges -- combinatorially large open-world tasks and variations across web interfaces.""",2023-10-05T17:40:09Z
"Fine-tuning Aligned Language Models Compromises Safety, Even When Users Do Not Intend To!",Yes.,5.,"""We note that while existing safety alignment infrastructures can restrict harmful behaviors of LLMs at inference time, they do not cover safety risks when fine-tuning privileges are extended to end-users."" and ""Our red teaming studies find that the safety alignment of LLMs can be compromised by fine-tuning with only a few adversarially designed training examples."" and ""simply fine-t",2023-10-05T17:12:17Z
GoLLIE: Annotation Guidelines improve Zero-Shot Information-Extraction,Yes.,3.,"""Previous attempts to leverage such information have failed, even with the largest models, as they are not able to follow the guidelines out of the box.""",2023-10-05T16:43:13Z
Balancing Autonomy and Alignment: A Multi-Dimensional Taxonomy for Autonomous LLM-powered Multi-Agent Architectures,Yes.,4.,"""However, when faced with more complex and interconnected tasks that demand a profound and iterative thought process, LLMs reveal their inherent limitations.""",2023-10-05T16:37:29Z
Redefining Digital Health Interfaces with Large Language Models,Yes.,5.,"""Directly applying LLMs in clinical settings is not straightforward, however, with LLMs susceptible to providing inconsistent or nonsensical answers."" and ""addressing current issues with using LLMs in clinical settings such as hallucinations.""",2023-10-05T14:18:40Z
Controllable Multi-document Summarization: Coverage & Coherence Intuitive Policy with Large Language Model Based Rewards,Yes.,3.,"""Memory-efficient large language models are good at refining text input for better readability. However, controllability is a matter of concern when it comes to text generation tasks with long inputs, such as multi-document summarization.""",2023-10-05T11:29:09Z
Evaluating Hallucinations in Chinese Large Language Models,Yes.,5.,"""We analyze the primary types of hallucinations in different types of models and their causes. Additionally, we discuss which types of hallucinations should be prioritized for different types of models.""",2023-10-05T07:57:09Z
Fine-tune Language Models to Approximate Unbiased In-context Learning,Yes.,3.,"""the performance of models heavily relies on the quality of the input prompt when implementing in-context learning. Biased or imbalanced input prompts can significantly degrade the performance of language models.""",2023-10-05T06:16:01Z
Reformulating Domain Adaptation of Large Language Models as Adapt-Retrieve-Revise,Yes.,5.,"""they often generate content with hallucinations in specific domains such as Chinese law, hindering their application in these areas. This is typically due to the absence of training data that encompasses such a specific domain, preventing GPT-4 from acquiring in-domain knowledge. A pressing challenge is that it's not plausible to continue training LLMs of such scale on in-domain data.""",2023-10-05T05:55:06Z
Investigating the Limitation of CLIP Models: The Worst-Performing Categories,Yes.,3.,"""This phenomenon reveals the potential risks associated with using CLIP models, particularly in risk-sensitive applications where specific categories hold significant importance.""",2023-10-05T05:37:33Z
Learning Personalized Story Evaluation,Yes.,3.,"""While large language models (LLMs) have shown impressive results for more objective tasks such as QA and retrieval, it remains nontrivial to evaluate their performance on open-ended text generation for reasons including (1) data contamination; (2) multi-dimensional evaluation criteria; and (3) subjectiveness stemming from reviewers' personal preferences.""",2023-10-05T04:15:48Z
Benchmarking Large Language Models As AI Research Agents,Yes.,5.,"""Finally, we identify several key challenges for LLM-based research agents such as long-term planning and hallucination.""",2023-10-05T04:06:12Z
A New Dialogue Response Generation Agent for Large Language Models by Asking Questions to Detect User's Intentions,Yes.,5.,"""However, there are two issues with applying LLMs to dialogue tasks. 1. During the dialogue process, users may have implicit intentions that might be overlooked by LLMs. Consequently, generated responses couldn't align with the user's intentions. 2. It is unlikely for LLMs to encompass all fields comprehensively. In certain specific domains, their knowledge may be incomplete,",2023-10-05T03:45:54Z
A Formalism and Approach for Improving Robustness of Large Language Models Using Risk-Adjusted Confidence Scores,Yes.,5.,"""Despite their impressive performance, the models are known to pose important risks."" and ""a systematic understanding of different risks posed by these models on tasks such as natural language inference (NLI), is much needed.""",2023-10-05T03:20:41Z
InstructProtein: Aligning Human and Protein Language via Knowledge Instruction,Yes.,3.,"""Large Language Models (LLMs) have revolutionized the field of natural language processing, but they fall short in comprehending biological sequences such as proteins.""",2023-10-05T02:45:39Z
Predicting Emergent Abilities with Infinite Resolution Evaluation,Yes.,3.,"""Task performances typically show minor gains on small models until they improve dramatically once models exceed a size threshold, exemplifying the 'emergent abilities'.""",2023-10-05T02:35:00Z
Can Large Language Models be Good Path Planners? A Benchmark and Investigation on Spatial-temporal Reasoning,Yes.,5.,"""they still face limitations in scenarios that demand long-term planning and spatial reasoning"" and ""it still fails to perform long-term temporal reasoning"" and ""fine-tuned LLMs achieved impressive results on in-distribution reasoning tasks, they struggled to generalize to larger environments or environments with more obstacles.""",2023-10-05T01:42:16Z
FreshLLMs: Refreshing Large Language Models with Search Engine Augmentation,Yes.,5.,"""Through human evaluations involving more than 50K judgments, we shed light on limitations of these models and demonstrate significant room for improvement",2023-10-05T00:04:12Z
Misusing Tools in Large Language Models With Visual Adversarial Examples,Yes.,5.,"""These new capabilities bring new benefits and also new security risks."" and ""In this work, we show that an attacker can use visual adversarial examples to cause attacker-desired tool usage.""",2023-10-04T22:10:01Z
Retrieval-augmented Generation to Improve Math Question-Answering: Trade-offs Between Groundedness and Human Preference,Yes.,3.,"""However, LLM responses to math questions can be incorrect or mismatched to the educational context - such as being misaligned with a school's curriculum.""",2023-10-04T22:09:28Z
$\mathcal{B}$-Coder: Value-Based Deep Reinforcement Learning for Program Synthesis,Yes.,2.,"""Yet, training value-based methods presents challenges due to the enormous search space inherent to program synthesis.""",2023-10-04T21:40:36Z
Understanding In-Context Learning in Transformers and LLMs by Learning to Learn Discrete Functions,Yes.,3.,"""However, the limitations of Transformers in implementing learning algorithms, and their ability to learn other forms of algorithms are not well understood. Additionally, the degree to which these capabilities are confined to attention-based models is unclear. Furthermore, it remains to be seen whether the insights derived from these stylized settings can be extrapolated to pretrained Large Language Models (LLMs).""",2023-10-04T17:57:33Z
From Words to Watts: Benchmarking the Energy Costs of Large Language Model Inference,Yes.,4.,"""However, these models carry significant computational challenges, especially the compute and energy costs required for inference.""",2023-10-04T17:41:59Z
"JsonTuning: Towards Generalizable, Robust, and Controllable Instruction Tuning",Yes.,4.,"""prevalent text-to-text instruction tuning (TextTuning) methods suffer from limitations in generalization, robustness, and controllability due to the ambiguity and lack of explicit structure in tasks.""",2023-10-04T16:44:23Z
Shadow Alignment: The Ease of Subverting Safely-Aligned Language Models,Yes.,5.,"""To ensure AI safety, extensive safety-alignment measures have been conducted to armor these models against malicious use (primarily hard prompt attack). However, beneath the seemingly resilient facade of the armor, there might lurk a shadow. By simply tuning on 100 malicious examples with 1 GPU hour,",2023-10-04T16:39:31Z
Assessing Large Language Models on Climate Information,Yes.,4.,"""Our framework discerns up to 30 distinct issues in model outputs"" and ""shedding light on both the potential and the limitations of LLMs in the realm of climate communication.""",2023-10-04T16:09:48Z
Large language models in textual analysis for gesture selection,Yes.,1.,"""Here, we approach these challenges by using large language models (LLMs) to show that these powerful models of large amounts of data can be adapted for gesture analysis and generation.""",2023-10-04T14:46:37Z
How FaR Are Large Language Models From Agents with Theory-of-Mind?,Yes.,5.,"""LLMs such as GPT-4 and PaLM 2 seemingly excel at tracking characters' beliefs in stories, but they struggle to translate this capability into strategic action."" and ""Our analysis reveals the core challenge for LLMs lies in identifying the implicit inferences about mental states without being explicitly asked about as in ToMi, that lead to choosing the correct action in T4D",2023-10-04T06:47:58Z
NOLA: Networks as Linear Combination of Low Rank Random Basis,Yes.,4.,"""However, fine-tuning all parameters and storing a unique model for each downstream task or domain becomes impractical because of the massive size of checkpoints (e.g., 350GB in GPT-3)."" and ""Yet, these methods face two primary limitations",2023-10-04T03:30:24Z
Low-Resource Languages Jailbreak GPT-4,Yes.,5.,"""Our work exposes the inherent cross-lingual vulnerability of these safety mechanisms, resulting from the linguistic inequality of safety training data,"" and ""this deficiency now poses a risk to all LLMs users.""",2023-10-03T21:30:56Z
Novice Learner and Expert Tutor: Evaluating Math Reasoning Abilities of Large Language Models with Misconceptions,Yes.,5.,"""Our experiments reveal that, while LLMs can easily answer these questions correctly, they struggle to identify 1) the incorrect answer corresponding to specific incomplete knowledge (misconceptions); 2) the misconceptions that explain particular incorrect answers.""",2023-10-03T21:19:50Z
Can Large Language Models Provide Security & Privacy Advice? Measuring the Ability of LLMs to Refute Misconceptions,Yes.,5.,"""However, their accuracy and correctness have been called into question. Prior research has outlined the shortcomings of LLMs in answering multiple-choice questions and user ability to inadvertently circumvent model restrictions (e.g., to produce toxic content)."" and ""Both models demonstrate, on average, a 21.3% non-negligible error rate, incorrectly supporting popular S&P misconceptions. The error rate",2023-10-03T20:54:29Z
AutoDAN: Generating Stealthy Jailbreak Prompts on Aligned Large Language Models,Yes.,4.,"""However, these large models remain susceptible to jailbreak attacks, where adversaries manipulate prompts to elicit malicious outputs that should not be given by aligned LLMs.""",2023-10-03T19:44:37Z
Conversational Health Agents: A Personalized LLM-Powered Agent Framework,Yes.,3.,"""Current CHAs, especially those utilizing Large Language Models (LLMs), primarily focus on conversation aspects. However, they offer limited agent capabilities, specifically lacking multi-step problem-solving, personalized conversations, and multimodal data analysis.""",2023-10-03T18:54:10Z
Reinforcement Learning from Automatic Feedback for High-Quality Unit Test Generation,Yes.,3.,"""However, these LLMs are often trained on vast amounts of publicly available code, which may include test cases that do not adhere to best practices and may even contain test smells (anti-patterns).""",2023-10-03T18:48:31Z
Investigating Large Language Models' Perception of Emotion Using Appraisal Theory,Yes.,4.,"""The results show that LLMs' responses are similar to humans in terms of dynamics of appraisal and coping, but their responses did not differ along key appraisal dimensions as predicted by the theory and data. The magnitude of their responses is also quite different from humans in several variables. We also found that GPTs can be quite sensitive to instruction and how questions are asked.""",2023-10-03T16:34:47Z
Dynamic LLM-Agent Network: An LLM-agent Collaboration Framework with Agent Team Optimization,,,,2023-10-03T16:05:48Z
Editing Personality for Large Language Models,Yes.,3.,"""We conduct comprehensive experiments involving various baselines and discuss the representation of personality behavior in LLMs. Our intriguing findings uncover potential challenges of the proposed task, illustrating several remaining issues.""",2023-10-03T16:02:36Z
Unveiling the Pitfalls of Knowledge Editing for Large Language Models,Yes.,5.,"""Experimental results vividly demonstrate that knowledge editing might inadvertently cast a shadow of unintended consequences on LLMs, which warrant attention and efforts for future works.""",2023-10-03T15:10:46Z
OceanGPT: A Large Language Model for Ocean Science Tasks,Yes.,3.,"""current LLMs often fall short in catering to the needs of domain experts like oceanographers, and the potential of LLMs for ocean science is under-explored. The intrinsic reason may be the immense and intricate nature of ocean data as well as the necessity for higher granularity and richness in knowledge.""",2023-10-03T13:17:35Z
Fill in the Blank: Exploring and Enhancing LLM Capabilities for Backward Reasoning in Math Word Problems,Yes.,5.,"""Our findings show a significant drop in the accuracy of models on backward reasoning compared to forward reasoning across four SOTA LLMs (GPT4, GPT3.5, PaLM-2, and LLaMa-2).""",2023-10-03T12:03:06Z
Formalizing Natural Language Intent into Program Specifications via Large Language Models,Yes.,3.,"""However, it is unclear if LLMs can correctly translate informal natural language specifications into formal specifications that match programmer intent. Additionally, it is unclear if such translation could be useful in practice.""",2023-10-03T06:55:45Z
