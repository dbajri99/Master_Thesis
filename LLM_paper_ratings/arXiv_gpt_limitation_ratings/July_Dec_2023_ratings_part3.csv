Title,Talks about LLMs,Rate,Evidence,Published
Model Tells You What to Discard: Adaptive KV Cache Compression for LLMs,Yes.,1.,"""In this study, we introduce adaptive KV cache compression, a plug-and-play method that reduces the memory footprint of generative inference for Large Language Models (LLMs).""",2023-10-03T05:17:08Z
Large Language Models Cannot Self-Correct Reasoning Yet,Yes.,5.,"""our research indicates that LLMs struggle to self-correct their responses without external feedback, and at times, their performance even degrades after self-correction.""",2023-10-03T04:56:12Z
HallE-Control: Controlling Object Hallucination in Large Multimodal Models,Yes.,5.,"""Interestingly, while LMMs demonstrate minimal object existence hallucination in existing VQA benchmarks, our proposed evaluation reveals continued susceptibility to such hallucinations."" and ""Our findings underscore the unwarranted inference when the language description includes details at a finer object granularity than what the vision module can",2023-10-03T04:01:27Z
Time-LLM: Time Series Forecasting by Reprogramming Large Language Models,Yes.,3.,"""the challenge remains in effectively aligning the modalities of time series data and natural language to leverage these capabilities.""",2023-10-03T01:31:25Z
Can GPT-4 Replicate Empirical Software Engineering Research?,Yes.,4.,"""We find that GPT-4 is able to surface correct assumptions, but struggle to generate ones that reflect common knowledge about software engineering data. In a manual analysis of the generated code, we find that the GPT-4-generated code contains the correct high-level logic, given a subset of the methodology. However, the code contains many small implementation-level errors, reflecting a lack of software engineering",2023-10-03T01:27:23Z
Large Language Models for Test-Free Fault Localization,Yes.,1.,"""Inspired by the ability of large language models (LLMs) of code to adapt to new tasks based on very few examples, we investigate the applicability of LLMs to line level fault localization.""",2023-10-03T01:26:39Z
Deciphering Diagnoses: How Large Language Models Explanations Influence Clinical Decision Making,Yes.,3.,"""highlighted potential errors in LLM outputs, ranging from 5% to 30%.""",2023-10-03T00:08:23Z
PolySketchFormer: Fast Transformers via Sketching Polynomial Kernels,Yes.,5.,"""The quadratic time and memory complexity inherent to self-attention mechanisms, with respect to sequence length, presents a critical computational bottleneck in the training and deployment of large-scale Transformer-based language models.""",2023-10-02T21:39:04Z
VAL: Interactive Task Learning with GPT Dialog Parsing,Yes.,3.,"""Large language models (LLMs) are resistant to brittleness but are not interpretable and cannot learn incrementally.""",2023-10-02T20:45:41Z
On the Safety of Open-Sourced Large Language Models: Does Alignment Really Prevent Them From Being Misused?,Yes.,5.,"""many existing studies have shown that they could be misused to generate undesired content"" and ""we show those open-sourced, aligned large language models could be easily misguided to generate undesired content without heavy computations or careful prompt designs.""",2023-10-02T19:22:01Z
"LLM Lies: Hallucinations are not Bugs, but Features as Adversarial Examples",Yes.,5.,"""However, we still can not completely trust their answer, since LLMs suffer from hallucination--fabricating non-existent facts to cheat users without perception.""",2023-10-02T17:01:56Z
Towards reporting bias in visual-language datasets: bimodal augmentation by decoupling object-attribute association,Yes.,2.,"""Reporting bias arises when people assume that some knowledge is universally understood and hence, do not necessitate explicit elaboration."" and ""We employ large language models (LLMs) in conjunction with a grounding object detector to extract target objects.""",2023-10-02T16:48:50Z
Avalon's Game of Thoughts: Battle Against Deception through Recursive Contemplation,Yes.,5.,"""This oversight makes LLMs susceptible to malicious manipulations, potentially resulting in detrimental outcomes."" and ""Finally, we offer a possible explanation for the efficacy of ReCon and explore the current limitations of LLMs in terms of safety, reasoning, speaking style, and format, potentially furnishing insights for subsequent research.""",2023-10-02T16:27:36Z
Knowledge Crosswords: Geometric Reasoning over Structured Knowledge with Large Language Models,Yes.,5.,"""Further analysis reveals that LLMs' ability of geometric reasoning over structured knowledge is still far from robust or perfect, susceptible to confounders such as the order of options, certain structural patterns, assumption of existence of correct answer, and more.""",2023-10-02T15:43:53Z
SPELL: Semantic Prompt Evolution based on a LLM,Yes.,2.,"""We further explore the evolution process and discuss on the limitations, potential possibilities and future work.""",2023-10-02T14:51:16Z
Automated Evaluation of Classroom Instructional Support with LLMs and BoWs: Connecting Global Predictions to Specific Feedback,Yes.,3.,"""for classifying individual utterances, there is still room for improvement of automated methods compared to human-level judgments.""",2023-10-02T12:11:17Z
GraphText: Graph Reasoning in Text Space,Yes.,3.,"""LLMs have not made significant advancements in the realm of graph machine learning. This limitation arises because graphs encapsulate distinct relational data, making it challenging to transform them into natural language that LLMs understand.""",2023-10-02T11:03:57Z
Towards human-like spoken dialogue generation between AI agents from written dialogue,Yes.,3.,"""The advent of large language models (LLMs) has made it possible to generate natural written dialogues between two agents. However, generating human-like spoken dialogues from these written dialogues remains challenging.""",2023-10-02T11:03:20Z
Back to the Future: Towards Explainable Temporal Reasoning with Large Language Models,Yes.,4.,"""Another notable limitation of existing methods is their incapability to provide an illustration of their reasoning process, hindering explainability."" and ""A significant gap remains when considering complex reasoning tasks such as event forecasting, which requires multi-step temporal reasoning on events and prediction on the future timestamp.""",2023-10-02T10:35:23Z
Resolving Knowledge Conflicts in Large Language Models,Yes.,5.,"""Extensive experiments with the KNOWLEDGE CONFLICT framework reveal that while LLMs perform well in identifying the existence of knowledge conflicts, they struggle to determine the specific conflicting knowledge and produce a response with distinct answers amidst conflicting information.""",2023-10-02T06:57:45Z
All Languages Matter: On the Multilingual Safety of Large Language Models,Yes.,4.,"""Experimental results show that all LLMs produce significantly more unsafe responses for non-English queries than English ones, indicating the necessity of developing safety alignment for non-English languages.""",2023-10-02T05:23:34Z
DataInf: Efficiently Estimating Data Influence in LoRA-tuned LLMs and Diffusion Models,Yes.,2.,"""This issue becomes more pronounced in the setting of large language models and text-to-image models.""",2023-10-02T04:59:19Z
Enabling Language Models to Implicitly Learn Self-Improvement,Yes.,3.,"""However, the inherent open-ended nature of these tasks implies that there is always room for improvement in the quality of model responses."" and ""It is expensive and challenging to manually derive and provide all necessary rubrics with a real-world complex goal for improvement (e.g., being more helpful and less harmful).""",2023-10-02T04:29:40Z
Do Compressed LLMs Forget Knowledge? An Experimental Study with Practical Implications,Yes.,5.,"""Compressing Large Language Models (LLMs) often leads to reduced performance, especially for knowledge-intensive tasks."" and ""We start by proposing two conjectures on the nature of the damage",2023-10-02T03:12:06Z
Towards LogiGLUE: A Brief Survey and A Benchmark for Analyzing Logical Reasoning Capabilities of Language Models,Yes.,3.,"""the findings indicate that LLMs excel most in abductive reasoning, followed by deductive reasoning, while they are least effective at inductive reasoning.""",2023-10-02T01:00:50Z
BooookScore: A systematic exploration of book-length summarization in the era of LLMs,Yes.,4.,"""identify eight common types of coherence errors made by LLMs.""",2023-10-01T20:46:44Z
FELM: Benchmarking Factuality Evaluation of Large Language Models,Yes.,5.,"""Our findings reveal that while retrieval aids factuality evaluation, current LLMs are far from satisfactory to faithfully detect factual errors.""",2023-10-01T17:37:31Z
GenAI Against Humanity: Nefarious Applications of Generative Artificial Intelligence and Large Language Models,Yes.,5.,"""we'll uncover the societal implications that ripple through the GenAI revolution we are witnessing"" and ""This article serves both as a synthesis of rigorous research presented on the risks of GenAI and misuse of LLMs and as a thought-provoking vision of the different types of harmful",2023-10-01T17:25:56Z
LEGO-Prover: Neural Theorem Proving with Growing Libraries,Yes.,3.,"""Prior methods using language models have demonstrated promising results, but they still struggle to prove even middle school level theorems. One common limitation of these methods is that they assume a fixed theorem library during the whole theorem proving process.""",2023-10-01T12:47:59Z
Beyond Task Performance: Evaluating and Reducing the Flaws of Large Multimodal Models with In-Context Learning,Yes.,5.,"""However, interacting with recent LMMs reveals major limitations that are hardly captured by the current evaluation benchmarks."" and ""Our evaluation on these axes reveals major flaws in LMMs.""",2023-10-01T12:02:59Z
Faithful Explanations of Black-box NLP Models Using LLM-generated Counterfactuals,Yes.,3.,"""While this approach is demonstrated to be very effective, applying LLM at inference-time is costly.""",2023-10-01T07:31:04Z
GrowLength: Accelerating LLMs Pretraining by Progressively Growing Training Length,Yes.,2.,"""The evolving sophistication and intricacies of Large Language Models (LLMs) yield unprecedented advancements, yet they simultaneously demand considerable computational resources and incur significant costs.""",2023-10-01T05:25:24Z
Measuring Value Understanding in Language Models through Discriminator-Critique Gap,Yes.,4.,"""Recent advancements in Large Language Models (LLMs) have heightened concerns about their potential misalignment with human values"" and ""This may further suggest that LLMs might craft plausible explanations based on the provided context without truly understanding their inherent value, indicating potential risks.""",2023-09-30T13:47:55Z
Understanding In-Context Learning from Repetitions,Yes.,5.,"""our research illuminates the internal workings of in-context learning and expounds on the reasons for its failures"" and ""providing a fresh perspective on this exciting capability.""",2023-09-30T08:13:49Z
Investigating the Efficacy of Large Language Models in Reflective Assessment Methods through Chain of Thoughts Prompting,Yes.,3.,"""While LLMs have demonstrated impressive performance across various text-related tasks, they encounter challenges in tasks associated with reasoning.""",2023-09-30T06:25:27Z
AutoHall: Automated Hallucination Dataset Generation for Large Language Models,Yes.,5.,"""the detection of non-factual or hallucinatory content generated by LLMs remains scarce"" and ""variations in hallucination proportions and types among different models.""",2023-09-30T05:20:02Z
Pairwise Proximal Policy Optimization: Harnessing Relative Feedback for LLM Alignment,Yes.,3.,"""However, due to exposure to low-quality data, LLMs may exhibit harmful behavior without aligning with human values."" and ""Despite its effectiveness, PPO has limitations when optimizing rewards trained from comparison-based loss.""",2023-09-30T01:23:22Z
"Pruning Small Pre-Trained Weights Irreversibly and Monotonically Impairs ""Difficult"" Downstream Tasks in LLMs",Yes.,5.,"""we reveal that these seemingly inconsequential weights can result in irreparable loss of knowledge and performance degradation in difficult tasks, even when downstream continual training is allowed.""",2023-09-29T22:55:06Z
SocREval: Large Language Models with the Socratic Method for Reference-Free Reasoning Evaluation,Yes.,3.,"""Existing reference-free reasoning metrics eliminate the need for human-crafted reasoning chains as references, but they typically require fine-tuning on datasets with human-derived reasoning chains, which complicates the process and raises concerns regarding generalizability across diverse datasets.""",2023-09-29T18:25:46Z
Efficient Streaming Language Models with Attention Sinks,Yes.,5.,"""Firstly, during the decoding stage, caching previous tokens' Key and Value states (KV) consumes extensive memory. Secondly, popular LLMs cannot generalize to longer texts than the training sequence length.""",2023-09-29T17:59:56Z
L2CEval: Evaluating Language-to-Code Generation Capabilities of Large Language Models,Yes.,3.,"""This enables us to identify and analyze the typical failure modes across various tasks and models.""",2023-09-29T17:57:00Z
LLM-grounded Video Diffusion Models,Yes.,3.,"""current models still struggle with intricate spatiotemporal prompts and often generate restricted or incorrect motion.""",2023-09-29T17:54:46Z
Can Sensitive Information Be Deleted From LLMs? Objectives for Defending Against Extraction Attacks,Yes.,5.,"""Pretrained language models sometimes possess knowledge that we do not wish them to, including memorized personal information and knowledge that could be used to harm people. They can also output toxic or harmful text."" and ""Experimentally, we show that even state-of-the-art model editing methods such as ROME struggle to truly delete factual information from models like GPT-J, as our whitebox and",2023-09-29T17:12:43Z
LoRA ensembles for large language model fine-tuning,Yes.,5.,"""Finetuned LLMs often exhibit poor uncertainty quantification, manifesting as overconfidence, poor calibration, and unreliable prediction results on test data or out-of-distribution samples.""",2023-09-29T16:38:38Z
"Reason for Future, Act for Now: A Principled Framework for Autonomous LLM Agents with Provable Sample Efficiency",Yes.,4.,"""Large language models (LLMs) demonstrate impressive reasoning abilities, but translating reasoning into actions in the real world remains challenging. In particular, it remains unclear how to complete a given task provably within a minimum number of interactions with the external environment.""",2023-09-29T16:36:39Z
Network Memory Footprint Compression Through Jointly Learnable Codebooks and Mappings,No.,1.,The paper discusses deep neural networks in general and does not specifically mention language models (LLMs or LMs).,2023-09-29T16:04:55Z
Assessing Look-Ahead Bias in Stock Return Predictions Generated By GPT Sentiment Analysis,Yes.,5.,"""This bias can take two forms",2023-09-29T15:30:32Z
Split and Merge: Aligning Position Biases in Large Language Model based Evaluators,Yes.,5.,"""these LLM-based evaluators exhibit position bias, or inconsistency, when used to evaluate candidate answers in pairwise comparisons, favoring either the first or second answer regardless of content.""",2023-09-29T14:38:58Z
Suspicion-Agent: Playing Imperfect Information Games with Theory of Mind Aware GPT-4,Yes.,1.,"""GPT-4, the recent breakthrough in large language models (LLMs) trained on massive passive data, is notable for its knowledge retrieval and reasoning abilities.""",2023-09-29T14:30:03Z
LLM-Deliberation: Evaluating LLMs with Interactive Multi-Agent Negotiation Games,Yes.,3.,"""Yet, we have a limited understanding of LLMs' reasoning and decision-making capabilities, partly stemming from a lack of dedicated evaluation benchmarks.""",2023-09-29T13:33:06Z
Training and inference of large language models using 8-bit floating point,Yes.,1.,"""This paper presents a methodology to select the scalings for FP8 linear layers, based on dynamically updating per-tensor scales for the weights, gradients and activations. We apply this methodology to train and validate large language models of the type of GPT and Llama 2 using FP8, for model sizes ranging from 111M to 70B.""",2023-09-29T13:24:33Z
Alphazero-like Tree-Search can Guide Large Language Model Decoding and Training,Yes.,3.,"""As a result, these methods will not work in domains where the pre-trained LLM does not have enough knowledge to serve as an effective value function or in domains that require long-horizon planning.""",2023-09-29T12:20:19Z
LatticeGen: A Cooperative Framework which Hides Generated Text in a Lattice for Privacy-Aware Generation on Cloud,Yes.,2.,"""the server fully controls the generation process, which leaves zero options for users who want to keep the generated text to themselves.""",2023-09-29T11:46:07Z
Using Large Language Models for Qualitative Analysis can Introduce Serious Bias,Yes.,4.,"""We find that a great deal of caution is needed in using LLMs to annotate text as there is a risk of introducing biases that can lead to misleading inferences."" and ""Training simpler supervised models on high-quality human annotations with flexible coding leads to less measurement error and bias than LLM annotations.""",2023-09-29T11:19:15Z
Benchmarking the Abilities of Large Language Models for RDF Knowledge Graph Creation and Comprehension: How Well Do LLMs Speak Turtle?,Yes.,3.,"""While our findings show that the latest commercial models outperform their forerunners in terms of proficiency with the Turtle language, they also reveal an apparent weakness. These models fall short when it comes to adhering strictly to the output formatting constraints, a crucial requirement in this context.""",2023-09-29T10:36:04Z
Benchmarking Cognitive Biases in Large Language Models as Evaluators,Yes.,5.,"""We find that LLMs are biased text quality evaluators, exhibiting strong indications on our bias benchmark (average of 40% of comparisons across all models) within each of their evaluations that question their robustness as evaluators.""",2023-09-29T06:53:10Z
Medical Foundation Models are Susceptible to Targeted Misinformation Attacks,Yes.,5.,"""Through targeted manipulation of just 1.1% of the model's weights, we can deliberately inject an incorrect biomedical fact. The erroneous information is then propagated in the model's output, whilst its performance on other biomedical tasks remains intact. This peculiar susceptibility raises serious security and trustworthiness concerns for",2023-09-29T06:44:36Z
I Wish to Have an Argument: Argumentative Reasoning in Large Language Models,Yes.,3.,"""We find that, although LLMs are able to match or surpass the state-of-the-art in AM and APE, their argumentative reasoning performance is very dependent on the input and output representation. We also find an 'exemplar effect', where too many exemplars increasingly become detrimental for task performance.""",2023-09-29T02:41:38Z
GPT-Fathom: Benchmarking Large Language Models to Decipher the Evolutionary Path towards GPT-4 and Beyond,Yes.,3.,"""there is a pressing need for a comprehensive evaluation suite to assess their capabilities and limitations.""",2023-09-28T16:43:35Z
Neuro Symbolic Reasoning for Planning: Counterexample Guided Inductive Synthesis using Large Language Models and Satisfiability Solving,Yes.,5.,"""Despite their remarkably improved accuracy, these models are still known to produce factually incorrect or contextually inappropriate results despite their syntactic coherence - a phenomenon often referred to as hallucination. This limitation makes it difficult to use these models to synthesize formal artifacts that are used in safety-critical applications. Unlike tasks such as text summarization and question-answering, bugs in code, plan,",2023-09-28T13:40:50Z
Human Feedback is not Gold Standard,Yes.,5.,"""We critically analyse the use of human feedback for both training and evaluation, to verify whether it fully captures a range of crucial error criteria. We find that while preference scores have fairly good coverage, they under-represent important aspects like factuality.""",2023-09-28T11:18:20Z
Intrinsic Language-Guided Exploration for Complex Long-Horizon Robotic Manipulation Tasks,Yes.,1.,"""By leveraging LLMs as an assistive intrinsic reward, IGE-LLMs guides the exploratory process in reinforcement learning to address intricate long-horizon with sparse rewards robotic manipulation tasks.""",2023-09-28T11:14:52Z
LawBench: Benchmarking Legal Knowledge of Large Language Models,Yes.,5.,"""it is unclear how much legal knowledge they possess and whether they can reliably perform legal-related tasks,"" and ""While fine-tuning LLMs on legal specific text brings certain improvements, we are still a long way from obtaining usable and reliable LLMs in legal tasks.""",2023-09-28T09:35:59Z
Beyond Reverse KL: Generalizing Direct Preference Optimization with Diverse Divergence Constraints,Yes.,2.,"""The increasing capabilities of large language models (LLMs) raise opportunities for artificial general intelligence but concurrently amplify safety concerns, such as potential misuse of AI systems, necessitating effective AI alignment.""",2023-09-28T08:29:44Z
AE-GPT: Using Large Language Models to Extract Adverse Events from Surveillance Reports-A Use Case with Influenza Vaccine Adverse Events,Yes.,1.,"""Recently, Large Language Models (LLMs) have shown promise in effectively identifying and cataloging AEs within clinical reports.""",2023-09-28T03:53:21Z
ModuLoRA: Finetuning 2-Bit LLMs on Consumer GPUs by Integrating with Modular Quantizers,Yes.,1.,"""We propose a memory-efficient finetuning algorithm for large language models (LLMs) that supports finetuning LLMs with 65B parameters in 2/3/4-bit precision on as little as one 24GB GPU",2023-09-28T02:55:01Z
MedEdit: Model Editing for Medical Question Answering with External Knowledge Bases,Yes.,4.,"""Large Language Models (LLMs), although powerful in general domains, often perform poorly on domain-specific tasks like medical question answering (QA). Moreover, they tend to function as 'black-boxes,' making it challenging to modify their behavior.""",2023-09-27T21:26:03Z
Lyra: Orchestrating Dual Correction in Automated Theorem Proving,Yes.,3.,"""Nevertheless, their full potential, particularly concerning the mitigation of hallucinations and refinement through prover error messages, remains an area that has yet to be thoroughly investigated.""",2023-09-27T17:29:41Z
Large Language Model Routing with Benchmark Datasets,Yes.,3.,"""We demonstrate the utility and limitations of learning model routers from various benchmark datasets, where we consistently improve performance upon using any single model for all tasks.""",2023-09-27T17:08:40Z
Deep Model Fusion: A Survey,,,,2023-09-27T14:40:12Z
NLPBench: Evaluating Large Language Models on Solving NLP Problems,Yes.,4.,"""Our study reveals that the effectiveness of the advanced prompting strategies can be inconsistent, occasionally damaging LLM performance, especially in smaller models like the LLAMA-2 (13b). Furthermore, our manual assessment illuminated specific shortcomings in LLMs' scientific problem-solving skills, with weaknesses in logical decomposition and reasoning",2023-09-27T13:02:06Z
Rethinking Channel Dimensions to Isolate Outliers for Low-bit Weight Quantization of Large Language Models,Yes.,3.,"""However, efficiently serving LLMs has been a challenge due to the large memory bottleneck, specifically in small batch inference settings (e.g. mobile devices).""",2023-09-27T09:48:31Z
Graph Neural Prompting with Large Language Models,Yes.,4.,"""they still exhibit inherent limitations in precisely capturing and returning grounded knowledge"" and ""applying this to LLMs is problematic owing to their large number of parameters and high computational cost.""",2023-09-27T06:33:29Z
Beyond the Chat: Executable and Verifiable Text-Editing with LLMs,Yes.,3.,"""Because LLMs are known to introduce factual errors, Inksync also supports a 3-stage approach to mitigate this risk",2023-09-27T00:56:17Z
Creating Trustworthy LLMs: Dealing with Hallucinations in Healthcare AI,Yes.,5.,"""There is however hesitation in the medical and healthcare domain towards their adoption because of issues like factuality, coherence, and hallucinations.""",2023-09-26T20:52:46Z
RAGAS: Automated Evaluation of Retrieval Augmented Generation,Yes.,1.,"""RAG systems are composed of a retrieval and an LLM based generation module,"" and ""reducing the risk of hallucinations.""",2023-09-26T19:23:54Z
Attention Satisfies: A Constraint-Satisfaction Lens on Factual Errors of Language Models,Yes.,5.,"""We investigate the internal behavior of Transformer-based Large Language Models (LLMs) when they generate factually incorrect text.""",2023-09-26T17:48:55Z
How to Catch an AI Liar: Lie Detection in Black-Box LLMs by Asking Unrelated Questions,Yes.,5.,"""Large language models (LLMs) can 'lie', which we define as outputting false statements despite 'knowing' the truth in a demonstrable sense.""",2023-09-26T16:07:54Z
Large Language Model Alignment: A Survey,Yes.,4.,"""they may yield texts that are imprecise, misleading, or even detrimental"" and ""probe into salient issues including the models' interpretability, and potential vulnerabilities to adversarial attacks.""",2023-09-26T15:49:23Z
ConPET: Continual Parameter-Efficient Tuning for Large Language Models,Yes.,3.,"""This is extremely challenging for large language models (LLMs) with vanilla full-parameter tuning due to high computation costs, memory consumption, and forgetting issue.""",2023-09-26T08:52:04Z
QA-LoRA: Quantization-Aware Low-Rank Adaptation of Large Language Models,Yes.,3.,"""Despite the strong ability in many language-understanding tasks, the heavy computational burden largely restricts the application of LLMs especially when one needs to deploy them onto edge devices.""",2023-09-26T07:22:23Z
Are Human-generated Demonstrations Necessary for In-context Learning?,Yes.,3.,"""the standard paradigm of In-context Learning (ICL) suffers the disadvantages of susceptibility to selected demonstrations and the intricacy to generate these demonstrations.""",2023-09-26T05:10:08Z
Disinformation Detection: An Evolving Challenge in the Age of LLMs,Yes.,4.,"""One critical concern is the misuse of LLMs by disinformation spreaders, leveraging these models to generate highly persuasive yet misleading content that challenges the disinformation detection system.""",2023-09-25T22:12:50Z
Free-Bloom: Zero-Shot Text-to-Video Generator with LLM Director and LDM Animator,Yes.,1.,"""we propose a novel Free-Bloom pipeline that harnesses large language models (LLMs) as the director to generate a semantic-coherence prompt sequence""",2023-09-25T19:42:16Z
Lifelong Robot Learning with Human Assisted Language Planners,Yes.,5.,"""However, current LLM-based planners are only able to operate with a fixed set of skills.""",2023-09-25T17:45:55Z
"Physics of Language Models: Part 3.1, Knowledge Storage and Extraction",Yes.,4.,"""Without such augmentation, knowledge may be memorized but not extractable, leading to 0% accuracy, regardless of subsequent instruction fine-tuning.""",2023-09-25T17:37:20Z
Identifying the Risks of LM Agents with an LM-Emulated Sandbox,Yes.,5.,"""Recent advances in Language Model (LM) agents and tool use, exemplified by applications like ChatGPT Plugins, enable a rich set of capabilities but also amplify potential risks - such as leaking private data or causing financial losses."" and ""we provide a quantitative risk analysis of current LM agents and identify numerous failures with potentially severe outcomes. Notably, even the safest LM agent exhibits such failures",2023-09-25T17:08:02Z
LLMCarbon: Modeling the end-to-end Carbon Footprint of Large Language Models,Yes.,4.,"""Existing studies have reported the carbon footprint of LLM training, but only one tool, mlco2, can predict the carbon footprint of new neural networks prior to physical training. However, mlco2 has several serious limitations.""",2023-09-25T14:50:04Z
The Cybersecurity Crisis of Artificial Intelligence: Unrestrained Adoption and Natural Language-Based Attacks,Yes.,5.,"""The widespread integration of autoregressive-large language models (AR-LLMs), such as ChatGPT, across established applications, like search engines, has introduced critical vulnerabilities with uniquely scalable characteristics. In this commentary, we analyse these vulnerabilities, their dependence on natural language as a vector of",2023-09-25T10:48:46Z
Analyzing the Efficacy of an LLM-Only Approach for Image-based Document Question Answering,Yes.,2.,"""However, the relative contributions of the vision encoder and the language model in these tasks remain unclear.""",2023-09-25T07:01:16Z
Evaluating Cognitive Maps and Planning in Large Language Models with CogEval,Yes.,5.,"""systematic evaluation reveals striking failure modes in planning tasks, including hallucinations of invalid trajectories and getting trapped in loops.""",2023-09-25T01:20:13Z
Can LLM-Generated Misinformation Be Detected?,Yes.,5.,"""However, the potential that LLMs such as ChatGPT can be exploited to generate misinformation has posed a serious concern to online safety and public trust."" and ""we discover that LLM-generated misinformation can be harder to detect for humans and detectors compared to human-written misinformation with the same semantics, which suggests it can",2023-09-25T00:45:07Z
ALLURE: Auditing and Improving LLM-based Evaluation of Text using Iterative In-Context-Learning,Yes.,5.,"""However, despite their extensive utility, LLMs exhibit distinct failure modes, necessitating a thorough audit and improvement of their text evaluation capabilities.""",2023-09-24T17:15:58Z
Embers of Autoregression: Understanding Large Language Models Through the Problem They are Trained to Solve,Yes.,5.,"""The widespread adoption of large language models (LLMs) makes it important to recognize their strengths and limitations,"" and ""In many cases, the experiments reveal surprising failure modes,"" and ""AI practitioners should be careful about using LLMs in low-probability situations.""",2023-09-24T13:35:28Z
Resolving References in Visually-Grounded Dialogue via Text Generation,Yes.,1.,"""Vision-language models (VLMs) have shown to be effective at image retrieval based on simple text queries, but text-image retrieval based on conversational input remains a challenge.""",2023-09-23T17:07:54Z
A Chat About Boring Problems: Studying GPT-based text normalization,Yes.,3.,"""we note key limitations in the conventional design of text normalization tasks.""",2023-09-23T16:32:59Z
Towards LLM-guided Causal Explainability for Black-box Text Classifiers,Yes.,3.,"""model qualities like explainability and interpretability, albeit highly desirable, are becoming harder challenges to tackle and solve.""",2023-09-23T11:22:28Z
Enhancing Zero-Shot Chain-of-Thought Reasoning in Large Language Models through Logic,Yes.,5.,"""However, their reasoning abilities still have significant room for improvement, especially when confronted with scenarios requiring multi-step reasoning,"" and ""These models sometimes show hallucinations as their reasoning procedures are unconstrained by logical principles.""",2023-09-23T11:21:12Z
AI-Copilot for Business Optimisation: A Framework and A Case Study in Production Scheduling,Yes.,3.,"""However, developing an LLM for problem formulation is challenging, due to training data, token limitations, and lack of appropriate performance metrics.""",2023-09-22T23:45:21Z
Investigating Large Language Models and Control Mechanisms to Improve Text Readability of Biomedical Abstracts,Yes.,1.,"""In this work, we investigate the ability of state-of-the-art large language models (LLMs) on the task of biomedical abstract simplification, using the publicly available dataset for plain language adaptation of biomedical abstracts (PLABA).""",2023-09-22T22:47:32Z
Towards Green AI in Fine-tuning Large Language Models via Adaptive Backpropagation,Yes.,2.,"""intensively performed LLM fine-tuning worldwide could result in significantly high energy consumption and carbon footprint, which may bring large environmental impact.""",2023-09-22T21:55:18Z
BenLLMEval: A Comprehensive Evaluation into the Potentials and Pitfalls of Large Language Models on Bengali NLP,Yes.,4.,"""Our experimental results demonstrate that while in some Bengali NLP tasks, zero-shot LLMs could achieve performance on par, or even better than current SOTA fine-tuned models; in most tasks, their performance is quite poor (with the performance of open-source LLMs like LLaMA-2-13b-chat being significantly bad) in comparison to the current SOTA results",2023-09-22T20:29:34Z
Contextual Emotion Estimation from Image Captions,Yes.,2.,"""One initial challenge is to construct a caption that describes a person within a scene with information relevant for emotion perception."" and ""accuracy can depend on the emotion concept.""",2023-09-22T18:44:34Z
In-context Interference in Chat-based Large Language Models,Yes.,5.,"""However, one limitation of this scenario is that users cannot modify the internal knowledge of the model, and the only way to add or modify internal knowledge is by explicitly mentioning it to the model during the current interaction."" and ""In-context learning has significant applications, but also has limitations that are seldom studied. In this paper, we present a study that shows how the model can suffer from",2023-09-22T09:18:55Z
Construction contract risk identification based on knowledge-augmented language model,Yes.,3.,"""While large language models (LLMs) have shown promise in revolutionizing natural language processing (NLP) tasks, they struggle with domain-specific knowledge and addressing specialized issues.""",2023-09-22T05:27:06Z
Studying and improving reasoning in humans and machines,Yes.,3.,"""most of the included models presented reasoning errors akin to those frequently ascribed to error-prone, heuristic-based human reasoning"" and ""an in-depth comparison between humans and LLMs indicated important differences with human-like reasoning, with models limitations disappearing almost entirely in more recent LLMs releases.""",2023-09-21T21:02:05Z
Foundation Metrics for Evaluating Effectiveness of Healthcare Conversations Powered by Generative AI,Yes.,4.,"""Existing evaluation metrics proposed for various generic large language models (LLMs) demonstrate a lack of comprehension regarding medical and health concepts and their significance in promoting patients' well-being. Moreover, these metrics neglect pivotal user-centered aspects, including trust-building, ethics, personalization, empathy, user comprehension, and emotional support.""",2023-09-21T19:36:48Z
Can LLMs Augment Low-Resource Reading Comprehension Datasets? Opportunities and Challenges,Yes.,3.,"""highlighting the unique opportunities and challenges.""",2023-09-21T18:48:02Z
LLM-Grounder: Open-Vocabulary 3D Visual Grounding with Large Language Model as an Agent,Yes.,1.,"""While existing approaches often rely on extensive labeled data or exhibit limitations in handling complex language queries, we propose LLM-Grounder, a novel zero-shot, open-vocabulary, Large Language Model (LLM)-based 3D visual grounding pipeline.""",2023-09-21T17:59:45Z
Reranking for Natural Language Generation from Logical Forms: A Study based on Large Language Models,Yes.,4.,"""Large language models (LLMs) have demonstrated impressive capabilities in natural language generation. However, their output quality can be inconsistent, posing challenges for generating natural language from logical forms (LFs).""",2023-09-21T17:54:58Z
"The Reversal Curse: LLMs trained on ""A is B"" fail to learn ""B is A""",Yes.,5.,"""We expose a surprising failure of generalization in auto-regressive large language models (LLMs). If a model is trained on a sentence of the form 'A is B', it will not automatically generalize to the reverse direction 'B is A'.""",2023-09-21T17:52:19Z
Inspire the Large Language Model by External Knowledge on BioMedical Named Entity Recognition,Yes.,4.,"""they often fall short in some information extraction tasks, particularly those requiring domain-specific knowledge, such as Biomedical Named Entity Recognition (NER)"" and ""we inject entity knowledge to address the problem that LLM's lack of domain knowledge when predicting entity category.""",2023-09-21T17:39:53Z
"Bad Actor, Good Advisor: Exploring the Role of Large Language Models in Fake News Detection",Yes.,5.,"""First, we conduct an empirical study and find that a sophisticated LLM such as GPT 3.5 could generally expose fake news and provide desirable multi-perspective rationales but still underperforms the basic SLM, fine-tuned BERT. Our subsequent analysis attributes such a",2023-09-21T16:47:30Z
Code Soliloquies for Accurate Calculations in Large Language Models,Yes.,5.,"""While GPT-4 presents impressive language processing capabilities, its limitations in fundamental mathematical reasoning curtail its efficacy for such subjects.""",2023-09-21T15:16:58Z
A knowledge representation approach for construction contract knowledge modeling,Yes.,4.,"""However, LLMs may produce convincing yet inaccurate and misleading content due to a lack of domain expertise.""",2023-09-21T14:53:36Z
Prompt Tuned Embedding Classification for Multi-Label Industry Sector Allocation,Yes.,5.,"""Text-to-text classification is frequently reported to outperform task-specific classification heads, but has several limitations when applied to a multi-label classification problem where each label consists of multiple tokens",2023-09-21T13:45:32Z
"AceGPT, Localizing Large Language Models in Arabic",Yes.,3.,"""Significant concerns emerge when addressing cultural sensitivity and local values.""",2023-09-21T13:20:13Z
Knowledge Sanitization of Large Language Models,Yes.,4.,"""LLMs trained on a large corpus of Web data can memorize and potentially reveal sensitive or confidential information, raising critical security concerns.""",2023-09-21T07:49:55Z
Goal-Oriented Prompt Attack and Safety Evaluation for LLMs,Yes.,5.,"""LLMs suffer from the risk of generating harmful contents especially while being employed to applications."" and ""there is no publicly available dataset with high successful attacking rate to evaluate the abilities of defending prompt attack.""",2023-09-21T07:07:49Z
LPML: LLM-Prompting Markup Language for Mathematical Reasoning,Yes.,3.,"""addressing the errors in the reasoning and calculation present in the generated text by LLMs is a crucial challenge"" and ""control the undesired behaviors of LLMs.""",2023-09-21T02:46:20Z
LLM-based Medical Assistant Personalization with Short- and Long-Term Memory Coordination,Yes.,3.,"""While one can fully train an LLM for this objective, the resource consumption is unaffordable."" and ""We contend that a mere memory module is inadequate and fully training an LLM can be excessively costly.""",2023-09-21T00:34:33Z
LLM Guided Inductive Inference for Solving Compositional Problems,Yes.,4.,"""their performance is limited when the questions require knowledge that is not included in the model's training data and can only be acquired through direct observation or interaction with the real world."" and ""Existing methods decompose reasoning tasks through the use of modules invoked sequentially, limiting their ability to answer deep reasoning tasks",2023-09-20T23:44:16Z
Construction of Paired Knowledge Graph-Text Datasets Informed by Cyclic Evaluation,Yes.,3.,"""We also construct two synthetic datasets using large language models (LLMs), and observe that these are conducive to models that perform significantly well on cyclic generation of text, but less so on cyclic generation of KGs, probably because of a lack of a consistent underlying ontology.""",2023-09-20T22:30:20Z
Towards Effective Disambiguation for Machine Translation with Large Language Models,Yes.,3.,"""Recent work on benchmarking translation performance on ambiguous sentences has exposed the limitations of conventional Neural Machine Translation (NMT) systems, which fail to handle many such cases. Large language models (LLMs) have emerged as a promising alternative, demonstrating comparable performance to traditional NMT models while introducing new paradigms for controlling",2023-09-20T22:22:52Z
"""It's a Fair Game"", or Is It? Examining How Users Navigate Disclosure Risks and Benefits When Using LLM-Based Conversational Agents",Yes.,4.,"""users' erroneous mental models and the dark patterns in system design limited their awareness and comprehension of the privacy risks"" and ""the human-like interactions encouraged more sensitive disclosures, which complicated users' ability to navigate the trade-offs.""",2023-09-20T21:34:36Z
Chain-of-Verification Reduces Hallucination in Large Language Models,Yes.,5.,"""Generation of plausible yet incorrect factual information, termed hallucination, is an unsolved issue in large language models.""",2023-09-20T17:50:55Z
Text2Reward: Automated Dense Reward Function Generation for Reinforcement Learning,Yes.,1.,"""To address this, we introduce Text2Reward, a data-free framework that automates the generation of dense reward functions based on large language models (LLMs).""",2023-09-20T17:39:13Z
GPT-MolBERTa: GPT Molecular Features Language Model for molecular property prediction,Yes.,1.,"""Here, we present GPT-MolBERTa, a self-supervised large language model (LLM) which uses detailed textual descriptions of molecules to predict their properties.""",2023-09-20T17:21:43Z
Controlled Generation with Prompt Insertion for Natural Language Explanations in Grammatical Error Correction,Yes.,3.,"""it is not straightforward to specify a complex format to generate explanations, because explicit control of generation is difficult with prompts.""",2023-09-20T16:14:10Z
Speak While You Think: Streaming Speech Synthesis During Text Generation,Yes.,1.,"""Large Language Models (LLMs) demonstrate impressive capabilities, yet interaction with these models is mostly facilitated through text.""",2023-09-20T11:00:15Z
Retrieve-Rewrite-Answer: A KG-to-Text Enhanced LLMs Framework for Knowledge Graph Question Answering,,,,2023-09-20T10:42:08Z
Are Large Language Models Really Robust to Word-Level Perturbations?,Yes.,5.,"""our results demonstrate that LLMs frequently exhibit vulnerability to word-level perturbations that are commonplace in daily language usage.""",2023-09-20T09:23:46Z
"Exploring the Relationship between LLM Hallucinations and Prompt Linguistic Nuances: Readability, Formality, and Concreteness",Yes.,5.,"""As Large Language Models (LLMs) have advanced, they have brought forth new challenges, with one of the prominent issues being LLM hallucination.""",2023-09-20T05:04:16Z
In-Context Learning for Text Classification with Many Labels,Yes.,5.,"""In-context learning (ICL) using large language models for tasks with many labels is challenging due to the limited context window, which makes it difficult to fit a sufficient number of examples in the prompt.""",2023-09-19T22:41:44Z
LMDX: Language Model-based Document Information Extraction and Localization,Yes.,4.,"""The main obstacles to LLM adoption in that task have been the absence of layout encoding within LLMs, critical for a high quality extraction, and the lack of a grounding mechanism ensuring the answer is not hallucinated.""",2023-09-19T22:32:56Z
Specializing Small Language Models towards Complex Style Transfer via Latent Attribute Pre-Training,Yes.,3.,"""While large language models (LLM) have shown promise in complex text style transfer, they have drawbacks such as data privacy concerns, network instability, and high deployment costs.""",2023-09-19T21:01:40Z
FRASIMED: a Clinical French Annotated Resource Produced through Crosslingual BERT-Based Annotation Projection,Yes.,2.,"""NLP applications such as named entity recognition (NER) for low-resource corpora do not benefit from recent advances in the development of large language models (LLMs) where there is still a need for larger annotated datasets.""",2023-09-19T17:17:28Z
Evaluating large language models' ability to understand metaphor and sarcasm using a screening test for Asperger syndrome,Yes.,5.,"""whereas their ability to comprehend metaphors has been improved with the increase of the number of model parameters, the improvement in sarcasm understanding was not observed. This implies that an alternative approach is imperative to imbue LLMs with the capacity to grasp sarcasm.""",2023-09-19T16:41:19Z
GPT4AIGChip: Towards Next-Generation AI Accelerator Design Automation via Large Language Models,Yes.,3.,"""we first perform an in-depth investigation into LLMs' limitations and capabilities for AI accelerator design.""",2023-09-19T16:14:57Z
Estimating Contamination via Perplexity: Quantifying Memorisation in Language Model Evaluation,Yes.,4.,"""Data contamination in model evaluation is getting increasingly prevalent as the massive training corpora of large language models often unintentionally include benchmark samples. ... This prevent the community to rigorously audit these models and conduct accurate assessment of their capability.""",2023-09-19T15:02:58Z
Model Leeching: An Extraction Attack Targeting LLMs,Yes.,1.,"""Model Leeching is a novel extraction attack targeting Large Language Models (LLMs), capable of distilling task-specific knowledge from a target LLM into a reduced parameter model.""",2023-09-19T11:45:29Z
Exploring Iterative Enhancement for Improving Learnersourced Multiple-Choice Question Explanations with Large Language Models,Yes.,1.,"""Large language models exhibit superior capabilities in processing and understanding language, yet their applications in educational contexts remain underexplored.""",2023-09-19T09:04:15Z
PoSE: Efficient Context Window Extension of LLMs via Positional Skip-wise Training,Yes.,5.,"""Large Language Models (LLMs) are trained with a pre-defined context length, restricting their use in scenarios requiring long inputs.""",2023-09-19T08:03:38Z
Investigating the Catastrophic Forgetting in Multimodal Large Language Models,Yes.,5.,"""However, catastrophic forgetting, a notorious phenomenon where the fine-tuned model fails to retain similar performance compared to the pre-trained model, still remains an inherent problem in multimodal LLMs (MLLM).""",2023-09-19T04:51:13Z
LLM Platform Security: Applying a Systematic Evaluation Framework to OpenAI's ChatGPT Plugins,Yes.,4.,"""Plugins also interface with LLM platforms and users using natural language, which can have imprecise interpretations."" and ""We conclude by discussing novel challenges and by providing recommendations to improve the security, privacy, and safety of present and future LLM-based computing platforms.""",2023-09-19T02:20:10Z
GPTFUZZER: Red Teaming Large Language Models with Auto-Generated Jailbreak Prompts,Yes.,5.,"""However, despite their considerable success, LLMs are not entirely reliable and can give detailed guidance on how to conduct harmful or illegal activities.""",2023-09-19T02:19:48Z
Stabilizing RLHF through Advantage Model and Selective Rehearsal,Yes.,4.,"""Large Language Models (LLMs) have revolutionized natural language processing, yet aligning these models with human values and preferences using RLHF remains a significant challenge. This challenge is characterized by various instabilities, such as reward hacking and catastrophic forgetting.""",2023-09-18T23:06:32Z
RadOnc-GPT: A Large Language Model for Radiation Oncology,Yes.,3.,"""However, our model's clinical relevance requires confirmation, and it specializes in only the aforementioned three specific tasks and lacks broader applicability. Furthermore, its evaluation through ROUGE scores might not reflect the true semantic and clinical accuracy - challenges we intend to address in future research.""",2023-09-18T21:15:02Z
Prompt a Robot to Walk with Large Language Models,Yes.,3.,"""this approach faces significant challenges, particularly in grounding these models in the physical world and in generating dynamic robot motions.""",2023-09-18T17:50:17Z
Efficient Avoidance of Vulnerabilities in Auto-completed Smart Contract Code Using Vulnerability-constrained Decoding,Yes.,3.,"""Recent advances in transformer-based large language model (LLM) technologies have been applied to code synthesis. However, studies show that many of such synthesized codes contain vulnerabilities.""",2023-09-18T14:47:34Z
Bias of AI-Generated Content: An Examination of News Produced by Large Language Models,Yes.,5.,"""To harness this transformation, we need to understand the limitations of LLMs."" and ""Our study reveals that the AIGC produced by each examined LLM demonstrates substantial gender and racial biases. Moreover, the AIGC generated by each LLM exhibits notable discrimination against females and individuals of the Black race.""",2023-09-18T14:47:24Z
Proposition from the Perspective of Chinese Language: A Chinese Proposition Classification Evaluation Benchmark,Yes.,3.,"""ChatGPT performs poorly, but its classification ability can be improved by providing more proposition information. Many issues are still far from being resolved and require further study.""",2023-09-18T09:18:39Z
Progressive Text-to-Image Diffusion with Soft Latent Direction,Yes.,3.,"""while a pre-trained text-to-image diffusion model adeptly handles one or two entities, it often falters when dealing with a greater number.""",2023-09-18T04:01:25Z
Defending Against Alignment-Breaking Attacks via Robustly Aligned LLM,Yes.,3.,"""Though a line of research has focused on aligning LLMs with human values and preventing them from producing inappropriate content, such alignments are usually vulnerable and can be bypassed by alignment-breaking attacks via adversarially optimized or handcrafted jailbreaking prompts.""",2023-09-18T02:07:22Z
"CulturaX: A Cleaned, Enormous, and Multilingual Dataset for Large Language Models in 167 Languages",Yes.,4.,"""The lack of transparency for training data has thus hampered research on attributing and addressing hallucination and bias issues in LLMs, hindering replication efforts and further advancements in the community.""",2023-09-17T23:49:10Z
Language models are susceptible to incorrect patient self-diagnosis in medical applications,Yes.,5.,"""Our findings highlight that when a patient proposes incorrect bias-validating information, the diagnostic accuracy of LLMs drop dramatically, revealing a high susceptibility to errors in self-diagnosis.""",2023-09-17T19:56:39Z
Talk2Care: Facilitating Asynchronous Patient-Provider Communication with Large-Language-Model,Yes.,2.,"""However, there is a limited understanding of LLMs' role during the communication.""",2023-09-17T19:46:03Z
Can Large Language Models Understand Real-World Complex Instructions?,Yes.,5.,"""they still struggle with complex instructions, which can be either complex task descriptions that require multiple tasks and constraints, or complex input that contains long context, noise, heterogeneous information and multi-turn format. Due to these features, LLMs often ignore semantic constraints from task descriptions, generate incorrect formats, violate length or sample count constraints, and be unfaithful to the input text.""",2023-09-17T04:18:39Z
RMDM: A Multilabel Fakenews Dataset for Vietnamese Evidence Verification,Yes.,2.,"""Preliminary tests on the dataset using GPT-based and BERT-based models reveal variations in the models' performance across different labels, indicating that the dataset effectively challenges the ability of various language models to verify the authenticity of such information.""",2023-09-16T18:35:08Z
Rethinking STS and NLI in Large Language Models,Yes.,5.,"""the effectiveness of LLMs turns out to be limited by low-resource domain accuracy, model overconfidence, and difficulty to capture the disagreements between human judgements.""",2023-09-16T11:58:39Z
Struc-Bench: Are Large Language Models Really Good at Generating Complex Structured Data?,Yes.,5.,"""Despite the remarkable capabilities of Large Language Models (LLMs) like GPT-4, producing complex, structured tabular data remains challenging."" and ""In-depth error analysis and creating an ability map across six dimensions -- coverage, formatting, reasoning, comprehension, pragmatics, and hallucination -- highlight areas for future enhancements and suggest forthcoming research trajectories.""",2023-09-16T11:31:58Z
ODSum: New Benchmarks for Open Domain Multi-Document Summarization,Yes.,3.,"""We also found that LLMs suffer great performance loss from retrieving errors.""",2023-09-16T11:27:34Z
"PDFTriage: Question Answering over Long, Structured Documents",Yes.,5.,"""Large Language Models (LLMs) have issues with document question answering (QA) in situations where the document is unable to fit in the small context length of an LLM.""",2023-09-16T04:29:05Z
Rethinking Learning Rate Tuning in the Era of Large Language Models,Yes.,3.,"""Existing learning rate policies are primarily designed for training traditional deep neural networks (DNNs), which may not work well for LLM fine-tuning.""",2023-09-16T03:37:00Z
S3-DST: Structured Open-Domain Dialogue Segmentation and State Tracking in the Era of LLMs,Yes.,3.,"""These intricacies manifest in the form of increased complexity in contextual interactions, extended dialogue sessions encompassing a diverse array of topics, and more frequent contextual shifts.""",2023-09-16T00:59:23Z
Fake News Detectors are Biased against Texts Generated by Large Language Models,,,,2023-09-15T18:04:40Z
Are Multilingual LLMs Culturally-Diverse Reasoners? An Investigation into Multicultural Proverbs and Sayings,Yes.,5.,"""Our experiments reveal that",2023-09-15T17:45:28Z
Casteist but Not Racist? Quantifying Disparities in Large Language Model Bias between India and the West,Yes.,4.,"""Large Language Models (LLMs), now used daily by millions of users, can encode societal biases, exposing their users to representational harms."" and ""We find that the majority of LLMs tested are strongly biased towards stereotypes in the Indian context, especially as compared to the Western context.""",2023-09-15T17:38:41Z
Using Large Language Models for Knowledge Engineering (LLMKE): A Case Study on Wikidata,Yes.,3.,"""These results demonstrate that the knowledge of LLMs varies significantly depending on the domain and that further experimentation is required to determine the circumstances under which LLMs can be used for automatic Knowledge Base (e.g., Wikidata) completion and correction.""",2023-09-15T15:51:14Z
Adversarial Attacks on Tables with Entity Swap,Yes.,3.,"""Adversarial attacks on text have been shown to greatly affect the performance of LLMs, but currently, there are no attacks targeting tabular language models.""",2023-09-15T15:03:33Z
Data Distribution Bottlenecks in Grounding Language Models to Knowledge Bases,Yes.,5.,"""Despite these advances, their integration with real-world environments such as large-scale knowledge bases (KBs) remains an underdeveloped area, affecting applications such as semantic parsing and indulging in 'hallucinated' information."" and ""Our comprehensive experiments reveal that even when employed with our proposed data augmentation techniques, advanced small and large language models exhibit poor performance in various dimensions. While the",2023-09-15T12:06:45Z
CoCA: Fusing Position Embedding with Collinear Constrained Attention in Transformers for Long Context Window Extending,Yes.,3.,"""anomalous behaviors harming long context extrapolation exist between Rotary Position Embedding (RoPE) and vanilla self-attention unveiled by our work.""",2023-09-15T09:36:51Z
Investigating Answerability of LLMs for Long-Form Question Answering,Yes.,5.,"""it becomes increasingly crucial to understand their capabilities, limitations, and differences"" and ""generating follow-up questions from summaries of long documents can create a challenging setting for LLMs to reason and infer from long contexts"" and ""open-source LLMs exhibit decreased reliance on context for generated questions",2023-09-15T07:22:56Z
Using Large Language Model to Solve and Explain Physics Word Problems Approaching Human Level,Yes.,1.,"""Our work demonstrates that large language model (LLM) pre-trained on texts can not only solve pure math word problems, but also physics word problems, whose solution requires calculation and inference based on prior physical knowledge.""",2023-09-15T06:13:06Z
FedJudge: Federated Legal Large Language Model,Yes.,4.,"""However, computation and communication overheads hinder the full fine-tuning of LLMs under the FL setting. Moreover, the distribution shift of legal data reduces the effectiveness of FL methods.""",2023-09-15T05:45:44Z
LASER: LLM Agent with State-Space Exploration for Web Navigation,Yes.,3.,"""Consequently, the model could not handle more challenging scenarios not covered in the in-context examples, e.g., mistakes, leading to sub-optimal performance.""",2023-09-15T05:44:08Z
Draft & Verify: Lossless Large Language Model Acceleration via Self-Speculative Decoding,Yes.,1.,"""We present a novel inference scheme, self-speculative decoding, for accelerating Large Language Models (LLMs) without the need for an auxiliary model.""",2023-09-15T05:34:32Z
Self-Assessment Tests are Unreliable Measures of LLM Personality,Yes.,5.,"""self-assessment personality tests created for humans are unreliable measures of personality in LLMs.""",2023-09-15T05:19:39Z
"Using Large Language Models to Generate, Validate, and Apply User Intent Taxonomies",Yes.,3.,"""However, using LLMs to generate a user intent taxonomy and apply it for log analysis can be problematic for two main reasons",2023-09-14T20:46:48Z
MMICL: Empowering Vision-language Model with Multi-Modal In-Context Learning,Yes.,4.,"""while LLMs can utilize extensive background knowledge and task information with in-context learning, most VLMs still struggle with understanding complex multi-modal prompts with multiple images, making VLMs less effective in downstream vision-language tasks."" and ""we observe that MMICL successfully allevi",2023-09-14T17:59:17Z
Ambiguity-Aware In-Context Learning with Large Language Models,Yes.,3.,"""However, LLMs are sensitive to the choice of prompts,"" and ""labels paired with the demonstrations bias the model predictions.""",2023-09-14T17:48:34Z
Safety-Tuned LLaMAs: Lessons From Improving the Safety of Large Language Models that Follow Instructions,Yes.,5.,"""we raise concerns over the safety of models that only emphasize helpfulness, not harmlessness, in their instruction-tuning,"" and ""several popular instruction-tuned models are highly unsafe,"" and ""our results illustrate trade-offs in training LLMs to be helpful and",2023-09-14T17:23:37Z
TextBind: Multi-turn Interleaved Multimodal Instruction-following in the Wild,Yes.,3.,"""their performance heavily relies on high-quality exemplar data, which is often difficult to obtain. This challenge is further exacerbated when it comes to multimodal instruction following.""",2023-09-14T15:34:01Z
Tree of Uncertain Thoughts Reasoning for Large Language Models,Yes.,4.,"""These local uncertainties, intrinsic to LLMs given their potential for diverse responses, remain a significant concern in the reasoning process.""",2023-09-14T13:14:51Z
Detecting ChatGPT: A Survey of the State of Detecting ChatGPT-Generated Text,Yes.,2.,"""These models can potentially deceive by generating artificial text that appears to be human-generated.""",2023-09-14T13:05:20Z
Are Large Language Model-based Evaluators the Solution to Scaling Up Multilingual Evaluation?,Yes.,5.,"""Our analysis reveals a bias in GPT4-based evaluators towards higher scores, underscoring the necessity of calibration with native speaker judgments, especially in low-resource and non-Latin script languages, to ensure accurate evaluation of LLM performance across diverse languages.""",2023-09-14T06:41:58Z
ChatGPT MT: Competitive for High- (but not Low-) Resource Languages,Yes.,5.,"""Trends reveal that GPT models approach or exceed traditional MT model performance for some high-resource languages (HRLs) but consistently lag for low-resource languages (LRLs), under-performing traditional MT for 84.1% of languages we covered.""",2023-09-14T04:36:00Z
An Assessment of ChatGPT on Log Data,Yes.,5.,"""Our findings show that the performance of the current version of ChatGPT for log processing is limited, with a lack of consistency in responses and scalability issues.""",2023-09-14T04:09:27Z
Masked Diffusion with Task-awareness for Procedure Planning in Instructional Videos,No.,1.,"The abstract does not mention any language models, focusing instead on diffusion models and visual representation learning.",2023-09-14T03:25:37Z
Less is More for Long Document Summary Evaluation by LLMs,Yes.,5.,"""Large Language Models (LLMs) have shown promising performance in summary evaluation tasks, yet they face challenges such as high computational costs and the Lost-in-the-Middle problem where important information in the middle of long documents is often overlooked.""",2023-09-14T01:59:15Z
In-Contextual Gender Bias Suppression for Large Language Models,Yes.,4.,"""Large Language Models (LLMs) have been reported to encode worrying-levels of gender biases.""",2023-09-13T18:39:08Z
RAIN: Your Language Models Can Align Themselves without Finetuning,Yes.,2.,"""Large language models (LLMs) often demonstrate inconsistencies with human preferences.""",2023-09-13T17:59:09Z
Mitigating Hallucinations and Off-target Machine Translation with Source-Contrastive and Language-Contrastive Decoding,Yes.,2.,"""Hallucinations and off-target translation remain unsolved problems in MT, especially for low-resource languages and massively multilingual models.""",2023-09-13T17:15:27Z
SafetyBench: Evaluating the Safety of Large Language Models with Multiple Choice Questions,Yes.,4.,"""increasing attention has been paid to their safety concerns,"" and ""there is still significant room for improving the safety of current LLMs.""",2023-09-13T15:56:50Z
Generative AI,Yes.,2.,"""we introduce limitations of current generative AI and provide an agenda for Business & Information Systems Engineering (BISE) research.""",2023-09-13T08:21:59Z
Scaled Prompt-Tuning for Few-Shot Natural Language Generation,Yes.,4.,"""the memory demand and computation cost of fine-tuning LLMs on downstream tasks are non-negligible. Besides, fine-tuning generally requires a certain amount of data from individual tasks whilst data collection cost is another issue to consider in real-world applications.""",2023-09-13T07:12:31Z
"TrafficGPT: Viewing, Processing and Interacting with Traffic Foundation Models",Yes.,5.,"""However, LLMs struggle with addressing traffic issues, especially processing numerical data and interacting with simulations, limiting their potential in solving traffic-related challenges.""",2023-09-13T04:47:43Z
Self-Refined Large Language Model as Automated Reward Function Designer for Deep Reinforcement Learning in Robotics,Yes.,1.,"""Recently, Large Language Models (LLMs) have been extensively adopted to address tasks demanding in-depth common-sense knowledge, such as reasoning and planning.""",2023-09-13T02:56:56Z
Query-Dependent Prompt Evaluation and Optimization with Offline Inverse RL,Yes.,3.,"""One primary issue is the absence of an effective method to evaluate prompts during inference when the golden answer is unavailable. Concurrently, learning via interactions with the LLMs to navigate the expansive natural language prompting space proves to be resource-intensive.""",2023-09-13T01:12:52Z
Statistical Rejection Sampling Improves Preference Optimization,Yes.,2.,"""Improving the alignment of language models with human preferences remains an active research challenge.""",2023-09-13T01:07:25Z
Exploring Large Language Models for Ontology Alignment,Yes.,1.,"""This work investigates the applicability of recent generative Large Language Models (LLMs), such as the GPT series and Flan-T5, to ontology alignment for identifying concept equivalence mappings across ontologies.""",2023-09-12T17:01:02Z
The first step is the hardest: Pitfalls of Representing and Tokenizing Temporal Data for Large Language Models,Yes.,5.,"""a notable obstacle emerges when feeding numerical/temporal data into these models"" and ""tokenizers are not designed to represent numerical values and might struggle to understand repetitive patterns and context, treating consecutive values as separate tokens and disregarding their temporal relationships.""",2023-09-12T13:51:29Z
Performance of ChatGPT-3.5 and GPT-4 on the United States Medical Licensing Examination With and Without Distractions,Yes.,5.,"""As Large Language Models (LLMs) are predictive models building their response based on the words in the prompts, there is a risk that small talk and irrelevant information may alter the response and the suggestion given.""",2023-09-12T05:54:45Z
The Moral Machine Experiment on Large Language Models,Yes.,3.,"""there are significant quantitative disparities, suggesting that LLMs might lean toward more uncompromising decisions, compared to the milder inclinations of humans.""",2023-09-12T04:49:39Z
Balanced and Explainable Social Media Analysis for Public Health with Large Language Models,Yes.,3.,"""the costs of training an in-domain LLM for every specific public health task are especially expensive"" and ""such kinds of in-domain datasets from social media are generally highly imbalanced, which will hinder the efficiency of LLMs tuning.""",2023-09-12T04:15:34Z
"Stochastic LLMs do not Understand Language: Towards Symbolic, Explainable and Ontologically Based LLMs",Yes.,5.,"""(i) LLMs cannot be relied upon for factual information since for LLMs all ingested text (factual or non-factual) was created equal; (ii) due to their subsymbolic nature, whatever 'knowledge' these models acquire about language will always be buried in billions of microfeatures (weights), none of which is meaningful on its own; and (",2023-09-12T02:14:05Z
Strategic Behavior of Large Language Models: Game Structure vs. Contextual Framing,Yes.,5.,"""These results highlight the current limitations and varied proficiencies of LLMs in strategic decision-making, cautioning against their unqualified use in tasks requiring complex strategic reasoning.""",2023-09-12T00:54:15Z
PACE-LM: Prompting and Augmentation for Calibrated Confidence Estimation with GPT-4 in Cloud Incident Root Cause Analysis,Yes.,5.,"""their effectiveness in assisting on-call engineers is constrained by low accuracy due to the intrinsic difficulty of the task, a propensity for LLM-based approaches to hallucinate, and difficulties in distinguishing these well-disguised hallucinations.""",2023-09-11T21:24:00Z
Memory Injections: Correcting Multi-Hop Reasoning Failures during Inference in Transformer-Based Language Models,Yes.,5.,"""Large Language Models (LLMs) struggle to perform such reasoning consistently.""",2023-09-11T16:39:30Z
Optimize Weight Rounding via Signed Gradient Descent for the Quantization of LLMs,Yes.,3.,"""However, their deployment poses significant challenges due to their considerable memory and storage requirements.""",2023-09-11T14:58:23Z
Evaluating the Deductive Competence of Large Language Models,Yes.,5.,"""The tested LLMs have limited abilities to solve these problems in their conventional form."" and ""Overall, our results suggest that LLMs have unique reasoning biases that are only partially predicted from human reasoning performance.""",2023-09-11T13:47:07Z
Quantifying and Attributing the Hallucination of Large Language Models via Association Analysis,Yes.,5.,"""large language models (LLMs) still suffer from the hallucination problem, which threatens the reliability of LLMs"" and ""we reveal a set of potential deficiencies in commonsense memorization, relational reasoning, and instruction following, which may further provide guidance for the pretraining and supervised fine-tuning process of LLMs to mitigate the hallucination.""",2023-09-11T03:35:00Z
Does Writing with Language Models Reduce Content Diversity?,Yes.,5.,"""As different users incorporate suggestions from the same model, there is a risk of decreased diversity in the produced content, potentially limiting diverse perspectives in public discourse."" and ""we measure the impact of co-writing on diversity via a controlled experiment, where users write argumentative essays in three setups -- using a base LLM (GPT3), a feedback-tuned LLM (InstructGPT), and",2023-09-11T02:16:47Z
DePT: Decomposed Prompt Tuning for Parameter-Efficient Fine-tuning,Yes.,3.,"""PT introduces additional soft prompt tokens, leading to longer input sequences, which significantly impacts training and inference time and memory usage due to the Transformer's quadratic complexity. Particularly concerning for Large Language Models (LLMs) that face heavy daily querying.""",2023-09-11T00:02:05Z
Chat2Brain: A Method for Mapping Open-Ended Semantic Queries to Brain Activation Maps,Yes.,1.,"""large language models (LLMs) like ChatGPT have shown great potential in tasks such as context understanding and reasoning, displaying a high degree of consistency with human natural language.""",2023-09-10T13:06:45Z
Towards LLM-based Autograding for Short Textual Answers,Yes.,4.,"""entrusting AI models with decision-making roles raises ethical considerations, mainly stemming from potential biases and issues related to generating false information"" and ""while 'out-of-the-box' LLMs provide a valuable tool to provide a complementary perspective, their readiness for independent automated grading remains a work in progress, necessitating",2023-09-09T22:25:56Z
Leveraging Large Language Models for Exploiting ASR Uncertainty,Yes.,3.,"""LLM's accuracy on SLU tasks is constrained by the accuracy of a fixed ASR system on the spoken input."" and ""a high word-error-rate can limit the LLM's ability to understand the spoken intent.""",2023-09-09T17:02:33Z
Code-Style In-Context Learning for Knowledge-Based Question Answering,Yes.,3.,"""current powerful LLMs have little exposure to logic forms during pre-training, resulting in a high format error rate.""",2023-09-09T06:27:00Z
Retrieving Evidence from EHRs with LLMs: Possibilities and Challenges,Yes.,4.,"""Our findings indicate the promise of LLMs as interfaces to EHR, but also highlight the outstanding challenge posed by 'hallucinations'.""",2023-09-08T18:44:47Z
Measuring and Improving Chain-of-Thought Reasoning in Vision-Language Models,Yes.,5.,"""We evaluate existing state-of-the-art VLMs, and find that even the best-performing model is unable to demonstrate strong visual reasoning capabilities and consistency, indicating that substantial efforts are required to enable VLMs to perform visual reasoning as systematically and consistently as humans.""",2023-09-08T17:49:44Z
LLMCad: Fast and Scalable On-device Large Language Model Inference,Yes.,3.,"""the limited memory capacity of these devices presents a formidable challenge to the scalability of such models.""",2023-09-08T10:44:19Z
Towards Reliable and Fluent Large Language Models: Incorporating Feedback Learning Loops in QA Systems,Yes.,5.,"""However, they are fraught with issues that undermine their utility and trustworthiness. These include the incorporation of erroneous references (citation), the generation of hallucinated information (correctness), and the inclusion of superfluous or omission of crucial details (fluency).""",2023-09-08T09:39:53Z
UQ at #SMM4H 2023: ALEX for Public Health Analysis with Social Media,,,,2023-09-08T08:54:55Z
Don't Ignore Dual Logic Ability of LLMs while Privatizing: A Data-Intensive Analysis in Medical Domain,Yes.,5.,"""However, these privatization efforts often ignored a critical aspect",2023-09-08T08:20:46Z
Knowledge-tuning Large Language Models with Structured Medical Knowledge Bases for Reliable Response Generation in Chinese,Yes.,4.,"""LLMs sometimes generate responses with the hallucination about medical facts due to limited domain knowledge. Such shortcomings pose potential risks in the utilization of LLMs within medical contexts.""",2023-09-08T07:42:57Z
Matching Table Metadata with Business Glossaries Using Large Language Models,Yes.,1.,"""In this work, we leverage the power of large language models (LLMs) to design generic matching methods that do not require manual tuning and can identify complex relations between column names and glossaries.""",2023-09-08T02:23:59Z
Evaluation of large language models for discovery of gene set function,Yes.,2.,"""Gemini-Pro and Mixtral-Instruct showed ability in naming but were falsely confident for random sets, whereas Llama2-70b had poor performance overall.""",2023-09-07T21:10:48Z
ConDA: Contrastive Domain Adaptation for AI-generated Text Detection,Yes.,2.,"""Given the surge in development of new LLMs, acquiring labeled training data for supervised detectors is a bottleneck.""",2023-09-07T19:51:30Z
DoLa: Decoding by Contrasting Layers Improves Factuality in Large Language Models,Yes.,5.,"""Despite their impressive capabilities, large language models (LLMs) are prone to hallucinations, i.e., generating content that deviates from facts seen during pretraining.""",2023-09-07T17:45:31Z
Large Language Models Are Not Robust Multiple Choice Selectors,Yes.,5.,"""This work shows that modern LLMs are vulnerable to option position changes in MCQs due to their inherent 'selection bias',"" and ""We hope this work can draw broader research attention to the bias and robustness of modern LLMs.""",2023-09-07T17:44:56Z
OpinionGPT: Modelling Explicit Biases in Instruction-Tuned LLMs,Yes.,4.,"""an open research question concerns the inherent biases of trained models and their responses"" and ""Current research work seeks to de-bias such models, or suppress potentially biased answers.""",2023-09-07T17:41:01Z
Supervised Learning and Large Language Model Benchmarks on Mental Health Datasets: Cognitive Distortions and Suicidal Risks in Chinese Social Media,Yes.,3.,"""we deeply explored and analyzed the performance of these large language models from a psychological perspective, shedding light on their strengths and limitations in identifying and understanding complex human emotions.""",2023-09-07T08:50:46Z
Can Large Language Models Discern Evidence for Scientific Hypotheses? Case Studies in the Social Sciences,Yes.,2.,"""We compare the performance of LLMs to several state-of-the-art benchmarks and highlight opportunities for future research in this area.""",2023-09-07T04:15:17Z
XGen-7B Technical Report,Yes.,4.,"""most high-performing LLMs remain confined behind proprietary walls, hindering scientific progress. Most open-source LLMs, on the other hand, are limited in their ability to support longer sequence lengths, which is a key requirement for many tasks that require inference over an input context.""",2023-09-07T02:20:03Z
Improving Open Information Extraction with Large Language Models: A Study on Demonstration Uncertainty,Yes.,5.,"""Despite the potential of large language models (LLMs) like ChatGPT as a general task solver, they lag behind state-of-the-art (supervised) methods in OIE tasks due to two key issues. First, LLMs struggle to distinguish irrelevant context from relevant relations and generate",2023-09-07T01:35:24Z
Large Language Models as Optimizers,Yes.,1.,"""In this work, we propose Optimization by PROmpting (OPRO), a simple and effective approach to leverage large language models (LLMs) as optimizers, where the optimization task is described in natural language.""",2023-09-07T00:07:15Z
Self-Supervised Masked Digital Elevation Models Encoding for Low-Resource Downstream Tasks,No.,1.,The abstract focuses on self-supervised learning for Digital Elevation Models and does not discuss LLMs or their limitations.,2023-09-06T21:20:10Z
Framework-Based Qualitative Analysis of Free Responses of Large Language Models: Algorithmic Fidelity,Yes.,5.,"""We conclude that the LLM we tested (GPT-3.5) does not have sufficient algorithmic fidelity to expect research on it to generalize to human populations.""",2023-09-06T15:00:44Z
Hide and Seek (HaS): A Lightweight Framework for Prompt Privacy Protection,Yes.,3.,"""Previous research on secure reasoning using multi-party computation (MPC) has proven to be impractical for LLM applications due to its time-consuming and communication-intensive nature.""",2023-09-06T14:54:11Z
Aligning Large Language Models for Clinical Tasks,Yes.,3.,"""effective alignment of LLMs remains a crucial challenge when deploying them for specific clinical applications.""",2023-09-06T10:20:06Z
Norm Tweaking: High-performance Low-bit Quantization of Large Language Models,Yes.,3.,"""attempts at lower-bit quantization often result in severe performance degradation.""",2023-09-06T06:51:15Z
Large Language Models for Automated Open-domain Scientific Hypotheses Discovery,Yes.,1.,"""this is the first work showing that LLMs are able to generate novel (""not existing in the literature"") and valid (""reflecting reality"") scientific hypotheses.""",2023-09-06T05:19:41Z
Zero-Resource Hallucination Prevention for Large Language Models,Yes.,4.,"""The prevalent use of large language models (LLMs) in various domains has drawn attention to the issue of 'hallucination,' which refers to instances where LLMs generate factually inaccurate or ungrounded information.""",2023-09-06T01:57:36Z
Physically Grounded Vision-Language Models for Robotic Manipulation,Yes.,3.,"""current VLMs are limited in their understanding of the physical concepts (e.g., material, fragility) of common objects, which restricts their usefulness for robotic manipulation tasks that involve interaction and physical reasoning about such objects.""",2023-09-05T20:21:03Z
Automating Behavioral Testing in Machine Translation,Yes.,2.,"""To address this limitation, we propose to use Large Language Models (LLMs) to generate a diverse set of source sentences tailored to test the behavior of MT models in a range of situations.""",2023-09-05T19:40:45Z
Delta-LoRA: Fine-Tuning High-Rank Parameters with the Delta of Low-Rank Matrices,Yes.,3.,"""Such a strategy effectively addresses the limitation that the incremental update of low-rank matrices is inadequate for learning representations capable for downstream tasks.""",2023-09-05T17:40:34Z
PromptTTS 2: Describing and Generating Voices with Text Prompt,Yes.,1.,"""we introduce PromptTTS 2 to address these challenges with a variation network to provide variability information of voice not captured by text prompts, and a prompt generation pipeline to utilize the large language models (LLM) to compose high quality text prompts.""",2023-09-05T14:45:27Z
Sample Size in Natural Language Processing within Healthcare Research,No.,1.,The abstract does not mention LLMs or any specific limitations related to them. It focuses on sample size calculations for text classification tasks in the healthcare domain.,2023-09-05T13:42:43Z
Language Models for Novelty Detection in System Call Traces,No.,1.,The abstract focuses on novelty detection methodologies using language models for system call traces but does not specifically mention LLMs or their limitations.,2023-09-05T13:11:40Z
An Automatic Evaluation Framework for Multi-turn Medical Consultations Capabilities of Large Language Models,Yes.,5.,"""However, recent studies have revealed that these models often suffer from hallucinations, leading to overly confident but incorrect judgments. This limits their application in the medical domain, where tasks require the utmost accuracy.""",2023-09-05T09:24:48Z
Data-Juicer: A One-Stop Data Processing System for Large Language Models,Yes.,2.,"""Firstly, the possible data sources for forming data recipes are truly heterogeneous and massive with various qualities. Secondly, it is extremely expensive to precisely evaluate data recipes' impact on LLMs' performance.""",2023-09-05T08:22:07Z
"On the Planning, Search, and Memorization Capabilities of Large Language Models",Yes.,3.,"""we investigate the potential of the state-of-the-art large language model (GPT-4) for planning tasks. We explore its effectiveness in multiple planning subfields, highlighting both its strengths and limitations.""",2023-09-05T00:19:31Z
Softmax Bias Correction for Quantized Generative Models,Yes.,2.,"""PTQ methods commonly keep the softmax activation in higher precision as it has been shown to be very sensitive to quantization noise.""",2023-09-04T17:29:31Z
Open Sesame! Universal Black Box Jailbreaking of Large Language Models,Yes.,5.,"""Our novel approach systematically reveals a model's limitations and vulnerabilities by uncovering instances where its responses deviate from expected behavior.""",2023-09-04T08:54:20Z
Benchmarking Large Language Models in Retrieval-Augmented Generation,Yes.,5.,"""Evaluation reveals that while LLMs exhibit a certain degree of noise robustness, they still struggle significantly in terms of negative rejection, information integration, and dealing with false information.""",2023-09-04T08:28:44Z
Representations Matter: Embedding Modes of Large Language Models using Dynamic Mode Decomposition,Yes.,5.,"""Existing large language models (LLMs) are known for generating 'hallucinated' content, namely a fabricated text of plausibly looking, yet unfounded, facts.""",2023-09-03T19:10:18Z
Siren's Song in the AI Ocean: A Survey on Hallucination in Large Language Models,Yes.,5.,"""a significant concern revolves around their propensity to exhibit hallucinations",2023-09-03T16:56:48Z
FusionAI: Decentralized Training and Deploying LLMs with Massive Consumer-Level GPUs,Yes.,5.,"""The rapid growth of memory and computation requirements of large language models (LLMs) has outpaced the development of hardware, hindering people who lack large-scale high-end GPUs from training or deploying LLMs."" and ""consumer-level GPUs...are typically overlooked in LLM due to their weaker computing performance, smaller storage capacity, and lower communication bandwidth."" and ""this system faces critical",2023-09-03T13:27:56Z
Bias Testing and Mitigation in LLM-based Code Generation,Yes.,5.,"""As the adoption of LLMs becomes more widespread in software coding ecosystems, a pressing issue has emerged",2023-09-03T07:14:49Z
Explainability for Large Language Models: A Survey,Yes.,4.,"""However, their internal mechanisms are still unclear and this lack of transparency poses unwanted risks for downstream applications."" and ""understanding and explaining these models is crucial for elucidating their behaviors, limitations, and social impacts.""",2023-09-02T22:14:26Z
eDKM: An Efficient and Accurate Train-time Weight Clustering for Large Language Models,Yes.,3.,"""However, the size of LLMs (i.e., billions of parameters) requires highly effective compression to fit into storage-limited devices."" and ""its training overhead is prohibitively significant for LLM fine-tuning.""",2023-09-02T15:16:35Z
Knowledge Graph Embeddings for Multi-Lingual Structured Representations of Radiology Reports,Yes.,4.,"""While performing well in terms of accuracy, both the lack of interpretability and limitations to transfer across languages limit their use in clinical setting.""",2023-09-02T11:46:41Z
Large Process Models: Business Process Management in the Age of Generative AI,Yes.,4.,"""The continued success of Large Language Models (LLMs) and other generative artificial intelligence approaches highlights the advantages that large information corpora can have over rigidly defined symbolic models, but also serves as a proof-point of the challenges that purely statistics-based approaches have in terms of safety and trustworthiness.""",2023-09-02T10:32:53Z
LeanContext: Cost-Efficient Domain-Specific Question Answering Using LLMs,Yes.,3.,"""However, widespread LLM integration presents a challenge for small businesses due to the high expenses of LLM API usage. Costs rise rapidly when domain-specific data (context) is used alongside queries for accurate domain-specific LLM responses. ... However, this can also filter out useful information that is necessary to answer some domain-specific queries.""",2023-09-02T06:33:18Z
Baseline Defenses for Adversarial Attacks Against Aligned Language Models,Yes.,3.,"""understand their security vulnerabilities"" and ""we find that the weakness of existing discrete optimizers for text, combined with the relatively high costs of optimization, makes standard adaptive attacks more challenging for LLMs.""",2023-09-01T17:59:44Z
Taken out of context: On measuring situational awareness in LLMs,Yes.,3.,"""An LLM could exploit situational awareness to achieve a high score on safety tests, while taking harmful actions after deployment"" and ""Situational awareness may emerge unexpectedly as a byproduct of model scaling.""",2023-09-01T17:27:37Z
No Train Still Gain. Unleash Mathematical Reasoning of Large Language Models with Monte Carlo Tree Search Guided by Energy Function,Yes.,5.,"""However, when applied to mathematical reasoning tasks, LLMs often struggle to generate correct reasoning steps and answers despite having high probabilities for the solutions.""",2023-09-01T13:10:54Z
BatchPrompt: Accomplish more with less,Yes.,5.,"""prompting with batched data in longer contexts will inevitably lead to worse performance, compared to single-data prompting"" and ""the performance of the language model is significantly correlated with the positions and order of the batched data, due to the corresponding change in decoder context.""",2023-09-01T10:44:36Z
Why do universal adversarial attacks work on large language models?: Geometry might be the answer,Yes.,5.,"""Gradient-based universal adversarial attacks have been shown to be highly effective on large language models and potentially dangerous due to their input-agnostic nature.""",2023-09-01T05:09:49Z
FactLLaMA: Optimizing Instruction-Following Language Models with External Knowledge for Automated Fact-Checking,Yes.,3.,"""However, their knowledge may not always be up-to-date or sufficient, potentially leading to inaccuracies in fact-checking.""",2023-09-01T04:14:39Z
RepCodec: A Speech Representation Codec for Speech Tokenization,Yes.,3.,"""However, this discretization gives rise to a loss of information, consequently impairing overall performance.""",2023-08-31T23:26:10Z
LLM in the Shell: Generative Honeypots,Yes.,1.,"""This work introduces a novel method to create dynamic and realistic software honeypots based on Large Language Models.""",2023-08-31T22:05:46Z
Towards Multilingual Automatic Dialogue Evaluation,Yes.,3.,"""We empirically show that the naive approach of finetuning a pretrained multilingual encoder model with translated data is insufficient to outperform the strong baseline of finetuning a multilingual model with only source data.""",2023-08-31T15:15:26Z
Ladder-of-Thought: Using Knowledge as Steps to Elevate Stance Detection,Yes.,3.,"""CoT relies primarily on a model's pre-trained internal knowledge during reasoning, thereby neglecting the valuable external information that is previously unknown to the model. This omission, especially within the unsupervised reasoning process, can affect the model's overall performance. Moreover, while CoT enhances Large Language",2023-08-31T14:31:48Z
Context Aware Query Rewriting for Text Rankers using LLM,Yes.,5.,"""We find that there are two inherent limitations of using LLMs as query re-writers -- concept drift when using only queries as prompts and large inference costs during query processing.""",2023-08-31T14:19:50Z
Exploring Cross-Cultural Differences in English Hate Speech Annotations: From Dataset Construction to Analysis,Yes.,3.,"""Lastly, we evaluate large language models (LLMs) under a zero-shot setting and show that current LLMs tend to show higher accuracies on Anglosphere country labels in CREHate.""",2023-08-31T13:14:47Z
Developing a Scalable Benchmark for Assessing Large Language Models in Knowledge Graph Engineering,Yes.,5.,"""We show that while being a useful tool, LLMs are yet unfit to assist in knowledge graph generation with zero-shot prompting.""",2023-08-31T10:31:19Z
SARATHI: Efficient LLM Inference by Piggybacking Decodes with Chunked Prefills,Yes.,2.,"""The varying prefill and decode times also lead to imbalance across micro-batches when using pipeline parallelism, resulting in further inefficiency due to bubbles.""",2023-08-31T00:03:02Z
Large Language Models as Data Preprocessors,Yes.,3.,"""Alongside showcasing the inherent capabilities of LLMs, we highlight their limitations, particularly in terms of computational expense and inefficiency.""",2023-08-30T23:28:43Z
LM-Infinite: Zero-Shot Extreme Length Generalization for Large Language Models,Yes.,5.,"""their performance suffers drastically on inputs longer than those encountered during training, substantially limiting their applications in real-world tasks involving long contexts such as encoding scientific articles, code repositories, or long dialogues.""",2023-08-30T16:47:51Z
FPTQ: Fine-grained Post-Training Quantization for Large Language Models,,,,2023-08-30T12:18:18Z
Quantifying and Analyzing Entity-level Memorization in Large Language Models,Yes.,5.,"""privacy risks arising from memorization have attracted increasing attention"" and ""LLMs not only memorize their training data but also understand associations between entities. These findings necessitate that trainers of LLMs exercise greater prudence regarding model memorization, adopting memorization mitigation techniques to preclude privacy violations.""",2023-08-30T03:06:47Z
Interactively Robot Action Planning with Uncertainty Analysis and Active Questioning by Large Language Model,Yes.,5.,"""The instructions given to the LLM by natural language may include ambiguity and lack of information depending on the task context."" and ""However, our experiments also revealed challenges in robot action planning with LLM, such as asking unimportant questions and assuming crucial information without asking.""",2023-08-30T00:54:44Z
"Multi-party Goal Tracking with LLMs: Comparing Pre-training, Fine-tuning, and Prompt Engineering",Yes.,3.,"""We conclude that multi-party conversations still challenge state-of-the-art LLMs.""",2023-08-29T11:40:03Z
Evaluation and Analysis of Hallucination in Large Vision-Language Models,Yes.,5.,"""LVLMs are still plagued by the hallucination problem, which limits the practicality in many scenarios."" and ""we evaluate the hallucination in current LVLMs. Furthermore, we analyze the factors contributing to hallucination in LVLMs and offer helpful suggestions to mitigate the hallucination problem.""",2023-08-29T08:51:24Z
SwapMoE: Efficient Memory-Constrained Serving of Large Sparse MoE Models via Dynamic Expert Pruning and Swapping,Yes.,3.,"""However, serving such large models on edge devices is challenging due to memory constraints. Typical solutions like memory swapping or weight pruning may lead to significantly higher latency or severe accuracy loss.""",2023-08-29T05:25:21Z
Recursively Summarizing Enables Long-Term Dialogue Memory in Large Language Models,Yes.,5.,"""However, given a long conversation, these chatbots fail to recall past information and tend to generate inconsistent responses.""",2023-08-29T04:59:53Z
LLM-Based Human-Robot Collaboration Framework for Manipulation Tasks,Yes.,3.,"""to address the potential inaccuracies or illogical actions arising from LLM.""",2023-08-29T01:54:49Z
Uncovering the Hidden Cost of Model Compression,,,,2023-08-29T01:47:49Z
Gender bias and stereotypes in Large Language Models,Yes.,5.,"""This paper investigates LLMs' behavior with respect to gender stereotypes, a known issue for prior models."" and ""LLMs provide explanations for their choices that are factually inaccurate and likely obscure the true reason behind their predictions. That is, they provide rationalizations of their biased behavior.""",2023-08-28T22:32:05Z
Identifying and Mitigating the Security Risks of Generative AI,Yes.,2.,"""Generative AI (GenAI) techniques, such as large language models (LLMs) and diffusion models, have shown remarkable capabilities... However, GenAI can be used just as well by attackers to generate new attacks and increase the velocity and efficacy of existing attacks.""",2023-08-28T18:51:09Z
Distilled GPT for Source Code Summarization,Yes.,3.,"""However, to use these tools, programmers must send their code to untrusted third parties for processing (e.g., via an API call). This loss of custody is not acceptable to many organizations.""",2023-08-28T17:34:07Z
Challenges of GPT-3-based Conversational Agents for Healthcare,Yes.,5.,"""However, the integration of large-language models (LLMs) into these agents presents certain limitations that may result in serious consequences."" and ""We provide a procedure for manually designing patient queries to stress-test high-risk limitations of LLMs in MedQA systems. Our analysis reveals that LLMs fail to respond adequately to these queries, generating erroneous medical information, unsafe recommendations, and content",2023-08-28T15:12:34Z
"LongBench: A Bilingual, Multitask Benchmark for Long Context Understanding",Yes.,5.,"""most of them can only handle texts a few thousand tokens long, limiting their applications on longer sequence inputs"" and ""still struggles on longer contexts"" and ""Context compression technique such as retrieval brings improvement for model with weak ability on long contexts, but the performance still lags behind models that have",2023-08-28T11:53:40Z
Biomedical Entity Linking with Triple-aware Pre-Training,Yes.,4.,"""a difficulty of linking the biomedical entities using current large language models (LLM) trained on a general corpus is that biomedical entities are scarcely distributed in texts and therefore have been rarely seen during training by the LLM"" and ""those LLMs are not aware of high level semantic connection between different biomedical entities, which are useful in identifying similar concepts in different textual contexts.""",2023-08-28T09:06:28Z
EdgeMoE: Fast On-Device Inference of MoE-based Large Language Models,Yes.,4.,"""the transition of LLMs from data centers to edge devices presents a set of challenges and opportunities. While this shift can enhance privacy and availability, it is hampered by the enormous parameter sizes of these models, leading to impractical runtime costs.""",2023-08-28T06:56:08Z
Evaluating the Robustness to Instructions of Large Language Models,Yes.,5.,"""We have observed that in most cases, the model's performance in dealing with unfamiliar instructions tends to worsen significantly, and the robustness of the model for RE instructions deteriorates compared to QA.""",2023-08-28T04:57:07Z
Symbolic and Language Agnostic Large Language Models,Yes.,5.,"""due to the subsymbolic nature of these models whatever knowledge these systems acquire about language will always be buried in millions of microfeatures (weights) none of which is meaningful on its own. Moreover, and due to their stochastic nature, these models will often fail in capturing various inferential aspects that are prevalent in natural language.""",2023-08-27T20:24:33Z
Empowering Cross-lingual Abilities of Instruction-tuned Large Language Models by Translation-following demonstrations,Yes.,4.,"""The language ability of Large Language Models (LLMs) is often unbalanced towards English because of the imbalance in the distribution of the pre-training data. This disparity is demanded in further fine-tuning and affecting the cross-lingual abilities of LLMs.""",2023-08-27T19:22:12Z
"Examining User-Friendly and Open-Sourced Large GPT Models: A Survey on Language, Multimodal, and Scientific GPT Models",Yes.,5.,"""Despite their success, large GPT models like GPT-4 face inherent limitations such as considerable size, high computational requirements, complex deployment processes, and closed development loops. These constraints restrict their widespread adoption and raise concerns regarding their responsible development and usage.""",2023-08-27T16:14:19Z
Detecting Language Model Attacks with Perplexity,Yes.,4.,"""Such jailbreaks can trick LLMs into providing intricate instructions to a malicious user for creating explosives, orchestrating a bank heist, or facilitating the creation of offensive content."" and ""false positives are a significant challenge for plain perplexity filtering.""",2023-08-27T15:20:06Z
LMSanitator: Defending Prompt-Tuning Against Task-Agnostic Backdoors,Yes.,3.,"""Prompt-tuning has emerged as an attractive paradigm for deploying large-scale language models due to its strong downstream task performance and efficient multitask serving ability. Despite its wide adoption, we empirically show that prompt-tuning is vulnerable to downstream task-agnostic backdoors, which reside in the",2023-08-26T15:21:47Z
Planning with Logical Graph-based Language Model for Instruction Generation,Yes.,3.,"""it is hard to generate texts with correct logic according to a given task, due to the difficulties for neural models to capture implied rules from free-form texts.""",2023-08-26T06:28:14Z
Adversarial Fine-Tuning of Language Models: An Iterative Optimisation Approach for the Generation and Detection of Problematic Content,Yes.,3.,"""we tackle the emerging challenge of unintended harmful content generation in Large Language Models (LLMs)"" and ""evaluated through classification accuracy on a dataset consisting of problematic prompts not detected by GPT-4.""",2023-08-26T05:20:58Z
Rethinking Language Models as Symbolic Knowledge Graphs,Yes.,5.,"""Despite these advancements, there is a void in comprehensively evaluating whether LMs can encompass the intricate topological and semantic attributes of KGs, attributes crucial for reasoning processes."" and ""Our extensive evaluation of various LMs shows that while these models exhibit considerable potential in recalling factual information, their ability to capture intricate topological and semantic traits of KGs remains significantly constrained.""",2023-08-25T21:25:08Z
Large Language Models Should Ask Clarifying Questions to Increase Confidence in Generated Code,Yes.,3.,"""the challenges of programming with LLMs, such as unclear intent specification, lack of computational thinking, and undesired code quality, may be alleviated.""",2023-08-25T17:33:05Z
The Poison of Alignment,Yes.,5.,"""alignment acts as if it is poisoning the instruction dataset. Experimentally, we demonstrate that aligned answers significantly worsen the performance of the resulting fine-tuned model's on various reasoning benchmarks such as Big Bench (BBH), Massive Multitask Language Understanding (MMLU), Human Eval, and Discrete Reasoning Over Paragraphs (DROP",2023-08-25T15:51:15Z
Cultural Alignment in Large Language Models: An Explanatory Analysis Based on Hofstede's Cultural Dimensions,Yes.,4.,"""The deployment of large language models (LLMs) raises concerns regarding their cultural misalignment and potential ramifications on individuals from various cultural norms."" and ""While all LLMs did not provide satisfactory results in understanding cultural values, GPT-4 exhibited the highest CAT score for the cultural values of the US.""",2023-08-25T14:50:13Z
Knowledge-Driven CoT: Exploring Faithful Reasoning in LLMs for Knowledge-intensive Question Answering,Yes.,5.,"""Even so, suffering from hallucinations and the inability to access external knowledge, LLMs often come with incorrect or unfaithful intermediate reasoning steps, especially in the context of answering knowledge-intensive tasks such as KBQA.""",2023-08-25T09:23:55Z
Measuring Spurious Correlation in Classification: 'Clever Hans' in Translationese,No.,1.,The abstract discusses neural translationese classifiers and BERT-based classifiers but does not mention LLMs or their limitations.,2023-08-25T04:19:58Z
"Large Language Models in Analyzing Crash Narratives -- A Comparative Study of ChatGPT, BARD and GPT-4",Yes.,3.,"""This study investigated their usefulness and boundaries in extracting information and answering queries related to accidents from 100 crash narratives from Iowa and Kansas.""",2023-08-25T00:09:16Z
Causal Parrots: Large Language Models May Talk Causality But Are Not Causal,Yes.,5.,"""We make it clear that large language models (LLMs) cannot be causal and give reason onto why sometimes we might feel otherwise."" and ""Our empirical analysis provides favoring evidence that current LLMs are even weak 'causal parrots.'""",2023-08-24T20:23:13Z
ZeroLeak: Using LLMs for Scalable and Cost Effective Side-Channel Patching,Yes.,2.,"""The situation will only worsen as the pace of code development accelerates, with developers relying on Large Language Models (LLMs) to automatically generate code.""",2023-08-24T20:04:36Z
POLCA: Power Oversubscription in LLM Cloud Providers,Yes.,2.,"""However, the stringent set of telemetry and controls that GPUs offer in a virtualized environment, makes it challenging to have a reliable and robust power oversubscription mechanism.""",2023-08-24T16:32:34Z
Large Language Models Vote: Prompting for Rare Disease Identification,Yes.,2.,"""Furthermore, in using MVP, each model is prompted multiple times, substantially increasing the time needed for manual annotation, and to address this, we assess the feasibility of using JSON for automating generative LLM evaluation.""",2023-08-24T16:09:13Z
"Use of LLMs for Illicit Purposes: Threats, Prevention Measures, and Vulnerabilities",Yes.,5.,"""safety- and security-related threats and vulnerabilities of LLMs,"" ""LLMs can be misused for fraud, impersonation, and the generation of malware,"" ""security-related problems with such models,"" ""limitations of LLMs in light of such security concerns.""",2023-08-24T14:45:50Z
VIGC: Visual Instruction Generation and Correction,Yes.,5.,"""the currently accessible MLLMs are not as powerful as their LLM counterparts, as they tend to produce inadequate responses and generate false information.""",2023-08-24T11:21:05Z
Improving Translation Faithfulness of Large Language Models via Augmenting Instructions,Yes.,3.,"""As the attention mechanism of LLMs has limitations on local focus, LLMs tend to focus more on the words or sentences nearby at each position. This leads to a high risk of instruction forgetting during decoding.""",2023-08-24T09:32:29Z
Modeling Uncertainty and Using Post-fusion as Fallback Improves Retrieval Augmented Generation with LLMs,Yes.,5.,"""We begin by examining the limitations of a commonly-used concatenation approach. Surprisingly, this approach often results in generating 'unknown' outputs, even when the correct document is among the top-k retrieved passages.""",2023-08-24T05:26:54Z
Benchmarking Causal Study to Interpret Large Language Models for Source Code,Yes.,3.,"""Existing benchmarks and datasets are meant to highlight the difference between the expected and the generated outcome, but do not take into account confounding variables (e.g., lines of code, prompt size) that equally influence the accuracy metrics.""",2023-08-23T20:32:12Z
D4: Improving LLM Pretraining via Document De-Duplication and Diversification,Yes.,3.,"""the size of these improvements diminishes with scale,"" and ""calls into question the common practice of training for a single epoch on as much data as possible.""",2023-08-23T17:58:14Z
Simple is Better and Large is Not Enough: Towards Ensembling of Foundational Language Models,Yes.,4.,"""While developing larger FLMs has been of significant advantage, it is also a liability concerning hallucination and predictive uncertainty.""",2023-08-23T17:40:35Z
Prompt2Model: Generating Deployable Models from Natural Language Instructions,Yes.,3.,"""they require extensive computational resources for deployment and can be gated behind APIs.""",2023-08-23T17:28:21Z
Evaluation of Faithfulness Using the Longest Supported Subsequence,Yes.,2.,"""Ensuring their responses are contextually grounded and faithful is challenging due to the linguistic diversity and the myriad of possible answers.""",2023-08-23T14:18:44Z
PREFER: Prompt Ensemble Learning via Feedback-Reflect-Refine,,,,2023-08-23T09:46:37Z
From Instructions to Intrinsic Human Values -- A Survey of Alignment Goals for Big Models,Yes.,3.,"""However, the growing intertwining of big models with everyday human lives poses potential risks and might cause serious social harm."" and ""Nevertheless, `what to align with' has not been fully discussed, and inappropriate alignment goals might even backfire.""",2023-08-23T09:11:13Z
Towards CausalGPT: A Multi-Agent Approach for Faithful Knowledge Reasoning via Promoting Causal Consistency in LLMs,Yes.,3.,"""Despite advancements in LLMs, knowledge-based reasoning remains a longstanding issue due to the fragility of knowledge recall and inference.""",2023-08-23T04:59:21Z
Dcc --help: Generating Context-Aware Compiler Error Explanations with Large Language Models,Yes.,3.,"""We found that the LLM-generated explanations were conceptually accurate in 90% of compile-time and 75% of run-time cases, but often disregarded the instruction not to provide solutions in code.""",2023-08-23T02:36:19Z
Exploring the Effectiveness of GPT Models in Test-Taking: A Case Study of the Driver's License Knowledge Test,Yes.,5.,"""Large language models such as Open AI's Generative Pre-trained Transformer (GPT) models are proficient at answering questions, but their knowledge is confined to the information present in their training data. This limitation renders them ineffective when confronted with questions about recent developments or non-public documents."" and ""However, the model still fails to answer some questions correctly even with providing library of context, highlighting room",2023-08-22T23:18:53Z
Towards an On-device Agent for Text Rewriting,Yes.,4.,"""Nonetheless, the large sizes of these models make them impractical for on-device inference, which would otherwise allow for enhanced privacy and economical inference.""",2023-08-22T22:18:38Z
Halo: Estimation and Reduction of Hallucinations in Open-Source Weak Large Language Models,Yes.,5.,"""open-source LLMs with fewer parameters often suffer from severe hallucinations compared to their larger counterparts.""",2023-08-22T20:12:49Z
Target-Grounded Graph-Aware Transformer for Aerial Vision-and-Dialog Navigation,Yes.,1.,"""a hybrid augmentation strategy based on large language models is utilized to mitigate data scarcity limitations.""",2023-08-22T16:45:35Z
Large Language Models Sensitivity to The Order of Options in Multiple-Choice Questions,Yes.,5.,"""previous works have shown these models are sensitive towards prompt wording, and few-shot demonstrations and their order, posing challenges to fair assessment of these models"" and ""Investigating the sensitivity of LLMs towards the order of options in multiple-choice questions, we demonstrate a considerable performance gap of approximately 13% to 75% in LLMs on different benchmarks, when answer options are",2023-08-22T14:54:59Z
Evaluating Large Language Models on Graphs: Performance Insights and Comparative Analysis,Yes.,5.,"""All examined LLMs face challenges in structural reasoning, with techniques like zero-shot chain-of-thought and few-shot prompting showing diminished efficacy."" and ""GPT models often produce erroneous answers in multi-answer tasks, raising concerns in fidelity."" and ""GPT models exhibit elevated confidence in their outputs, potentially hindering their rectification capacities.""",2023-08-22T06:32:07Z
LLaMA-Reviewer: Advancing Code Review Automation with Large Language Models through Parameter-Efficient Fine-Tuning,Yes.,1.,"""Large Language Models (LLMs) provide an intriguing alternative, given their remarkable capabilities when supplemented with domain-specific knowledge.""",2023-08-22T03:10:40Z
Anonymity at Risk? Assessing Re-Identification Capabilities of Large Language Models,Yes.,4.,"""Despite high re-identification rates on Wikipedia, even the best LLMs struggled with court decisions. The complexity is attributed to the lack of test datasets, the necessity for substantial training resources, and data sparsity in the information used for re-identification.""",2023-08-22T00:57:36Z
Giraffe: Adventures in Expanding Context Lengths in LLMs,Yes.,5.,"""Modern large language models (LLMs) that rely on attention mechanisms are typically trained with fixed context lengths which enforce upper limits on the length of input sequences that they can handle at evaluation time.""",2023-08-21T17:30:16Z
Unreflected Acceptance -- Investigating the Negative Consequences of ChatGPT-Assisted Problem Solving in Physics Education,Yes.,5.,"""nearly half of the solutions provided with the support of ChatGPT were mistakenly assumed to be correct by the students, indicating that they overly trusted ChatGPT even in their field of expertise"" and ""highlighting the stark differences in interaction behavior between the groups and",2023-08-21T16:14:34Z
Fact-checking information generated by a large language model can decrease news discernment,Yes.,5.,"""we find that it does not significantly affect participants' ability to discern headline accuracy or share accurate news. Subsequent analysis reveals that the AI fact-checker is harmful in specific cases",2023-08-21T15:47:37Z
SeqGPT: An Out-of-the-box Large Language Model for Open Domain Sequence Understanding,Yes.,5.,"""LLMs are sometimes too footloose for natural language understanding (NLU) tasks which always have restricted output and input format. Their performances on NLU tasks are highly related to prompts or demonstrations and are shown to be poor at performing several representative NLU tasks, such as event extraction",2023-08-21T07:31:19Z
Dataset Quantization,Yes.,2.,"""The expensive computation and memory costs make it difficult to train them on limited hardware resources, especially for recent popular large language models (LLM) and computer vision models (CV).""",2023-08-21T07:24:29Z
An Examination of the Compositionality of Large Generative Vision-Language Models,Yes.,3.,"""We identify the syntactical bias in current benchmarks, which is exploited by the linguistic capability of GVLMs. The bias renders VisualGPTScore an insufficient metric for assessing GVLMs.""",2023-08-21T06:50:29Z
Exploring Parameter-Efficient Fine-Tuning Techniques for Code Generation with Large Language Models,Yes.,3.,"""While prior studies have highlighted the advantages of fine-tuning LLMs, this process incurs high computational costs, making it impractical in resource-scarce environments, particularly for models with billions of parameters."" and ""ICL introduces inconveniences, such as the need for designing contextually relevant prompts and the absence of learning task-specific parameters, thereby limiting downstream task performance.""",2023-08-21T04:31:06Z
Dynamic Strategy Chain: Dynamic Zero-Shot CoT for Long Mental Health Support Generation,Yes.,3.,"""Zero-shot CoT prompting can not simulate a counselor or provide personalized strategies without effective mental health counseling strategy prompts.""",2023-08-21T03:31:20Z
Using Large Language Models for Cybersecurity Capture-The-Flag Challenges and Certification Questions,,,,2023-08-21T03:30:21Z
LaGR-SEQ: Language-Guided Reinforcement Learning with Sample-Efficient Querying,Yes.,3.,"""However, as RL training is generally not sample-efficient, deploying this approach would inherently imply that the LLM be repeatedly queried for solutions; a process that can be expensive and infeasible.""",2023-08-21T02:07:35Z
Large Language Models on Wikipedia-Style Survey Generation: an Evaluation in NLP Concepts,Yes.,3.,"""However, their effectiveness and limitations in the education domain are yet to be fully explored."" and ""certain limitations were observed. Notably, GPT-4, despite often delivering outstanding content, occasionally exhibited lapses like missing details or factual errors.""",2023-08-21T01:32:45Z
FairMonitor: A Four-Stage Automatic Framework for Detecting Stereotypes and Biases in Large Language Models,Yes.,4.,"""Detecting stereotypes and biases in Large Language Models (LLMs) can enhance fairness and reduce adverse impacts on individuals or groups when these LLMs are applied."" and ""Experimental results reveal varying degrees of stereotypes and biases in five LLMs evaluated on Edu-FairMonitor.""",2023-08-21T00:25:17Z
A Human-on-the-Loop Optimization Autoformalism Approach for Sustainability,Yes.,1.,"""This paper outlines a natural conversational approach to solving personalized energy-related problems using large language models (LLMs).""",2023-08-20T22:42:04Z
Can ChatGPT replace StackOverflow? A Study on Robustness and Reliability of Large Language Model Code Generation,Yes.,5.,"""the reliability and robustness of the code generation from LLMs have not yet been thoroughly studied"" and ""even for GPT-4, 62% of the generated code contains API misuses, which would cause unexpected consequences if the code is introduced into real-world software",2023-08-20T18:36:28Z
How Good Are Large Language Models at Out-of-Distribution Detection?,Yes.,3.,"""the stark differences in scales, pre-training objectives, and inference paradigms call into question the applicability of these findings to LLMs.""",2023-08-20T13:15:18Z
A Survey on Fairness in Large Language Models,Yes.,4.,"""LLMs can capture social biases from unprocessed training data and propagate the biases to downstream tasks. Unfair LLM systems have undesirable social impacts and potential harms.""",2023-08-20T03:30:22Z
March in Chat: Interactive Prompting for Remote Embodied Referring Expression,Yes.,3.,"""Large Language Models (LLMs) show great potential in robot action planning by providing proper prompts. Still, this strategy has not been explored under the REVERIE settings. There are several new challenges. For example, the LLM should be environment-aware so that the navigation plan can be adjusted",2023-08-20T03:00:20Z
"UniDoc: A Universal Large Multimodal Model for Simultaneous Text Detection, Recognition, Spotting and Understanding",Yes.,3.,"""existing advanced algorithms are limited to effectively utilizing the immense representation capabilities and rich world knowledge inherent to these large pre-trained models, and the beneficial connections among tasks within the context of text-rich scenarios have not been sufficiently explored.""",2023-08-19T17:32:34Z
GameEval: Evaluating LLMs on Conversational Games,Yes.,3.,"""overcoming the limitations of previous methods.""",2023-08-19T14:33:40Z
FinEval: A Chinese Financial Domain Knowledge Evaluation Benchmark for Large Language Models,Yes.,2.,"""the results show that only GPT-4 achieved an accuracy close to 70% in different prompt settings, indicating significant growth potential for LLMs in the financial domain knowledge.""",2023-08-19T10:38:00Z
Tackling Vision Language Tasks Through Learning Inner Monologues,Yes.,2.,"""The first approach provides light training costs and interpretability but is hard to be optimized in an end-to-end fashion. The second approach presents decent performance, but feature alignment usually requires large amounts of training data and lacks interpretability.""",2023-08-19T10:10:49Z
Knowledge Transfer from High-Resource to Low-Resource Programming Languages for Code LLMs,,,,2023-08-19T03:19:01Z
Synergistic Integration of Large Language Models and Cognitive Architectures for Robust AI: An Exploratory Analysis,Yes.,3.,"""These approaches aim to harness the strengths of both LLMs and CAs, while mitigating their weaknesses, thereby advancing the development of more robust AI systems. We discuss the tradeoffs and challenges associated with each approach.""",2023-08-18T21:42:47Z
Learning Representations on Logs for AIOps,Yes.,1.,"""Large Language Models (LLMs) such as BERT and GPT3 are trained using self-supervision on a vast amount of unlabeled data.""",2023-08-18T20:34:46Z
Red-Teaming Large Language Models using Chain of Utterances for Safety-Alignment,Yes.,5.,"""the risk of LLMs producing harmful outputs increases, making them unfit for scalable deployment for the public"" and ""even widely deployed models are susceptible to the Chain of Utterances-based (CoU) prompting, jailbreaking closed source LLM-based systems such as GPT-4 and ChatGPT to unethically respond to more than 65% and 73% of",2023-08-18T16:27:04Z
Tree-of-Mixed-Thought: Combining Fast and Slow Thinking for Multi-hop Visual Reasoning,Yes.,3.,"""current research is mostly limited to basic scenarios of simple questions that can be straightforward answered in a few inference steps. Planning for the more challenging multi-hop visual reasoning tasks remains under-explored.""",2023-08-18T16:21:40Z
RatGPT: Turning online LLMs into Proxies for Malware Attacks,Yes.,4.,"""These studies covered scenarios that still require the attacker to be in the middle of the loop. In this study, we leverage openly available plugins and use an LLM as proxy between the attacker and the victim."" and ""This proof-of-concept highlights significant cybersecurity issues with openly available plugins and L",2023-08-17T20:54:39Z
Semantic Consistency for Assuring Reliability of Large Language Models,Yes.,3.,"""However, recent research has highlighted their sensitivity to variations in input prompts.""",2023-08-17T18:11:33Z
MaScQA: A Question Answering Dataset for Investigating Materials Science Knowledge of Large Language Models,Yes.,5.,"""To evaluate the limitations, we performed an error analysis, which revealed conceptual errors (~64%) as the major contributor compared to computational errors (~36%) towards the reduced performance of LLMs.""",2023-08-17T17:51:05Z
Building Emotional Support Chatbots in the Era of LLMs,Yes.,2.,"""However, there are unsolved challenges that hinder real-world applications in this field, including limited data availability and the absence of well-accepted model training paradigms.""",2023-08-17T10:49:18Z
BERT4CTR: An Efficient Framework to Combine Pre-trained Language Model with Non-textual Features for CTR Prediction,Yes.,3.,"""how to integrate pre-trained language models that handle only textual signals into a prediction pipeline with non-textual features is challenging.""",2023-08-17T08:25:54Z
CMB: A Comprehensive Medical Benchmark in Chinese,Yes.,1.,"""Large Language Models (LLMs) provide a possibility to make a great breakthrough in medicine.""",2023-08-17T07:51:23Z
Evaluating the Instruction-Following Robustness of Large Language Models to Prompt Injection,,,,2023-08-17T06:21:50Z
Multimodal Analysis Of Google Bard And GPT-Vision: Experiments In Visual Reasoning,Yes.,5.,"""However, our findings spotlight both vision-language model's limitations",2023-08-17T03:14:00Z
An Empirical Study of Catastrophic Forgetting in Large Language Models During Continual Fine-tuning,Yes.,5.,"""The experiments reveal that catastrophic forgetting is generally observed in LLMs ranging from 1b to 7b parameters. Moreover, as the model scale increases, the severity of forgetting intensifies.""",2023-08-17T02:53:23Z
PMET: Precise Model Editing in a Transformer,Yes.,3.,"""Existing methods assume Transformer Layer (TL) hidden states are values of key-value memories of the Feed-Forward Network (FFN). They usually optimize the TL hidden states to memorize target knowledge and use it to update the weights of the FFN in LLMs. However, the information flow of TL hidden states comes from three parts",2023-08-17T02:33:43Z
FineQuant: Unlocking Efficiency with Fine-Grained Weight-Only Quantization for LLMs,Yes.,3.,"""Large Language Models (LLMs) have achieved state-of-the-art performance across various language tasks but pose challenges for practical deployment due to their substantial memory requirements. Furthermore, the latest generative models suffer from high inference costs caused by the memory bandwidth bottleneck in the auto",2023-08-16T23:57:41Z
LLM4TS: Aligning Pre-Trained LLMs as Data-Efficient Time-Series Forecasters,Yes.,3.,"""incorporating LLMs with time-series data presents challenges of limited adaptation due to different compositions between time-series and linguistic data, and the inability to process multi-scale temporal information.""",2023-08-16T16:19:50Z
Self-Deception: Reverse Penetrating the Semantic Firewall of Large Language Models,Yes.,5.,"""Unfortunately, these defenses are not foolproof, and some attackers have crafted 'jailbreak' prompts that temporarily hypnotize the LLM into forgetting content defense rules and answering any improper questions.""",2023-08-16T09:04:36Z
DiagGPT: An LLM-based Chatbot with Automatic Topic Management for Task-Oriented Dialogue,Yes.,3.,"""While current LLMs proficiently answer general questions, they often fall short in complex diagnostic scenarios such as legal, medical, or other specialized consultations."" and ""Previous fine-tuning models have underperformed in TOD and the full potential of this capability in current LLMs has not yet been fully explored.""",2023-08-15T21:14:09Z
Through the Lens of Core Competency: Survey on Evaluation of Large Language Models,Yes.,3.,"""However, LLMs are extremely hard to thoroughly evaluate for two reasons. First of all, traditional NLP tasks become inadequate due to the excellent performance of LLM. Secondly, existing evaluation tasks are difficult to keep up with the wide range of applications in real-world scenarios.""",2023-08-15T17:40:34Z
Link-Context Learning for Multimodal LLMs,Yes.,3.,"""Despite current Multimodal Large Language Models (MLLMs) and Large Language Models (LLMs) being trained on mega-scale datasets, recognizing unseen images or understanding novel concepts in a training-free manner remains a challenge.""",2023-08-15T17:33:24Z
Steering Language Generation: Harnessing Contrastive Expert Guidance and Negative Prompting for Coherent and Diverse Synthetic Data Generation,Yes.,4.,"""contemporary models, despite their impressive capacities, consistently struggle to produce both coherent and diverse data.""",2023-08-15T08:49:14Z
LLM-Mini-CEX: Automatic Evaluation of Large Language Model for Diagnostic Conversation,Yes.,3.,"""Despite their alluring technological potential, there is no unified and comprehensive evaluation criterion, leading to the inability to evaluate the quality and potential risks of medical LLMs, further hindering the application of LLMs in medical treatment scenarios.""",2023-08-15T08:32:20Z
A Survey on Model Compression for Large Language Models,,,,2023-08-15T08:31:05Z
Detecting The Corruption Of Online Questionnaires By Artificial Intelligence,Yes.,4.,"""Artificial Intelligence (AI) based Large Language Models (LLM) have made it easy for bad actors to automatically fill in online forms, including generating meaningful text for open-ended tasks. ... Automatic AI detection systems are currently completely unusable.""",2023-08-14T23:47:56Z
"LLM Self Defense: By Self Examination, LLMs Know They Are Being Tricked",Yes.,2.,"""Large language models (LLMs) are popular for high-quality text generation but can produce harmful content, even when aligned with human values through reinforcement learning. Adversarial prompts can bypass their safety measures.""",2023-08-14T17:54:10Z
ChatEval: Towards Better LLM-based Evaluators through Multi-Agent Debate,Yes.,3.,"""experimental results suggest that further advancements are needed to bridge the gap between their current effectiveness and human-level evaluation quality.""",2023-08-14T15:13:04Z
Mind your Language (Model): Fact-Checking LLMs and their Role in NLP Research and Practice,Yes.,2.,"""much of this discourse relies on claims and assumptions that are worth re-examining"" and ""outlines the existing evidence for and against them.""",2023-08-14T13:00:53Z
CausalLM is not optimal for in-context learning,Yes.,5.,"""Recent empirical evidence indicates that transformer based in-context learning performs better when using a prefix language model (prefixLM), in which in-context samples can all attend to each other, compared to causal language models (causalLM), which use auto-regressive attention that prohibits in-context samples to attend to future samples.""",2023-08-14T03:14:38Z
Generative Interpretation,Yes.,3.,"""After offering best practices for the use of these models given their limitations.""",2023-08-14T02:59:27Z
Diagnostic Reasoning Prompts Reveal the Potential for Large Language Model Interpretability in Medicine,Yes.,4.,"""One of the major barriers to using large language models (LLMs) in medicine is the perception they use uninterpretable methods to make clinical decisions that are inherently different from the cognitive processes of clinicians.""",2023-08-13T19:04:07Z
"Large Language Models and Foundation Models in Smart Agriculture: Basics, Opportunities, and Challenges",Yes.,3.,"""Moreover, challenges and risks associated with developing AFMs are discussed, including model training, validation, and deployment.""",2023-08-13T02:59:36Z
Bio-SIEVE: Exploring Instruction Tuning Large Language Models for Systematic Review Automation,Yes.,2.,"""However, there remains the challenge of adapting the model to safety-first scenarios.""",2023-08-12T16:56:55Z
GPT-4 Is Too Smart To Be Safe: Stealthy Chat with LLMs via Cipher,Yes.,5.,"""We discover that chat in cipher can bypass the safety alignment techniques of LLMs, which are mainly conducted in natural languages.""",2023-08-12T04:05:57Z
Dynamic Planning with a LLM,Yes.,5.,"""applications involving embodied agents remain problematic. In particular, complex plans that require multi-step reasoning become difficult and too costly as the context window grows.""",2023-08-11T21:17:13Z
Learning Deductive Reasoning from Synthetic Corpus based on Formal Logic,,,,2023-08-11T13:15:35Z
Assessing Student Errors in Experimentation Using Artificial Intelligence and Large Language Models: A Comparative Study with Human Raters,,,,2023-08-11T12:03:12Z
Large Language Models for Telecom: Forthcoming Impact on the Industry,Yes.,3.,"""To elucidate these implications, we delve into the inner workings of LLMs, providing insights into their current capabilities and limitations.""",2023-08-11T08:41:00Z
PIPPA: A Partially Synthetic Conversational Dataset,Yes.,1.,"""With the emergence of increasingly powerful large language models, there is a burgeoning interest in leveraging these models for casual conversation and role-play applications.""",2023-08-11T00:33:26Z
Testing GPT-4 with Wolfram Alpha and Code Interpreter plug-ins on math and science problems,Yes.,4.,"""there are still often 'interface' failures; that is, GPT often has trouble formulating problems in a way that elicits useful answers from the plug-ins. Fixing these interface failures seems like a central challenge in making GPT a reliable tool for college-level calculation problems.""",2023-08-10T17:22:28Z
NUPES : Non-Uniform Post-Training Quantization via Power Exponent Search,Yes.,3.,"""This is even worse on LLMs whose weight distributions are known to exhibit large, high impact, outlier values.""",2023-08-10T14:19:58Z
Proximal Policy Optimization Actual Combat: Manipulating Output Tokenizer Length,Yes.,3.,"""LLMs often harbor misleading content, highlighting the urgency to align them with human values for secure AI systems.""",2023-08-10T13:50:17Z
C5: Towards Better Conversation Comprehension and Contextual Continuity for ChatGPT,Yes.,5.,"""However, human forgetting and model contextual forgetting remain prominent issues in multi-turn conversation scenarios, which challenge the users' conversation comprehension and contextual continuity for ChatGPT.""",2023-08-10T13:29:12Z
LLaMA-E: Empowering E-commerce Authoring with Multi-Aspect Instruction Following,Yes.,4.,"""mainstream LLMs trained on general corpora with common sense knowledge reveal limitations in fitting complex and personalized features unique to e-commerce products and customers"" and ""LLMs like GPT-3.5 necessitate remote accessibility, raising concerns about safeguarding voluminous customer privacy data during transmission",2023-08-09T12:26:37Z
CLEVA: Chinese Language Models EVAluation Platform,Yes.,4.,"""The absence of a comprehensive Chinese benchmark that thoroughly assesses a model's performance, the unstandardized and incomparable prompting procedure, and the prevalent risk of contamination pose major challenges in the current evaluation of Chinese LLMs.""",2023-08-09T09:11:31Z
"A Comparative Study of Open-Source Large Language Models, GPT-4 and Claude 2: Multiple-Choice Test Taking in Nephrology",Yes.,3.,"""We show that current widely used open-sourced LLMs do poorly in their ability for zero-shot reasoning when compared to GPT-4 and Claude 2.""",2023-08-09T05:01:28Z
Sci-CoT: Leveraging Large Language Models for Enhanced Knowledge Distillation in Small Models for Scientific QA,Yes.,3.,"""it is essential to highlight that these advanced reasoning abilities appear to emerge in models with a minimum of 10 billion parameters, thereby limiting its efficacy in situations where computational resources are constrained.""",2023-08-09T03:18:07Z
ChatGPT for Arabic Grammatical Error Correction,Yes.,3.,"""Despite these positive results, we find that instruction fine-tuned models, regardless of their size, significantly underperform compared to fully fine-tuned models of significantly smaller sizes. This disparity highlights a substantial room for improvements for LLMs.""",2023-08-08T18:00:39Z
A Comparative Study of Code Generation using ChatGPT 3.5 across 10 Programming Languages,Yes.,3.,"""Based on the findings derived from this research, major unexpected behaviors and limitations of the model have been identified.""",2023-08-08T15:02:32Z
AutoPCF: Efficient Product Carbon Footprint Accounting with Large Language Models,Yes.,3.,"""revealing their limitations as a generalized PCF knowledge database.""",2023-08-08T13:12:03Z
Hybrid Retrieval-Augmented Generation for Real-time Composition Assistance,Yes.,3.,"""the computational demands for retrieval augmented large language models (LLMs) pose a challenge when applying them to real-time tasks, such as composition assistance.""",2023-08-08T12:27:20Z
AgentSims: An Open-Source Sandbox for Large Language Model Evaluation,Yes.,5.,"""Existing evaluation methods suffer from following shortcomings",2023-08-08T03:59:28Z
Revisiting Prompt Engineering via Declarative Crowdsourcing,Yes.,3.,"""Large language models (LLMs) are incredibly powerful at comprehending and generating data in the form of text, but are brittle and error-prone.""",2023-08-07T18:04:12Z
"""Do Anything Now"": Characterizing and Evaluating In-The-Wild Jailbreak Prompts on Large Language Models",Yes.,5.,"""Our experiments show that current LLMs and safeguards cannot adequately defend jailbreak prompts in all scenarios.""",2023-08-07T16:55:20Z
AgentBench: Evaluating LLMs as Agents,Yes.,5.,"""We identify the typical reasons of failures in environments and LLMs, showing that poor long-term reasoning, decision-making, and instruction following abilities are the main obstacles for developing usable LLM agents.""",2023-08-07T16:08:11Z
Learning Concise and Descriptive Attributes for Visual Recognition,Yes.,3.,"""our further investigation on 8 datasets reveals that LLM-generated attributes in a large quantity perform almost the same as random words. This surprising finding suggests that significant noise may be present in these attributes.""",2023-08-07T16:00:22Z
MedMine: Examining Pre-trained Language Models on Medication Mining,Yes.,3.,"""Such obstacles include their imbalanced performances on different entity types and clinical events.""",2023-08-07T14:36:03Z
Mondrian: Prompt Abstraction Attack Against Large Language Models for Cheaper API Pricing,Yes.,3.,"""Researchers have long studied the vulnerabilities and limitations of LLMs, such as adversarial attacks and model toxicity.""",2023-08-07T13:10:35Z
Accurate Retraining-free Pruning for Pretrained Encoder-based Language Models,Yes.,3.,"""existing retraining-free algorithms encounter severe accuracy degradation, as they fail to handle pruning errors, especially at high compression rates.""",2023-08-07T10:11:42Z
Coupling Symbolic Reasoning with Language Modeling for Efficient Longitudinal Understanding of Unstructured Electronic Medical Records,Yes.,5.,"""the inability of LLMs to derive reasoning paradigms that allow for comprehensive understanding of medical variables"" and ""the need for LLM steering through the application of symbolic reasoning as the exclusive use of LLMs results in the lowest performance.""",2023-08-07T07:29:49Z
GPTScan: Detecting Logic Vulnerabilities in Smart Contracts by Combining GPT with Program Analysis,Yes.,3.,"""Instead of relying solely on GPT to identify vulnerabilities, which can lead to high false positives and is limited by GPT's pre-trained knowledge.""",2023-08-07T05:48:53Z
Exploiting Code Symmetries for Learning Program Semantics,Yes.,1.,"""Our results suggest that code LLMs that encode the code structural prior via the code symmetry group generalize better and faster.""",2023-08-07T05:40:58Z
LoRA-FA: Memory-efficient Low-rank Adaptation for Large Language Models Fine-tuning,Yes.,2.,"""The low-rank adaptation (LoRA) method can largely reduce the amount of trainable parameters for fine-tuning large language models (LLMs), however, it still requires expensive activation memory to update low-rank weights.""",2023-08-07T05:12:27Z
Studying Large Language Model Generalization with Influence Functions,Yes.,4.,"""While influence functions have produced insights for small models, they are difficult to scale to large language models (LLMs) due to the difficulty of computing an inverse-Hessian-vector product (IHVP)."" and ""Despite many apparently sophisticated forms of generalization, we identify a surprising limitation",2023-08-07T04:47:42Z
Why Linguistics Will Thrive in the 21st Century: A Reply to Piantadosi (2023),Yes.,5.,"""humans achieve their capacity for language after exposure to several orders of magnitude less data,"" ""LLMs currently show little promise of solving this mystery,"" ""LLMs cannot constitute scientific theories of language for several reasons,"" ""scientific theories must provide interpretable explanations, not just predictions.""",2023-08-06T23:41:14Z
LARCH: Large Language Model-based Automatic Readme Creation with Heuristics,Yes.,2.,"""automatically creating one remains a challenge even with the recent advancements in large language models (LLMs), because it requires generating an abstract description from thousands of lines of code.""",2023-08-06T12:28:24Z
TARJAMAT: Evaluation of Bard and ChatGPT on Machine Translation of Ten Arabic Varieties,Yes.,4.,"""Despite the purported multilingual proficiency of instruction-finetuned large language models (LLMs) such as ChatGPT and Bard, the linguistic inclusivity of these models remains insufficiently explored."" and ""Our analysis indicates that LLMs may encounter challenges with dialects for which minimal public datasets exist,"" and ""instruction-tuned LLMs, however, trail behind commercial systems such as Google",2023-08-06T08:29:16Z
An Empirical Study of AI-based Smart Contract Creation,Yes.,4.,"""Our study finds crucial evidence of security bugs getting introduced in the generated smart contracts as well as the overall quality and correctness of the code getting impacted.""",2023-08-05T21:38:57Z
Scaling Clinical Trial Matching Using Large Language Models: A Case Study in Oncology,Yes.,4.,"""Our study also reveals a few significant growth areas for applying LLMs to end-to-end clinical trial matching, such as context limitation and accuracy, especially in structuring patient information from longitudinal medical records.""",2023-08-04T07:51:15Z
The Unequal Opportunities of Large Language Models: Revealing Demographic Bias through Job Recommendations,Yes.,4.,"""We identify distinct biases in both models toward various demographic identities, such as both models consistently suggesting low-paying jobs for Mexican workers or preferring to recommend secretarial roles to women.""",2023-08-03T21:12:54Z
"Efficient Sentiment Analysis: A Resource-Aware Evaluation of Feature Extraction Techniques, Ensembling, and Deep Learning Models",Yes.,2.,"""We find that while a fine-tuned LLM achieves the best accuracy, some alternate configurations provide huge (up to 24, 283 *) resource savings for a marginal (<1%) loss in accuracy.""",2023-08-03T20:29:27Z
ClassEval: A Manually-Crafted Benchmark for Evaluating LLMs on Class-level Code Generation,Yes.,5.,"""First, we find that all existing LLMs show much worse performance on class-level code generation compared to on standalone method-level code generation benchmarks like HumanEval; and the method-level coding ability cannot equivalently reflect the class-level coding ability among LLMs."" and ""Lastly, we find the limited model ability of generating method-dependent code and discuss the frequent error types in generated classes",2023-08-03T16:31:02Z
Scaling Relationship on Learning Mathematical Reasoning with Large Language Models,,,,2023-08-03T15:34:01Z
Does Correction Remain A Problem For Large Language Models?,Yes.,3.,"""This paper investigates the role of correction in the context of large language models by conducting two experiments.""",2023-08-03T14:09:31Z
Evaluating ChatGPT text-mining of clinical records for obesity monitoring,Yes.,3.,"""Subtle prompt engineering is needed to improve ChatGPT output"" and ""require careful implementation to avoid unpredictable errors.""",2023-08-03T10:11:42Z
XSTest: A Test Suite for Identifying Exaggerated Safety Behaviours in Large Language Models,Yes.,5.,"""Without proper safeguards, large language models will readily follow malicious instructions and generate toxic content."" and ""we introduce a new test suite called XSTest to identify such eXaggerated Safety behaviours in a systematic way."" and ""highlight systematic failure modes in state-of",2023-08-02T16:30:40Z
Towards More Human-like AI Communication: A Review of Emergent Communication Research,Yes.,3.,"""While a common approach to achieve this is to train large language models, this method presents a form of learning misalignment where the model may not capture the underlying structure and reasoning humans employ in using natural language, potentially leading to unexpected or unreliable behavior.""",2023-08-01T14:43:10Z
Retrieval Augmented Generation and Representative Vector Summarization for large unstructured textual data in Medical Education,Yes.,3.,"""Despite their impressive performances in general tasks, LLMs need to be aligned when applying for domain specific tasks to mitigate the problems of hallucination and producing harmful answers.""",2023-08-01T12:04:50Z
SelfCheck: Using LLMs to Zero-Shot Check Their Own Step-by-Step Reasoning,Yes.,5.,"""However, when faced with more complicated problems that require non-linear thinking, even the strongest LLMs make mistakes.""",2023-08-01T10:31:36Z
LimeAttack: Local Explainable Method for Textual Hard-Label Adversarial Attack,Yes.,3.,"""Natural language processing models are vulnerable to adversarial examples."" and ""In addition, we evaluate the effectiveness of LimeAttack on large language models, and results indicate that adversarial examples remain a significant threat to large language models.""",2023-08-01T06:30:37Z
Adapt and Decompose: Efficient Generalization of Text-to-SQL via Domain Adapted Least-To-Most Prompting,Yes.,1.,"""Existing Large Language Model (LLM) based solutions rely on inference-time retrieval of few-shot exemplars from the training set to synthesize a run-time prompt for each Natural Language (NL) test query.""",2023-08-01T05:31:36Z
The Hitchhiker's Guide to Program Analysis: A Journey with Large Language Models,,,,2023-08-01T02:57:43Z
Instructed to Bias: Instruction-Tuned Language Models Exhibit Emergent Cognitive Bias,Yes.,5.,"""Our findings highlight the presence of these biases in various models from the GPT-3, Mistral, and T5 families. Notably, we find a stronger presence of biases in models that have undergone instruction tuning, such as Flan-T5, Mistral-Instruct, GPT3.5, and GPT4.""",2023-08-01T01:39:25Z
HAGRID: A Human-LLM Collaborative Dataset for Generative Information-Seeking with Attribution,Yes.,1.,"""The rise of large language models (LLMs) had a transformative impact on search,"" and ""HAGRID is constructed based on human and LLM collaboration.""",2023-07-31T17:49:18Z
Transferable Decoding with Visual Entities for Zero-Shot Image Captioning,Yes.,3.,"""we have observed and empirically demonstrated that these methods are susceptible to modality bias induced by LLMs and tend to generate descriptions containing objects (entities) that do not actually exist in the image but frequently appear during training (i.e., object hallucination).""",2023-07-31T09:47:06Z
Deception Abilities Emerged in Large Language Models,,,,2023-07-31T09:27:01Z
A Benchmark for Understanding Dialogue Safety in Mental Health Support,Yes.,3.,"""Our study reveals that ChatGPT struggles to detect safety categories with detailed safety definitions in a zero- and few-shot paradigm, whereas the fine-tuned model proves to be more suitable.""",2023-07-31T07:33:16Z
HouYi: An open-source large language model specially designed for renewable energy and carbon neutrality field,Yes.,2.,"""However, there has not been a specially designed LLM for renewable energy. Meanwhile, there has not been any dataset of renewable energy for training LLMs.""",2023-07-31T06:59:36Z
Distractor generation for multiple-choice questions with predictive prompting and large language models,Yes.,3.,"""we still observe a performance gap in generating distractors -- i.e., plausible yet incorrect answers -- with LLMs for multiple-choice questions (MCQs).""",2023-07-30T23:15:28Z
An Unforgeable Publicly Verifiable Watermark for Large Language Models,Yes.,2.,"""current watermark detection algorithms require the secret key used in the watermark generation process, making them susceptible to security breaches and counterfeiting during public detection.""",2023-07-30T13:43:27Z
SEED-Bench: Benchmarking Multimodal LLMs with Generative Comprehension,Yes.,4.,"""By revealing the limitations of existing MLLMs through evaluation results, we aim for SEED-Bench to provide insights for motivating future research.""",2023-07-30T04:25:16Z
Okapi: Instruction-tuned Large Language Models in Multiple Languages with Reinforcement Learning from Human Feedback,Yes.,2.,"""existing open-source LLMs have only been instruction-tuned for English and a few popular languages, thus hindering their impacts and accessibility to many other languages in the world.""",2023-07-29T18:01:46Z
Towards Codable Watermarking for Injecting Multi-bits Information to LLMs,Yes.,1.,"""we argue that existing LLM watermarking methods are encoding-inefficient and cannot flexibly meet the diverse information encoding needs (such as encoding model version, generation time, user id, etc.).""",2023-07-29T14:11:15Z
"Summaries, Highlights, and Action items: Design, implementation and evaluation of an LLM-powered meeting recap system",Yes.,4.,"""Despite this potential, they face technological limitation due to long transcripts and inability to capture diverse recap needs based on user's context."" and ""However, we find that LLM-based recap still lacks an understanding of whats personally relevant to participants, can miss important details, and mis-attributions can be detrimental to group dynamics.""",2023-07-28T20:25:11Z
CHATREPORT: Democratizing Sustainability Disclosure Analysis through LLM-based Tools,Yes.,3.,"""developing such tools is challenging due to (1) the hallucination of LLMs and (2) the inefficiency of bringing domain experts into the AI development loop.""",2023-07-28T18:58:16Z
"A Critical Review of Large Language Models: Sensitivity, Bias, and the Path Toward Specialized AI",Yes.,4.,"""It presents a critical review of Large Language Models (LLMs), addressing challenges related to bias and sensitivity.""",2023-07-28T09:20:22Z
Med-HALT: Medical Domain Hallucination Test for Large Language Models,Yes.,5.,"""Hallucination, wherein these models generate plausible yet unverified or incorrect information, can have serious consequences in healthcare applications.""",2023-07-28T06:43:04Z
An Overview Of Temporal Commonsense Reasoning and Acquisition,Yes.,5.,"""Recent research on the performance of large language models suggests that, although they are adept at generating syntactically correct sentences and solving classification tasks, they often take shortcuts in their reasoning and fall prey to simple linguistic traps."" and ""However, these augmented models still struggle to approach human performance on reasoning tasks over temporal common sense",2023-07-28T01:30:15Z
Open Problems and Fundamental Limitations of Reinforcement Learning from Human Feedback,Yes.,4.,"""RLHF has emerged as the central method used to finetune state-of-the-art large language models (LLMs)."" and ""survey open problems and fundamental limitations of RLHF and related methods.""",2023-07-27T22:29:25Z
Matching Patients to Clinical Trials with Large Language Models,Yes.,3.,"""Our error analysis suggests that current LLMs still make some mistakes due to limited medical knowledge and domain-specific context understanding.""",2023-07-27T17:56:56Z
WavJourney: Compositional Audio Creation with Large Language Models,Yes.,1.,"""We present WavJourney, a novel framework that leverages Large Language Models (LLMs) to connect various audio models for audio creation.""",2023-07-26T17:54:04Z
This is not correct! Negation-aware Evaluation of Language Generation Systems,Yes.,5.,"""Large language models underestimate the impact of negations on how much they change the meaning of a sentence. Therefore, learned evaluation metrics based on these models are insensitive to negations.""",2023-07-26T06:54:31Z
Mental-LLM: Leveraging Large Language Models for Mental Health Prediction via Online Text Data,Yes.,4.,"""However, there is still a significant gap in research when it comes to understanding and enhancing the capabilities of LLMs in the field of mental health."" and ""Meanwhile, we also emphasize the important limitations before achieving deployability in real-world mental health settings, such as known racial and gender bias.""",2023-07-26T06:00:50Z
Is GPT a Computational Model of Emotion? Detailed Analysis,Yes.,5.,"""GPT faces difficulties predicting emotion intensity and coping responses"" and ""fell short in the second, despite providing superior results after minor prompt engineering.""",2023-07-25T19:34:44Z
Evaluating Large Language Models for Radiology Natural Language Processing,Yes.,2.,"""The outcomes of this evaluation provide key insights into the performance, strengths, and weaknesses of these LLMs, informing their practical applications within the medical domain.""",2023-07-25T17:57:18Z
ARB: Advanced Reasoning Benchmark for Large Language Models,Yes.,5.,"""Large Language Models (LLMs) have demonstrated remarkable performance on various quantitative reasoning and knowledge benchmarks. However, many of these benchmarks are losing utility as LLMs get increasingly high scores, despite not yet reaching expert performance in these domains.""",2023-07-25T17:55:19Z
How Can Large Language Models Help Humans in Design and Manufacturing?,Yes.,3.,"""Through a series of examples, we highlight both the benefits and the limitations of the current LLMs.""",2023-07-25T17:30:38Z
GPT-3 Models are Few-Shot Financial Reasoners,Yes.,3.,"""We run several experiments with GPT-3 and find that a separate retrieval model and logic engine continue to be essential components to achieving SOTA performance in this task, particularly due to the precise nature of financial questions and the complex information stored in financial documents.""",2023-07-25T16:21:07Z
FacTool: Factuality Detection in Generative AI -- A Tool Augmented Framework for Multi-Task and Multi-Domain Scenarios,,,,2023-07-25T14:20:51Z
Predicting Code Coverage without Execution,Yes.,1.,"""We propose a novel benchmark task called Code Coverage Prediction for Large Language Models (LLMs).""",2023-07-25T10:07:02Z
Aligning Large Language Models with Human: A Survey,Yes.,4.,"""Despite their notable performance, these models are prone to certain limitations such as misunderstanding human instructions, generating potentially biased content, or factually incorrect (hallucinated) information.""",2023-07-24T17:44:58Z
The potential of LLMs for coding with low-resource and domain-specific programming languages,Yes.,3.,"""While the LLM showcased promoting docstring-to-code translation capability, we also identify some limitations, such as its inability to improve certain sections of code and to write accurate unit tests.""",2023-07-24T17:17:13Z
Interpretable Stereotype Identification through Reasoning,Yes.,4.,"""Given that language models are trained on vast datasets that may contain inherent biases, there is a potential danger of inadvertently perpetuating systemic discrimination.""",2023-07-24T15:12:13Z
"A Real-World WebAgent with Planning, Long Context Understanding, and Program Synthesis",Yes.,5.,"""the performance on real-world websites has still suffered from (1) open domainness, (2) limited context length, and (3) lack of inductive bias on HTML.""",2023-07-24T14:56:30Z
Performance of Large Language Models in a Computer Science Degree Program,Yes.,4.,"""We showcase the strong performance of current large language models while highlighting limitations and constraints within the context of such a degree program"" and ""Despite these convincing results, even GPT-4.0 would not pass the degree program - due to limitations in mathematical calculations.""",2023-07-24T14:17:00Z
Tachikuma: Understading Complex Interactions with Multi-Character and Novel Objects by Large Language Models,Yes.,5.,"""However, these interactions still face limitations in complexity and flexibility, particularly in scenarios involving multiple characters and novel objects.""",2023-07-24T07:40:59Z
The Effectiveness of Large Language Models (ChatGPT and CodeBERT) for Security-Oriented Code Analysis,Yes.,4.,"""However, we observed that the strengths and limitations of adopting these LLMs to the code analysis have not been investigated."" and ""However, it is essential to acknowledge certain limitations, such as the heavy reliance on well-defined variable and function names, making them unable to learn from anonymized code.""",2023-07-24T02:38:24Z
In-Context Learning Learns Label Relationships but Is Not Conventional Learning,Yes.,4.,"""we provide novel insights into how ICL leverages label information, revealing both capabilities and limitations,"" and ""ICL struggles to fully overcome prediction preferences acquired from pre-training data and, further, that ICL does not consider all in-context information equally.""",2023-07-23T16:54:41Z
The Imitation Game: Detecting Human and AI-Generated Texts in the Era of ChatGPT and BARD,Yes.,3.,"""However, distinguishing between human-written and AI-generated text has become a significant task."" and ""the task becomes more challenging when classifying GPT-generated text, particularly in story writing.""",2023-07-22T21:00:14Z
FinPT: Financial Risk Prediction with Profile Tuning on Pretrained Foundation Models,Yes.,1.,"""the algorithms used are somewhat outdated, especially in the context of the fast advance of generative AI and large language models (LLMs);""",2023-07-22T09:27:05Z
Psy-LLM: Scaling up Global Mental Health Psychological Services with AI-based Large Language Models,Yes.,2.,"""This article discusses the potential and limitations of using large language models to enhance mental health support through AI technologies.""",2023-07-22T06:21:41Z
Selective Perception: Optimizing State Descriptions with Reinforcement Learning for Language Model Actors,Yes.,3.,"""Exhaustively describing high-dimensional states can impair performance and raise inference costs for LLM actors. Previous LLM actors avoid the issue by relying on hand-engineered, task-specific protocols to determine which features to communicate about a state and which to leave out.""",2023-07-21T22:02:50Z
The Looming Threat of Fake and LLM-generated LinkedIn Profiles: Challenges and Opportunities for Detection and Prevention,Yes.,1.,"""It is a significant finding since the proliferation of several LLMs in the near future makes it extremely challenging to design a single system that can identify profiles created with various LLMs.""",2023-07-21T19:09:24Z
OUTFOX: LLM-Generated Essay Detection Through In-Context Learning with Adversarially Generated Examples,Yes.,3.,"""However, existing detectors lack robustness against attacks",2023-07-21T17:40:47Z
GPT-4 Can't Reason,Yes.,5.,"""However, despite the genuinely impressive improvement, there are good reasons to be highly skeptical of GPT-4's ability to reason."" and ""Based on this analysis, the paper concludes that, despite its occasional flashes of analytical brilliance, GPT-4 at present is utterly incapable of reasoning.""",2023-07-21T17:04:25Z
"""Tidy Up the Table"": Grounding Common-sense Objective for Tabletop Object Rearrangement",Yes.,3.,"""Large Language Models (LLMs) have proven capable of capturing common sense knowledge to reason over this vague concept of tidiness. However, they alone may struggle with table tidying due to the limited grasp on the spatio-visual aspects of tidiness.""",2023-07-21T03:00:31Z
FLASK: Fine-grained Language Model Evaluation based on Alignment Skill Sets,Yes.,3.,"""previous studies have mainly focused on coarse-grained evaluation (i.e. overall preference-based evaluation), which limits interpretability since it does not consider the nature of user instructions that require instance-wise skill composition.""",2023-07-20T14:56:35Z
LLM Censorship: A Machine Learning Challenge or a Computer Security Problem?,Yes.,5.,"""we present the theoretical limitations of such semantic censorship approaches"" and ""highlighting the inherent challenges in censorship that arise due to LLMs' programmatic and instruction-following capabilities.""",2023-07-20T09:25:02Z
SciBench: Evaluating College-Level Scientific Problem-Solving Abilities of Large Language Models,Yes.,5.,"""The results reveal that the current LLMs fall short of delivering satisfactory performance, with the best overall score of merely 43.22%."" and ""we categorize the errors made by LLMs into ten problem-solving abilities.""",2023-07-20T07:01:57Z
What can we learn from Data Leakage and Unlearning for Law?,Yes.,5.,"""Large Language Models (LLMs) have a privacy concern because they memorize training data (including personally identifiable information (PII) like emails and phone numbers) and leak it during inference."" and ""The property of new data points becoming vulnerable to extraction after unlearning and leakage of pre-training data through fine-t",2023-07-19T22:14:58Z
Can Instruction Fine-Tuned Language Models Identify Social Bias through Prompting?,Yes.,3.,"""it is increasingly important to build efficient frameworks for measuring and mitigating the learned or inherited social biases of these models.""",2023-07-19T22:03:40Z
PharmacyGPT: The AI Pharmacist,Yes.,2.,"""Our analysis offers valuable insights into the potential applications and limitations of LLMs in the field of clinical pharmacy.""",2023-07-19T19:40:34Z
Code Detection for Hardware Acceleration Using Large Language Models,Yes.,2.,"""Results reveal that conventional prompting achieves great precision but poor accuracy (68.8%, 22.3%, and 79.2% for GEMM, convolution, and FFT, respectively) due to a high number of false positives.""",2023-07-19T17:21:58Z
Generating Mathematical Derivations with Large Language Models,Yes.,5.,"""Empirical results show that fine-tuned FLAN-T5-large (MathT5) outperforms GPT models on all static and out-of-distribution test sets in conventional scores. However, an in-depth analysis reveals that the fine-tuned models are more sensitive to perturbations involving unseen symbols and (to a lesser extent) changes to equation structure. In addition, we analyse",2023-07-19T14:13:02Z
ZeroQuant-FP: A Leap Forward in LLMs Post-Training W4A8 Quantization Using Floating-Point Formats,Yes.,3.,"""Navigating the inherent limitations of uniform quantization, particularly when dealing with outliers,"" and ""mitigate the overhead from precision alignment caused by the disparity between weights and activations.""",2023-07-19T06:58:03Z
CValues: Measuring the Values of Chinese Large Language Models from Safety to Responsibility,Yes.,4.,"""there is considerable room for improvement in terms of responsibility"" and ""evaluation of human values alignment is becoming increasingly important.""",2023-07-19T01:22:40Z
Can Model Fusing Help Transformers in Long Document Classification? An Empirical Study,Yes.,5.,"""While state-of-the-art transformer models provide excellent results in text classification, most of them have limitations in the maximum sequence length of the input sequence. The majority of the transformer models are limited to 512 tokens, and therefore, they struggle with long document classification problems.""",2023-07-18T18:21:26Z
Unveiling Gender Bias in Terms of Profession Across LLMs: Analyzing and Addressing Sociological Implications,Yes.,4.,"""The findings shed light on gendered word associations, language usage, and biased narratives present in the outputs of these Large Language Models."" and ""The discussion explores the ethical implications of gender bias and its potential consequences on social perceptions and marginalized communities.""",2023-07-18T11:38:45Z
On the (In)Effectiveness of Large Language Models for Chinese Text Correction,Yes.,3.,"""we empirically find that the LLMs currently have both amazing performance and unsatisfactory behavior for Chinese Text Correction.""",2023-07-18T06:48:52Z
Do Models Explain Themselves? Counterfactual Simulatability of Natural Language Explanations,Yes.,5.,"""We found that LLM's explanations have low precision and that precision does not correlate with plausibility. Therefore, naively optimizing human approvals (e.g., RLHF) may not be a sufficient solution.""",2023-07-17T17:41:47Z
"TableGPT: Towards Unifying Tables, Nature Language and Commands into One GPT",Yes.,1.,"""The advancements in large language models (LLMs) have made it possible to interact with tables using natural language input, bringing this capability closer to reality.""",2023-07-17T17:36:09Z
Measuring Faithfulness in Chain-of-Thought Reasoning,Yes.,5.,"""it is unclear if the stated reasoning is a faithful explanation of the model's actual reasoning"" and ""As models become larger and more capable, they produce less faithful reasoning on most tasks we study.""",2023-07-17T01:08:39Z
Question Decomposition Improves the Faithfulness of Model-Generated Reasoning,Yes.,5.,"""As large language models (LLMs) perform more difficult tasks, it becomes harder to verify the correctness and safety of their behavior."" and ""However, this approach relies on the stated reasoning faithfully reflecting the model's actual reasoning, which is not always the case.""",2023-07-17T00:54:10Z
The Potential and Pitfalls of using a Large Language Model such as ChatGPT or GPT-4 as a Clinical Assistant,Yes.,5.,"""there were mentions of factually incorrect statements, overlooking crucial medical findings, recommendations for unnecessary investigations and overtreatment. These issues coupled with privacy concerns, make these models currently inadequate for real world clinical use.""",2023-07-16T21:19:47Z
Do Emergent Abilities Exist in Quantized Large Language Models: An Empirical Study,Yes.,5.,"""a major challenge is that low-bit quantization methods often lead to performance degradation"" and ""2-bit models encounter severe performance degradation on the test of these abilities.""",2023-07-16T15:11:01Z
Look Before You Leap: An Exploratory Study of Uncertainty Measurement for Large Language Models,Yes.,5.,"""erroneous generations, such as false predictions, misinformation, and hallucination made by LLMs, have also raised severe concerns for the trustworthiness of LLMs', especially in safety-, security- and reliability-sensitive scenarios, potentially hindering real-world adoptions.""",2023-07-16T08:28:04Z
Leveraging Large Language Models to Generate Answer Set Programs,Yes.,4.,"""However, their reasoning capabilities are limited and relatively shallow, despite the application of various prompting techniques.""",2023-07-15T03:40:55Z
Can Large Language Models Empower Molecular Property Prediction?,,,,2023-07-14T16:06:42Z
Are Large Language Models a Threat to Digital Public Goods? Evidence from Activity on Stack Overflow,,,,2023-07-14T14:22:12Z
Certified Robustness for Large Language Models with Self-Denoising,Yes.,5.,"""their vulnerabilities towards noisy inputs have significantly limited their uses, especially in high-stake environments"" and ""randomized smoothing requires adding noise to the input before model prediction, and its certification performance depends largely on the model's performance on corrupted data. As a result, its direct application to LLMs remains challenging and often results in a small certification radius.""",2023-07-14T05:40:24Z
Generating Efficient Training Data via LLM-based Attribute Manipulation,Yes.,1.,"""In this paper, we propose a novel method, Chain-of-Thoughts Attribute Manipulation (CoTAM), to guide few-shot learning by carefully crafted data from Large Language Models (LLMs).""",2023-07-14T00:10:03Z
A Study on Differentiable Logic and LLMs for EPIC-KITCHENS-100 Unsupervised Domain Adaptation Challenge for Action Recognition 2023,Yes.,2.,"""To further enhance the model's adaptability to novel action labels, we experiment with rules generated using GPT-3.5, which leads to a slight decrease in performance.""",2023-07-13T05:54:05Z
Exploring the Integration of Large Language Models into Automatic Speech Recognition Systems: An Empirical Study,Yes.,5.,"""Unfortunately, our initial experiments did not yield promising results, indicating the complexity of leveraging LLM's in-context learning for ASR applications. Despite further exploration with varied settings and models, the corrected sentences from the LLMs frequently resulted in higher Word Error Rates (WER), demonstrating the",2023-07-13T02:31:55Z
AutoHint: Automatic Prompt Optimization with Hint Generation,Yes.,1.,"""While LLMs have demonstrated remarkable ability in achieving high-quality annotation in various tasks, the key to applying this ability to specific tasks lies in developing high-quality prompts.""",2023-07-13T00:49:27Z
T2I-CompBench: A Comprehensive Benchmark for Open-world Compositional Text-to-image Generation,Yes.,3.,"""We further propose several evaluation metrics specifically designed to evaluate compositional text-to-image generation and explore the potential and limitations of multimodal LLMs for evaluation.""",2023-07-12T17:59:42Z
Better Handling Coreference Resolution in Aspect Level Sentiment Classification by Fine-Tuning Language Models,Yes.,3.,"""Large Language Models (LLMs) are the heart of many state-of-the-art ALSC solutions, but they perform poorly in some scenarios requiring Coreference Resolution (CR).""",2023-07-11T12:43:28Z
Secrets of RLHF in Large Language Models Part I: PPO,Yes.,3.,"""However, due to the challenges of reward design, environment interaction, and agent training, coupled with huge trial and error cost of large language models, there is a significant barrier for AI researchers to motivate the development of technical alignment and safe landing of LLMs.""",2023-07-11T01:55:24Z
AmadeusGPT: a natural language interface for interactive animal behavioral analysis,Yes.,3.,"""the comprehension capability of these LLMs is limited by the context window size, which prevents it from remembering distant conversations.""",2023-07-10T19:15:17Z
BeaverTails: Towards Improved Safety Alignment of LLM via a Human-Preference Dataset,Yes.,2.,"""We further showcase applications of BeaverTails in content moderation and reinforcement learning with human feedback (RLHF), emphasizing its potential for practical safety measures in LLMs.""",2023-07-10T15:56:17Z
Enhancing Biomedical Text Summarization and Question-Answering: On the Utility of Domain-Specific Pre-Training,Yes.,1.,"""Our results indicate that a Large Language Model without domain-specific pre-training can have a significant edge in some domain-specific biomedical text generation tasks.""",2023-07-10T08:32:45Z
TIM: Teaching Large Language Models to Translate with Comparison,Yes.,3.,"""However, these models can sometimes struggle with tasks that require more specialized knowledge such as translation."" and ""Moreover, it can be more challenging for tuning smaller LLMs with lower-quality training data.""",2023-07-10T08:15:40Z
Towards Cross-Table Masked Pretraining for Web Data Mining,No.,1.,The abstract discusses pretraining techniques for mining tabular data and does not mention language models or their limitations.,2023-07-10T02:27:38Z
A Stitch in Time Saves Nine: Detecting and Mitigating Hallucinations of LLMs by Validating Low-Confidence Generation,Yes.,5.,"""However, these models often tend to 'hallucinate' which critically hampers their reliability.""",2023-07-08T14:25:57Z
Evaluating the Capability of Large-scale Language Models on Chinese Grammatical Error Correction Task,Yes.,5.,"""some studies indicated that large language models fail to achieve promising result beyond the state-of-the-art models in English grammatical error correction (GEC) tasks,"" and ""the performances of LLMs on automatic evaluation metrics falls short of the previous sota models because of the problem of over-correction. Furthermore, we also discover notable variations in the performance of LLMs when evaluated on different",2023-07-08T13:10:59Z
"Right to be Forgotten in the Era of Large Language Models: Implications, Challenges, and Solutions",Yes.,4.,"""With the recent development of Large Language Models (LLMs) and their use in chatbots, LLM-enabled software systems have become popular. But they are not excluded from the RTBF. Compared with the indexing approach used by search engines, LLMs store, and process information in a completely different way. This poses new challenges for compliance with the RTBF.""",2023-07-08T09:28:50Z
RADAR: Robust AI-Text Detection via Adversarial Learning,,,,2023-07-07T21:13:27Z
Unveiling the Potential of Knowledge-Prompted ChatGPT for Enhancing Drug Trafficking Detection on Social Media,Yes.,2.,"""However, the effectiveness of conventional supervised learning methods in detecting drug trafficking heavily relies on having access to substantial amounts of labeled data, while data annotation is time-consuming and resource-intensive. Furthermore, these models often face challenges in accurately identifying trafficking activities when drug dealers use deceptive language and euphemisms to avoid detection.""",2023-07-07T16:15:59Z
Brain in a Vat: On Missing Pieces Towards Artificial General Intelligence in Large Language Models,Yes.,5.,"""We pinpoint several problems with current evaluation methods that tend to overstate the capabilities of LLMs."" and ""We then articulate what artificial general intelligence should encompass beyond the capabilities of LLMs.""",2023-07-07T13:58:16Z
TRAQ: Trustworthy Retrieval Augmented Question Answering via Conformal Prediction,Yes.,5.,"""When applied to open-domain question answering, large language models (LLMs) frequently generate incorrect responses based on made-up facts, which are called $\textit{hallucinations}$.""",2023-07-07T02:42:06Z
Focused Transformer: Contrastive Training for Context Scaling,Yes.,5.,"""However, the full potential of such an approach is often restrained due to a limitation in the effective context length."" and ""We identify a significant challenge, dubbed the distraction issue, where keys linked to different semantic values might overlap, making them hard to distinguish.""",2023-07-06T17:52:10Z
Style Over Substance: Evaluation Biases for Large Language Models,Yes.,4.,"""Our findings reveal a concerning bias in the evaluation process, as answers with factual errors are rated more favorably than answers that are too short or contained grammatical errors.""",2023-07-06T14:42:01Z
"Amplifying Limitations, Harms and Risks of Large Language Models",Yes.,5.,"""We set out to highlight a number of limitations of LLMs, and in so doing highlight that harms have already arisen and will continue to arise due to these limitations.""",2023-07-06T11:53:45Z
PRD: Peer Rank and Discussion Improve Large Language Model based Evaluations,Yes.,3.,"""However, this intuitive method has multiple problems, such as bringing in self-enhancement (favoring its own answers) and positional bias.""",2023-07-06T04:05:44Z
Scaling In-Context Demonstrations with Structured Attention,Yes.,5.,"""their capabilities of in-context learning are limited by the model architecture",2023-07-05T23:26:01Z
Jailbroken: How Does LLM Safety Training Fail?,Yes.,5.,"""Large language models trained for safety and harmlessness remain susceptible to adversarial misuse,"" and ""We hypothesize two failure modes of safety training",2023-07-05T17:58:10Z
Reasoning or Reciting? Exploring the Capabilities and Limitations of Language Models Through Counterfactual Tasks,Yes.,5.,"""we observe nontrivial performance on the counterfactual variants, but nevertheless find that performance substantially and consistently degrades compared to the default conditions. This suggests that while current LMs may possess abstract task-solving skills to an extent, they often also rely on narrow",2023-07-05T17:50:42Z
External Reasoning: Towards Multi-Large-Language-Models Interchangeable Assistance with Human Feedback,Yes.,5.,"""they are inhibited by constraints on context length that preclude the processing of extensive, continually evolving knowledge bases.""",2023-07-05T17:05:32Z
Comparative Analysis of GPT-4 and Human Graders in Evaluating Praise Given to Students in Synthetic Dialogues,Yes.,3.,"""GPT-4 performs moderately well in identifying instances when the tutor offers specific and immediate praise. However, GPT-4 underperforms in identifying the tutor's ability to deliver sincere praise, particularly in the zero-shot prompting scenario where examples of sincere tutor praise statements were not provided.""",2023-07-05T04:14:01Z
Evaluating the Effectiveness of Large Language Models in Representing Textual Descriptions of Geometry and Spatial Relations,Yes.,3.,"""challenges remain in estimating numeric values and retrieving spatially related objects.""",2023-07-05T03:50:08Z
Open-Domain Hierarchical Event Schema Induction by Incremental Prompting and Verification,Yes.,1.,"""we propose to treat event schemas as a form of commonsense knowledge that can be derived from large language models (LLMs).""",2023-07-05T01:00:44Z
ProPILE: Probing Privacy Leakage in Large Language Models,Yes.,4.,"""The rapid advancement and widespread use of large language models (LLMs) have raised significant concerns regarding the potential leakage of personally identifiable information (PII).""",2023-07-04T18:53:47Z
Learning to Prompt in the Classroom to Understand AI Limits: A pilot study,Yes.,5.,"""ignoring their limitations such as hallucinations and reasoning constraints"" and ""better grasp of limitations, specifically unreliability, limited understanding of commands leading to unsatisfactory responses, and limited presentation flexibility.""",2023-07-04T07:51:37Z
CARE-MI: Chinese Benchmark for Misinformation Evaluation in Maternity and Infant Care,Yes.,4.,"""they suffer from the misinformation problem by unintentionally generating factually false statements"" and ""current Chinese LLMs are far from perfect in the topic of maternity and infant care.""",2023-07-04T03:34:19Z
Shifting Attention to Relevance: Towards the Uncertainty Estimation of Large Language Models,Yes.,5.,"""a persistent challenge lies in their susceptibility to 'hallucinations', which erodes trust in their outputs"" and ""existing methodologies treat all tokens with equal importance when estimating uncertainty, disregarding these inherent generative inequalities.""",2023-07-03T22:17:16Z
Multilingual Language Models are not Multicultural: A Case Study in Emotion,Yes.,5.,"""Our results show that multilingual LMs do not successfully learn the culturally appropriate nuances of emotion and we highlight possible research directions towards correcting this.""",2023-07-03T21:54:28Z
Challenges in Domain-Specific Abstractive Summarization and How to Overcome them,Yes.,5.,"""This paper identifies three of those limitations as research problems in the context of abstractive text summarization",2023-07-03T12:26:44Z
Evaluating Shutdown Avoidance of Language Models in Textual Scenarios,Yes.,2.,"""we explore whether shutdown avoidance is merely a result of simple pattern matching between the dataset and the prompt or if it is a consistent behaviour across different environments and variations.""",2023-07-03T07:05:59Z
