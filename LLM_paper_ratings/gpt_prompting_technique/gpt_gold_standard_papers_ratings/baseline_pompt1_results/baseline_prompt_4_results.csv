Title,LMs,Limitations of LMs,Evidence
A Survey of using Large Language Models for Generating Infrastructure as Code,,,"""LLMs are large neural network-based models which have demonstrated significant language processing abilities and shown to be capable of following a range of instructions within a broad scope. Recently, they have also been adapted for code understanding and generation tasks successfully, which makes them a promising choice for the automatic generation of IaC configurations... Finally, we conclude by presenting the challenges in this area and highlighting the scope for future research."""
Injecting New Knowledge into Large Language Models via Supervised Fine-Tuning,,,"""However, adapting these models to incorporate new, out-of-domain knowledge remains a challenge, particularly for facts and events that occur after the model's knowledge cutoff date."""
"DataAgent: Evaluating Large Language Models' Ability to Answer Zero-Shot, Natural Language Queries",,,"""Our findings demonstrate great potential for leveraging Large Language Models for low-level, zero-shot data analysis."" (This indicates potential but does not explicitly discuss limitations.)"
On-the-fly Definition Augmentation of LLMs for Biomedical NER,,,"""Despite their general capabilities, LLMs still struggle on biomedical NER tasks, which are difficult due to the presence of specialized terminology and lack of training data."""
ITCMA: A Generative Agent Based on a Computational Consciousness Structure,,,"""Large Language Models (LLMs) still face challenges in tasks requiring understanding implicit instructions and applying common-sense knowledge. In such scenarios, LLMs may require multiple attempts to achieve human-level performance, potentially leading to inaccurate responses or inferences in practical environments, affecting their long-term consistency and behavior."""
Retrieval-Enhanced Knowledge Editing for Multi-Hop Question Answering in Language Models,,,"""Large Language Models (LLMs) have shown proficiency in question-answering tasks but often struggle to integrate real-time knowledge updates, leading to potentially outdated or inaccurate responses. This problem becomes even more challenging when dealing with multi-hop questions since they require LLMs to update and integrate multiple knowledge pieces relevant to the questions."""
Mixed Preference Optimization: Reinforcement Learning with Data Selection and Better Reference Model,,,"""LLMs can inherit harmful biases and produce outputs that are not aligned with human values."""
FACTOID: FACtual enTailment fOr hallucInation Detection,,,"""The widespread adoption of Large Language Models (LLMs) has facilitated numerous benefits. However, hallucination is a significant concern."" and ""This paper argues that conventional TE methods are inadequate for spotting hallucinations in content generated by LLMs."""
Dual Instruction Tuning with Large Language Models for Mathematical Reasoning,,,"""Despite the fine-tuned LLMs, challenges persist, such as incorrect, missing, and redundant steps in CoT generation leading to inaccuracies in answer predictions."""
Boosting Conversational Question Answering with Fine-Grained Retrieval-Augmentation and Self-Check,,,"""Retrieval-Augmented Generation (RAG) aims to generate more reliable and accurate responses, by augmenting large language models (LLMs) with the external vast and dynamic knowledge."""
Aligning Large Language Models for Enhancing Psychiatric Interviews through Symptom Delineation and Summarization,,,"""Recent advancements in Large Language Models (LLMs)..."", ""appropriately prompted LLMs can achieve high performance..."", ""demonstrates their potential effectiveness in aiding mental health practitioners."""
PropTest: Automatic Property Testing for Improved Visual Programming,,,"""This type of methods leverage Large Language Models (LLMs) to decompose a problem and generate the source code for an executable computer program."""
LARA: Linguistic-Adaptive Retrieval-Augmented LLMs for Multi-Turn Intent Classification,,,"""However, these studies focused on monolingual, single-turn classification tasks."" and ""Multi-turn intent classification is notably challenging due to the complexity and evolving nature of conversational contexts."""
CodeS: Natural Language to Code Repository via Multi-Layer Sketch,,,"""The impressive performance of large language models (LLMs) on code-related tasks has shown the potential of fully automated software development."""
"Synthesize Step-by-Step: Tools, Templates and LLMs as Data Generators for Reasoning-Based Chart VQA",,,"""Although strong in extractive questions, current chart visual question answering (chart VQA) models suffer on complex reasoning questions."""
ChatDBG: An AI-Powered Debugging Assistant,,,"""ChatDBG integrates large language models (LLMs) to significantly enhance the capabilities and user-friendliness of conventional debuggers."""
A Chain-of-Thought Prompting Approach with LLMs for Evaluating Students' Formative Assessment Responses in Science,,,"""A systematic analysis of our method's pros and cons sheds light on the potential for human-in-the-loop techniques to enhance automated grading for open-ended science assessments."""
Summing Up the Facts: Additive Mechanisms Behind Factual Recall in LLMs,,,"""We find that the mechanistic story behind factual recall is more complex than previously thought."""
CPSDBench: A Large Language Model Evaluation Benchmark and Baseline for Chinese Public Security Domain,,,"""Through the in-depth analysis and evaluation conducted in this research, we not only enhance our understanding of the performance strengths and limitations of existing models in addressing public security issues but also provide references for the future development of more accurate and customized LLM models targeted at applications in this field."""
GraphTranslator: Aligning Graph Model to Large Language Model for Open-ended Tasks,,,"""Although several methods applying LLMs to graphs have been proposed, they fail to simultaneously handle the pre-defined and open-ended tasks, with LLM as a node feature enhancer or as a standalone predictor."""
