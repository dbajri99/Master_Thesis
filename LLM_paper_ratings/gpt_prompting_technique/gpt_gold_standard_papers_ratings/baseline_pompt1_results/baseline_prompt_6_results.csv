Title,LMs,Limitations of LMs,Evidence
Meta-Reasoning: Semantics-Symbol Deconstruction for Large Language Models,Yes.,4.,"""However, existing methods mainly rely on syntactically mapping natural languages to complete formal languages like Python and SQL. Those methods require that reasoning tasks be convertible into programs, which cater to the computer execution mindset and deviate from human reasoning habits."""
Large Language Models are Effective Text Rankers with Pairwise Ranking Prompting,Yes.,4.,"""researchers have found it difficult to outperform fine-tuned baseline rankers on benchmark datasets"" and ""off-the-shelf LLMs do not fully understand these challenging ranking formulations."""
Preference Ranking Optimization for Human Alignment,Yes.,5.,"""Large language models (LLMs) often contain misleading content, emphasizing the need to align them with human values to ensure secure AI systems. Reinforcement learning from human feedback (RLHF) has been employed to achieve this alignment. However, it encompasses two main drawbacks: (1) RLHF exhibits complexity, instability, and sensitivity to hyperparameters in contrast to SFT. (2) Despite massive trial-and-error,"
"A Survey on Large Language Models: Applications, Challenges, Limitations, and Practical Usage",yes.,5.,"""This survey paper provides a comprehensive overview of LLMs, including their history, architecture, training methods, applications, and challenges... The paper then discusses the challenges associated with deploying LLMs in real-world scenarios, including ethical considerations, model biases, interpretability, and computational resource requirements... Finally, the paper concludes by highlighting the future of LLM research and the challenges that need to be addressed in order to make"
Concept-Oriented Deep Learning with Large Language Models,Yes.,4.,"""Text-only LLMs, however, can represent only symbolic (conceptual) knowledge."""
Automatic Calibration and Error Correction for Generative Large Language Models via Pareto Optimal Self-Supervision,Yes.,5.,"""Generative Large language models (LLMs) have demonstrated remarkable capabilities for a wide range of applications, but reducing ungrounded or erroneous responses remains a major growth area."" and ""there lack an effective method to calibrate the confidence level of LLM responses to indicate potential errors and facilitate human-in-the-loop verification."""
Taqyim: Evaluating Arabic NLP Tasks Using ChatGPT Models,Yes.,1.,"""Large language models (LLMs) have demonstrated impressive performance on various downstream tasks without requiring fine-tuning, including ChatGPT, a chat-based model built on top of LLMs such as GPT-3.5 and GPT-4."""
Large Language Model as Attributed Training Data Generator: A Tale of Diversity and Bias,Yes.,5.,"""they generally rely on simple class-conditional prompts, which may limit the diversity of the generated data and inherit systematic biases of LLM."" and ""synthetic datasets generated by simple prompts exhibit significant biases, such as regional bias."""
Large Language Models as Annotators: Enhancing Generalization of NLP Models at Minimal Cost,Yes.,2.,"""we study the use of large language models (LLMs) for annotating inputs and improving the generalization of NLP models."" and ""State-of-the-art supervised NLP models achieve high accuracy but are also susceptible to failures on inputs from low-data regimes, such as domains that are not represented in training data."""
ChatGPT Label: Comparing the Quality of Human-Generated and LLM-Generated Annotations in Low-resource Language NLP Tasks,Yes.,4.,"""The observed differences highlight LLM limitations in understanding context and addressing ambiguity."""
REFLECT: Summarizing Robot Experiences for Failure Explanation and Correction,yes.,1.,"""Recently, Large Language Models (LLMs) have demonstrated strong reasoning abilities on textual inputs."""
Exploring the Robustness of Large Language Models for Solving Programming Problems,yes.,4.,"""LLMs, such as Transformer-based models like Codex and ChatGPT, have been shown to be highly capable of solving a wide range of programming problems. However, the extent to which LLMs understand problem descriptions and generate programs accordingly or just retrieve source code from the most relevant problem in training data based on superficial cues has not been discovered yet. ... Our experimental results show that CodeGen and Codex are sensitive"
Language models are weak learners,Yes.,3.,"""prompt-based large language models can operate effectively as said weak learners"" and ""The results illustrate the potential for prompt-based LLMs to function not just as few-shot learners themselves, but as components of larger machine learning pipelines."""
Teaching Large Language Models to Self-Debug,Yes.,4.,"""Large language models (LLMs) have achieved impressive performance on code generation. However, for complex programming tasks, generating the correct solution in one go becomes challenging, thus some prior works have designed program repair approaches to improve code generation performance."""
Towards an Understanding and Explanation for Mixed-Initiative Artificial Scientific Text Detection,Yes.,4.,"""Their potential misuse has raised social concerns about plagiarism in academic contexts. However, effective artificial scientific text detection is a non-trivial task due to several challenges, including 1) the lack of a clear understanding of the differences between machine-generated and human-written scientific text, 2) the poor generalization performance of existing methods caused by out-of-distribution issues, and 3) the limited support for human-machine collaboration"
On the Possibilities of AI-Generated Text Detection,yes.,2.,"""as machine-generated text approximates human-like quality, the sample size needed for detection increases."""
Learnings from Data Integration for Augmented Language Models,yes.,5.,"""One of the limitations of large language models is that they do not have access to up-to-date, proprietary or personal data."""
Graph-ToolFormer: To Empower LLMs with Graph Reasoning Ability via Prompt Augmented by ChatGPT,Yes.,5.,"""Currently, LLMs have achieved very impressive performance on various natural language learning tasks, extensions of which have also been applied to study the vision tasks with multi-modal data. However, when it comes to the graph learning tasks, existing LLMs present very serious flaws due to their several inherited weaknesses in performing {multi-step logic reasoning}, {precise mathematical calculation} and {perception about the spatial and temporal factors"
Towards Generating Functionally Correct Code Edits from Natural Language Issue Descriptions,Yes.,4.,"""However, there is currently a lack of benchmark datasets for assessing the ability of LLMs to generate functionally correct code edits based on natural language descriptions of intended changes."""
Revisiting Automated Prompting: Are We Actually Doing Better?,yes.,3.,"""We find that automated prompting does not consistently outperform simple manual prompts."""
