Title,Talks about LLMs,Rate,Evidence
Large Language Models Enable Few-Shot Clustering,Yes.,1.,"The abstract discusses the effectiveness of LLMs in improving clustering and their incorporation into various stages of the clustering process, but it does not mention any limitations of LLMs."
JustiLM: Few-shot Justification Generation for Explainable Fact-Checking of Real-world Claims,Yes.,1.,"The abstract focuses on the development and performance of JustiLM for justification generation in fact-checking, with no mention of limitations of LLMs."
To Diverge or Not to Diverge: A Morphosyntactic Perspective on Machine Translation vs Human Translation,No.,1.,"The abstract discusses machine translations (MTs) and human translations (HTs) through the lens of morphosyntactic divergence, comparing their performance and decoding algorithms. It does not mention large language models (LLMs) or their limitations."
What Do Self-Supervised Speech Models Know About Words?,No.,1.,"The abstract discusses self-supervised speech models (S3Ms) and their performance on various speech tasks, but it does not mention large language models (LLMs) or their limitations."
Are Character-level Translations Worth the Wait? Comparing ByT5 and mT5 for Machine Translation,Yes.,1.,"""Pretrained character-level and byte-level language models have been shown to be competitive with popular subword models across a range of Natural Language Processing tasks."" The abstract does not mention any limitations of LLMs."
Geographic Adaptation of Pretrained Language Models,Yes.,1.,"""While pretrained language models (PLMs) have been shown to possess a plethora of linguistic knowledge, the existing body of research has largely neglected extralinguistic knowledge, which is generally difficult to obtain by pretraining on text alone."""
Do Text Simplification Systems Preserve Meaning? A Human Evaluation via Reading Comprehension,No.,1.,The abstract discusses automatic text simplification (TS) and its evaluation protocols without mentioning large language models (LLMs) or their limitations.
Text-to-OverpassQL: A Natural Language Interface for Complex Geodata Querying of OpenStreetMap,Yes.,1.,"""enables tool-augmented large language models to access information stored in the OSM database"" and ""We establish strong baselines by finetuning sequence-to-sequence models and adapting large language models with in-context examples."""
Eliciting the Translation Ability of Large Language Models via Multilingual Finetuning with Translation Instructions,Yes.,1.,"""Firstly, we show that multilingual LLMs have stronger translation abilities than previously demonstrated. For a certain language, the translation performance depends on its similarity to English and the amount of data used in the pretraining phase."""
Semantics of Multiword Expressions in Transformer-Based Models: A Survey,Yes.,4.,"""We overall find that they capture MWE semantics inconsistently, as shown by reliance on surface patterns and memorized information."" and ""Our findings overall question the ability of transformer models to robustly capture fine-grained semantics."""
Extracting Social Determinants of Health from Pediatric Patient Notes Using Large Language Models: Novel Corpus and Methods,Yes.,1.,"The abstract focuses on the application and performance of LLMs in extracting social determinants of health from pediatric patient notes but does not discuss any limitations of the LLMs. The emphasis is on the novel corpus and the evaluation of extraction methods using LLMs, without mentioning their shortcomings."
Fairness in Large Language Models: A Taxonomic Survey,Yes.,4.,"""most of these algorithms lack fairness considerations. Consequently, they may lead to discriminatory outcomes against certain communities, particularly marginalized populations,"" and ""an analysis of factors contributing to bias in LLMs. Additionally, the concept of fairness in LLMs is discussed categorically, summarizing metrics for evaluating bias in LLMs and existing algorithms for promoting fairness. Furthermore, resources for evaluating bias"
Algorithmic Collusion by Large Language Models,Yes.,2.,"""Our findings underscore the need for antitrust regulation regarding algorithmic pricing, and uncover regulatory challenges unique to LLM-based pricing agents."""
Recover: A Neuro-Symbolic Framework for Failure Detection and Recovery,,,
Can Language Models Recognize Convincing Arguments?,Yes.,1.,"""The remarkable and ever-increasing capabilities of Large Language Models (LLMs) have raised concerns about their potential misuse for creating personalized, convincing misinformation and propaganda."""
WavLLM: Towards Robust and Adaptive Speech Large Language Model,Yes.,2.,"""However, effectively integrating listening capabilities into LLMs poses significant challenges, particularly with respect to generalizing across varied contexts and executing complex auditory tasks."""
RQ-RAG: Learning to Refine Queries for Retrieval Augmented Generation,Yes.,4.,"""Large Language Models (LLMs) exhibit remarkable capabilities but are prone to generating inaccurate or hallucinatory responses. This limitation stems from their reliance on vast pretraining datasets, making them susceptible to errors in unseen scenarios."""
CHOPS: CHat with custOmer Profile Systems for Customer Service with LLMs,Yes.,3.,"""current LLM-based customer service models have limited integration with customer profiles and lack the operational capabilities necessary for effective service. Moreover, existing API integrations emphasize diversity over the precision and error avoidance essential in real-world customer service scenarios."""
NumeroLogic: Number Encoding for Enhanced LLMs' Numerical Reasoning,Yes.,4.,"""Language models struggle with handling numerical data and performing arithmetic operations. We hypothesize that this limitation can be partially attributed to non-intuitive textual numbers representation."" This indicates a significant limitation in LLMs' ability to process numerical data, which is a primary focus of the paper."
Can LLMs Master Math? Investigating Large Language Models on Math Stack Exchange,Yes.,4.,"""This paper explores the current limitations of LLMs in navigating complex mathematical problem-solving. Through case analysis, we shed light on the gaps in LLM capabilities within mathematics, thereby setting the stage for future research and advancements in AI-driven mathematical reasoning."""
Augmenting NER Datasets with LLMs: Towards Automated and Refined Annotation,Yes.,2.,"""Traditional methodologies for annotating datasets for NER models are challenged by high costs and variations in dataset quality."" and ""by employing a label mixing strategy, it addresses the issue of class imbalance encountered in LLM-based annotations."""
ST-LLM: Large Language Models Are Effective Temporal Learners,Yes.,2.,"""to address the overhead and stability issues introduced by uncompressed video tokens within LLMs"" and ""we have also designed a global-local input module to balance efficiency and effectiveness."""
