Title,Talks about LLMs,Rate,Evidence
Using Large Language Models to Automate and Expedite Reinforcement Learning with Reward Machine,Yes.,1.,"""Our method uses Large Language Models (LLM) to obtain high-level domain-specific knowledge using prompt engineering instead of providing the reinforcement learning algorithm directly with the high-level knowledge which requires an expert to encode the automaton."""
Evolutionary Computation in the Era of Large Language Model: Survey and Roadmap,Yes.,1.,The abstract primarily discusses the interplay between LLMs and Evolutionary Algorithms (EAs) and their combined potential in various domains. It does not explicitly mention any limitations of LLMs. The focus is on the complementary advantages and collaborative potential of LLMs and EAs.
Large Language Models Are Neurosymbolic Reasoners,Yes.,1.,"""This paper investigates the potential application of Large Language Models (LLMs) as symbolic reasoners."" The abstract focuses on the application and enhancement of LLMs for symbolic reasoning tasks in text-based games without mentioning any limitations."
LLMs for Relational Reasoning: How Far are We?,Yes.,4.,"""it is hard to conclude that the LLMs possess strong reasoning ability by merely achieving positive results on these benchmarks"" and ""Recent efforts have demonstrated that the LLMs are poor at solving sequential decision-making problems that require common-sense planning"" and ""Our evaluations illustrate that compared with the neural program induction systems which are much smaller in model size, the state-of-the-art L"
Large Language Models in Plant Biology,Yes.,1.,"""This review outlines the different types of LLMs and showcases their recent uses in biology. Since LLMs have not yet been embraced by the plant community, we also cover how these models can be deployed for the plant kingdom."""
From LLM to Conversational Agent: A Memory Enhanced Architecture with Fine-Tuning of Large Language Models,Yes.,1.,"""This approach appears to enhance agent controllability and adaptability in complex, multi-turn dialogues. Our preliminary evaluations in a real estate sales context suggest that RAISE has some advantages over traditional agents, indicating its potential for broader applications."""
GeoGalactica: A Scientific Large Language Model in Geoscience,Yes.,1.,"The abstract primarily discusses the development and specialization of a large language model (GeoGalactica) for the geoscience domain, including pre-training and fine-tuning processes. It does not mention any limitations of LLMs."
Large Language Models for Generative Information Extraction: A Survey,Yes.,1.,"The abstract primarily focuses on the capabilities and advancements of LLMs in information extraction tasks. It discusses how LLMs have been harnessed for IE tasks and offers a comprehensive review of recent advancements. However, it does not mention any limitations of LLMs."
Building Efficient Universal Classifiers with Natural Language Inference,Yes.,2.,"""Many users, however, do not need the broad capabilities of generative LLMs when they only want to automate a classification task. Smaller BERT-like models can also learn universal tasks, which allow them to do any text classification task without requiring fine-tuning (zeroshot classification) or to learn new tasks with only a few examples (fewshot), while being significantly more"
Large Language Models for Conducting Advanced Text Analytics Information Systems Research,,,
LLMs with User-defined Prompts as Generic Data Operators for Reliable Data Processing,Yes.,3.,"""we summarize the challenges and opportunities introduced by LLMs to provide a complete view of this design pattern for more discussions."""
Zero-Shot Cross-Lingual Reranking with Large Language Models for Low-Resource Languages,Yes.,2.,"""Despite their successful implementations, there is still a gap in existing literature on their effectiveness in low-resource languages."""
Comparative Analysis of Deep Natural Networks and Large Language Models for Aspect-Based Sentiment Analysis,Yes.,3.,"""the existing models for ABSA face three main challenges, including domain-specificity, reliance on labeled data, and a lack of exploration into the potential of newer large language models (LLMs) such as GPT, PaLM, and T5."" and ""Our findings reveal nuanced strengths and weaknesses of these models across different domains."""
LlaMaVAE: Guiding Large Language Model Generation via Continuous Latent Sentence Spaces,Yes.,1.,"""To combine the controllability of VAE latent spaces with the state-of-the-art performance of recent large language models (LLMs), we present in this work LlaMaVAE, which combines expressive encoder and decoder models (sentenceT5 and LlaMA) with a VAE architecture, aiming to provide better text generation control to LLMs."""
A Comparative Analysis of Large Language Models for Code Documentation Generation,Yes.,1.,The abstract discusses the performance of various LLMs in generating code documentation but does not mention any limitations of the models. It focuses on the comparative analysis and evaluation parameters without addressing any constraints or drawbacks of the LLMs.
TigerBot: An Open Multilingual Multitask LLM,Yes.,1.,"The abstract focuses on the introduction and performance of the TigerBot family of LLMs, emphasizing their development, performance gains, and contributions to the open-source community. It does not mention any limitations of LLMs."
Efficiently Programming Large Language Models using SGLang,Yes.,2.,"""However, efficient systems for programming and executing these applications are lacking."""
Large Language Models on Graphs: A Comprehensive Survey,Yes.,3.,"""While LLMs are mainly designed to process pure texts, there are many real-world scenarios where text data is associated with rich structure information in the form of graphs... although LLMs have shown their pure text-based reasoning ability, it is underexplored whether such ability can be generalized to graphs (i.e., graph-based reasoning)."""
Still No Lie Detector for Language Models: Probing Empirical and Conceptual Roadblocks,Yes.,4.,"""We provide empirical results that show that these methods fail to generalize in very basic ways,"" and ""we consider some recent arguments aiming to show that LLMs cannot have beliefs."" These statements indicate a detailed discussion on the limitations of LLMs, particularly in the context of evaluating their ""beliefs"" and the failure of existing methods to generalize."
SPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen LLMs,,,
