Title,Talks about LLMs,Rate,Evidence
Meta-Reasoning: Semantics-Symbol Deconstruction for Large Language Models,,,
Large Language Models are Effective Text Rankers with Pairwise Ranking Prompting,,,
Preference Ranking Optimization for Human Alignment,Yes.,4.,"""Large language models (LLMs) often contain misleading content, emphasizing the need to align them with human values to ensure secure AI systems. Reinforcement learning from human feedback (RLHF) has been employed to achieve this alignment. However, it encompasses two main drawbacks"
"A Survey on Large Language Models: Applications, Challenges, Limitations, and Practical Usage",Yes.,5.,"""The paper then discusses the challenges associated with deploying LLMs in real-world scenarios, including ethical considerations, model biases, interpretability, and computational resource requirements. It also highlights techniques for enhancing the robustness and controllability of LLMs and addressing bias, fairness, and generation quality issues."""
Concept-Oriented Deep Learning with Large Language Models,Yes.,3.,"""However, the prerequisite is that LLMs understand concepts and ensure conceptual consistency"" and ""Text-only LLMs, however, can represent only symbolic (conceptual) knowledge. Multimodal LLMs, on the other hand, are capable of representing the full range (conceptual and sensory) of human knowledge."""
Automatic Calibration and Error Correction for Generative Large Language Models via Pareto Optimal Self-Supervision,Yes.,4.,"""Generative Large language models (LLMs) have demonstrated remarkable capabilities for a wide range of applications, but reducing ungrounded or erroneous responses remains a major growth area."" and ""Unlike task-specific models, there lack an effective method to calibrate the confidence level of LLM responses to indicate potential errors and facilitate human-in-the-loop verification."""
Taqyim: Evaluating Arabic NLP Tasks Using ChatGPT Models,Yes.,1.,"""Large language models (LLMs) have demonstrated impressive performance on various downstream tasks without requiring fine-tuning, including"
Large Language Model as Attributed Training Data Generator: A Tale of Diversity and Bias,Yes.,4.,"""they generally rely on simple class-conditional prompts, which may limit the diversity of the generated data and inherit systematic biases of LLM"" and ""synthetic datasets generated by simple prompts exhibit significant biases, such as regional bias."""
Large Language Models as Annotators: Enhancing Generalization of NLP Models at Minimal Cost,,,
ChatGPT Label: Comparing the Quality of Human-Generated and LLM-Generated Annotations in Low-resource Language NLP Tasks,Yes.,3.,"""The observed differences highlight LLM limitations in understanding context and addressing ambiguity."""
REFLECT: Summarizing Robot Experiences for Failure Explanation and Correction,Yes.,1.,"""Recently, Large Language Models (LLMs) have demonstrated strong reasoning abilities on textual inputs. To leverage the power of LLMs for robot failure explanation, we introduce REFLECT, a framework which queries LLM for failure reasoning based on a hierarchical summary of robot past experiences generated from multisensory observations."""
Exploring the Robustness of Large Language Models for Solving Programming Problems,Yes.,3.,"""Our experimental results show that CodeGen and Codex are sensitive to the superficial modifications of problem descriptions and significantly impact code generation performance."" and ""This highlights the fact that slight modifications to the prompts given to the LLMs can greatly affect code generation performance, and careful formatting of prompts is essential for high-quality code generation."""
Language models are weak learners,Yes.,1.,The abstract primarily discusses the use of large language models (LLMs) as weak learners in a boosting algorithm and their effectiveness in this role. It does not mention any limitations or challenges associated with LLMs.
Teaching Large Language Models to Self-Debug,Yes.,3.,"""Large language models (LLMs) have achieved impressive performance on code generation. However, for complex programming tasks, generating the correct solution in one go becomes challenging, thus some prior works have designed program repair approaches to improve code generation performance."""
Towards an Understanding and Explanation for Mixed-Initiative Artificial Scientific Text Detection,Yes.,3.,"""Their potential misuse has raised social concerns about plagiarism in academic contexts"" and ""effective artificial scientific text detection is a non-trivial task due to several challenges, including 1) the lack of a clear understanding of the differences between machine-generated and human-written scientific text, 2) the poor generalization performance of existing methods caused by out-of-distribution issues, and 3)"
On the Possibilities of AI-Generated Text Detection,,,
Learnings from Data Integration for Augmented Language Models,Yes.,4.,"""One of the limitations of large language models is that they do not have access to up-to-date, proprietary or personal data."""
Graph-ToolFormer: To Empower LLMs with Graph Reasoning Ability via Prompt Augmented by ChatGPT,Yes.,4.,"""existing LLMs present very serious flaws due to their several inherited weaknesses in performing {multi-step logic reasoning}, {precise mathematical calculation} and {perception about the spatial and temporal factors}."""
Towards Generating Functionally Correct Code Edits from Natural Language Issue Descriptions,Yes.,2.,"""Results show that these LLMS together are capable of generating plausible fixes for 64.6% of the bugs, and the best LLM-based technique can achieve up to 21.20% top-1 and 35.68% top-5 accuracy on this benchmark."" This indicates some limitations in the accuracy and performance of LLMs, but it is mentioned as a"
Revisiting Automated Prompting: Are We Actually Doing Better?,Yes.,2.,"""We find that automated prompting does not consistently outperform simple manual prompts. Our work suggests that, in addition to fine-tuning, manual prompts should be used as a baseline in this line of research."""
