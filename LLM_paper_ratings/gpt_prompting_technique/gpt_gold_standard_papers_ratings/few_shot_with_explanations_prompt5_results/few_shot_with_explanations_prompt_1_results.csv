Title,Talks about LLMs,Rate,Evidence
Evaluating Modular Dialogue System for Form Filling Using Large Language Models,Yes.,2.,"""We show that using multiple independent sub-modules working cooperatively on this task can improve performance and handle the typical constraints of using LLMs, such as context limitations."""
Improving Cross-Domain Low-Resource Text Generation through LLM Post-Editing: A Programmer-Interpreter Approach,Yes.,3.,"""However, relying solely on smaller language models for post-editing can limit the LLMs' ability to generalize across domains."" and ""the editing strategies in these methods are not optimally designed for text generation tasks."""
Re3val: Reinforced and Reranked Generative Retrieval,,,
Reward Engineering for Generating Semi-structured Explanation,Yes.,4.,"""Despite the recent improvements in generative capabilities of language models, producing structured explanations to verify a model's true reasoning capabilities remains a challenge. This issue is particularly pronounced for not-so-large LMs (e.g., FLAN-T5-XXL). In this work, we first underscore the limitations of supervised fine-tuning (SFT) in tackling this challenge."""
Are Large Language Model-based Evaluators the Solution to Scaling Up Multilingual Evaluation?,Yes.,4.,"""yet their evaluation, particularly in languages beyond the top 20, remains inadequate due to existing benchmarks and metrics limitations"" and ""Our analysis reveals a bias in LLM-based evaluators towards higher scores, underscoring the necessity of calibration with native speaker judgments, especially in low-resource and non-Latin script languages, to ensure accurate evaluation of LLM performance across diverse languages."""
Why Generate When You Can Discriminate? A Novel Technique for Text Classification using Language Models,Yes.,2.,"""Our approach stands out by eliminating the need for parameter updates in LMs, as required in fine-tuning, and does not impose limitations on the number of training examples faced while building prompts for in-context learning."""
Evaluating Large Language Models Trained on Code,Yes.,4.,"""Careful investigation of our model reveals its limitations, including difficulty with docstrings describing long chains of operations and with binding operations to variables. Finally, we discuss the potential broader impacts of deploying powerful code generation technologies, covering safety, security, and economics."""
Fine-tuning CLIP Text Encoders with Two-step Paraphrasing,Yes.,3.,"""current models still face limitations in dealing with linguistic variations in input queries, such as paraphrases, making it challenging to handle a broad range of user queries in real-world applications."""
ICE-Score: Instructing Large Language Models to Evaluate Code,Yes.,4.,"""Although these models have shown promising results in tasks such as machine translation and summarization, their applicability in code intelligence tasks remains limited without human involvement. The complexity of programming concepts required for such tasks makes it difficult to develop evaluation metrics that align with human judgment. Token-matching-based metrics, such as BLEU, have demonstrated weak correlations with human practitioners in code intelligence tasks. Moreover,"
Transformer-specific Interpretability,Yes.,4.,"""we will present Transformer-specific interpretability methods, a new trending approach, that make use of specific features of the Transformer architecture and are deemed more promising for understanding Transformer-based models. We start by discussing the potential pitfalls and misleading results model-agnostic approaches may produce when interpreting Transformers."""
Can docstring reformulation with an LLM improve code generation?,Yes.,4.,"""Our results show that, when operating on docstrings reformulated by an LLM instead of the original (or worsened) inputs, the performance of a number of open-source LLMs does not change significantly. This finding demonstrates an unexpected robustness of current open-source LLMs to the details of the docstrings. We conclude by examining a series of questions, accompanied by in"
Equipping Language Models with Tool Use Capability for Tabular Data Analysis in Finance,Yes.,4.,"""Large language models (LLMs) have exhibited an array of reasoning capabilities but face challenges like error propagation and hallucination, particularly in specialised areas like finance, where data is heterogeneous, and precision is paramount."""
Generation-driven Contrastive Self-training for Zero-shot Text Classification with Instruction-following LLM,Yes.,3.,"""employing LLMs for large-scale inference or domain-specific fine-tuning requires immense computational resources due to their substantial model size."""
Document-Level Language Models for Machine Translation,Yes.,2.,"""Despite the known limitations, most machine translation systems today still operate on the sentence-level."" and ""However, we also find that in most scenarios, back-translation gives even better results, at the cost of having to re-train the translation system."""
ChatGPT MT: Competitive for High- (but Not Low-) Resource Languages,Yes.,5.,"""GPT models approach or exceed traditional MT model performance for some high-resource languages (HRLs) but consistently lag for low-resource languages (LRLs), under-performing traditional MT for 84.1% of languages we covered."" and ""ChatGPT is especially disadvantaged for LRLs and African languages."""
"Large Language Models Effectively Leverage Document-level Context for Literary Translation, but Critical Errors Persist",Yes.,4.,"""critical errors still abound, including occasional content omissions, and a human translator's intervention remains necessary to ensure that the author's voice remains intact."""
"Machine Translation with Large Language Models: Prompting, Few-shot Learning, and Fine-tuning with QLoRA",Yes.,1.,"""While large language models have made remarkable advancements in natural language generation, their potential in machine translation, especially when fine-tuned, remains under-explored."""
