Title,Talks about LLMs,Rate,Evidence
Using Large Language Models to Automate and Expedite Reinforcement Learning with Reward Machine,Yes.,1.,The abstract discusses the use of Large Language Models (LLMs) to automate and expedite reinforcement learning but does not mention any limitations of LLMs. It focuses on how LLMs are used to obtain high-level domain-specific knowledge and improve the efficiency of reinforcement learning. There is no discussion of the limitations or challenges associated with using LLMs.
Evolutionary Computation in the Era of Large Language Model: Survey and Roadmap,Yes.,1.,"The abstract does not mention any limitations of LLMs. It focuses on the complementary advantages and collaborative potential of LLMs and Evolutionary Algorithms (EAs), without discussing any drawbacks or limitations of LLMs."
Large Language Models Are Neurosymbolic Reasoners,Yes.,1.,"The abstract discusses the application of Large Language Models (LLMs) as symbolic reasoners and their performance in text-based games. However, it does not mention any limitations of LLMs. The focus is on the capabilities and enhancements in symbolic reasoning tasks, with no discussion of the drawbacks or limitations of LLMs."
LLMs for Relational Reasoning: How Far are We?,Yes.,5.,"""Recent efforts have demonstrated that the LLMs are poor at solving sequential decision-making problems that require common-sense planning by evaluating their performance on the reinforcement learning benchmarks."" and ""Our evaluations illustrate that compared with the neural program induction systems which are much smaller in model size, the state-of-the-art LLMs are much poorer in terms of reasoning ability by achieving much lower performance and"
Large Language Models in Plant Biology,Yes.,1.,"""This review outlines the different types of LLMs and showcases their recent uses in biology. Since LLMs have not yet been embraced by the plant community, we also cover how these models can be deployed for the plant kingdom."""
From LLM to Conversational Agent: A Memory Enhanced Architecture with Fine-Tuning of Large Language Models,Yes.,1.,"The abstract discusses the integration of Large Language Models (LLMs) like GPT-4 into conversational agents and introduces a new architecture, but it does not mention any limitations of LLMs. The focus is on the enhancements and potential advantages of the proposed system rather than the limitations of the LLMs themselves."
GeoGalactica: A Scientific Large Language Model in Geoscience,Yes.,1.,"""Large language models (LLMs) have achieved huge success for their general knowledge and ability to solve a wide spectrum of tasks in natural language processing (NLP). Due to their impressive abilities, LLMs have shed light on potential inter-discipline applications to foster scientific discoveries of a specific domain by using artificial intelligence (AI for science, AI4S)."""
Large Language Models for Generative Information Extraction: A Survey,Yes.,1.,"The abstract discusses the capabilities and advancements of generative Large Language Models (LLMs) in the context of information extraction. However, it does not mention any limitations of LLMs. The focus is on the remarkable capabilities, generalization, and promising research directions, without addressing any specific limitations."
Building Efficient Universal Classifiers with Natural Language Inference,Yes.,3.,"""Generative Large Language Models (LLMs) have become the mainstream choice for fewshot and zeroshot learning thanks to the universality of text generation. Many users, however, do not need the broad capabilities of generative LLMs when they only want to automate a classification task. Smaller BERT-like models can also learn universal tasks, which allow them to do any text"
Large Language Models for Conducting Advanced Text Analytics Information Systems Research,Yes.,3.,"""We also outline potential challenges and limitations in adopting LLMs for IS."""
LLMs with User-defined Prompts as Generic Data Operators for Reliable Data Processing,Yes.,3.,"""Furthermore, we summarize the challenges and opportunities introduced by LLMs to provide a complete view of this design pattern for more discussions."""
Zero-Shot Cross-Lingual Reranking with Large Language Models for Low-Resource Languages,yes.,3.,"""Despite their successful implementations, there is still a gap in existing literature on their effectiveness in low-resource languages."" and ""While reranking remains most effective in English, our results reveal that cross-lingual reranking may be competitive with reranking in African languages depending on the multilingual capability of the LLM."""
Comparative Analysis of Deep Natural Networks and Large Language Models for Aspect-Based Sentiment Analysis,Yes.,2.,"""the existing models for ABSA face three main challenges, including domain-specificity, reliance on labeled data, and a lack of exploration into the potential of newer large language models (LLMs) such as GPT, PaLM, and T5."""
LlaMaVAE: Guiding Large Language Model Generation via Continuous Latent Sentence Spaces,Yes.,1.,"""To combine the controllability of VAE latent spaces with the state-of-the-art performance of recent large language models (LLMs), we present in this work LlaMaVAE, which combines expressive encoder and decoder models (sentenceT5 and LlaMA) with a VAE architecture, aiming to provide better text generation control to LLMs."""
A Comparative Analysis of Large Language Models for Code Documentation Generation,Yes.,2.,"The abstract mentions that ""GPT-4 demonstrated the longest duration"" and ""file level documentation had a considerably worse performance across all parameters (except for time taken) as compared to inline and function level documentation."" These points indicate some limitations, but they are secondary to the main focus of the paper, which is the comparative performance analysis of the LLMs."
TigerBot: An Open Multilingual Multitask LLM,Yes.,1.,"The abstract focuses on the introduction and performance of the TigerBot family of large language models, detailing their size, development, performance gains, and contributions to the open-source community. It does not mention any limitations of LLMs."
Efficiently Programming Large Language Models using SGLang,Yes.,2.,"While the abstract mentions some limitations of LLMs, such as the lack of efficient systems for programming and executing complex tasks, these points are secondary to the main focus of introducing SGLang. The limitations are not discussed in detail or with strong wording. The primary emphasis is on the proposed solution and its benefits."
Large Language Models on Graphs: A Comprehensive Survey,Yes.,3.,"""While LLMs are mainly designed to process pure texts, there are many real-world scenarios where text data is associated with rich structure information in the form of graphs... it is underexplored whether such ability can be generalized to graphs (i.e., graph-based reasoning)."" The paper mentions the limitations of LLMs in the context of their ability to handle graph-based data and reasoning"
Still No Lie Detector for Language Models: Probing Empirical and Conceptual Roadblocks,Yes.,5.,"""We provide empirical results that show that these methods fail to generalize in very basic ways. We then argue that, even if LLMs have beliefs, these methods are unlikely to be successful for conceptual reasons. Thus, there is still no lie-detector for LLMs... We consider some recent arguments aiming to show that LLMs cannot have beliefs. We show that these"
SPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen LLMs,Yes.,1.,The abstract primarily focuses on the introduction and capabilities of the Semantic Pyramid AutoEncoder (SPAE) and its ability to enable frozen LLMs to handle multimodal tasks. It does not discuss any limitations of LLMs.
