Title,Talks about LLMs,Rate,Evidence
Meta-Reasoning: Semantics-Symbol Deconstruction for Large Language Models,Yes.,3.,"""However, existing methods mainly rely on syntactically mapping natural languages to complete formal languages like Python and SQL. Those methods require that reasoning tasks be convertible into programs, which cater to the computer execution mindset and deviate from human reasoning habits."""
Large Language Models are Effective Text Rankers with Pairwise Ranking Prompting,Yes.,4.,"""However, researchers have found it difficult to outperform fine-tuned baseline rankers on benchmark datasets. We analyze pointwise and listwise ranking prompts used by existing methods and argue that off-the-shelf LLMs do not fully understand these challenging ranking formulations."""
Preference Ranking Optimization for Human Alignment,Yes.,4.,"""Large language models (LLMs) often contain misleading content, emphasizing the need to align them with human values to ensure secure AI systems. Reinforcement learning from human feedback (RLHF) has been employed to achieve this alignment. However, it encompasses two main drawbacks"
"A Survey on Large Language Models: Applications, Challenges, Limitations, and Practical Usage",Yes.,5.,"""The paper then discusses the challenges associated with deploying LLMs in real-world scenarios, including ethical considerations, model biases, interpretability, and computational resource requirements. It also highlights techniques for enhancing the robustness and controllability of LLMs and addressing bias, fairness, and generation quality issues."""
Concept-Oriented Deep Learning with Large Language Models,yes.,4.,"""Text-only LLMs, however, can represent only symbolic (conceptual) knowledge. Multimodal LLMs, on the other hand, are capable of representing the full range (conceptual and sensory) of human knowledge. We discuss conceptual understanding in visual-language LLMs, the most important multimodal LLMs, and major uses of them for CODL including"
Automatic Calibration and Error Correction for Generative Large Language Models via Pareto Optimal Self-Supervision,Yes.,4.,"""Generative Large language models (LLMs) have demonstrated remarkable capabilities for a wide range of applications, but reducing ungrounded or erroneous responses remains a major growth area. Unlike task-specific models, there lack an effective method to calibrate the confidence level of LLM responses to indicate potential errors and facilitate human-in-the-loop verification. An important source of calibration stems from expert-stip"
Taqyim: Evaluating Arabic NLP Tasks Using ChatGPT Models,Yes.,1.,"The abstract discusses the performance of LLMs like GPT-3.5 and GPT-4 on various Arabic NLP tasks and highlights their capabilities and achievements. However, it does not mention any limitations of these models."
Large Language Model as Attributed Training Data Generator: A Tale of Diversity and Bias,Yes.,4.,"""While previous research has explored different approaches to training models using generated data, they generally rely on simple class-conditional prompts, which may limit the diversity of the generated data and inherit systematic biases of LLM... Additionally, we present a comprehensive empirical study on data generation encompassing vital aspects like bias, diversity, and efficiency, and highlight three key observations"
Large Language Models as Annotators: Enhancing Generalization of NLP Models at Minimal Cost,Yes.,2.,"""State-of-the-art supervised NLP models achieve high accuracy but are also susceptible to failures on inputs from low-data regimes, such as domains that are not represented in training data."" This indicates a limitation but is mentioned as a secondary point. The primary focus is on using LLMs for annotating inputs to improve generalization."
ChatGPT Label: Comparing the Quality of Human-Generated and LLM-Generated Annotations in Low-resource Language NLP Tasks,Yes.,3.,"""The observed differences highlight LLM limitations in understanding context and addressing ambiguity. This research contributes to the ongoing discourse on annotation sources in Turkish, Indonesian, and Minangkabau NLP, emphasizing the importance of judicious selection between human and LLM-generated annotations. It also underscores the necessity for continued advancements in LLM capabilities, as they continue to reshape the landscape of data annotation in NLP"
REFLECT: Summarizing Robot Experiences for Failure Explanation and Correction,Yes.,1.,"""Recently, Large Language Models (LLMs) have demonstrated strong reasoning abilities on textual inputs. To leverage the power of LLMs for robot failure explanation, we introduce REFLECT, a framework which queries LLM for failure reasoning based on a hierarchical summary of robot past experiences generated from multisensory observations. The failure explanation can further guide a language-based planner to correct the failure and"
Exploring the Robustness of Large Language Models for Solving Programming Problems,Yes.,4.,"""However, the extent to which LLMs understand problem descriptions and generate programs accordingly or just retrieve source code from the most relevant problem in training data based on superficial cues has not been discovered yet... Our experimental results show that CodeGen and Codex are sensitive to the superficial modifications of problem descriptions and significantly impact code generation performance... This highlights the fact that slight modifications to the prompts given"
Language models are weak learners,Yes.,1.,The abstract discusses the use of large language models (LLMs) as weak learners in boosting algorithms and highlights their potential and performance in this context. It does not address any limitations of LLMs. The primary focus is on the positive aspects and applications of LLMs in machine learning pipelines.
Teaching Large Language Models to Self-Debug,Yes.,4.,"""Large language models (LLMs) have achieved impressive performance on code generation. However, for complex programming tasks, generating the correct solution in one go becomes challenging, thus some prior works have designed program repair approaches to improve code generation performance."""
Towards an Understanding and Explanation for Mixed-Initiative Artificial Scientific Text Detection,yes.,4.,"""Large language models (LLMs) have gained popularity in various fields for their exceptional capability of generating human-like text. Their potential misuse has raised social concerns about plagiarism in academic contexts. However, effective artificial scientific text detection is a non-trivial task due to several challenges, including 1) the lack of a clear understanding of the differences between machine-generated and human-written scientific text,"
On the Possibilities of AI-Generated Text Detection,Yes.,2.,"The abstract mentions the challenge of distinguishing AI-generated text from human-produced text, which can be considered a limitation of LLMs, but this is not the primary focus. The primary focus is on the detection methods and their efficacy. The abstract does not go into detailed discussion about the limitations of LLMs themselves."
Learnings from Data Integration for Augmented Language Models,Yes.,4.,"""One of the limitations of large language models is that they do not have access to up-to-date, proprietary or personal data."""
Graph-ToolFormer: To Empower LLMs with Graph Reasoning Ability via Prompt Augmented by ChatGPT,Yes.,5.,"""Currently, LLMs have achieved very impressive performance on various natural language learning tasks, extensions of which have also been applied to study the vision tasks with multi-modal data. However, when it comes to the graph learning tasks, existing LLMs present very serious flaws due to their several inherited weaknesses in performing {multi-step logic reasoning}, {precise mathematical calculation} and {per"
Towards Generating Functionally Correct Code Edits from Natural Language Issue Descriptions,Yes.,2.,"The abstract mentions that ""there is currently a lack of benchmark datasets for assessing the ability of LLMs to generate functionally correct code edits"" and provides empirical evaluation results, highlighting that even the best LLM-based technique achieves only 21.20% top-1 accuracy. However, the discussion of limitations is not the primary focus and is mentioned more in passing."
Revisiting Automated Prompting: Are We Actually Doing Better?,Yes.,3.,"""We find that automated prompting does not consistently outperform simple manual prompts. Our work suggests that, in addition to fine-tuning, manual prompts should be used as a baseline in this line of research."""
