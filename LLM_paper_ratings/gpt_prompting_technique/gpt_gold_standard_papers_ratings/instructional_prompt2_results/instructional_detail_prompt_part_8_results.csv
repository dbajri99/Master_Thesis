Title,Talks about LLMs,Rate,Evidence
Generative Spoken Dialogue Language Modeling,Yes.,1.,The abstract introduces a new model for generating spoken dialogues and compares its performance to a text-based model but does not discuss any limitations or challenges of language models.
Discontinuous Combinatory Constituency Parsing,no.,1.,"The abstract focuses on combinatory constituency parsing, constituent vectors, and parsing models. There is no mention of language models or their limitations."
Efficient Long-Text Understanding with Short-Text Models,Yes.,4.,"""Transformer-based pretrained language models (LMs) are ubiquitous across natural language understanding, but cannot be applied to long sequences such as stories, scientific articles, and long documents due to their quadratic complexity."" This sentence highlights a significant limitation of LLMs related to their inefficiency with long-text sequences. The abstract also discusses the proposed solution and evaluation, but the limitation is a primary focus"
Hate Speech Classifiers Learn Normative Social Stereotypes,No.,1.,"The abstract focuses on the impact of social stereotypes on hate speech classifiers, annotation behaviors, and annotated datasets. It does not mention language models (LMs or LLMs) or their limitations."
Domain-Specific Word Embeddings with Structure Prediction,no.,1.,The abstract and title focus on domain-specific word embeddings and structure prediction. There is no mention of language models (LMs or LLMs) or their limitations.
Why Does Surprisal From Larger Transformer-Based Language Models Provide a Poorer Fit to Human Reading Times?,Yes.,5.,"""This work presents a linguistic analysis into why larger Transformer-based pre-trained language models with more parameters and lower perplexity nonetheless yield surprisal estimates that are less predictive of human reading times...These results suggest that the propensity of larger Transformer-based models to ‘memorize’ sequences during training makes their surprisal estimates diverge from humanlike expectations, which warrants caution in using pre-trained language models"
On the Robustness of Dialogue History Representation in Conversational Question Answering: A Comprehensive Study and a New Prompt-based Method,Yes.,3.,"""While existing models show impressive results on CQA leaderboards, it remains unclear whether they are robust to shifts in setting (sometimes to more realistic ones), training data size (e.g., from large to small sets) and domain. We find that high benchmark scores do not necessarily translate to strong robustness, and that various methods can perform extremely differently under different settings."""
Bridging the Gap between Synthetic and Natural Questions via Sentence Decomposition for Semantic Parsing,No.,1.,"The abstract discusses semantic parsing, data synthesis, and sentence decomposition to improve generalization to natural questions. It does not mention language models (LMs or LLMs) or their limitations."
Naturalistic Causal Probing for Morpho-Syntax,yes.,2.,"""there is still a lack of understanding of the limitations and weaknesses of various types of probes."""
Tracking Brand-Associated Polarity-Bearing Topics in User Reviews,No.,1.,The abstract and title do not mention language models (LMs or LLMs) or their limitations. The focus is on a dynamic Brand-Topic Model (dBTM) for tracking brand-associated sentiment and topics in user reviews.
Dubbing in Practice: A Large Scale Study of Human Localization With Insights for Automatic Dubbing,no.,1.,"The abstract and title focus on human and automatic dubbing processes, vocal naturalness, translation quality, and constraints like isometric and isochronic. There is no mention of language models (LMs or LLMs) or their limitations."
Aggretriever: A Simple Approach to Aggregate Textual Representations for Robust Dense Passage Retrieval,Yes.,4.,"""Pre-trained language models have been successful in many knowledge-intensive NLP tasks. However, recent work has shown that models such as BERT are not 'structurally ready' to aggregate textual information into a [CLS] vector for dense passage retrieval (DPR). This 'lack of readiness' results from the gap between language model pre-training and DPR fine-tuning. Previous solutions call"
InSCIt: Information-Seeking Conversations with Mixed-Initiative Interactions,No.,1.,The abstract does not mention language models (LMs or LLMs) or discuss their limitations. It focuses on a dataset for information-seeking conversations and the performance of systems in this context.
Sub-Character Tokenization for Chinese Pretrained Language Models,Yes.,2.,"""Existing tokenization methods for Chinese PLMs typically treat each character as an indivisible token. However, they ignore the unique feature of the Chinese writing system where additional linguistic information exists below the character level, i.e., at the sub-character level."""
Erasure of Unaligned Attributes from Neural Representations,no.,1.,The abstract and title focus on the AMSAL algorithm for erasing information from neural representations and discuss its application to various datasets. There is no mention of language models or their limitations.
Less is More: Mitigate Spurious Correlations for Open-Domain Dialogue Response Generation Models by Causal Discovery,Yes.,2.,"""The current models indeed suffer from spurious correlations and have a tendency to generate irrelevant and generic responses."""
The Parallelism Tradeoff: Limitations of Log-Precision Transformers,Yes.,5.,"""We thus speculatively introduce the idea of a fundamental parallelism tradeoff"
Understanding and Detecting Hallucinations in Neural Machine Translation via Model Introspection,Yes.,4.,"""Neural sequence generation models are known to 'hallucinate', by producing outputs that are unrelated to the source text. These hallucinations are potentially harmful, yet it remains unclear in what conditions they arise and how to mitigate their impact."""
Visual Writing Prompts: Character-Grounded Story Generation with Curated Image Sequences,No.,1.,"The abstract focuses on visual story generation and discusses the creation of a new image-grounded dataset, Visual Writing Prompts (VWP). It does not mention language models (LLMs) or their limitations."
