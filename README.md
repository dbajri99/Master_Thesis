# Master Thesis on Large Language Model Limitations
## Project Overview
This repository hosts the research and analytical processes underlying my master's thesis, which aims to systematically discover and analyze the limitations of Large Language Models (LLMs). Leveraging an expansive dataset comprising approximately 146,000 academic papers from ArXiv and ACL Anthology spanning 2022 to 2024, this study employs advanced computational techniques to build a comprehensive taxonomy of LLM limitations.

Despite the rapid advancements in Natural Language Processing, prominent LLMs such as GPT, LLaMA, and Mistral exhibit critical shortcomings in areas like reasoning, multilingual capabilities, and security. This thesis distinguishes itself by not only systematically categorizing these limitations across various contexts but also by quantifying the frequency and depth of these discussions over time, showing a significant increase in awareness and scholarly discussion around these issues.

Using advanced language models like GPT-4.0, LLaMA 2, and Mistral, the study utilizes a mix of zero-shot and few-shot learning techniques to rate and analyze the depth of limitation discussions within these papers. Through the use of LLM-based embeddings and BERTopic clustering, combined with few-shot learning approaches, this research identifies and clusters the recurring limitations, highlighting the most prevalent challenges as reasoning failures, bias propagation, hallucination risks, privacy concerns, and resource constraints.

The resulting taxonomy provides a structured understanding of the challenges LLMs face across different contexts and includes detailed categories such as Cognitive and Logical Limitations, Ethical and Social Limitations, Technical and Operational Limitations, Application-Specific Limitations, and Performance and Reliability. This taxonomy serves as a critical resource for guiding future research and development efforts aimed at addressing these limitations.
