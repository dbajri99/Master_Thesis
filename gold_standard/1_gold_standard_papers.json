[
    {
        "title": "Evaluating Modular Dialogue System for Form Filling Using Large Language Models",
        "authors": [
            "Sherzod Hakimov",
            "Yan Weiser",
            "David Schlangen"
        ],
        "published": "2024-03-01T00:00:00Z",
        "summary": "This paper introduces a novel approach to form-filling and dialogue system evaluation by leveraging Large Language Models (LLMs). The proposed method establishes a setup wherein multiple modules collaborate on addressing the form-filling task. The dialogue system is constructed on top of LLMs, focusing on defining specific roles for individual modules. We show that using multiple independent sub-modules working cooperatively on this task can improve performance and handle the typical constraints of using LLMs, such as context limitations. The study involves testing the modular setup on four selected forms of varying topics and lengths, employing commercial and open-access LLMs. The experimental results demonstrate that the modular setup consistently outperforms the baseline, showcasing the effectiveness of this approach. Furthermore, our findings reveal that open-access models perform comparably to commercial models for the specified task.",
        "pdf_link": "https://aclanthology.org/2024.scichat-1.4"
     }, 
     {
        "title": "Improving Cross-Domain Low-Resource Text Generation through LLM Post-Editing: A Programmer-Interpreter Approach",
        "authors": [
            "Zhuang Li",
            "Levon Haroutunian",
            "Raj Tumuluri",
            "Philip Cohen",
            "Reza Haf"
        ],
        "published": "2024-03-01T00:00:00Z",
        "summary": "Post-editing has proven effective in improving the quality of text generated by large language models (LLMs) such as GPT-3.5 or GPT-4, particularly when direct updating of their parameters to enhance text quality is infeasible or expensive. However, relying solely on smaller language models for post-editing can limit the LLMs' ability to generalize across domains. Moreover, the editing strategies in these methods are not optimally designed for text generation tasks. To address these limitations, we propose a neural programmer-interpreter approach that preserves the domain generalization ability of LLMs while editing their output. The editing actions in this framework are specifically devised for text generation. Extensive experiments demonstrate that the programmer-interpreter significantly enhances GPT-3.5's performance in logical form-to-text conversion and low-resource machine translation, surpassing other state-of-the-art (SOTA) LLM post-editing methods in cross-domain settings.",
        "pdf_link": "https://aclanthology.org/2024.findings-eacl.24"
     },
     {
        "title": "Re3val: Reinforced and Reranked Generative Retrieval",
        "authors": [
            "EuiYul Song",
            "Sangryul Kim",
            "Haeju Lee",
            "Joonkee Kim",
            "James Thorne"
        ],
        "published": "2024-03-01T00:00:00Z",
        "summary": "Generative retrieval models encode pointers to information in a corpus as an index within the model's parameters. These models serve as part of a larger pipeline, where retrieved information conditions generation for knowledge-intensive NLP tasks. However, we identify two limitations: the generative retrieval does not account for contextual information. Secondly, the retrieval can't be tuned for the downstream readers as decoding the page title is a non-differentiable operation. This paper introduces Re3val, trained with generative reranking and reinforcement learning using limited data. Re3val leverages context acquired via Dense Passage Retrieval to rerank the retrieved page titles and utilizes REINFORCE to maximize rewards generated by constrained decoding. Additionally, we generate questions from our pre-training dataset to mitigate epistemic uncertainty and bridge the domain gap between the pre-training and fine-tuning datasets. Subsequently, we extract and rerank contexts from the KILT database using the rerank page titles. Upon grounding the top five reranked contexts, Re3val demonstrates the Top 1 KILT scores compared to all other generative retrieval models across five KILT datasets.",
        "pdf_link": "https://aclanthology.org/2024.findings-eacl.27"
     }, 
     {
        "title": "Reward Engineering for Generating Semi-structured Explanation",
        "authors": [
            "Jiuzhou Han",
            "Wray Buntine",
            "Ehsan Shareghi"
        ],
        "published": "2024-03-01T00:00:00Z",
        "summary": "Semi-structured explanation depicts the implicit process of a reasoner with an explicit representation. This explanation highlights how available information in a specific query is utilised and supplemented with information a reasoner produces from its internal weights towards generating an answer. Despite the recent improvements in generative capabilities of language models, producing structured explanations to verify a model's true reasoning capabilities remains a challenge. This issue is particularly pronounced for not-so-large LMs (e.g., FLAN-T5-XXL). In this work, we first underscore the limitations of supervised fine-tuning (SFT) in tackling this challenge, and then introduce a carefully crafted reward engineering method in reinforcement learning (RL) to better address this problem. We investigate multiple reward aggregation methods and provide a detailed discussion which sheds light on the promising potential of RL for future research. Our proposed method on two semi-structured explanation generation benchmarks (ExplaGraph and COPA-SSE) achieves new state-of-the-art results.",
        "pdf_link": "https://aclanthology.org/2024.findings-eacl.41"
     }, 
     {
        "title": "Are Large Language Model-based Evaluators the Solution to Scaling Up Multilingual Evaluation?",
        "authors": [
            "Rishav Hada",
            "Varun Gumma",
            "Adrian Wynter",
            "Harshita Diddee",
            "Mohamed Ahmed",
            "Monojit Choudhury",
            "Kalika Bali",
            "Sunayana Sitaram"
        ],
        "published": "2024-03-01T00:00:00Z",
        "summary": "Large Language Models (LLMs) excel in various Natural Language Processing (NLP) tasks, yet their evaluation, particularly in languages beyond the top 20, remains inadequate due to existing benchmarks and metrics limitations. Employing LLMs as evaluators to rank or score other models' outputs emerges as a viable solution, addressing the constraints tied to human annotators and established benchmarks. In this study, we explore the potential of LLM-based evaluators in enhancing multilingual evaluation by calibrating them against 20K human judgments across three text-generation tasks, five metrics, and eight languages. Our analysis reveals a bias in LLM-based evaluators towards higher scores, underscoring the necessity of calibration with native speaker judgments, especially in low-resource and non-Latin script languages, to ensure accurate evaluation of LLM performance across diverse languages.",
        "pdf_link": "https://aclanthology.org/2024.findings-eacl.71"
     }, 
     {
        "title": "Why Generate When You Can Discriminate? A Novel Technique for Text Classification using Language Models",
        "authors": [
            "Sachin Pawar",
            "Nitin Ramrakhiyani",
            "Anubhav Sinha",
            "Manoj Apte",
            "Girish Palshikar"
        ],
        "published": "2024-03-01T00:00:00Z",
        "summary": "In this paper, we propose a novel two-step technique for text classification using autoregressive Language Models (LM). In the first step, a set of perplexity and log-likelihood based numeric features are elicited from an LM for a text instance to be classified. Then, in the second step, a classifier based on these features is trained to predict the final label. The classifier used is usually a simple machine learning classifier like Support Vector Machine (SVM) or Logistic Regression (LR) and it is trained using a small set of training examples. We believe, our technique presents a whole new way of exploiting the available training instances, in addition to the existing ways like fine-tuning LMs or in-context learning. Our approach stands out by eliminating the need for parameter updates in LMs, as required in fine-tuning, and does not impose limitations on the number of training examples faced while building prompts for in-context learning. We evaluate our technique across 5 different datasets and compare with multiple competent baselines.",
        "pdf_link": "https://aclanthology.org/2024.findings-eacl.74"
     }, 
     {
        "title": "Evaluating Large Language Models Trained on Code",
        "authors": [
            "Mark Chen",
            "Jerry Tworek",
            "Heewoo Jun",
            "Qiming Yuan",
            "Henrique Ponde de Oliveira Pinto",
            "Jared Kaplan",
            "Harri Edwards",
            "Yuri Burda",
            "Nicholas Joseph",
            "Greg Brockman",
            "Alex Ray",
            "Raul Puri",
            "Gretchen Krueger",
            "Michael Petrov",
            "Heidy Khlaaf",
            "Girish Sastry",
            "Pamela Mishkin",
            "Brooke Chan",
            "Scott Gray",
            "Nick Ryder",
            "Mikhail Pavlov",
            "Alethea Power",
            "Lukasz Kaiser",
            "Mohammad Bavarian",
            "Clemens Winter",
            "Philippe Tillet",
            "Felipe Petroski Such",
            "Dave Cummings",
            "Matthias Plappert",
            "Fotios Chantzis",
            "Elizabeth Barnes",
            "Ariel Herbert-Voss",
            "William Hebgen Guss",
            "Alex Nichol",
            "Alex Paino",
            "Nikolas Tezak",
            "Jie Tang",
            "Igor Babuschkin",
            "Suchir Balaji",
            "Shantanu Jain",
            "William Saunders",
            "Christopher Hesse",
            "Andrew N. Carr",
            "Jan Leike",
            "Josh Achiam",
            "Vedant Misra",
            "Evan Morikawa",
            "Alec Radford",
            "Matthew Knight",
            "Miles Brundage",
            "Mira Murati",
            "Katie Mayer",
            "Peter Welinder",
            "Bob McGrew",
            "Dario Amodei",
            "Sam McCandlish",
            "Ilya Sutskever",
            "Wojciech Zaremba"
        ],
        "published": "2022-07-14T00:00:00Z",
        "summary": "We introduce Codex, a GPT language model fine-tuned on publicly available code from GitHub, and study its Python code-writing capabilities. A distinct production version of Codex powers GitHub Copilot. On HumanEval, a new evaluation set we release to measure functional correctness for synthesizing programs from docstrings, our model solves 28.8% of the problems, while GPT-3 solves 0% and GPT-J solves 11.4%. Furthermore, we find that repeated sampling from the model is a surprisingly effective strategy for producing working solutions to difficult prompts. Using this method, we solve 70.2% of our problems with 100 samples per problem. Careful investigation of our model reveals its limitations, including difficulty with docstrings describing long chains of operations and with binding operations to variables. Finally, we discuss the potential broader impacts of deploying powerful code generation technologies, covering safety, security, and economics.",
        "pdf_link": "https://doi.org/10.48550/arXiv.2107.03374"
     },
     {
        "title": "Fine-tuning CLIP Text Encoders with Two-step Paraphrasing",
        "authors": [
            "Hyunjae Kim",
            "Seunghyun Yoon",
            "Trung Bui",
            "Handong Zhao",
            "Quan Tran",
            "Franck Dernoncourt",
            "Jaewoo Kang"
        ],
        "published": "2024-03-01T00:00:00Z",
        "summary": "Contrastive language-image pre-training (CLIP) models have demonstrated considerable success across various vision-language tasks, such as text-to-image retrieval, where the model is required to effectively process natural language input to produce an accurate visual output. However, current models still face limitations in dealing with linguistic variations in input queries, such as paraphrases, making it challenging to handle a broad range of user queries in real-world applications. In this study, we introduce a straightforward fine-tuning approach to enhance the representations of CLIP models for paraphrases. Our approach involves a two-step paraphrase generation process, where we automatically create two categories of paraphrases from web-scale image captions by leveraging large language models. Subsequently, we fine-tune the CLIP text encoder using these generated paraphrases while freezing the image encoder. Our resulting model, which we call ParaCLIP, exhibits significant improvements over baseline CLIP models across various tasks, including paraphrased retrieval (with rank similarity scores improved by up to 7.6% and 9.6%), Visual Genome Relation and Attribution, as well as seven semantic textual similarity tasks.",
        "pdf_link": "https://aclanthology.org/2024.findings-eacl.144"
     }, 
     {
        "title": "ICE-Score: Instructing Large Language Models to Evaluate Code",
        "authors": [
            "Terry Yue Zhuo"
        ],
        "published": "2024-03-01T00:00:00Z",
        "summary": "Recent advancements in the field of natural language generation have facilitated the use of large language models to assess the quality of generated text. Although these models have shown promising results in tasks such as machine translation and summarization, their applicability in code intelligence tasks remains limited without human involvement. The complexity of programming concepts required for such tasks makes it difficult to develop evaluation metrics that align with human judgment. Token-matching-based metrics, such as BLEU, have demonstrated weak correlations with human practitioners in code intelligence tasks. Moreover, utilizing human-written test suites to evaluate functional correctness can be challenging in domains with low resources. To overcome these obstacles, we propose ICE-Score, a new evaluation metric via instructing large language models (LLMs) for code assessments. Our metric addresses the limitations of existing approaches by achieving superior correlations with functional correctness and human preferences, without the need for test oracles or references. We evaluate the efficacy of our metric on two different aspects (human preference and execution success) and four programming languages. Our results demonstrate that our metric surpasses state-of-the-art metrics for code generation, delivering high levels of accuracy and consistency across various programming languages and tasks. We also make our evaluation metric and datasets available to the public, encouraging further research in evaluating code intelligence tasks.",
        "pdf_link": "https://aclanthology.org/2024.findings-eacl.148"
     },
     {
        "title": "Transformer-specific Interpretability",
        "authors": [
            "Hosein Mohebbi",
            "Jaap Jumelet",
            "Michael Hanna",
            "Afra Alishahi",
            "Willem Zuidema"
        ],
        "published": "2024-03-01T00:00:00Z",
        "summary": "Transformers have emerged as dominant players in various scientific fields, especially NLP. However, their inner workings, like many other neural networks, remain opaque. In spite of the widespread use of model-agnostic interpretability techniques, including gradient-based and occlusion-based, their shortcomings are becoming increasingly apparent for Transformer interpretation, making the field of interpretability more demanding today. In this tutorial, we will present Transformer-specific interpretability methods, a new trending approach, that make use of specific features of the Transformer architecture and are deemed more promising for understanding Transformer-based models. We start by discussing the potential pitfalls and misleading results model-agnostic approaches may produce when interpreting Transformers. Next, we discuss Transformer-specific methods, including those designed to quantify context-mixing interactions among all input pairs (as the fundamental property of the Transformer architecture) and those that combine causal methods with low-level Transformer analysis to identify particular subnetworks within a model that are responsible for specific tasks. By the end of the tutorial, we hope participants will understand the advantages (as well as current limitations) of Transformer-specific interpretability methods, along with how these can be applied to their own research.",
        "pdf_link": "https://aclanthology.org/2024.eacl-tutorials.4"
     }, 
     {
        "title": "Can docstring reformulation with an LLM improve code generation?",
        "authors": [
            "Nicola Dainese",
            "Alexander Ilin",
            "Pekka Marttinen"
        ],
        "published": "2024-03-01T00:00:00Z",
        "summary": "Generating code is an important application of Large Language Models (LLMs) and the task of function completion is one of the core open challenges in this context. Existing approaches focus on either training, fine-tuning or prompting LLMs to generate better outputs given the same input. We propose a novel and complementary approach: to optimize part of the input, the docstring (summary of a function's purpose and usage), via reformulation with an LLM, in order to improve code generation. We develop two baseline methods for optimizing code generation via docstring reformulation and test them on the original HumanEval benchmark and multiple curated variants which are made more challenging by realistically worsening the docstrings. Our results show that, when operating on docstrings reformulated by an LLM instead of the original (or worsened) inputs, the performance of a number of open-source LLMs does not change significantly. This finding demonstrates an unexpected robustness of current open-source LLMs to the details of the docstrings. We conclude by examining a series of questions, accompanied by in-depth analyses, pertaining to the sensitivity of current open-source LLMs to the details in the docstrings, the potential for improvement via docstring reformulation and the limitations of the methods employed in this work.",
        "pdf_link": "https://aclanthology.org/2024.eacl-srw.24"
     }, 
     {
        "title": "Equipping Language Models with Tool Use Capability for Tabular Data Analysis in Finance",
        "authors": [
            "Adrian Theuma",
            "Ehsan Shareghi"
        ],
        "published": "2024-01-27T07:08:37Z",
        "summary": "Large language models (LLMs) have exhibited an array of reasoning capabilities but face challenges like error propagation and hallucination, particularly in specialised areas like finance, where data is heterogeneous, and precision is paramount. We explore the potential of language model augmentation with external tools to mitigate these limitations and offload certain reasoning steps to external tools that are more suited for the task, instead of solely depending on the LLM's inherent abilities. More concretely, using financial domain question-answering datasets, we apply supervised fine-tuning on a LLaMA-2 13B Chat model to act both as a 'task router' and 'task solver'. The 'task router' dynamically directs a question to either be answered internally by the LLM or externally via the right tool from the tool set. Our tool-equipped SFT model, Raven, demonstrates an improvement of 35.2% and 5.06% over the base model and SFT-only baselines, respectively, and is highly competitive with strong GPT-3.5 results. To the best of our knowledge, our work is the first that investigates tool augmentation of language models for the finance domain.",
        "pdf_link": "https://aclanthology.org/2024.eacl-short.10"
     },
     {
        "title": "Generation-driven Contrastive Self-training for Zero-shot Text Classification with Instruction-following LLM",
        "authors": [
            "Ruohong Zhang",
            "Yau-Shian Wang",
            "Yiming Yang"
        ],
        "published": "2024-03-01T00:00:00Z",
        "summary": "The remarkable performance of large language models (LLMs) in zero-shot language understanding has garnered significant attention. However, employing LLMs for large-scale inference or domain-specific fine-tuning requires immense computational resources due to their substantial model size. To overcome these limitations, we introduce a novel method, namely GenCo, which leverages the strong generative power of LLMs to assist in training a smaller and more adaptable language model. In our method, an LLM plays an important role in the self-training loop of a smaller model in two important ways. Firstly, we utilize an LLM to generate multiple augmented texts for each input instance to enhance its semantic meaning for better understanding. Secondly, we additionally generate high-quality training instances conditioned on predicted labels, ensuring the generated texts are relevant to the labels. In this way, GenCo not only corrects the errors of predicted labels during self-training but also eliminates the need for extensive unlabeled texts. In our experiments, GenCo outperforms previous state-of-the-art methods when only limited (<5% of original) in-domain text data is available. Notably, our approach surpasses Alpaca-7B with human instructions, highlighting the significance of self-training.",
        "pdf_link": "https://aclanthology.org/2024.eacl-long.39"
     },
     {
        "title": "Document-Level Language Models for Machine Translation",
        "authors": [
            "Frithjof Petrick",
            "Christian Herold",
            "Pavel Petrushkov",
            "Shahram Khadivi",
            "Hermann Ney"
        ],
        "published": "2023-12-01T00:00:00Z",
        "summary": "Despite the known limitations, most machine translation systems today still operate on the sentence-level. One reason for this is, that most parallel training data is only sentence-level aligned, without document-level meta information available. In this work, we set out to build context-aware translation systems utilizing document-level monolingual data instead. This can be achieved by combining any existing sentence-level translation model with a document-level language model. We improve existing approaches by leveraging recent advancements in model combination. Additionally, we propose novel weighting techniques that make the system combination more flexible and significantly reduce computational overhead. In a comprehensive evaluation on four diverse translation tasks, we show that our extensions improve document-targeted scores significantly and are also computationally more efficient. However, we also find that in most scenarios, back-translation gives even better results, at the cost of having to re-train the translation system. Finally, we explore language model fusion in the light of recent advancements in large language models. Our findings suggest that there might be strong potential in utilizing large language models via model combination.",
        "pdf_link": "https://aclanthology.org/2023.wmt-1.39"
     }, 
     {
        "title": "ChatGPT MT: Competitive for High- (but Not Low-) Resource Languages",
        "authors": [
            "Nathaniel Robinson",
            "Perez Ogayo",
            "David R. Mortensen",
            "Graham Neubig"
        ],
        "published": "2023-12-01T00:00:00Z",
        "summary": "Large language models (LLMs) implicitly learn to perform a range of language tasks, including machine translation (MT). Previous studies explore aspects of LLMs{'} MT capabilities. However, there exist a wide variety of languages for which recent LLM MT performance has never before been evaluated. Without published experimental evidence on the matter, it is difficult for speakers of the world{'}s diverse languages to know how and whether they can use LLMs for their languages. We present the first experimental evidence for an expansive set of 204 languages, along with MT cost analysis, using the FLORES-200 benchmark. Trends reveal that GPT models approach or exceed traditional MT model performance for some high-resource languages (HRLs) but consistently lag for low-resource languages (LRLs), under-performing traditional MT for 84.1% of languages we covered. Our analysis reveals that a language{'}s resource level is the most important feature in determining ChatGPT{'}s relative ability to translate it, and suggests that ChatGPT is especially disadvantaged for LRLs and African languages.",
        "pdf_link": "https://aclanthology.rg/2023.wmt-1.40"
     }, 
     {
        "title": "Large Language Models Effectively Leverage Document-level Context for Literary Translation, but Critical Errors Persist",
        "authors": [
            "Marzena Karpinska",
            "Mohit Iyyer"
        ],
        "published": "2023-12-01T00:00:00Z",
        "summary": "Large language models (LLMs) are competitive with the state of the art on a wide range of sentence-level translation datasets. However, their ability to translate paragraphs and documents remains unexplored because evaluation in these settings is costly and difficult. We show through a rigorous human evaluation that asking the GPT-3.5 (text-davinci-003) LLM to translate an entire literary paragraph (e.g., from a novel) at once results in higher-quality translations than standard sentence-by-sentence translation across 18 linguistically-diverse language pairs (e.g., translating into and out of Japanese, Polish, and English). Our evaluation, which took approximately 350 hours of effort for annotation and analysis, is conducted by hiring translators fluent in both the source and target language and asking them to provide both span-level error annotations as well as preference judgments of which system's translations are better. We observe that discourse-level LLM translators commit fewer mistranslations, grammar errors, and stylistic inconsistencies than sentence-level approaches. With that said, critical errors still abound, including occasional content omissions, and a human translator's intervention remains necessary to ensure that the author's voice remains intact. We publicly release our dataset and error annotations to spur future research on the evaluation of document-level literary translation.",
        "pdf_link": "https://aclanthology.org/2023.wmt-1.41"
     },
     {
        "title": "Machine Translation with Large Language Models: Prompting, Few-shot Learning, and Fine-tuning with QLoRA",
        "authors": [
            "Xuan Zhang",
            "Navid Rajabi",
            "Kevin Duh",
            "Philipp Koehn"
        ],
        "published": "2023-12-01T00:00:00Z",
        "summary": "While large language models have made remarkable advancements in natural language generation, their potential in machine translation, especially when fine-tuned, remains under-explored. In our study, we conduct comprehensive experiments, evaluating 15 publicly available language models on machine translation tasks. We compare the performance across three methodologies: zero-shot prompting, few-shot learning, and fine-tuning. Central to our approach is the use of QLoRA, an efficient fine-tuning method. On French-English, QLoRA fine-tuning outperforms both few-shot learning and models trained from scratch. This superiority is highlighted in both sentence-level and document-level translations, with a significant BLEU score improvement of 28.93 over the prompting method. Impressively, with QLoRA, the enhanced performance is achieved by fine-tuning a mere 0.77% of the model's parameters.",
        "pdf_link": "https://aclanthology.org/2023.wmt-1.43"
     }
]