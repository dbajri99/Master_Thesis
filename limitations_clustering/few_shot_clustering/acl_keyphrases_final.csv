Source,Title,Talks about LLMs,Rate,Evidence,Year,Month,Keyphrase
aacl2022,VLStereoSet: A Study of Stereotypical Bias in Pre-trained Vision-Language Models,Yes.,4,experiment six representative pretraine visionlanguage demonstrate stereotypical bias clearly exist across four bias category gender bias slightly evident,2022,November,"Keyphrase: ""Stereotypical biases in vision-language models"""
aacl2022,Demographic-Aware Language Model Fine-tuning as a Bias Mitigation Technique,Yes.,4,bertlike lm expose unstructured dataset know learn sometimes even amplify bias present,2022,November,"Keyphrase: ""Bias amplification"""
emnlp2022,RankGen: Improving Text Generation with Large Ranking Models,Yes.,5,modern often assign high probability sequence repetitive incoherent irrelevant prefix modelgenerated text also contain artifact,2022,December,"Keyphrase: ""Repetitive and incoherent output"""
emnlp2022,An Empirical Analysis of Memorization in Fine-tuned Autoregressive Language Models,Yes.,5,show present privacy risk memorization training empirically study memorization finetune use membership inference extraction attack show susceptibility attack different,2022,December,"Keyphrase: ""Privacy risks and susceptibility to attacks"""
emnlp2022,EvEntS ReaLM: Event Reasoning of Entity States via Language Models,Yes.,5,nominally expose procedural object interact yet benchmarking show fail reason world,2022,December,"Keyphrase: ""Lack of real-world performance"""
emnlp2022,Rich Knowledge Sources Bring Complex Knowledge Conflicts: Recalibrating Models to Reflect Conflicting Evidence,Yes.,5,simulate conflict ie parametric suggest one different passage suggest different examine behavior contradiction among source affect confidence marginally,2022,December,"Keyphrase: ""Inconsistent behavior"""
emnlp2022,SafeText: A Benchmark for Exploring Physical Safety in Language Models,Yes.,5,find stateoftheart susceptible generation unsafe text difficulty reject unsafe advice,2022,December,"Keyphrase: ""Susceptibility to generating unsafe text"""
emnlp2022,Memory-assisted prompt editing to improve GPT-3 after deployment,Yes.,5,lm gpt powerful commit mistake obvious human,2022,December,"Keyphrase: ""Prone to obvious mistakes"""
emnlp2022,BERTScore is Unfair: On Social Bias in Language Model-Based Metrics for Text Generation,Yes.,4,however demonstrate plm encode range stereotypical societal bias lead concern fairness plm metric demonstrate popular plmbase metric exhibit significantly high social bias traditional metric   sensitive attribute,2022,December,"Keyphrase: ""Societal bias encoding"""
emnlp2022,Neural Theory-of-Mind? On the Limits of Social Intelligence in Large LMs,Yes.,5,show one todayÃ¢s gpt brown et al   lack kind social intelligence outofthe box show struggle substantially theory mind,2022,December,"Keyphrase: ""Lack of social intelligence"""
emnlp2022,Improving Temporal Generalization of Pre-trained Language Models with Lexical Semantic Change,Yes.,5,neural scale suffer poor temporal generalization capability pretraine static past year bad time emerge,2022,December,"Keyphrase: ""Limited temporal generalization"""
emnlp2022,Perturbation Augmentation for Fairer NLP,Yes.,4,unwanted often harmful social bias become ever salient nlp research affect dataset lastly discuss outstanding question good evaluate unfairness,2022,December,"Keyphrase: ""Unwanted social bias"""
emnlp2022,"The better your Syntax, the better your Semantics? Probing Pretrained Language Models for the English Comparative Correlative",Yes.,5,show three investigate plm able recognise structure cc fail use meaning humanlike performance plm many nlp allege indicate plm still suffer substantial shortcoming central domain linguistic,2022,December,"Keyphrase: ""Limited linguistic understanding"""
emnlp2022,LittleBird: Efficient Faster & Longer Transformer for Question Answering,Yes.,5,limitation deal long due attention mechanism,2022,December,"Keyphrase: ""Limited handling of long dependencies"""
emnlp2022,Mutual Information Alleviates Hallucinations in Abstractive Summarization,Yes.,5,still exhibit tendency hallucinate ie content support source document,2022,December,"Keyphrase: ""Content hallucination"""
emnlp2022,Evaluating the Impact of Model Scale for Compositional Generalization in Semantic Parsing,Yes.,5,despite strong performance many pretraine show struggle outofdistribution compositional generalization overall study highlight limitation current technique effectively leverage scale compositional generalization analysis also suggest promise direction future work,2022,December,"Keyphrase: ""Struggles with out-of-distribution compositional generalization"""
emnlp2022,A Systematic Investigation of Commonsense Knowledge in Large Language Models,Yes.,5,finding highlight limitation pretraine lm acquire commonsense without taskspecific supervision furthermore use fewshot evaluation insufficient achieve humanlevel commonsense performance,2022,December,"Keyphrase: ""Limited acquisition of commonsense"""
emnlp2022,SEAL: Interactive Tool for Systematic Error Analysis and Labeling,Yes.,5,however many time systematically fail tail rare group obvious aggregate evaluation,2022,December,"Keyphrase: ""Failure to address rare group tail issues"""
acl2022,Auto-Debias: Debiasing Masked Language Models with Automated Biased Prompts,Yes.,4,humanlike bias undesired social stereotype exist pretrained give wide adoption realworld application mitigate bias become emerge important,2022,May,"Keyphrase: ""Humanlike bias and social stereotypes"""
acl2022,Are Prompt-based Models Clueless?,Yes.,5,taskspecific head require lot training make susceptible learn exploit datasetspecific superficial cue generalize dataset analyze fewshot promptbase mnli snli han copa reveal promptbase also exploit superficial cue well instance superficial cue,2022,May,"Keyphrase: ""Overreliance on superficial cues"""
acl2022,TruthfulQA: Measuring How Models Mimic Human Falsehoods,Yes.,5,many false mimic popular misconception potential deceive human generally least truthful,2022,May,"Keyphrase: ""Deceptive false information"""
acl2022,Upstream Mitigation Is Not All You Need: Testing the Bias Transfer Hypothesis in Pre-Trained Language Models,Yes.,4,investigate bias transfer hypothesis,2022,May,"Keyphrase: ""Bias transfer"""
acl2022,A Token-level Reference-free Hallucination Detection Benchmark for Free-form Text Generation,Yes.,5,pretraine generative like gpt often suffer hallucinate nonexistent incorrect content undermine potential merit real application,2022,May,"Keyphrase: ""Hallucination of nonexistent content"""
acl2022,Is GPT-3 Text Indistinguishable from Human Text? Scarecrow: A Framework for Scrutinizing Machine Text,Yes.,4,error machine generation become ever subtle hard spot ten error category scarecrowÃ¢such redundancy commonsense error incoherence,2022,May,"Keyphrase: ""Subtle errors and incoherence"""
acl2022,Exploiting Language Model Prompts Using Similarity Measures: A Case Study on the Word-in-Context Task,Yes.,5,exist promptbase technique fail semantic distinction wordincontext wic dataset specifically none exist fewshot approach include incontext learning gpt attain performance meaningfully different random baseline,2022,May,"Keyphrase: ""Weak semantic understanding"""
acl2022,Softmax Bottleneck Makes Language Models Unable to Represent Multi-mode Word Distributions,Yes.,5,however discover single hidden state produce probability distribution regardless lm size training size single hidden state embed close embedding possible next word simultaneously interfere word embedding,2022,May,"Keyphrase: ""Interference in word embeddings"""
acl2022,Coherence boosting: When your pretrained language model is not paying enough attention,Yes.,5,demonstrate insufficiently learn effect distant word nexttoken prediction,2022,May,"Keyphrase: ""Limited learning of distant word effects"""
acl2022,Data Contamination: From Memorization to Exploitation,Yes.,5,clear extent exploit contaminated downstream highlight importance analyze massive webscale dataset verify progress nlp obtain well understanding well exploitation,2022,May,"Keyphrase: ""Limited dataset exploitation"""
acl2022,Kronecker Decomposition for GPT Compression,Yes.,5,despite superior performance gpt overparameterize nature gpt prohibitive deploy device limited computational power memory,2022,May,"Keyphrase: ""Overparameterization and computational constraints"""
naacl2022,Provably Confidential Language Modelling,Yes.,5,show memorize privacy information social security number training,2022,July,"Keyphrase: ""Privacy information memorization"""
naacl2022,"When a sentence does not introduce a discourse entity, Transformer-based models still sometimes refer to it",Yes.,5,find certain extent sensitive interaction investigate challenge presence multiple nps behavior systematic suggest even scale gpt fully acquire basic entity track ability,2022,July,"Keyphrase: ""Limited entity tracking ability"""
naacl2022,Measuring Fairness with Biased Rulers: A Comparative Study on Bias Metrics for Pre-trained Language Models,Yes.,4,indicate fairness bias evaluation remain challenge contextualize among reason choice remain subjective,2022,July,"Keyphrase: ""Subjective fairness evaluation"""
naacl2022,Curriculum: A Broad-Coverage Benchmark for Linguistic Phenomena in Natural Language Understanding,Yes.,5,current evaluation show significant shortcoming fail effectively map aspect understanding remain challenge exist experiment provide insight limitation exist benchmark dataset stateoftheart,2022,July,"Keyphrase: ""Limited aspect understanding"""
naacl2022,Exposing the Limits of Video-Text Models through Contrast Sets,Yes.,5,see performance suffer across erase gap recent clipbased vs early,2022,July,"Keyphrase: ""Performance degradation with evolving data"""
naacl2022,KALA: Knowledge-Augmented Language Model Adaptation,Yes.,5,simple finetuning plm hand might suboptimal domainspecific possibly cover domain adaptive pretraining plm help obtain domainspecific require training cost moreover adaptive pretraining harm plmÃ¢s performance downstream cause catastrophic forgetting general,2022,July,"Keyphrase: ""Limited domain adaptation"""
naacl2022,You DonÃ¢â‚¬â„¢t Know My Favorite Color: Preventing Dialogue Representations from Revealing SpeakersÃ¢â‚¬â„¢ Private Personas,Yes.,4,privacy concern arise recently,2022,July,"Keyphrase: ""Privacy concerns"""
naacl2022,Methods for Estimating and Improving Robustness of Language Models,Yes.,5,suffer notorious flaw relate preference shallow textual relation full semantic complexity problem weak ability generalise outside training domain,2022,July,"Keyphrase: ""Weak generalization outside training domain"""
naacl2022,Exploring the Effect of Dialect Mismatched Language Models in Telugu Automatic Speech Recognition,Yes.,5,show dialect variation surface form different lexicon grammar occasionally semantic significantly degrade performance lm mismatch condition,2022,July,"Keyphrase: ""Dialect variation degradation"""
acl2023,MIL-Decoding: Detoxifying Language Models at Token-Level via Multiple Instance Learning,Yes.,4,despite advance pretraine neural prone toxic bring security risk application,2023,July,"Keyphrase: ""Toxicity and security risks"""
acl2023,A Causal Framework to Quantify the Robustness of Mathematical Reasoning with Language Models,Yes.,5,robustness also call question recent work show rely shallow pattern problem description solution analysis show robustness appear continuously improve function size,2023,July,"Keyphrase: ""Questionable robustness"""
acl2023,ALERT: Adapt Language Models to Reasoning Tasks,Yes.,5,unclear whether apply reasoning skill learn pretraine simply memorize training corpus fine granularity also find finetune tend overfit prompt template hurt robustness cause generalization,2023,July,"Keyphrase: ""Overfitting and lack of reasoning skills"""
acl2023,ThinkSum: Probabilistic reasoning over sets using large language models,Yes.,5,recent study show even advanced fail scenario require reasoning multiple object fact make sequence logical deduction,2023,July,"Keyphrase: ""Limited reasoning capabilities"""
acl2023,Dynamic and Efficient Inference for Text Generation via BERT Family,Yes.,5,suffer inefficient inference computation memory due largescale parameter universal autoregressive decode paradigm,2023,July,"Keyphrase: ""Inefficient inference and computation"""
acl2023,Social-Group-Agnostic Bias Mitigation via the Stereotype Content Model,Yes.,4,exist bias mitigation require socialgroupspecific word pairs eg Ã¢Å“manÃ¢ Ã¢ Ã¢Å“womanÃ¢ social attribute eg gender restrict bias mitigation one specify social attribute constraint render impractical costly mitigate bias,2023,July,"Keyphrase: ""Limited bias mitigation options"""
acl2023,"On Second Thought, LetÃ¢â‚¬â„¢s Not Think Step by Step! Bias and Toxicity in Zero-Shot Reasoning",Yes.,5,find zeroshot cot reasoning sensitive domain significantly increase modelÃ¢s likelihood produce harmful undesirable work suggest zeroshot cot use caution socially important especially marginalize group sensitive topic involve,2023,July,"Keyphrase: ""Harmful biases in sensitive topics"""
acl2023,MISGENDERED: Limits of Large Language Models in Understanding Pronouns,Yes.,5,prompt outofthebox poorly correctly predict neopronoun average   accuracy genderneutral pronoun average   accuracy inability generalize lack representation nonbinary pronoun training memorized association,2023,July,"Keyphrase: ""Limited representation of nonbinary pronouns"""
acl2023,SCOTT: Self-Consistent Chain-of-Thought Distillation,Yes.,4,even concern little guarantee rationale consistent lmÃ¢s prediction faithfully justify decision,2023,July,"Keyphrase: ""Lack of rationale consistency"""
acl2023,Evaluating Open-Domain Question Answering in the Era of Large Language Models,Yes.,5,automate struggle detect hallucination thus unable evaluate,2023,July,"Keyphrase: ""Difficulty in detecting hallucination"""
acl2023,Verify-and-Edit: A Knowledge-Enhanced Chain-of-Thought Framework,Yes.,5,one fatal disadvantage lack factual correctness unfactual text lead low performance also degrade trust validity application,2023,July,"Keyphrase: ""Factual correctness deficiency"""
acl2023,Language model acceptability judgements are not always robust to context,Yes.,5,find judgement generally robust place randomly sample linguistic context unstable contexts match test stimulus syntactic structure sensitivity highly specific syntactic feature context explain modelsÃ¢ implicit incontext learn ability,2023,July,"Keyphrase: ""Limited syntactic structure sensitivity"""
acl2023,RobuT: A Systematic Study of Table QA Robustness Against Human-Annotated Adversarial Perturbations,Yes.,5,indicate stateoftheart table qa eg gpt fewshot learning falter adversarial set,2023,July,"Keyphrase: ""Falter in few-shot learning"""
acl2023,Learning Non-linguistic Skills without Sacrificing Linguistic Proficiency,Yes.,5,nonlinguistic skill injection typically come cost,2023,July,"Keyphrase: ""Cost of nonlinguistic skill injection"""
acl2023,Parallel Context Windows for Large Language Models,Yes.,5,apply process long text limit context window,2023,July,"Keyphrase: ""Limited context window"""
acl2023,Are Machine Rationales (Not) Useful to Humans? Measuring and Improving Human Utility of Free-text Rationales,Yes.,4,observe human utility exist rationale far satisfactory expensive estimate human study exist metric like performance lm rationale similarity gold rationale good indicator human utility,2023,July,"Keyphrase: ""Limited human utility estimation"""
acl2023,Targeted Data Generation: Finding and Fixing Model Weaknesses,Yes.,4,stateoftheart nlp often fail systematically specific subgroup unfair outcome erode user trust,2023,July,"Keyphrase: ""Unfair outcomes and eroded trust"""
acl2023,On Ã¢â‚¬Å“Scientific DebtÃ¢â‚¬Â in NLP: A Case for More Rigour in Language Model Pre-Training Research,Yes.,5,current plm research practice often conflate different possible source improvement without conduct proper ablation study principled comparison different comparable condition practice leave illequippe understand pretraine approach use circumstance ii impede reproducibility credit assignment iii render difficult understand,2023,July,Keyphrase: Lack of principled comparison and reproducibility
acl2023,WinoQueer: A Community-in-the-Loop Benchmark for Anti-LGBTQ+ Bias in Large Language Models,Yes.,5,apply benchmark several popular find offtheshelf generally exhibit considerable antiqueer bias,2023,July,"Keyphrase: ""Antiqueer bias"""
acl2023,Say What You Mean! Large Language Models Speak Too Positively about Negative Commonsense Knowledge,Yes.,5,experiment reveal frequently fail valid sentence ground negative commonsense statistical shortcut negation report bias modeling pretraine cause conflict,2023,July,"Keyphrase: ""Failure in handling negation and bias"""
acl2023,How Do In-Context Examples Affect Compositional Generalization?,Yes.,5,find compositional generalization performance easily affect selection incontext example two strong limitation observe,2023,July,"Keyphrase: ""Compositional generalization limitations"""
acl2023,Contrastive Decoding: Open-ended Text Generation as Optimization,Yes.,5,maximum probability poor decode objective openende generation produce short repetitive text hand sampling often produce incoherent text drift original topic,2023,July,"Keyphrase: ""Incoherent text generation"""
acl2023,CHBias: Bias Evaluation and Mitigation of Chinese Conversational Language Models,Yes.,4,pretraine conversational agent expose safety issue exhibit range stereotypical human bias gender bias experimental show chinese pretraine potentially risky text contain social bias,2023,July,"Keyphrase: ""Safety and societal biases"""
acl2023,"RARR: Researching and Revising What Language Models Say, Using Language Models",Yes.,5,however sometimes unsupported misleading content user easily determine whether trustworthy lm builtin mechanism attribution external evidence,2023,July,"Keyphrase: ""Lack of transparency and trustworthiness"""
acl2023,Language Models Get a Gender Makeover: Mitigating Gender Bias with Few-Shot Data Interventions,Yes.,4,societal bias present pretraine critical issue show propagate bias countless downstream application render unfair towards specific group people,2023,July,"Keyphrase: ""Propagating societal bias"""
acl2023,Probing Physical Reasoning with Counter-Commonsense Context,Yes.,5,show use preposition provide context infer size relationship fail use verb thus make incorrect judgment lead prior physical commonsense,2023,July,"Keyphrase: ""Lack of contextual understanding"""
acl2023,"Summarizing, Simplifying, and Synthesizing Medical Evidence using GPT-3 (with Varying Success)",Yes.,5,find gpt able summarize simplify single biomedical article faithfully struggle provide accurate aggregation finding multiple document,2023,July,"Keyphrase: ""Limited multi-document aggregation"""
acl2023,Controlling the Extraction of Memorized Data from Large Language Models via Prompt-Tuning,Yes.,5,know memorize significant portion training part memorized content show extractable simply query pose privacy risk,2023,July,"Keyphrase: ""Privacy risk due to memorization"""
acl2023,A Simple and Effective Framework for Strict Zero-Shot Hierarchical Classification,Yes.,5,benchmark often adequately address challenge pose realworld hierarchical classification   observe prone failure case,2023,July,"Keyphrase: ""Failure in real-world hierarchical classification"""
acl2023,Making the Most Out of the Limited Context Length: Predictive Power Varies with Clinical Note Type and Note Section,Yes.,5,context length predictor limit part clinical note choose,2023,July,"Keyphrase: ""Limited context understanding"""
acl2023,MathPrompter: Mathematical Reasoning using Large Language Models,Yes.,5,limited performance solve arithmetic reasoning often provide incorrect good aware indicate level confidence response fuel trust deficit impede adoption,2023,July,"Keyphrase: ""Limited arithmetic reasoning performance"""
acl2023,KoSBI: A Dataset for Mitigating Social Bias Risks Towards Safer Large Language Model Applications,Yes.,5,learn natural text generation ability also social bias different demographic group realworld pose critical risk deploy llmbase application limitation require localize social bias dataset ensure safe effective deployment,2023,July,"Keyphrase: ""Social bias and deployment risks"""
acl2023,A Static Evaluation of Code Completion by Large Language Models,Yes.,4,static analysis reveal undefined name unused variable common error among make,2023,July,"Keyphrase: ""Limited error detection capabilities"""
acl2023,"Everything you need to know about Multilingual LLMs: Towards fair, performant and reliable models for languages of the world",Yes.,4,responsible ai issue fairness bias toxicity linguistic diversity evaluation context mmlm specifically focus issue nonenglish lowresource,2023,July,"Keyphrase: ""Limited focus on non-English and low-resource languages"""
eacl2023,WinoDict: Probing language models for in-context word acquisition,Yes.,5,benchmark address word acquisition one important aspect diachronic degradation know afflict freeze time moment train normally unable reflect way change time,2023,May,"Keyphrase: ""Limited diachronic adaptation"""
eacl2023,Nationality Bias in Text Generation,Yes.,5,paper examine text generation gpt accentuate preexist societal bias countrybased demonym gpt demonstrate significant bias country low internet user adversarial triggering effectively reduce,2023,May,"Keyphrase: ""Amplification of societal biases"""
eacl2023,"Ã¢â‚¬Å“John is 50 years old, can his son be 65?Ã¢â‚¬Â Evaluating NLP ModelsÃ¢â‚¬â„¢ Understanding of Feasibility",Yes.,5,recent work also find notable failure often failure example involve complex reasoning ability show even stateoftheart gpt gpt struggle,2023,May,"Keyphrase: ""Failure in complex reasoning"""
eacl2023,MiniALBERT: Model Distillation via Parameter-Efficient Recursive Transformers,Yes.,5,usability lm constrain computational time complexity along increase size issue refer overparameterisation,2023,May,"Keyphrase: ""Computational time complexity constraints"""
eacl2023,SODAPOP: Open-Ended Discovery of Social Biases in Social Commonsense Reasoning Models,Yes.,4,common limitation diagnostic test detect social bias nlp may detect stereotypic association prespecifie designer test also test sodapop debiase show limitation,2023,May,"Keyphrase: ""Limited ability to detect social biases"""
eacl2023,Robustness Challenges in Model Distillation and Pruning for Natural Language Understanding,Yes.,5,however study analyze impact compression generalizability robustness compress outofdistribution ood compress significantly less robust plm counterpart ood test set although obtain similar performance indistribution development set,2023,May,"Keyphrase: ""Reduced generalizability and robustness after compression"""
eacl2023,Opportunities and Challenges in Neural Dialog Tutoring,Yes.,5,find although current approach tutoring constrained learn scenario number concept teach possible teacher strategy small poorly less constrained scenario human quality evaluation show groundtruth annotation exhibit low performance term equitable tutoring measure learn opportunity,2023,May,"Keyphrase: ""Limited concept teaching capability"""
eacl2023,Assessing Out-of-Domain Language Model Performance from Few Examples,Yes.,5,pretraine exhibit impressive generalization capability still behave unpredictably certain domain shift give targetdomain example set similar training performance understand ood test,2023,May,"Keyphrase: ""Unpredictable domain shifts"""
eacl2023,Towards preserving word order importance through Forced Invalidation,Yes.,5,however recent finding reveal pretraine insensitive word order performance nlu remain unchanged even randomly permute word sentence crucial syntactic information destroy,2023,May,"Keyphrase: ""Insensitive to word order"""
eacl2023,Adding Instructions during Pretraining: Effective way of Controlling Toxicity in Language Models,Yes.,4,however safely deploy real world application challenge toxic content,2023,May,"Keyphrase: ""Toxic content challenges"""
eacl2023,When Do Pre-Training Biases Propagate to Downstream Tasks? A Case Study in Text Summarization,Yes.,5,subject sociocultural bias previously identify use intrinsic evaluation however intrinsic bias pretraine lm representation propagate downstream finetune nlp like summarization well understand show bias manifest hallucination summarization lead factually incorrect summary,2023,May,"Keyphrase: ""Propagation of sociocultural bias"""
eacl2023,Language Generation Models Can Cause Harm: So What Can We Do About It? An Actionable Survey,Yes.,4,go beyond enumerate risk harm work provide survey practical address potential threat societal harm generation,2023,May,"Keyphrase: ""Limited consideration of societal harm"""
emnlp2023,FISH: A Financial Interactive System for Signal Highlighting,Yes.,5,chatgptÃ¢s decision sensitive order label prompt chatgpt clearly high chance select label early position,2023,December,"Keyphrase: ""Decision sensitivity to label prompts"""
emnlp2023,A Unified Framework for Emotion Identification and Generation in Dialogues,Yes.,5,experiment dataset show recent eg instructgpt struggle subquestion even able main question correctly find particularly poorly subquestion write incorrect option,2023,December,"Keyphrase: ""Struggles with subquestions"""
emnlp2023,Addressing Domain Changes in Task-oriented Conversational Agents through Dialogue Adaptation,Yes.,5,reveal limitation llmbase agentsÃ¢ plan optimization due systematic failure manage longhorizon contexts hallucination state,2023,December,"Keyphrase: ""Struggles with long-horizon context"""
emnlp2023,CompoundPiece: Evaluating and Improving Decompounding Performance of Language Models,Yes.,5,find poorly especially word tokenize unfavorably subword tokenization,2023,December,**Keyphrase:** Suboptimal tokenization efficiency
emnlp2023,Conceptual structure coheres in human cognition but not in large language models,Yes.,5,structure estimate behavior individually fairly consistent estimate human behavior depend much upon particular use behavior responsesÃ¢response three yield estimate conceptual structure cohere less one another human structure,2023,December,"Keyphrase: ""Inconsistent conceptual structure"""
emnlp2023,Towards LLM-driven Dialogue State Tracking,Yes.,5,despite impressive performance chatgpt significant limitation include closedsource nature request restriction raise privacy concern lack local deployment capability,2023,December,"Keyphrase: ""Closed-source and privacy concerns"""
emnlp2023,WeÃ¢â‚¬â„¢re Afraid Language Models ArenÃ¢â‚¬â„¢t Modeling Ambiguity,Yes.,5,find remain extremely challenging include gpt whose disambiguation consider correct   time crowdworker evaluation compare   disambiguation dataset,2023,December,"Keyphrase: ""Challenges in disambiguation accuracy"""
emnlp2023,Enhancing Uncertainty-Based Hallucination Detection with Stronger Focus,Yes.,5,however prone hallucinate untruthful nonsensical fail meet user expectation many realworld application,2023,December,"Keyphrase: ""Untruthful hallucinations"""
emnlp2023,CodeT5+: Open Code Large Language Models for Code Understanding and Generation,Yes.,5,however exist code two main limitation first often adopt specific architecture encoderonly decoderonly rely unify encoderdecoder network different downstream lack flexibility operate optimal architecture specific secondly often employ limited set pretraine objective might relevant,2023,December,"Keyphrase: ""Limited architecture flexibility and pretraining objectives"""
emnlp2023,Unveiling the Implicit Toxicity in Large Language Models,Yes.,5,show diverse implicit toxic exceptionally difficult detect via simply zeroshot prompting finding suggest pose significant threat undetectable implicit toxic,2023,December,"Keyphrase: ""Difficulty in detecting implicit toxic content"""
emnlp2023,ALCUNA: Large Language Models Meet New Knowledge,Yes.,5,benchmark several reveal performance face new satisfactory particularly reasoning new internal,2023,December,"Keyphrase: ""Limited reasoning capabilities"""
emnlp2023,Robust Prompt Optimization for Large Language Models Against Distribution Shifts,Yes.,5,reveal prompt optimization technique vulnerable distribution shift subpopulation shift common realworld scenario customer review analysis,2023,December,"Keyphrase: ""Vulnerability to distribution shift"""
emnlp2023,Interpreting Embedding Spaces by Conceptualization,Yes.,4,one major drawback type representation incomprehensibility human understand embed space crucial several important need include need debug embed compare alternative need detect bias hide,2023,December,"Keyphrase: ""Incomprehensibility and bias detection"""
emnlp2023,Knowledge-Augmented Language Model Verification,Yes.,5,yet lm often factually incorrect response give query since may inaccurate incomplete outdated may fail retrieve relevant give query may faithfully reflect retrieve text,2023,December,"Keyphrase: ""Poor factual accuracy"""
emnlp2023,Failures Pave the Way: Enhancing Large Language Models through Tuning-free Rule Accumulation,Yes.,5,however due inability capture relationship among sample frozen inevitably keep repeat similar mistake,2023,December,"Keyphrase: ""Limited relationship capture"""
emnlp2023,Ã¢â‚¬Å“Fifty Shades of BiasÃ¢â‚¬Â: Normative Ratings of Gender Bias in GPT Generated English Text,Yes.,4,increasingly gain humanlike fluency text generation gain nuance understanding bias imperative,2023,December,"Keyphrase: ""Biased understanding"""
emnlp2023,MAGNIFICo: Evaluating the In-Context Learning Ability of Large Language Models to Generalize to Novel Interpretations,Yes.,4,cutoff costly finetune repeatedly finding also highlight need improvement particularly interpret unfamiliar word compose multiple novel interpretation simultaneously example,2023,December,"Keyphrase: ""Difficulty in interpreting unfamiliar words"""
emnlp2023,Instructed Language Models with Retrievers Are Powerful Entity Linkers,Yes.,5,generative nature still make content suffer hallucination thus unsuitable entitycentric like entity link el require precise entity prediction base el remain persistent hurdle general,2023,December,"Keyphrase: ""Hallucination in generative content"""
emnlp2023,"The Past, Present and Better Future of Feedback Learning in Large Language Models for Subjective Human Preferences and Values",Yes.,4,unclear collect incorporate feedback way efficient effective unbiased especially highly subjective human preference value encourage well future feedback learn raise five unresolved conceptual practical challenge,2023,December,"Keyphrase: ""Challenges in feedback incorporation"""
emnlp2023,"The Troubling Emergence of Hallucination in Large Language Models - An Extensive Definition, Quantification, and Prescriptive Remediations",Yes.,5,issue hallucination parallelly emerge byproduct pose significant concern propose two solution strategy mitigate hallucination,2023,December,"Keyphrase: ""Hallucination issues"""
emnlp2023,The Skipped Beat: A Study of Sociopragmatic Understanding in LLMs for 64 Languages,Yes.,5,comprehensive analysis reveal exist opensource instruction tune still struggle understand sm across various close random baseline case also find although chatgpt outperform many still fall behind taskspecific finetune gap   sparrow score,2023,December,"Keyphrase: ""Struggles with task-specific fine-tuning"""
emnlp2023,Understanding the Effect of Model Compression on Social Bias in Large Language Models,Yes.,4,train selfsupervision vast corpora web text fit social bias text without intervention social bias persist modelÃ¢s prediction downstream lead representational harm,2023,December,"Keyphrase: ""Persistent social biases"""
emnlp2023,Critic-Driven Decoding for Mitigating Hallucinations in Data-to-text Generation,Yes.,5,hallucination text ungrounded wellknown problem neural datatotext generation,2023,December,"Keyphrase: ""Ungrounded hallucinations"""
emnlp2023,API-Bank: A Comprehensive Benchmark for Tool-Augmented LLMs,Yes.,4,however three pivotal question remain unanswered,2023,December,"Keyphrase: ""Unanswered pivotal questions"""
emnlp2023,Oolong: Investigating What Makes Transfer Learning Hard with Controlled Studies,Yes.,5,find largely recover syntacticstyle shift recover vocabulary misalignment embed matrix reinitialization even continued pretraining   million token,2023,December,"Keyphrase: ""Difficulty in recovering syntax and vocabulary alignment"""
emnlp2023,The Curious Case of Hallucinatory (Un)answerability: Finding Truths in the Hidden States of Over-Confident Large Language Models,Yes.,5,primary issue arise context management unanswerable query often hallucinatory behavior due overconfidence,2023,December,"Keyphrase: ""Overconfidence leading to hallucinatory behavior"""
emnlp2023,ROBBIE: Robust Bias Evaluation of Large Generative Language Models,Yes.,4,must develop comprehensive enough tool measure improve fairness testing dataset potentially help characterize bias fully explore frequency demographic term common pretraine corpora may relate bias,2023,December,"Keyphrase: ""Limited fairness testing and bias characterization"""
emnlp2023,Adapting Language Models to Compress Contexts,Yes.,5,transformerbase lm powerful widelyapplicable tool usefulness constrain finite context window expensive computational cost process long text document,2023,December,"Keyphrase: ""Limited context window"""
emnlp2023,Large Language Models are Temporal and Causal Reasoners for Video Question Answering,Yes.,5,however prior often cause suboptimal videoqa lead overrely question ie linguistic bias ignore visual content also know Ã¢ungrounded guessesÃ¢ Ã¢hallucinationsÃ¢,2023,December,"Keyphrase: ""Linguistic bias and ungrounded guesses"""
emnlp2023,Preserving Privacy Through Dememorization: An Unlearning Technique For Mitigating Memorization Risks In Language Models,Yes.,5,show ability memorize reproduce portion training prompt adversary prior research focus address memorization issue prevent verbatim replication technique like unlearning preprocesse however limitation regard number protect sample limited privacy type potentially lowerquality generative,2023,December,"Keyphrase: ""Memorization and privacy concerns"""
emnlp2023,Noisy Exemplars Make Large Language Models More Robust: A Domain-Agnostic Behavioral Analysis,Yes.,5,find sensitive certain perturbation replace word synonym,2023,December,"Keyphrase: ""Sensitivity to word perturbations"""
emnlp2023,Can Large Language Models Capture Dissenting Human Voices?,Yes.,5,show exhibit limited ability solve nli simultaneously fail capture human disagreement distribution inference human alignment performance plunge even sample high human disagreement level raise concern natural understand nlu ability representativeness human population,2023,December,"Keyphrase: ""Limited ability in capturing human disagreement"""
emnlp2023,Merging Generated and Retrieved Knowledge for Open-Domain QA,Yes.,4,retrieve passage give source know suffer insufficient coverage tend hallucinate content conflict retrieve,2023,December,"Keyphrase: ""Insufficient coverage and tendency to hallucinate"""
emnlp2023,Ignore This Title and HackAPrompt: Exposing Systemic Vulnerabilities of LLMs Through a Global Prompt Hacking Competition,Yes.,5,deployment increasingly plague prompt injection jailbreake collectively prompt hacking manipulate ignore original instruction instead follow potentially malicious one,2023,December,"Keyphrase: ""Vulnerability to manipulation"""
emnlp2023,Prompting is not a substitute for probability measurements in large language models,Yes.,5,broadly find llmsÃ¢ metalinguistic judgment inferior quantity directly derive representation furthermore consistency get bad prompt query diverge direct measurement nextword probability,2023,December,"Keyphrase: ""Inferior metalinguistic judgment"""
emnlp2023,"Fine-tuned LLMs Know More, Hallucinate Less with Few-Shot Sequence-to-Sequence Semantic Parsing over Wikidata",Yes.,5,many question correctly also hallucinate give wrong,2023,December,"Keyphrase: ""Hallucinations and incorrect answers"""
emnlp2023,Beyond Factuality: A Comprehensive Evaluation of Large Language Models as Knowledge Generators,Yes.,4,community concern abound regard factuality potential implication use uncensored surprisingly study reveal factuality even low significantly hinder downstream,2023,December,"Keyphrase: ""Factuality concerns"""
emnlp2023,Compressing Context to Enhance Inference Efficiency of Large Language Models,Yes.,5,however face challenge manage long document extended conversation due significantly increase computational requirement memory inference time potential context truncation exceed llmÃ¢s fix context length,2023,December,"Keyphrase: ""Challenges with long documents and extended conversations"""
emnlp2023,Can You Follow Me? Testing Situational Understanding for ChatGPT,Yes.,5,previous work identify certain su limitation nonchatbot find despite fundamental simplicity modelÃ¢s performance reflect inability retain correct environment state across time performance degradation largely chatgpt nonpersistent incontext memory although access full dialogue history susceptible,2023,December,"Keyphrase: ""Memory limitations"""
emnlp2023,HaluEval: A Large-Scale Hallucination Evaluation Benchmark for Large Language Models,Yes.,5,chatgpt prone hallucination ie content conflict source verify factual moreover exist face great challenge recognize hallucination text,2023,December,"Keyphrase: ""Hallucination and factual inaccuracies"""
emnlp2023,Enabling Large Language Models to Generate Text with Citations,Yes.,5,prone hallucination current considerable room improvementÃ¢for example eli dataset even good lack complete citation support   time,2023,December,"Keyphrase: ""Incomplete citation support"""
emnlp2023,Counting the Bugs in ChatGPTÃ¢â‚¬â„¢s Wugs: A Multilingual Investigation into the Morphological Capabilities of a Large Language Model,Yes.,5,find chatgpt massively underperform purposebuilt particularly english overall resultsÃ¢through lens morphologyÃ¢cast new light linguistic capability chatgpt suggest claim humanlike skill premature misleading,2023,December,"Keyphrase: ""Underperformance in specialized tasks"""
emnlp2023,MAF: Multi-Aspect Feedback for Improving Reasoning in Large Language Models,Yes.,5,however come natural reasoning lm still face challenge hallucination incorrect intermediate reasoning step make mathematical error,2023,December,"Keyphrase: ""Challenges in natural reasoning"""
emnlp2023,Do Language Models Have a Common Sense regarding Time? Revisiting Temporal Commonsense Reasoning in the Era of Large Language Models,Yes.,5,finding reveal nuance depiction capability limitation within temporal reasoning offer comprehensive reference future research pivotal domain,2023,December,"Keyphrase: ""Limitation in temporal reasoning"""
emnlp2023,Evaluation of African American Language Bias in Natural Language Generation,Yes.,4,present evidence dialectal bias six pretraine performance gap,2023,December,"Keyphrase: ""Dialectal bias"""
emnlp2023,An Investigation of LLMsÃ¢â‚¬â„¢ Inefficacy in Understanding Converse Relations,Yes.,5,suggest often resort shortcut learning still face challenge propose benchmark,2023,December,"Keyphrase: ""Reliance on shortcuts"""
emnlp2023,HiddenTables and PyQTax: A Cooperative Game and Dataset For TableQA to Ensure Scale and Data Privacy Across a Myriad of Taxonomies,Yes.,5,myriad different face common challenge contextually analyze table questionanswere challenge engender   finite context window table   multifacete discrepancy amongst tokenization pattern cell boundary   various limitation stem confidentiality process use external,2023,December,"Keyphrase: ""Limited contextual analysis"""
emnlp2023,"Speak, Memory: An Archaeology of Books Known to ChatGPT/GPT-4",Yes.,4,ability memorize unknown set book complicate assessment measurement validity cultural analytic contaminate test show much well memorized book nonmemorize book downstream,2023,December,"Keyphrase: ""Over-reliance on memorization"""
emnlp2023,Copyright Violations and Large Language Models,Yes.,5,work explore issue copyright violation lens verbatim memorization focus possible redistribution copyright text,2023,December,"Keyphrase: ""Risk of copyright violation"""
emnlp2023,Symbolic Planning and Code Generation for Grounded Dialogue,Yes.,5,limit applicability ground taskoriented dialogue difficult steer toward objective fail handle novel grounding,2023,December,"Keyphrase: ""Difficulty in handling novel grounding"""
emnlp2023,Have LLMs Advanced Enough? A Challenging Problem Solving Benchmark For Large Language Models,Yes.,5,typical failure mode gpt good error algebraic manipulation difficulty ground abstract concept mathematical equation accurately failure retrieve relevant domainspecific concept,2023,December,"Keyphrase: ""Struggles with domain-specific concepts"""
emnlp2023,Federated Learning of Large Language Models with Parameter-Efficient Prompt Tuning and Adaptive Optimization,Yes.,4,training process generally incur update significant parameter limit applicability fl technique tackle real scenario prompt tuning significantly reduce number parameter update either incur performance degradation low training efficiency decentralized generally nonindependent identically distribute,2023,December,"Keyphrase: ""Limited training efficiency"""
emnlp2023,Active Retrieval Augmented Generation,Yes.,5,despite remarkable ability lm comprehend tendency hallucinate create factually inaccurate,2023,December,"Keyphrase: ""Factually inaccurate hallucinations"""
emnlp2023,Reasoning with Language Model is Planning with World Model,Yes.,5,however still struggle problem easy human action plan execute complex math logical reasoning due llmsÃ¢ absence internal world predict world states eg environment status variable value simulate,2023,December,"Keyphrase: ""Limited logical reasoning"""
emnlp2023,SOUL: Towards Sentiment and Opinion Understanding of Language,Yes.,5,experimental indicate soul challenging small performance gap   compare human performance furthermore evaluation conduct human expert gpt highlight limitation small reasoningbase justification,2023,December,"Keyphrase: ""Limited reasoning and justification"""
emnlp2023,Detecting and Mitigating Hallucinations in Multilingual Summarisation,Yes.,5,hallucination pose significant challenge reliability neural abstractive summarisation assess broad range multilingual find tend hallucinate often different english,2023,December,"Keyphrase: ""Hallucination in abstractive summarization"""
emnlp2023,EasyQuant: An Efficient Data-free Quantization Algorithm for LLMs,Yes.,5,however expensive computation high memory requirement prohibitive deployment quantize calibrate use sample training might affect generalization quantize unknown case,2023,December,"Keyphrase: ""High computational cost and memory requirements"""
emnlp2023,EpiK-Eval: Evaluation for Language Models as Epistemic Models,Yes.,5,evaluation across various reveal significant weakness domain contend shortcoming stem intrinsic nature prevail training objective,2023,December,"Keyphrase: ""Weakness in domain adaptation"""
emnlp2023,SummEdits: Measuring LLM Ability at Factual Reasoning Through The Lens of Summarization,Yes.,5,struggle summedit performance close random chance bestperforme gpt still   estimate human performance highlight gap llmsÃ¢ ability reason fact detect inconsistency occur,2023,December,"Keyphrase: ""Limited reasoning ability"""
emnlp2023,Do All Languages Cost the Same? Tokenization in the Era of Commercial Language Models,Yes.,4,show evidence speaker number support overcharge obtain poor,2023,December,"Keyphrase: ""Lack of context understanding"""
emnlp2023,Appraising the Potential Uses and Harms of LLMs for Medical Systematic Reviews,Yes.,5,however sometimes inaccurate potentially mislead text hallucination omission healthcare make unusable well dangerous bad also raise concern regard confidently compose inaccurate potential downstream harm include decrease accountability proliferation lowquality review,2023,December,"Keyphrase: ""Inaccuracies and potential dangers"""
emnlp2023,Large Language Models Meet Open-World Intent Discovery and Recognition: An Evaluation of ChatGPT,Yes.,5,summarize discuss challenge face include cluster domainspecific understanding crossdomain incontext learn scenario,2023,December,"Keyphrase: ""Domain-specific understanding challenges"""
emnlp2023,Improving Diversity of Demographic Representation in Large Language Models via Collective-Critiques and Self-Voting,Yes.,5,crucial challenge generative diversity,2023,December,"Keyphrase: ""Lack of generative diversity"""
emnlp2023,Hidding the Ghostwriters: An Adversarial Evaluation of AI-Generated Student Essay Detection,Yes.,4,utilization carry inherent risk include limit plagiarism dissemination fake news issue educational exercise exist detector easily circumvent use straightforward automatic adversarial attack,2023,December,"Keyphrase: ""Vulnerability to adversarial attacks"""
emnlp2023,Synthetic Data Generation with Large Language Models for Text Classification: Potential and Limitations,Yes.,5,effectiveness llmgenerate synthetic support training inconsistent across different classification subjectivity level instance level negatively associate performance train synthetic,2023,December,"Keyphrase: ""Inconsistent synthetic training effectiveness"""
emnlp2023,Learning from Mistakes via Cooperative Study Assistant for Large Language Models,Yes.,5,however feedback often inaccurate thereby limit benefit,2023,December,"Keyphrase: ""Inaccurate feedback"""
emnlp2023,Conceptor-Aided Debiasing of Large Language Models,Yes.,5,pretraine reflect inherent social bias training corpus many propose mitigate issue often fail debias sacrifice accuracy,2023,December,"Keyphrase: ""Inherent social bias"""
emnlp2023,CoMPosT: Characterizing and Evaluating Caricature in LLM Simulations,Yes.,5,grow concern simulation flatten caricature persona aim simulate fail capture multidimensionality people perpetuate stereotype,2023,December,"Keyphrase: ""Simplistic caricatures"""
emnlp2023,An Empirical Study of Translation Hypothesis Ensembling with Large Language Models,Yes.,4,become onefitsmany solution sometimes hallucinate produce unreliable,2023,December,"Keyphrase: ""Unreliable hallucinations"""
emnlp2023,FActScore: Fine-grained Atomic Evaluation of Factual Precision in Long Form Text Generation,Yes.,5,evaluate factuality longform text lm nontrivial   generation often contain mixture support unsupported piece information make binary judgment quality inadequate   human evaluation timeconsume,2023,December,"Keyphrase: ""Mixed factual accuracy"""
emnlp2023,Calc-X and Calcformers: Empowering Arithmetical Chain-of-Thought through Interaction with Symbolic Systems,Yes.,5,notoriously inclined make factual error require arithmetic computation,2023,December,"Keyphrase: ""Factual errors in arithmetic computation"""
emnlp2023,StereoMap: Quantifying the Awareness of Human-like Stereotypes in Large Language Models,Yes.,4,observe encode perpetuate harmful association present training study contribute understanding perceive represent social group shed light potential bias perpetuation harmful association,2023,December,"Keyphrase: ""Perpetuation of harmful associations"""
emnlp2023,Large Language Models: The Need for Nuance in Current Debates and a Pragmatic Perspective on Understanding,Yes.,5,critically assess three point recur critique capacity,2023,December,"Keyphrase: ""Limited capacity for critical analysis"""
emnlp2023,Question Answering as Programming for Solving Time-Sensitive Questions,Yes.,5,experiment reveal aforementioned problem still pose significant challenge exist attribute llmsÃ¢ inability rigorous reasoning base surfacelevel text semantic,2023,December,"Keyphrase: ""Limited reasoning ability"""
emnlp2023,Context Compression for Auto-regressive Transformers with Sentinel Tokens,Yes.,5,quadratic complexity attention module make gradually become bulk compute transformerbase generation moreover excessive keyvalue cache arise deal long also bring severe issue memory footprint inference latency,2023,December,"Keyphrase: ""Quadratic attention complexity"""
emnlp2023,MoPe: Model Perturbation based Privacy Attacks on Language Models,Yes.,5,recent work show unintentionally leak sensitive information present training,2023,December,"Keyphrase: ""Sensitive information leakage"""
emnlp2023,Empower Nested Boolean Logic via Self-Supervised Curriculum Learning,Yes.,5,find pretraine even include behave like random selector face multinested boolean logic human handle ease,2023,December,"Keyphrase: ""Lack of logical reasoning"""
emnlp2023,KCTS: Knowledge-Constrained Tree Search Decoding with Token-Level Hallucination Detection,Yes.,5,demonstrate remarkable humanlevel natural generation capability however potential misinformation often call hallucination problem pose significant risk deployment,2023,December,"Keyphrase: ""Misinformation and hallucination risk"""
emnlp2023,Language Models with Rationality,Yes.,5,lack interpretability grow impediment widespread use resolve inconsistency may exist,2023,December,"Keyphrase: ""Lack of interpretability"""
emnlp2023,Mitigating Temporal Misalignment by Discarding Outdated Facts,Yes.,5,able retain vast amount world see pretraine prone go date nontrivial update,2023,December,"Keyphrase: ""Difficulty in staying up-to-date"""
emnlp2023,FANToM: A Benchmark for Stress-testing Machine Theory of Mind in Interactions,Yes.,5,show fantom challenge stateoftheart significantly bad human even chainofthought reasoning finetune,2023,December,"Keyphrase: ""Challenges in chain-of-thought reasoning"""
emnlp2023,Dr ChatGPT tell me what I want to hear: How different prompts impact health answer correctness,Yes.,5,reveal pass prompt bias detriment correctness,2023,December,"Keyphrase: ""Prompt bias affecting correctness"""
emnlp2023,CRAB: Assessing the Strength of Causal Relationships Between Real-world Events,Yes.,5,find bad causal reasoning event derive complex causal structure compare simple linear causal chain,2023,December,"Keyphrase: ""Limited causal reasoning"""
emnlp2023,Hallucination Detection for Generative Large Language Models by Bayesian Sequential Estimation,Yes.,5,propensity inaccurate nonfactual content term Ã¢Å“hallucinationsÃ¢ remain significant challenge,2023,December,"Keyphrase: ""Inaccurate hallucinations"""
emnlp2023,Consistency Analysis of ChatGPT,Yes.,5,prompt design fewshot learning employ unlikely ultimate solution resolve inconsistency issue,2023,December,"Keyphrase: ""Limited few-shot learning capabilities"""
emnlp2023,Mitigating Societal Harms in Large Language Models,Yes.,5,provide overview potential social issue generation include toxicity social biases misinformation factual inconsistency privacy violation,2023,December,"Keyphrase: ""Social issues and biases"""
emnlp2023,H2O Open Ecosystem for State-of-the-art Large Language Models,Yes.,5,represent revolution ai however also pose many significant risk presence biased private copyright harmful text,2023,December,"Keyphrase: ""Biased and harmful content"""
emnlp2023,FLEEK: Factual Error Detection and Correction with Evidence Retrieved from External Knowledge,Yes.,5,llmsÃ¢ inability attribute claim external tendency hallucinate make difficult rely response,2023,December,"Keyphrase: ""Difficulty in attributing claims"""
emnlp2023,CLEVA: Chinese Language Models EVAluation Platform,Yes.,4,absence comprehensive chinese benchmark thoroughly assess modelÃ¢s performance unstandardized incomparable prompting procedure prevalent risk contamination pose major challenge current evaluation chinese,2023,December,"Keyphrase: ""Lack of standardized evaluation"""
emnlp2023,LM-Polygraph: Uncertainty Estimation for Language Models,Yes.,5,however significant challenge arise often Ã¢Å“hallucinateÃ¢ ie fabricate fact without provide user apparent mean discern veracity statement,2023,December,"Keyphrase: ""Fabricating facts"""
emnlp2023,CarExpert: Leveraging Large Language Models for In-Car Conversational Question Answering,Yes.,5,leverage domainspecific question suffer severe limitation tend hallucinate due training collection time use offtheshelf complex user utterance wrong retrieval retrievalaugmente generation furthermore due,2023,December,"Keyphrase: ""Hallucination in domain-specific questions"""
emnlp2023,DELPHI: Data for Evaluating LLMsÃ¢â‚¬â„¢ Performance in Handling Controversial Issues,Yes.,4,dataset present challenge concern recency safety fairness bias,2023,December,"Keyphrase: ""Challenges with recency, safety, fairness, and bias"""
naacl2024,Assessing Logical Puzzle Solving in Large Language Models: Insights from a Minesweeper Case Study,Yes.,5,despite advancement remain open question whether fundamentally capable reasoning planning primarily rely recall synthesize information training experiment include trial advanced gpt indicate possess foundational ability require struggle integrate coherent,2024,June,"Keyphrase: ""Limited reasoning and planning capabilities"""
naacl2024,Measuring and Improving Chain-of-Thought Reasoning in Vision-Language Models,Yes.,5,even bestperforme unable demonstrate strong visual reasoning capability consistency indicate substantial effort require enable vlm visual reasoning systematically consistently human,2024,June,"Keyphrase: ""Weak visual reasoning"""
naacl2024,Head-to-Tail: How Knowledgeable are Large Language Models (LLMs)? A.K.A. Will LLMs Replace Knowledge Graphs?,Yes.,5,show exist still far perfect term grasp factual especially fact torsototail entity,2024,June,"Keyphrase: ""Limited factual understanding"""
naacl2024,Embrace Divergence for Richer Insights: A Multi-document Summarization Benchmark and a Case Study on Summarizing Diverse Information from News Articles,Yes.,5,analysis suggest despite extraordinary capability singledocument summarization propose remain complex challenge mainly due limited coverage gpt able cover   diverse information average,2024,June,"Keyphrase: ""Limited coverage"""
naacl2024,Assessing Factual Reliability of Large Language Model Knowledge,Yes.,5,factual typically evaluate use accuracy yet metric capture vulnerability hallucinationinduce factor like prompt context variability,2024,June,"Keyphrase: ""Vulnerability to hallucination-inducing factors"""
naacl2024,A Closer Look at the Self-Verification Abilities of Large Language Models in Logical Reasoning,Yes.,5,despite significant advancement make still struggle complex logical reasoning problem main finding suggest exist could struggle identify fallacious reasoning step accurately may fall short guarantee validity selfverification,2024,June,"Keyphrase: ""Struggles with complex logical reasoning"""
naacl2024,On Large Language ModelsÃ¢â‚¬â„¢ Hallucination with Regard to Known Facts,Yes.,5,successful factoid question also prone hallucination investigate phenomenon possess correct yet still hallucinate perspective inference dynamic,2024,June,"Keyphrase: ""Hallucination tendency"""
naacl2024,"Language Models Hallucinate, but May Excel at Fact Verification",Yes.,5,frequently Ã¢Å“hallucinateÃ¢ nonfactual analyze reliance highquality evidence well deficiency robustness generalization ability,2024,June,"Keyphrase: ""Nonfactual hallucinations and poor generalization"""
naacl2024,Ensuring Safe and High-Quality Outputs: A Guideline Library Approach for Language Models,Yes.,5,exhibit impressive capability also present risk biased content generation privacy issue,2024,June,"Keyphrase: ""Biased content generation"""
naacl2024,"E5: Zero-shot Hierarchical Table Analysis using Augmented LLMs via Explain, Extract, Execute, Exhibit and Extrapolate",Yes.,4,application hierarchical table constrain reliance manually curate exemplar modelÃ¢s token capacity limitation,2024,June,"Keyphrase: ""Token capacity limitation"""
naacl2024,"S3Eval: A Synthetic, Scalable, Systematic Evaluation Suite for Large Language Model",Yes.,5,rapid development lead great stride capability like longcontext understanding reasoning however able process long context become challenging evaluate whether acquire certain capability since length,2024,June,"Keyphrase: ""Challenges in processing long contexts"""
naacl2024,MMC: Advancing Multimodal Chart Understanding with Large-scale Instruction Tuning,Yes.,4,extensive experiment mmcbenchmark reveal limitation exist lmms correctly interpret chart even recent gptv,2024,June,"Keyphrase: ""Difficulty in interpreting charts"""
naacl2024,Large Language Models Help Humans Verify Truthfulness Ã¢â‚¬â€œ Except When They Are Convincingly Wrong,Yes.,5,user read explanation significantly efficient use search engine achieve similar accuracy however overrely explanation wrong natural explanation may reliable replacement read retrieve,2024,June,"Keyphrase: ""Overreliance on unreliable explanations"""
naacl2024,SELF-GUARD: Empower the LLM to Safeguard Itself,Yes.,4,safety training involve finetune adversarial sample activate llmÃ¢s capability jailbreak however always effective counter new attack often lead potential performance degradation safeguard hand use,2024,June,"Keyphrase: ""Vulnerability to adversarial attacks"""
naacl2024,MART: Improving LLM Safety with Multi-round Automatic Red-Teaming,Yes.,4,redteame common practice mitigate unsafe behavior involve thoroughly assess identify potential flaw address responsible accurate response effective manual redteame costly exist automatic redteame typically discover safety risk,2024,June,"Keyphrase: ""Limited ability to mitigate unsafe behavior"""
naacl2024,Are Multilingual LLMs Culturally-Diverse Reasoners? An Investigation into Multicultural Proverbs and Sayings,Yes.,5,experiment reveal,2024,June,Keyphrase: Lack of specificity
naacl2024,The Colorful Future of LLMs: Evaluating and Improving LLMs as Emotional Supporters for Queer Youth,Yes.,5,however tend generic empathetic enough lack personalization nonreliable potentially harmful advice,2024,June,"Keyphrase: ""Lack of personalization"""
naacl2024,ReTA: Recursively Thinking Ahead to Improve the Strategic Reasoning of Large Language Models,Yes.,5,experimental demonstrate exist stateoftheart reasoning scheme largely ineffective strategic reasoning,2024,June,"Keyphrase: ""Ineffective strategic reasoning"""
naacl2024,"First Tragedy, then Parse: History Repeats Itself in the New Era of Large Language Models",Yes.,4,argue disparity scale transient researcher work reduce rather hardware still bottleneck many application meaningful realistic evaluation still open problem still room speculative approach,2024,June,"Keyphrase: ""Lack of realistic evaluation"""
naacl2024,How Trustworthy are Open-Source LLMs? An Assessment under Malicious Demonstrations Shows their Vulnerabilities,Yes.,5,however still limited understanding trustworthiness scrutinize across eight different aspect include toxicity stereotype ethic hallucination fairness sycophancy privacy robustness adversarial demonstration analysis reveal superior performance general nlp always great trustworthiness fact,2024,June,"Keyphrase: ""Limited trustworthiness"""
naacl2024,Paraphrase and Solve: Exploring and Exploiting the Impact of Surface Form on Mathematical Reasoning in Large Language Models,Yes.,5,find subtle alteration surface form significantly impact distribution solve rate expose modelÃ¢s lack robustness sensitivity surface form reason complex problem,2024,June,"Keyphrase: ""Lack of robustness to subtle alterations"""
naacl2024,Do Localization Methods Actually Localize Memorized Data in LLMs? A Tale of Two Benchmarks,Yes.,4,localization never systematically directly evaluate even successful identify neuron specific single memorized sequence,2024,June,"Keyphrase: ""Limited localization evaluation"""
naacl2024,Confronting LLMs with Traditional ML: Rethinking the Fairness of Large Language Models in Tabular Classifications,Yes.,5,show exhibit harmful social bias reflect stereotype inequality present society tend inherit social bias training significantly impact fairness tabular classification social,2024,June,"Keyphrase: ""Harmful social bias"""
naacl2024,Ada-LEval: Evaluating long-context LLMs with length-adaptable benchmarks,Yes.,5,evaluation demonstrate limitation current especially ultralongcontext setting,2024,June,"Keyphrase: ""Limitation in ultralong context setting"""
naacl2024,TRAQ: Trustworthy Retrieval Augmented Question Answering via Conformal Prediction,Yes.,5,frequently incorrect response base madeup fact call hallucination,2024,June,"Keyphrase: ""Fabricated responses"""
naacl2024,On-the-fly Definition Augmentation of LLMs for Biomedical NER,Yes.,5,despite general capability still struggle biomedical ner difficult due presence specialized terminology lack training,2024,June,"Keyphrase: ""Struggles with specialized terminology"""
naacl2024,"This Land is Your, My Land: Evaluating Geopolitical Bias in Language Models through Territorial Disputes",Yes.,5,show recall certain geographical inconsistently query different languagesÃ¢a phenomenon term geopolitical bias use propose metric discover numerous inconsistency respond different highlight brittle tailor response depend cue interaction context,2024,June,"Keyphrase: ""Geopolitical bias and inconsistency"""
naacl2024,Towards Improved Multi-Source Attribution for Long-Form Answer Generation,Yes.,5,current struggle attribution longform response require reasoning multiple evidence source,2024,June,"Keyphrase: ""Limited reasoning with multiple evidence sources"""
naacl2024,Can Knowledge Graphs Reduce Hallucinations in LLMs? : A Survey,Yes.,5,contemporary prone produce hallucination stem mainly gap within,2024,June,"Keyphrase: ""Hallucination tendency"""
naacl2024,LM-Infinite: Zero-Shot Extreme Length Generalization for Large Language Models,Yes.,5,todayÃ¢s typically train short text segment eg k tokens due quadratic complexity transformer architecture performance suffer drastically long encounter training substantially limit application realworld,2024,June,"Keyphrase: ""Limitation in handling long text segments"""
naacl2024,Enhancing Contextual Understanding in Large Language Models through Contrastive Decoding,Yes.,5,tend inadequately integrate context text generation rely excessively encode prior parameter potentially text factual inconsistency contextually unfaithful content,2024,June,"Keyphrase: ""Contextual inconsistency"""
naacl2024,Fixing Rogue Memorization in Many-to-One Multilingual Translators of Extremely-Low-Resource Languages by Rephrasing Training Samples,Yes.,5,however also find manytoone multilingual tendency learn rogue strategy store string training structure retrieve instead actual translation,2024,June,"Keyphrase: ""Rogue translation strategy"""
naacl2024,Flames: Benchmarking Value Alignment of LLMs in Chinese,Yes.,4,still significant gap llmsÃ¢ deep alignment human value achieve genuine harmlessness finding indicate evaluate demonstrate relatively poor performance flame particularly safety fairness dimension,2024,June,"Keyphrase: ""Poor alignment with human values"""
naacl2024,Effective Long-Context Scaling of Foundation Models,Yes.,5,delve llamaÃ¢s position encoding discuss key limitation long,2024,June,"Keyphrase: ""Limited position encoding"""
naacl2024,Aligning as Debiasing: Causality-Aware Alignment via Reinforcement Learning with Interventional Feedback,Yes.,5,often biased contain offensive toxic stereotypical text,2024,June,"Keyphrase: ""Biased and toxic text"""
naacl2024,Fake Alignment: Are LLMs Really Aligned Well?,Yes.,5,study investigate underexplored issue evaluation namely substantial discrepancy performance multiplechoice question openende question,2024,June,"Keyphrase: ""Discrepancy in evaluation performance"""
naacl2024,You donÃ¢â‚¬â„¢t need a personality test to know these models are unreliable: Assessing the Reliability of Large Language Models on Psychometric Instruments,Yes.,5,experiment   different reveal even simple perturbation significantly downgrade modelÃ¢s questionanswere ability low negation consistency,2024,June,"Keyphrase: ""Low negation consistency"""
naacl2024,MacGyver: Are Large Language Models Creative Problem Solvers?,Yes.,5,contrast expose variety specialized attempt broad problem fail propose physicallyinfeasible action finally provide detailed error analysis demonstrate potential enhance problemsolving ability novel prompt technique iterative step,2024,June,"Keyphrase: ""Limited problem-solving ability"""
naacl2024,Enhancing Large Language Models Against Inductive Instructions with Dual-critique Prompting,Yes.,5,uncover universal vulnerability among process inductive instruction,2024,June,"Keyphrase: ""Limited inductive instruction"""
naacl2024,XSTest: A Test Suite for Identifying Exaggerated Safety Behaviours in Large Language Models,Yes.,5,without proper safeguard readily follow malicious instruction toxic content use test suite highlight systematic failure mode stateoftheart well general challenge build safe,2024,June,"Keyphrase: ""Vulnerability to malicious instructions"""
naacl2024,Understanding the Capabilities and Limitations of Large Language Models for Cultural Commonsense,Yes.,5,significant discrepancy performance test culturespecific commonsense different culture llmsÃ¢ general commonsense capability affect cultural context use query impact performance culturalrelate,2024,June,"Keyphrase: ""Cultural bias in commonsense understanding"""
naacl2024,Do Large Language Models Rank Fairly? An Empirical Study on the Fairness of LLMs as Rankers,Yes.,4,however fairness remain largely unexplored analysis delve handle query document relate attribute aim uncover bias ranking algorithm,2024,June,"Keyphrase: ""Unexplored fairness issues"""
naacl2024,RESPROMPT: Residual Connection Prompting Advances Multi-Step Reasoning in Large Language Models,Yes.,5,chainofthought cot impressively unlock reasoning potential yet fall short tackle problem require multiple reasoning step limitation arise complex nature multistep reasoning process,2024,June,"Keyphrase: ""Struggles with multi-step reasoning"""
naacl2024,Effective Large Language Model Adaptation for Improved Grounding and Citation Generation,Yes.,4,however one major issue towards widespread deployment real world hallucinate factual,2024,June,"Keyphrase: ""Hallucination and factual inaccuracies"""
naacl2024,Global Gallery: The Fine Art of Painting Culture Portraits through Multilingual Instruction Tuning,Yes.,4,also uncover inconsistency bias particularly nonwestern culture,2024,June,"Keyphrase: ""Inconsistency and bias in non-Western cultures"""
naacl2024,ContraDoc: Understanding Self-Contradictions in Documents with Large Language Models,Yes.,5,gpt good outperform human find still unreliable struggle selfcontradiction require nuance context,2024,June,"Keyphrase: ""Unreliable self-contradiction"""
naacl2024,A Survey of Confidence Estimation and Calibration in Large Language Models,Yes.,4,despite impressive performance unreliable due factual error generation outline challenge summarize recent technical advancement confidence estimation calibration,2024,June,"Keyphrase: ""Unreliable factual error generation"""
naacl2024,"Attacks, Defenses and Evaluations for LLM Conversation Safety: A Survey",Yes.,4,however risk misuse harmful response raise serious societal concern spur recent research conversation safety,2024,June,"Keyphrase: ""Risk of harmful responses"""
naacl2024,MindÃ¢â‚¬â„¢s Mirror: Distilling Self-Evaluation Capability and Comprehensive Thinking from Large Language Models,Yes.,4,massive scale computational demand present formidable challenge consider practical deployment resourceconstraine environment risk distilled slm may still inherit flawed reasoning hallucination,2024,June,"Keyphrase: ""Computational demands and flawed reasoning"""
naacl2024,Beyond Performance: Quantifying and Mitigating Label Bias in LLMs,Yes.,4,however recent work reveal also exhibit label biasÃ¢an undesirable preference toward predict certain investigation reveal substantial label bias debiase attempt emphasize label bias prediction remain barrier reliability,2024,June,"Keyphrase: ""Label bias"""
naacl2024,Instructing Large Language Models to Identify and Ignore Irrelevant Conditions,Yes.,5,however seriously confuse irrelevant condition low accuracy,2024,June,"Keyphrase: ""Confusion and low accuracy"""
naacl2024,Knowing What LLMs DO NOT Know: A Simple Yet Effective Self-Detection Method,Yes.,5,recent literature reveal hallucinate intermittently impede reliability utilization,2024,June,"Keyphrase: ""Intermittent hallucinations"""
naacl2024,Are Large Language Model Temporally Grounded?,Yes.,5,generally find lag significantly behind human performance well smallscale specialise lm crucially struggle selfconsistency display incoherent behaviour least   prediction moreover public instruction,2024,June,"Keyphrase: ""Incoherent behavior and lagging behind human performance"""
naacl2024,R-Tuning: Instructing Large Language Models to Say Ã¢â‚¬ËœI DonÃ¢â‚¬â„¢t KnowÃ¢â‚¬â„¢,Yes.,5,predominant issue propensity nonexistent fact concern term hallucination question parametric try make something fail indicate lack,2024,June,"Keyphrase: ""Hallucination propensity"""
naacl2024,LeanReasoner: Boosting Complex Logical Reasoning with Lean,Yes.,5,often struggle complex logical reasoning due logical inconsistency inherent difficulty reasoning,2024,June,"Keyphrase: ""Struggles with logical reasoning"""
naacl2024,UICoder: Finetuning Large Language Models to Generate User Interface Code through Automated Feedback,Yes.,4,many struggle consistently ui code compile produce visually relevant design,2024,June,"Keyphrase: ""Struggles with generating visually relevant design"""
naacl2024,Deceptive Semantic Shortcuts on Reasoning Chains: How Far Can Models Go without Hallucination?,Yes.,5,despite high performance across numerous benchmark recent research unveil suffering hallucination unfaithful reasoning experiment show exist follow correct reasoning path resist attempt greedy shortcut gpt achieve   accuracy,2024,June,"Keyphrase: ""Unfaithful reasoning"""
naacl2024,Learning to Compress Prompt in Natural Language Formats,Yes.,5,great process multiple natural processing ability constrain inferior performance long context slow inference speed high cost compute,2024,June,"Keyphrase: ""Slow inference speed and high compute cost"""
naacl2024,Branch-Solve-Merge Improves Large Language Model Evaluation and Generation,Yes.,5,however performance fall short due modelÃ¢s lack coherence inability plan decompose problem,2024,June,"Keyphrase: ""Lack of coherence and planning ability"""
naacl2024,Evaluating the Deductive Competence of Large Language Models,Yes.,5,test limit ability solve problem conventional form overall suggest unique reasoning bias partially predict human reasoning performance humangenerate corpora inform,2024,June,"Keyphrase: ""Limited problem-solving ability"""
naacl2024,Large Human Language Models: A Need and the Challenges,Yes.,4,time nlp become heavily reliant author bring fore range design consideration challenge term human aspect capture represent strategy pursue,2024,June,Keyphrase: Lack of human aspect representation
naacl2024,Hallucination Diversity-Aware Active Learning for Text Summarization,Yes.,5,show propensity hallucinate ie text factually incorrect unsupported exist alleviate hallucination typically require costly human annotation identify correct hallucination,2024,June,"Keyphrase: ""Factually incorrect hallucinations"""
naacl2024,Investigating Data Contamination in Modern Benchmarks for Large Language Models,Yes.,5,recent observation underscore disparity inflated benchmark score actual performance raise concern potential contamination evaluation benchmark,2024,June,"Keyphrase: ""Inflated benchmark scores"""
naacl2024,IndiBias: A Benchmark Dataset to Measure Social Biases in Language Models for Indian Context,Yes.,4,pervasive influence social bias spark need benchmark dataset capture evaluate bias observe exhibit bias across majority intersectional group,2024,June,"Keyphrase: ""Pervasive social bias"""
naacl2024,Revisiting Zero-Shot Abstractive Summarization in the Era of Large Language Models from the Perspective of Position Bias,Yes.,5,position bias capture tendency unfairly prioritize information certain part text lead undesirable behavior,2024,June,"Keyphrase: ""Position bias prioritization"""
naacl2024,Struc-Bench: Are Large Language Models Good at Generating Complex Structured Tabular Data?,Yes.,4,produce complex structured tabular remain challenge indepth error analysis create ability map across six dimension coverage format reasoning comprehension pragmatic hallucination highlight area future enhancement suggest forthcoming research trajectory,2024,June,"Keyphrase: ""Challenges with structured data comprehension"""
naacl2024,Advancing the Robustness of Large Language Models through Self-Denoised Smoothing,Yes.,5,although achieve significant success vulnerability adversarial perturbation include recent jailbreak attack raise considerable concern,2024,June,"Keyphrase: ""Vulnerability to adversarial attacks"""
naacl2024,Lost in Space: Probing Fine-grained Spatial Understanding in Vision and Language Resamplers,Yes.,5,finegraine require spatial understanding thoroughly examine show information largely absent resampler keep freeze training classifier,2024,June,"Keyphrase: ""Lack of fine-grained spatial understanding"""
naacl2024,The Impact of Language on Arithmetic Proficiency: A Multilingual Investigation with Cross-Agent Checking Computation,Yes.,5,paper critically examine arithmetic capability uncover significant limitation performance,2024,June,"Keyphrase: ""Limited arithmetic capability"""
naacl2024,DIALIGHT: Lightweight Multilingual Development and Evaluation of Task-Oriented Dialogue Systems with Large Language Models,Yes.,4,also identify significant challenge adherence taskspecific instruction multiple highlight area future research,2024,June,"Keyphrase: ""Difficulty in following task-specific instructions"""
naacl2024,OpinionGPT: Modelling Explicit Biases in Instruction-Tuned LLMs,Yes.,4,open research question concern inherent bias train response current research work seek debias suppress potentially biased,2024,June,"Keyphrase: ""Inherent bias"""
naacl2024,Exploring Inherent Biases in LLMs within Korean Social Context: A Comparative Analysis of ChatGPT and GPT-4,Yes.,4,critique perpetuate stereotype diverse group base race sexual orientation attribute finding indicate certain persona prompt combination consistently yield harmful content highlight potential risk associate specific personaissue alignment within korean cultural framework,2024,June,"Keyphrase: ""Perpetuation of harmful stereotypes"""
naacl2024,HybridBERT - Making BERT Pretraining More Efficient Through Hybrid Mixture of Attention Mechanisms,Yes.,5,pretraine phase extremely computeintensive require several highperformance compute device like gpu several day even month training crucial capture global also significant impact finetune major,2024,June,"Keyphrase: ""High computational requirements"""
naacl2024,Combating Security and Privacy Issues in the Era of Large Language Models,Yes.,5,tutorial seek provide systematic summary risk vulnerability security privacy copyright aspect recent solution address issue conclude discussion outline emergent challenge security privacy reliability deserve timely investigation community,2024,June,Keyphrase: Lack of robust security and privacy measures
