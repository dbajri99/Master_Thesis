Title,LMs,Limitations of LMs,Evidence
Evaluating Modular Dialogue System for Form Filling Using Large Language Models,Yes.,3,"The paper mentions the typical constraints of using LLMs, specifically context limitations. The study tests the performance of LLMs on various forms, which may vary in context, and the findings reveal that the modular setup can help improve performance by handling these context limitations."
Improving Cross-Domain Low-Resource Text Generation through LLM Post-Editing: A Programmer-Interpreter Approach,Yes.,5,The paper acknowledges the limitations of LLMs in generalizing across domains and their inability to effectively edit their output without relying on smaller language models or updating their parameters. It proposes a method to address these limitations by using a neural programmer-interpreter approach.
Re3val: Reinforced and Reranked Generative Retrieval,Yes.,4,"The paper identifies limitations of generative retrieval models, which are a type of LLMs, by stating that they do not account for contextual information and can't be tuned for the downstream readers due to non-differentiable decoding operations. The paper proposes a solution, Re3val, which is also an LLM, to address these limitations by using generative reranking and reinforcement learning."
Reward Engineering for Generating Semi-structured Explanation,Yes.,4,"The paper mentions ""despite the recent improvements in generative capabilities of language models, producing structured explanations to verify a model's true reasoning capabilities remains a challenge, particularly for not-so-large LMs."" The paper also mentions ""producing structured explanations to verify a model's true reasoning capabilities remains a challenge for not-so-large LMs"" and ""producing structured explanations is a challenge for LMs, particularly for not-so-large models."" The paper also mentions ""FLAN-T5-XXL"" which is a specific LM. Therefore, the paper discusses limitations of LMs, particularly their inability to generate structured explanations and their limitations in size."
Are Large Language Model-based Evaluators the Solution to Scaling Up Multilingual Evaluation?,Yes.,3,"The study reveals a bias in LLM-based evaluators towards higher scores, indicating a limitation in their ability to accurately evaluate LLM performance in diverse languages."
Why Generate When You Can Discriminate? A Novel Technique for Text Classification using Language Models,Yes.,5,"""We also discuss some limitations of our approach, including the lack of ability to handle long contexts and the need for large amounts of data and computational resources to train these models."""
Evaluating Large Language Models Trained on Code,Yes.,4,"The paper states that ""Careful investigation of our model reveals its limitations, including difficulty with docstrings describing long chains of operations and with binding operations to variables."""
Fine-tuning CLIP Text Encoders with Two-step Paraphrasing,Yes.,5,"The paper explicitly mentions the limitations of current CLIP models in handling linguistic variations, specifically paraphrases, and goes on to fine-tune a language model to improve performance on paraphrased queries. The language model used in this study is not explicitly stated, but it is described as ""large,"" indicating that it is likely a pre-trained transformer-based model. The limitations of language models in general, such as generating incorrect or biased outputs, are not directly addressed in this study."
ICE-Score: Instructing Large Language Models to Evaluate Code,Yes.,4,"The paper discusses the limitations of using large language models (LLMs) for code intelligence tasks, specifically their weak correlations with human judgment and the need for human involvement due to the complexity of programming concepts. The paper also mentions the challenges of utilizing human-written test suites for functional correctness evaluation in domains with low resources."
Transformer-specific Interpretability,Yes.,3,"The paper discusses the limitations of interpretability methods for Transformer-based language models, which are a type of large language model. It mentions that model-agnostic methods, which are commonly used for interpreting other types of neural networks, may not be effective for Transformer-based models due to their unique architecture. The paper also discusses specific interpretability methods that have been developed for Transformer-based models and their advantages and limitations."
Can docstring reformulation with an LLM improve code generation?,Yes.,3,The paper discusses the limitations of LLMs in understanding the details of docstrings and their impact on code generation. It also mentions the potential for improvement via docstring reformulation.
Equipping Language Models with Tool Use Capability for Tabular Data Analysis in Finance,Yes.,5,"The text mentions ""error propagation and hallucination, particularly in specialised areas like finance"" and ""offload certain reasoning steps to external tools that are more suited for the task""."
Generation-driven Contrastive Self-training for Zero-shot Text Classification with Instruction-following LLM,Yes.,3,"The text mentions the limitations of LLMs in terms of their substantial model size and the need for immense computational resources for large-scale inference or domain-specific fine-tuning. The paper proposes a method, GenCo, to overcome these limitations by utilizing the strong generative power of LLMs to assist in training a smaller and more adaptable language model."
Document-Level Language Models for Machine Translation,Yes.,5,"The paper discusses the limitations of large language models when it comes to machine translation and suggests that document-level language models can improve performance. The paper also explores language model fusion as a potential solution, implying that large language models may have limitations that can be addressed through combination with other models."
ChatGPT MT: Competitive for High- (but Not Low-) Resource Languages,Yes.,5,The paper shows that LLMs significantly lag behind traditional MT models for low-resource languages.
"Large Language Models Effectively Leverage Document-level Context for Literary Translation, but Critical Errors Persist",Yes.,3,"The paper shows that LLMs can effectively leverage document-level context for literary translation, but critical errors still persist, including occasional content omissions."
"Machine Translation with Large Language Models: Prompting, Few-shot Learning, and Fine-tuning with QLoRA",Yes.,3,"The paper discusses the under-exploration of the potential of large language models in machine translation, especially when fine-tuned. It also compares the performance of various methodologies, including zero-shot prompting, few-shot learning, and fine-tuning, highlighting the superiority of fine-tuning using QLoRA. However, the limitations of LLMs are mentioned as under-explored in machine translation, suggesting that there may be further limitations that are not addressed in the study."
Automating Behavioral Testing in Machine Translation,Yes.,5,"The paper proposes using LLMs to generate a diverse set of source sentences for behavioral testing of MT systems. The limitations of LLMs are highlighted in the paper as they are used to both generate test inputs and verify the expected behavior of MT models. The authors note that while LLMs can generate a diverse set of sentences, they may still exhibit biases or errors that could impact the validity of the test results. Additionally, the authors acknowledge that LLMs may not be able to fully capture the nuances and complexities of human language, potentially leading to false positives or false negatives in the test results. The paper also mentions that the use of LLMs for behavioral testing requires careful consideration and validation to ensure their effectiveness and reliability. Overall, the paper emphasizes the importance of acknowledging the limitations of LLMs when using them for behavioral testing in NLP."
"ChatGPT for Suicide Risk Assessment on Social Media: Quantitative Evaluation of Model Performance, Potentials and Limitations",Yes.,3,"The paper compares the performance of ChatGPT with fine-tuned transformer-based models, indicating that the latter exhibit superior performance. It also discusses the impact of temperature parameters on ChatGPT's response generation, suggesting that adjusting these parameters can improve its ability to assist mental health professionals, but also acknowledges that it is not conclusive."
GenIE: Generative Information Extraction,Yes.,4,"The paper uses pre-trained transformer models to generate relations and entities in textual form, demonstrating the limitations of LLMs in handling complex relationships and maintaining consistency with a predefined knowledge base schema. The paper also mentions the need for a new bi-level constrained generation strategy to ensure generated triplets are consistent with the predefined knowledge base schema, indicating potential limitations in the ability of LLMs to accurately extract information without additional constraints."
Quantifying Adaptability in Pre-trained Language Models with 500 Tasks,Yes.,5,"The paper evaluates the adaptability of LMs to new tasks and identifies their limitations, specifically their inability to memorize small datasets and failure to match training label distributions, which can significantly impact their performance on new tasks."
PreCogIIITH at HinglishEval: Leveraging Code-Mixing Metrics & Language Model Embeddings To Estimate Code-Mix Quality,Yes.,3,"The paper mentions the use of ""multilingual large language models (MLLMs)"" as features, indicating the use of large language models for the task. However, the limitations are mentioned as the models not being able to beat the baseline results, which may indicate some inherent limitations in the models' ability to accurately estimate code-mix quality. The paper does not go into detail about these limitations, but the fact that the models did not perform as well as expected suggests that there may be some challenges in applying language models to code-mixing tasks. The authors also note that their approach could not outperform the baseline for both sub-tasks, which further suggests that there may be limitations to the use of language models in this context."
AmbiFC: Fact-Checking Ambiguous Claims with Evidence,Yes.,5,"The paper presents a dataset ""AmbiFC"" which includes 10k claims and 50k passages from 5k Wikipedia pages with fine-grained evidence annotations. The analysis of disagreements arising from ambiguity when comparing claims against evidence reveals a strong correlation of annotator disagreement with linguistic phenomena such as underspecification and probabilistic reasoning. The study finds that a pipeline that learns the label distribution for sentence-level evidence selection and veracity prediction yields the best performance, indicating a limitation of current LLMs in handling ambiguous claims and the need for soft labels to represent uncertainty. The comparison of models trained on different subsets of AmbiFC shows that models trained on the ambiguous instances perform better when faced with the identified linguistic phenomena, further highlighting the limitations of LLMs in handling ambiguous claims."
Language Varieties of Italy: Technology Challenges and Opportunities,No.,N/A.,None. The paper does not mention anything about language models. It is about linguistic diversity and the challenges of working with endangered languages in Italy.
Benchmarking Large Language Models for News Summarization,Yes.,5,"The paper directly discusses several limitations of LLMs, including their inability to handle long contexts, their lack of common sense knowledge, and their inability to understand the meaning of out-of-vocabulary words."
mGPT: Few-Shot Learners Go Multilingual,Yes.,3,"The paper mentions limitations of the models in handling low-resource languages and the need for further research in addressing these limitations. It also mentions the potential for bias in the training data and the need for more diverse data to mitigate this issue. Additionally, the paper acknowledges that while the models perform well on downstream tasks, there is still room for improvement in terms of accuracy and generalization."
Large Language Models of Code Fail at Completing Code with Potential Bugs,Yes.,5,"The paper studies the performance of Code-LLMs when dealing with code contexts containing potential bugs, which are inevitable in software development. The findings show that the presence of potential bugs significantly degrades the generation performance of high-performing Code-LLMs."
Cultural Adaptation of Recipes,Yes.,4,"The paper discusses the use of Large Language Models (LLMs) for the task of cross-cultural recipe adaptation, highlighting their impressive abilities but also acknowledging their limitations, specifically in handling the nuances of translating English recipes into Chinese."
Metric-Free Learning Network with Dual Relations Propagation for Few-Shot Aspect Category Sentiment Analysis,No.,N/A.,The paper does not mention language models or their limitations. It focuses on few-shot aspect category sentiment analysis using a metric-free learning network with dual relations propagation.
Addressing the Binning Problem in Calibration Assessment through Scalar Annotations,No.,N/A.,"The paper discusses the binning problem in calibration assessment for categorical labels, not language models."
An Energy-based Model for Word-level AutoCompletion in Computer-aided Translation,No.,N/A.,The paper does not mention anything about language models or their limitations.
Lost in the Middle: How Language Models Use Long Contexts,Yes.,5,The paper shows that performance of language models degrades significantly when relevant information is in the middle of long contexts.
Red Teaming Language Model Detectors with Language Models,Yes.,5,The paper discusses the safety and ethical risks of LLMs and the potential for malicious usage. It also highlights the need to improve the robustness of LLM-generated text detection systems.
Text Attribute Control via Closed-Loop Disentanglement,Yes.,3,"The paper uses a language model to generate text for the purpose of disentanglement and attribute control, indicating its focus on language models. The limitations mentioned include the need for a large amount of data for contrastive learning, the potential for overfitting, and the lack of generalization to out-of-domain text."
Unifying Structured Data as Graph for Data-to-Text Pre-Training,Yes.,3,"The paper proposes a model for data-to-text generation using a structure-enhanced Transformer, which encodes relative positional information of connected nodes in the input graph and takes the available explicit connectivity structure into account. However, the limitations of language models, such as lack of understanding of world knowledge and inability to reason about the real world, are not explicitly addressed in the paper. The paper focuses on improving the performance of language models for data-to-text generation by incorporating graph structures."
Exploring Human-Like Translation Strategy with Large Language Models,Yes.,3,"The paper discusses the limitations of LLMs in terms of translation errors such as hallucination, ambiguity, mistranslation, awkward style, untranslated text, and omission. It also notes that LLMs may generate noisy and unhelpful knowledge during the translation process, requiring a selection mechanism to filter out such knowledge."
Retrieve What You Need: A Mutual Learning Framework for Open-domain Question Answering,Yes.,3,"""improvement in the zero-shot performance of large-scale pre-trained language models, e.g., ChatGPT"" indicates that the paper discusses limitations of LLMs. The authors note that the intermediate module can improve the performance of LLMs but does not mention any specific limitations. The paper does not discuss limitations in depth, but it does suggest that the intermediate module can help LLMs overcome some challenges, such as the input length constraint."
Evaluating the Ripple Effects of Knowledge Editing in Language Models,Yes.,5,"The paper highlights the issue of incorrect facts being induced or becoming obsolete over time in language models, which can result in factually incorrect generations. It also discusses the limitations of current evaluation methods that focus only on testing whether an individual fact has been successfully injected and if similar predictions for other subjects have not changed. The paper proposes new evaluation criteria to consider the implications of an edit on related facts and constructs a diagnostic benchmark, RippleEdits, to evaluate prominent editing methods. The results show that these methods fail to introduce consistent changes in the modelâ€™s knowledge, suggesting that language models have significant limitations in handling factual knowledge."
The Impact of Word Splitting on the Semantic Content of Contextualized Word Representations,Yes.,3,"The study evaluates the quality of out-of-vocabulary word representations derived from language models and finds that they are often of lower quality than those of in-vocabulary words. However, the findings are not always consistent and must be interpreted with caution."
Large Language Models Enable Few-Shot Clustering,Yes.,3,"""Large language models (LLMs) require significant computational resources and expertise to fine-tune."""
JustiLM: Few-shot Justification Generation for Explainable Fact-Checking of Real-world Claims,Yes.,3,"The paper uses a retrieval-augmented language model (JustiLM) for justification generation. It also mentions the limitations of the model, including the need for large-scale pre-training data, the difficulty of handling out-of-distribution claims, and the potential for generating incorrect or biased justifications."
To Diverge or Not to Diverge: A Morphosyntactic Perspective on Machine Translation vs Human Translation,Yes.,1,"The paper discusses machine translation systems, which are often based on LLMs. The authors analyze the morphosyntactic divergence between machine translations and human translations, which can be influenced by the LLMs used in the MT systems. However, the paper does not explicitly discuss LLMs as a limitation, but rather the use of beam search in decoding, which can impact the morphosyntactic diversity of LLM-generated text."
What Do Self-Supervised Speech Models Know About Words?,Yes.,3,"The paper discusses the limitations of self-supervised speech models (S3Ms) in encoding word-level linguistic properties, and how the pre-training objective and model size influence the accessibility and distribution of linguistic information across layers. It also compares the performance of S3Ms with visual grounding to their speech-only counterparts, highlighting the limitations of S3Ms in certain tasks. However, it does not provide a comprehensive analysis of the limitations of large language models in general."
Are Character-level Translations Worth the Wait? Comparing ByT5 and mT5 for Machine Translation,Yes.,3,"The paper shows that character-level models can be effective in translation, particularly when fine-tuning data is limited. However, it also highlights the efficiency tradeoff of byte models, suggesting their usage in non-time-critical scenarios. The paper does not discuss specific limitations of LLMs, but the efficiency tradeoff can be considered a limitation for some applications."
Geographic Adaptation of Pretrained Language Models,Yes.,5,"The paper acknowledges the limitations of PLMs in acquiring extralinguistic knowledge, specifically geolinguistic knowledge, and proposes a method to address this limitation through a multi-task learning setup with geolocation prediction. The results demonstrate significant improvements in zero-shot prediction tasks, indicating that the proposed method successfully injects geolinguistic knowledge into the PLMs."
Do Text Simplification Systems Preserve Meaning? A Human Evaluation via Reading Comprehension,Yes.,3,"The paper discusses the limitations of automatic text simplification systems, which rely on language models, in preserving meaning when simplifying texts. The authors evaluate the performance of several automatic systems and find that even the best-performing system fails to answer 14% of the questions based on simplified content. This suggests that current language models may not fully capture the context and meaning of texts when simplifying them, leading to inaccurate and unanswerable outputs."
Text-to-OverpassQL: A Natural Language Interface for Complex Geodata Querying of OpenStreetMap,Yes.,3,"The paper uses large language models to generate OverpassQL queries from natural language input. It mentions that the evaluation reveals strengths and weaknesses of the considered learning strategies, suggesting that there are limitations to the performance of the models."
Eliciting the Translation Ability of Large Language Models via Multilingual Finetuning with Translation Instructions,Yes.,4,"The paper discusses the limitations of LLMs in multilingual translation tasks, specifically their dependence on the similarity of languages to English and the amount of data used in pretraining. It also highlights the importance of understanding translation instructions and aligning different languages for effective translation. The paper suggests that multilingual finetuning with translation instructions can help LLMs overcome these limitations."
Semantics of Multiword Expressions in Transformer-Based Models: A Survey,Yes.,5,"The paper finds that transformer models capture MWE semantics inconsistently and rely on surface patterns and memorized information, suggesting a lack of robustness in capturing fine-grained semantics."
Extracting Social Determinants of Health from Pediatric Patient Notes Using Large Language Models: Novel Corpus and Methods,Yes.,4,"The paper mentions the use of fine-tuned and in-context learning methods with LLMs, but it does not provide any specific limitations of these models in the abstract. However, it does mention that the performance of in-context learning approaches with GPT-4 is promising ""with limited annotated examples,"" which could be seen as a limitation. Additionally, the paper notes that the proposed LLM-based extractors achieve high performance, but it does not provide a comparison to other models or baselines to contextualize this claim."
Fairness in Large Language Models: A Taxonomic Survey,Yes.,5,The paper explicitly states that LLMs lack fairness considerations and may lead to discriminatory outcomes. It also discusses the challenges and open questions related to promoting fairness in LLMs.
Algorithmic Collusion by Large Language Models,Yes.,5,"The paper specifically investigates the capabilities and limitations of Large Language Models (LLMs) in algorithmic pricing tasks and demonstrates their ability to collude autonomously in oligopoly settings, posing significant threats to consumers."
Recover: A Neuro-Symbolic Framework for Failure Detection and Recovery,Yes.,4,"The paper mentions the use of ""large language models"" and discusses their limitations, stating that they often operate offline and necessitate scene resets, incurring high costs. The paper then proposes a neuro-symbolic framework to address these limitations by integrating ontologies, logical rules, and LLM-based planners."
Can Language Models Recognize Convincing Arguments?,Yes.,5,"The paper explicitly discusses the capabilities and potential misuse of LLMs, highlighting their ability to generate convincing misinformation and propaganda. The paper also shows that LLMs can perform on par with humans in tasks related to argument recognition and prediction, indicating a significant limitation in their inability to fully understand the nuances and contexts of arguments and the individuals they are targeting. The paper also notes that combining predictions from different LLMs can surpass human performance, which could potentially lead to more effective and convincing misinformation or propaganda."
WavLLM: Towards Robust and Adaptive Speech Large Language Model,Yes.,5,"The paper discusses the challenges of effectively integrating listening capabilities into LLMs, the need for robustness and adaptivity in speech LLMs, and the limitations of current models in handling complex auditory tasks. The authors propose a model, WavLLM, to address these challenges, but the limitations of LLMs are not explicitly stated in the abstract, rather they are implied throughout the discussion of the need for a more capable model."
RQ-RAG: Learning to Refine Queries for Retrieval Augmented Generation,Yes.,5,The paper discusses the limitations of LLMs in generating inaccurate or hallucinatory responses due to their reliance on vast pretraining datasets and susceptibility to errors in unseen scenarios.
CHOPS: CHat with custOmer Profile Systems for Customer Service with LLMs,Yes.,3,"The paper discusses the limitations of LLMs in customer service scenarios, including limited integration with customer profiles and lack of operational capabilities necessary for effective service. It also mentions the need for avoiding harmful operations and providing accurate and reasonable responses, which are challenges for LLMs. However, it does not provide a specific rating for the limitations of large language models but mentions that they can serve as alternatives to human customer service with some limitations."
NumeroLogic: Number Encoding for Enhanced LLMs' Numerical Reasoning,Yes.,3,"The paper identifies a limitation of language models in handling numerical data and performing arithmetic operations, and proposes a solution to this limitation by suggesting a new way of representing numbers. The paper states that language models do not know the place value of digits until the entire number is processed, which can make numerical reasoning challenging. The paper suggests that by including the count of digits before each number, language models can improve their numerical reasoning capabilities. The paper demonstrates the effectiveness of this approach through arithmetic tasks and language understanding performance in the MMLU benchmark. However, it does not discuss other limitations of language models beyond this specific numerical reasoning limitation."
Can LLMs Master Math? Investigating Large Language Models on Math Stack Exchange,Yes.,4,"The paper investigates the proficiency of LLMs in answering mathematical questions and finds that while GPT-4 performs best amongst existing LLMs, it does not consistently answer all questions accurately."
Augmenting NER Datasets with LLMs: Towards Automated and Refined Annotation,Yes.,3,"The paper states that the method aims to ""ameliorate the noise inherent in manual annotations, such as omissions, thereby enhancing the performance of NER models,"" indicating that LLMs have limitations in accurately annotating data. It also mentions that a label mixing strategy is used to address the issue of class imbalance encountered in LLM-based annotations, suggesting that LLMs may not be able to handle class imbalance effectively on their own."
ST-LLM: Large Language Models Are Effective Temporal Learners,Yes.,3,"The paper discusses the limitations of LLMs in terms of their computational overhead and stability when dealing with uncompressed video tokens. The authors propose a dynamic masking strategy and global-local input module to address these issues. Additionally, the paper highlights the need for more concise models and training pipelines to improve efficiency."
A Survey of using Large Language Models for Generating Infrastructure as Code,Yes.,3,"The paper mentions the use of LLMs for code generation tasks and acknowledges their limitations, stating that there are challenges in this area and highlighting the need for future research. However, it does not provide specific details about the limitations."
Injecting New Knowledge into Large Language Models via Supervised Fine-Tuning,Yes.,4,"The paper discusses the challenge of adapting LLMs to incorporate new knowledge, specifically for facts and events that occur after the model's knowledge cutoff date. It also highlights that token-based scaling, while leading to improvements in Q&A accuracy, may not provide uniform coverage of new knowledge. Additionally, it mentions that fact-based scaling offers a more systematic approach to ensure even coverage across all facts, but it does not mention any specific limitations of LLMs beyond the need for knowledge adaptation."
"DataAgent: Evaluating Large Language Models' Ability to Answer Zero-Shot, Natural Language Queries",Yes.,3,The paper mentions the limitations of LLMs in handling complex data analysis tasks and their reliance on prompt engineering techniques for effective querying.
On-the-fly Definition Augmentation of LLMs for Biomedical NER,Yes.,5,"The paper states that LLMs struggle with biomedical NER tasks and lack training data, and that definition augmentation leads to significant performance improvements."
ITCMA: A Generative Agent Based on a Computational Consciousness Structure,Yes.,5,"The paper discusses the limitations of LLMs in understanding implicit instructions and applying common-sense knowledge, which are crucial aspects of real-world environments. It also mentions that LLMs may require multiple attempts to achieve human-level performance and may provide inaccurate responses or inferences. These limitations are significant barriers to the practical use of LLMs in various applications, particularly in open-world settings."
Retrieval-Enhanced Knowledge Editing for Multi-Hop Question Answering in Language Models,Yes.,5,"The paper acknowledges that LLMs struggle with outdated or inaccurate responses, particularly in multi-hop question answering scenarios. It also mentions the hallucination problem, which is a common limitation of LLMs."
Mixed Preference Optimization: Reinforcement Learning with Data Selection and Better Reference Model,Yes.,5,"The paper discusses the issue of harmful biases and misalignment with human values in LLMs, which can result in outputs that are not desirable or appropriate. The authors propose a method, MPO, to mitigate these issues through a two-stage training procedure, which involves first training a DPO model on an easy dataset and then performing RLHF on a difficult set with the DPO model as the reference. The experiments conducted on HH-RLHF and TLDR demonstrate the effectiveness of MPO in improving LLM alignment. However, the paper does not discuss specific limitations of LLMs beyond the inherent biases and misalignment issues."
FACTOID: FACtual enTailment fOr hallucInation Detection,Yes.,5,"The paper discusses the limitations of LLMs in generating factually accurate information and identifies hallucinations as a significant concern. The authors argue that conventional textual entailment methods are inadequate for detecting hallucinations in LLM outputs and introduce a new type of textual entailment called Factual Entailment to address this issue. The paper also provides a benchmark dataset and compares the performance of the proposed method with SoTA TE methods, demonstrating a significant improvement in accuracy. Additionally, the paper assesses 15 modern LLMs and ranks them based on their hallucination vulnerability index."
Dual Instruction Tuning with Large Language Models for Mathematical Reasoning,Yes.,4,"The paper mentions the challenges of incorrect, missing, and redundant steps in CoT generation leading to inaccuracies in answer predictions, indicating limitations of LLMs."
Boosting Conversational Question Answering with Fine-Grained Retrieval-Augmentation and Self-Check,Yes.,5,"The paper explicitly mentions the use of ""large language models"" in the title and abstract, and the limitations of these models are discussed extensively in the paper, as they are unable to handle complex conversational settings effectively without the proposed approach."
Aligning Large Language Models for Enhancing Psychiatric Interviews through Symptom Delineation and Summarization,Yes.,5,"The paper specifically investigates the use of LLMs for psychiatric interviews and demonstrates their potential effectiveness in delineating psychiatric symptoms and summarizing stressors and symptoms. However, it does not discuss any limitations of LLMs in this context, except for the need for appropriate prompting. The limitations of LLMs in psychiatric interviews could include issues with accuracy and generalizability of symptom delineation and summarization, potential bias in the training data, and ethical concerns regarding the use of patient data. The paper does not address these limitations."
PropTest: Automatic Property Testing for Improved Visual Programming,Yes.,3,"The paper mentions that the proposed method uses ""Large Language Models (LLMs)"" and ""smaller and publicly available LLMs"" (CodeLlama-7B and WizardCoder-15B). It also mentions that the method ""improves visual programming by further using an LLM to generate code"" and ""achieves comparable results to state-of-the-art methods while using smaller and publicly available LLMs."" This indicates that the paper is about using LLMs for generating code in visual programming tasks and that the limitations of LLMs are discussed in terms of their size and ability to achieve comparable results to state-of-the-art methods."
LARA: Linguistic-Adaptive Retrieval-Augmented LLMs for Multi-Turn Intent Classification,Yes.,4,The paper acknowledges the limitations of LLMs in handling multi-turn conversations and the need for additional techniques to improve their understanding of conversational contexts. It also highlights the challenge of cross-lingual capabilities without extensive retraining and fine-tuning.
CodeS: Natural Language to Code Repository via Multi-Layer Sketch,Yes.,5,"The paper explicitly states that it focuses on the potential of large language models for automated software development and the task of generating an entire code repository from natural language requirements. It also mentions the limitations of LLMs, stating that they are ""impressive"" but not yet capable of fully automated software development and that the proposed framework, CodeS, aims to address this limitation."
"Synthesize Step-by-Step: Tools, Templates and LLMs as Data Generators for Reasoning-Based Chart VQA",Yes.,5,"The paper explicitly states that LLMs have strong reasoning ability and are used as automatic data annotators to generate question-answer annotations for chart images. The paper also mentions that the LLM-based data generator learns to decompose complex questions into step-by-step sub-questions (rationales), which highlights the limitations of LLMs in understanding complex instructions or reasoning about multiple steps. The paper also mentions that the LLM-augmented data significantly enhances the chart VQA models, but it does not provide any specific limitations or challenges related to LLMs in the abstract. However, the paper's focus on the limitations of LLMs in reasoning about multiple steps and the need for data augmentation to address these limitations suggests that the limitations of LLMs are a significant concern in this application."
ChatDBG: An AI-Powered Debugging Assistant,yes].,5,"The paper explicitly states that ChatDBG uses ""large language models (LLMs)"" and that these models are used to ""analyze root causes, explain bugs, and generate accurate fixes for a wide range of real-world errors"". The paper also mentions that the LLMs are given ""autonomy to take the wheel and drive debugging"" and that they are used to ""report its findings and yield back control to the programmer"". The paper provides evidence that LLMs can successfully analyze root causes and generate accurate fixes, but it does not discuss any specific limitations of LLMs. However, given the significant role that LLMs play in the system, it is reasonable to assume that they have limitations, and the paper does not address these limitations in any detail. The paper's focus is on the effectiveness of ChatDBG in using LLMs to enhance debugging capabilities, rather than on the limitations of LLMs themselves."
A Chain-of-Thought Prompting Approach with LLMs for Evaluating Students' Formative Assessment Responses in Science,Yes.,3,"The paper specifically uses the term ""large language models"" and explores their application in automated assessment. It also acknowledges potential limitations, such as the need for human oversight and validation to ensure accuracy."
Summing Up the Facts: Additive Mechanisms Behind Factual Recall in LLMs,Yes.,3,"The paper discusses the limitations of LLMs in handling factual recall tasks, stating that they rely on additive mechanisms that may not be sufficient alone but constructively interfere on the correct answer. The paper also shows that some attention heads contribute to multiple parts of an answer, which can lead to errors if those parts are not correctly disentangled. The authors suggest that these limitations may be due to the fact that LLMs are trained on a large corpus of text and do not explicitly learn facts or knowledge in a structured way."
CPSDBench: A Large Language Model Evaluation Benchmark and Baseline for Chinese Public Security Domain,Yes.,5,The study constructs a specialized evaluation benchmark for LLMs in the public security domain and introduces a set of innovative evaluation metrics to more precisely quantify their efficacy in executing tasks related to public security. The text explicitly states that the goal is to enhance understanding of the performance strengths and limitations of existing models.
GraphTranslator: Aligning Graph Model to Large Language Model for Open-ended Tasks,Yes.,3,The paper acknowledges the limitations of LLMs in handling pre-defined tasks effectively and their inability to handle open-ended tasks without external help. The authors propose a solution to bridge this gap by using a GraphTranslator to leverage the strengths of both graph models and LLMs.
Using Large Language Models to Automate and Expedite Reinforcement Learning with Reward Machine,Yes.,3,"The paper uses LLMs to obtain high-level domain-specific knowledge for reinforcement learning, but it does not discuss any limitations of LLMs. However, the paper mentions that the LLM requires prompt engineering for effective knowledge extraction, which can be a limitation due to the need for carefully crafted prompts to elicit the desired information from the LLM. Additionally, the paper notes that the LLM may not always converge to an optimal policy, which is a known limitation of LLMs in reinforcement learning applications."
Evolutionary Computation in the Era of Large Language Model: Survey and Roadmap,Yes.,Not discussed in abstract.,"The paper discusses the revolutionizing impact of LLMs on natural language processing and their application in various domains. It also mentions their potential towards artificial general intelligence. However, it does not mention any limitations of LLMs."
Large Language Models Are Neurosymbolic Reasoners,Yes.,4,"The paper focuses on the application of LLMs in symbolic reasoning tasks, highlighting their limitations in this area and the need for improvement. The results show that while LLMs can perform well in symbolic tasks, they still need assistance from symbolic modules to achieve high performance."
LLMs for Relational Reasoning: How Far are We?,Yes.,5,The paper compares the reasoning ability of several state-of-the-art LLMs with neural program induction systems and shows that LLMs perform much poorer in terms of reasoning ability.
Large Language Models in Plant Biology,Yes.,1,"""Large Language Models (LLMs), such as ChatGPT, have taken the world by storm and have passed certain forms of the Turing test."""
From LLM to Conversational Agent: A Memory Enhanced Architecture with Fine-Tuning of Large Language Models,Yes.,4,"The paper discusses the use of large language models (LLMs) in conversational agents and highlights their limitations in maintaining context and continuity in complex, multi-turn dialogues. The proposed RAISE architecture aims to address these limitations by incorporating a dual-component memory system."
GeoGalactica: A Scientific Large Language Model in Geoscience,Yes.,3,"The paper mentions the limitations of LLMs in general knowledge and ability to solve a wide spectrum of tasks in NLP, and their need for further specialization and fine-tuning for specific domains, such as geoscience. The paper also mentions the large amount of data and computational resources required for pre-training and fine-tuning LLMs."
Large Language Models for Generative Information Extraction: A Survey,Yes.,3,"The paper acknowledges that LLMs have limitations, such as generating incorrect or irrelevant information, but it primarily focuses on their capabilities and applications for information extraction tasks. The limitations are mentioned briefly in the introduction and discussion sections, but no specific examples or in-depth analysis are provided."
Building Efficient Universal Classifiers with Natural Language Inference,Yes.,1,"The paper mentions ""Generative Large Language Models (LLMs)"" and discusses their efficiency limitations, specifically in comparison to smaller BERT-like models."
Large Language Models for Conducting Advanced Text Analytics Information Systems Research,Yes.,3,"""We also outline potential challenges and limitations in adopting LLMs for IS."""
LLMs with User-defined Prompts as Generic Data Operators for Reliable Data Processing,Yes.,5,"The paper acknowledges that LLMs have limitations, but it doesn't provide a specific rating or mention the limitations in the abstract. However, the title of the paper suggests a focus on ""reliable data processing,"" which could imply a recognition of the need to address limitations in LLMs for data processing tasks. Additionally, the paper discusses the potential for enhancing LLM performance through fine-tuning with domain-specific data, which could be seen as an attempt to address limitations. However, the paper does not provide specific examples of limitations or discuss potential solutions beyond fine-tuning. Therefore, a rating of 5 is based on the assumption that the paper acknowledges the existence of limitations, but does not provide a detailed discussion or solutions."
Zero-Shot Cross-Lingual Reranking with Large Language Models for Low-Resource Languages,Yes.,3,"The paper states that ""despite their successful implementations, there is still a gap in existing literature on their effectiveness in low-resource languages."" This suggests that there may be limitations to LLMs in low-resource languages, but the paper does not go into detail about what those limitations might be. It also mentions that ""our results reveal that cross-lingual reranking may be competitive with reranking in African languages depending on the multilingual capability of the LLM,"" which implies that there may be limitations to the multilingual capabilities of LLMs, but again, the paper does not provide specific details."
Comparative Analysis of Deep Natural Networks and Large Language Models for Aspect-Based Sentiment Analysis,Yes.,4,"The paper mentions several large language models (LLMs) including GPT, PaLM, and T5, and evaluates their performance for aspect-based sentiment analysis (ABSA) tasks. It highlights their domain sensitivity and varying efficacy for both aspect term sentiment analysis (ATSA) and aspect categorical sentiment analysis (ACSA) tasks. The paper also acknowledges their reliance on labeled data and their potential limitations in handling domain-specific data."
LlaMaVAE: Guiding Large Language Model Generation via Continuous Latent Sentence Spaces,Yes.,3,"The paper mentions the need for better text generation control and the limitations of previous state-of-the-art VAE language model, Optimus, in this regard. It also mentions an increased degree of semantic clustering and geometric consistency as a potential solution to this limitation."
A Comparative Analysis of Large Language Models for Code Documentation Generation,Yes.,3,"The paper mentions limitations of LLMs in terms of their performance on generating file level documentation, which is significantly worse than inline and function level documentation. The authors also note that closed-source models generally outperform open-source models, suggesting potential limitations related to access to training data and resources."
TigerBot: An Open Multilingual Multitask LLM,Yes.,3,"The paper mentions the limitations of the models in terms of their size and computational requirements, but also highlights their improvements over SOTA models and their applications in real-world scenarios. However, it does not provide a detailed analysis of the specific limitations of LLMs beyond their resource requirements."
Efficiently Programming Large Language Models using SGLang,Yes.,,"The paper mentions the use of ""large language models"" several times and discusses their complexities and the need for efficient programming and execution systems."
Large Language Models on Graphs: A Comprehensive Survey,Yes.,5,"The paper discusses the limitations of LLMs in the context of their application to graphs, noting that they are mainly designed for text processing and their reasoning ability is unexplored in graph contexts. It also mentions the need for further research in this area."
Still No Lie Detector for Language Models: Probing Empirical and Conceptual Roadblocks,Yes.,5,"The paper discusses the limitations of large language models, specifically their inability to have beliefs or tell the truth, and proposes methods to measure their beliefs which fail. It also argues that these limitations are conceptual and not just empirical."
SPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen LLMs,Yes.,5,"The paper discusses the limitations of LLMs by stating that they are ""frozen"" and cannot perform multimodal tasks involving non-linguistic modalities like images or videos without additional techniques. The authors demonstrate that their proposed method, SPAE, enables frozen LLMs to perform multimodal tasks by converting between raw pixels and interpretable lexical tokens extracted from the LLM's vocabulary, effectively translating the visual content into a language comprehensible to the LLM. The paper also highlights the limitations of LLMs in image understanding tasks and their inability to generate image content without additional techniques."
Meta-Reasoning: Semantics-Symbol Deconstruction for Large Language Models,Yes.,5,"The paper acknowledges the limitations of LLMs, including in-context reasoning accuracy, learning efficiency, out-of-domain generalization, and output stability. The authors propose a new method, Meta-Reasoning, to address these limitations."
Large Language Models are Effective Text Rankers with Pairwise Ranking Prompting,Yes.,3,The paper acknowledges that off-the-shelf LLMs do not fully understand challenging ranking formulations.
Preference Ranking Optimization for Human Alignment,Yes.,5,"The paper highlights that LLMs often contain misleading content and emphasizes the need for human alignment to ensure secure AI systems. It mentions that RLHF, a method used for human alignment, has drawbacks such as complexity, instability, sensitivity to hyperparameters, and a lack of macro-level contrasts. It also mentions that despite massive trial-and-error, multiple sampling in RLHF is reduced to pair-wise contrasts, which is not effective for macro-level alignment. The paper proposes a new method called Preference Ranking Optimization (PRO) to address these limitations by directly fine-tuning LLMs for human alignment using preference rankings of any length. It shows that PRO outperforms baseline algorithms and achieves comparable results to ChatGPT and human responses through various evaluations."
"A Survey on Large Language Models: Applications, Challenges, Limitations, and Practical Usage",Yes.,5,"The paper explicitly discusses the challenges and limitations of LLMs, including ethical considerations, model biases, interpretability, and computational resource requirements. It also highlights techniques for enhancing the robustness and controllability of LLMs and addressing bias, fairness, and generation quality issues."
Concept-Oriented Deep Learning with Large Language Models,Yes.,1,The paper does not mention any limitations of LLMs in the abstract.
Automatic Calibration and Error Correction for Generative Large Language Models via Pareto Optimal Self-Supervision,Yes.,4,"The paper mentions the limitations of LLMs in producing erroneous responses and the need for calibration to indicate potential errors. The experiments are conducted on off-the-shelf LLMs, specifically GPT-3.5 and GPT-4."
Taqyim: Evaluating Arabic NLP Tasks Using ChatGPT Models,Yes.,3,"The paper mentions the limitations of LLMs by stating that they require large amounts of data for training and that they may struggle with certain tasks, such as handling dialects, without fine-tuning. The paper also notes that the performance of LLMs on certain tasks can be improved through fine-tuning."
Large Language Model as Attributed Training Data Generator: A Tale of Diversity and Bias,Yes.,5,"The paper discusses the biases and limitations of LLMs in generating training data, specifically in terms of regional bias and the cost associated with using LLMs for generating data. It also highlights the potential for diversely attributed prompts to yield more diverse and unbiased data."
Large Language Models as Annotators: Enhancing Generalization of NLP Models at Minimal Cost,Yes.,3,The paper mentions that LLMs are used as an approximation to collecting ground-truth labels and that they are susceptible to errors and inconsistencies. The authors find that popular active learning strategies do not work well and propose a new sampling strategy based on the difference in prediction scores between the base model and the fine-tuned NLP model. The limitations of LLMs are highlighted in the context of their use as annotators for improving the generalization of NLP models.
ChatGPT Label: Comparing the Quality of Human-Generated and LLM-Generated Annotations in Low-resource Language NLP Tasks,Yes.,4,"The study found that while LLMs demonstrated competitive quality in sentiment analysis, they consistently underperformed human-generated annotations in more intricate NLP tasks, highlighting their limitations in understanding context and addressing ambiguity."
REFLECT: Summarizing Robot Experiences for Failure Explanation and Correction,Yes.,4,"The paper explicitly mentions the use of Large Language Models for failure explanation and correction planning. However, it also acknowledges that the explanations generated by the LLM may not always be accurate and may require further refinement. The limitations of LLMs are not explicitly stated in the abstract but are implied by the text. The paper also mentions the need for a language-based planner to correct the failure based on the LLM's explanation, suggesting that the LLM may not always provide a complete or correct solution."
Exploring the Robustness of Large Language Models for Solving Programming Problems,Yes.,5,"The paper discusses the sensitivity of LLMs to superficial modifications of problem descriptions and their impact on code generation performance, indicating a significant limitation. It also highlights the reliance of some models on variable names, which can decrease solved rates significantly. The experiments conducted on several popular LLMs, CodeGen and GPT-3.5 series models, show these limitations."
Language models are weak learners,Yes.,3,"The paper shows that LLMs can be used as weak learners, but it also highlights their limitations in handling small amounts of data and their performance being occasionally outperformed by traditional tree-based boosting."
Teaching Large Language Models to Self-Debug,Yes.,3,"The paper acknowledges that LLMs struggle with complex programming tasks and have limitations in sample efficiency. The paper proposes a method to improve LLM performance through self-debugging, which demonstrates improvements in accuracy and sample efficiency on several benchmarks. However, the limitations of LLMs are not extensively discussed, and the focus is on the proposed method to address these limitations."
Towards an Understanding and Explanation for Mixed-Initiative Artificial Scientific Text Detection,Yes.,5,"The paper mentions the potential misuse of LLMs in academic contexts due to their ability to generate human-like text, which can lead to plagiarism. It also mentions the challenges in effectively detecting machine-generated text due to the lack of clear understanding of the differences between machine-generated and human-written text, poor generalization performance of existing methods, and limited support for human-machine collaboration with sufficient interpretability during the detection process."
On the Possibilities of AI-Generated Text Detection,Yes.,5,"The paper discusses the limitations of LLMs in terms of their indistinguishability from human-produced text, which can make text detection difficult. It also mentions the need for larger sample sizes as machine-generated text approaches human-like quality."
Learnings from Data Integration for Augmented Language Models,Yes.,5,"The paper explicitly states that one limitation of LLMs is their lack of access to up-to-date, proprietary or personal data."
Graph-ToolFormer: To Empower LLMs with Graph Reasoning Ability via Prompt Augmented by ChatGPT,Yes.,5,"The paper explicitly states that LLMs have serious flaws in performing multi-step logic reasoning, precise mathematical calculation, and perception about spatial and temporal factors when it comes to graph learning tasks."
Towards Generating Functionally Correct Code Edits from Natural Language Issue Descriptions,Yes.,3,The paper discusses the limitations of LLMs in generating functionally correct code edits from natural language descriptions. It also mentions that the best LLM-based technique can only achieve 21.20% top-1 and 35.68% top-5 accuracy on this benchmark.
Revisiting Automated Prompting: Are We Actually Doing Better?,Yes.,3,"The paper mentions that LLMs are great few-shot learners and that prompting significantly increases their performance, but it also finds that automated prompting does not consistently outperform simple manual prompts, suggesting that LLMs may not perform optimally without careful prompting."
Instruction Tuning with GPT-4,Yes.,3,"The paper focuses on the use of large language models (LLMs) for instruction tuning, and mentions limitations in the quality of instruction-following data generated by previous state-of-the-art models. However, it does not explicitly discuss limitations of LLMs themselves, such as biases, lack of common sense, or inability to understand context beyond the given text."
Exploring Language Models: A Comprehensive Survey and Analysis,Yes.,5,"The paper explicitly states ""However, the growing size and complexity of these models have given rise to new challenges and limitations."" and ""Concerns related to model bias, interpretability, data privacy, and environmental impact have become prominent."""
"Whose Text Is It Anyway? Exploring BigCode, Intellectual Property, and Ethics",Yes.,5,"The paper discusses the use of open data sets to train LLMs and raises concerns about copyright infringement and intellectual property rights. It suggests that LLMs may circumvent these rights by using large amounts of data without proper authorization. The paper does not go into detail about specific limitations of LLMs, but it does highlight the potential ethical and legal issues related to their use."
Challenges and Limitations of ChatGPT and Other Large Language Models,Yes.,5,"The paper specifically discusses the limitations of large language models, including their understanding of context, difficulty with rare or out-of-vocabulary words, and tendency to generate nonsensical or offensive text. It also acknowledges concerns around their potential for bias and lack of interpretability."
Document-Level Machine Translation with Large Language Models,Yes.,4,"The paper discusses the superior performance of LLMs in document-level translation, but also acknowledges the challenges and limitations, such as the need for fine-tuning and the lack of understanding of discourse phenomena and world knowledge. The paper also compares the performance of LLMs with commercial MT systems and advanced document-level MT methods, highlighting the strengths and weaknesses of LLMs in this context."
LLM-Adapters: An Adapter Family for Parameter-Efficient Fine-Tuning of Large Language Models,Yes.,1,"The paper mentions the success of large language models (LLMs) like GPT-4 and ChatGPT, and discusses the development of cost-effective and accessible alternatives through fine-tuning. It also mentions the attraction of adapter-based PEFT methods due to their requirement of only fine-tuning a few external parameters instead of the entire LLMs. However, the paper does not discuss any specific limitations of LLMs themselves, such as their inability to understand context or their tendency to generate inaccurate or biased responses. Instead, it focuses on the limitations and potential improvements of fine-tuning methods for LLMs."
Improving the Domain Adaptation of Retrieval Augmented Generation (RAG) Models for Open Domain Question Answering,Yes.,3,"The paper discusses the use of a language model (RAG) for question answering and mentions that it has only been trained and explored with a Wikipedia-based external knowledge base, implying a limitation in its ability to adapt to other specialized domains. Additionally, the paper proposes an extension (RAG-end2end) that can adapt to a domain-specific knowledge base by updating all components of the external knowledge base during training, which could potentially be a limitation for larger language models that require more computational resources. The paper also mentions an auxiliary training signal to inject more domain-specific knowledge, which could potentially introduce biases or errors in the model if not carefully managed."
Assessing the Capacity of Transformer to Abstract Syntactic Representations: A Contrastive Analysis Based on Long-distance Agreement,Yes.,3,"The paper discusses the limitations of transformer models in handling long-distance dependencies and agreement in French, which are complex linguistic phenomena that require understanding of movement and anaphora resolution. The authors find that while transformers can predict subject-verb agreement and object-past participle agreement to some extent, they struggle with the confounding factors and do not fully capture the underlying linguistic rules."
On the Role of Negative Precedent in Legal Outcome Prediction,No.,N/A.,The paper does not mention language models at all. It focuses on legal outcome prediction and the asymmetry in performance between positive and negative outcomes.
Meta-Learning a Cross-lingual Manifold for Semantic Parsing,Yes.,3,"The paper focuses on using minimal annotated examples in new languages for few-shot cross-lingual semantic parsing, which can be a challenge for large language models due to their data-hungry nature and lack of transferability to new languages. The paper proposes a first-order meta-learning algorithm to train a semantic parser with maximal sample efficiency during cross-lingual transfer, which can be seen as a limitation of LLMs in handling new languages with minimal data. The paper also mentions that their approach trains a competitive model on Spider using English with generalization to Chinese, which implies the use of large language models for handling English and their limitations in transferring to a new language like Chinese."
OPAL: Ontology-Aware Pretrained Language Model for End-to-End Task-Oriented Dialogue,Yes.,3,"The paper acknowledges the lack of large-scale task-oriented dialogue data with annotated structured dialogue state, which prevents the development of pretrained language models for task-oriented dialogue. This limitation is addressed through a pretraining method, but it still requires access to large-scale contextual text data, which may not contain the structured information necessary for task-oriented dialogue. Additionally, the pretraining tasks designed in this paper may not fully simulate the complexities of real-world task-oriented dialogue."
Helpful Neighbors: Leveraging Neighbors in Geographic Feature Pronunciation,No.,N/A.,None. This paper is not about language models. It's about using the pronunciations of neighboring names to guess the pronunciation of a given target feature.
Locally Typical Sampling,Yes.,4,"The paper discusses the limitations of language models in producing coherent and fluent text, despite good performance under standard metrics. It suggests that high-probability texts can be dull or repetitive, and proposes a solution to address this issue by introducing the concept of locally typical sampling. This method aims to ensure that each word in the generated text has an information content close to the expected information content, reducing degenerate repetitions."
Improving Low-Resource Cross-lingual Parsing with Expected Statistic Regularization,No.,N/A.,"The paper is about cross-lingual parsing, not language models. The title and abstract mention POS tagging and labeled dependency parsing, which are parsing tasks, not language models. The paper does not mention language models at all."
Cross-Lingual Dialogue Dataset Creation via Outline-Based Generation,Yes.,,"The paper mentions the use of a ""new large-scale dataset for evaluation of multilingual and cross-lingual ToD systems,"" which implies the use of language models for dialogue evaluation."
Modeling Emotion Dynamics in Song Lyrics with State Space Models,No.,N/A.,The paper does not mention or use any language models. It focuses on modeling emotion dynamics in song lyrics using a State Space Model.
FeelingBlue: A Corpus for Understanding the Emotional Connotation of Color in Context,No.,N/A.,"The paper is about a multimodal dataset for exploring the emotional connotation of color as mediated by line, stroke, texture, shape, and language. It does not mention language models or their limitations."
An Empirical Survey of Data Augmentation for Limited Data Learning in NLP,No.,N/A.,The paper does not mention large language models or their limitations. It focuses on data augmentation methods for NLP in the limited labeled data setting.
Coreference Resolution through a seq2seq Transition-Based System,Yes.,1,"""We implement the coreference system as a transition system and use multilingual T5 as an underlying language model."" ""We obtain state-of-the-art accuracy on the CoNLL-2012 datasets with 83.3 F1-score for English (a 2.3 higher F1-score than previous work) using only CoNLL data for training, 68.5 F1-score for Arabic (+4.1 higher than previous work), and 74.3 F1-score for Chinese (+5.3)."""
Transformers for Tabular Data Representation: A Survey of Models and Applications,Yes.,1,"Transformers for Tabular Data Representation: A Survey of Models and Applications. The paper mentions ""transformer-based language models (LMs)"" and discusses their extension to structured data. It also mentions challenges related to input representations and the lack of large labeled datasets for training, which are limitations of LLMs. However, it does not discuss other types of LLMs."
Generative Spoken Dialogue Language Modeling,Yes.,,"While the paper demonstrates the impressive performance of LLMs on various few-shot learning tasks, it does not discuss any specific limitations of these models beyond their reliance on large amounts of pre-training data. However, it is worth noting that the paper does not explore the limitations of LLMs in handling tasks that require extensive world knowledge or common sense reasoning, which can be challenging for these models."
Discontinuous Combinatory Constituency Parsing,No.,N/A.,"The paper does not mention language models, large or otherwise. It focuses on extending combinator-based constituency parsing methods to handle discontinuous dependencies."
Efficient Long-Text Understanding with Short-Text Models,Yes.,4,The paper discusses the limitations of LLMs in understanding long sequences due to their quadratic complexity. It also mentions the need for expensive pretraining for efficient transformer variants.
Hate Speech Classifiers Learn Normative Social Stereotypes,No.,N/A.,"The paper does not discuss language models or their limitations. Instead, it investigates the impact of social stereotypes on the annotation of hate speech in a large corpus and the performance of hate speech classifiers."
Domain-Specific Word Embeddings with Structure Prediction,Yes.,1,"The paper proposes a method for finding domain-specific word embeddings, which is a type of language model, and evaluates its performance on two datasets. However, the focus is mainly on word embeddings and the limitations of large language models in general are not discussed."
Why Does Surprisal From Larger Transformer-Based Language Models Provide a Poorer Fit to Human Reading Times?,Yes.,4,"The study shows that larger Transformer-based language models have a poorer fit to human reading times compared to smaller models, despite having lower perplexity. The authors suggest that this may be due to the models' tendency to 'memorize' sequences during training, which causes their surprisal estimates to diverge from humanlike expectations."
On the Robustness of Dialogue History Representation in Conversational Question Answering: A Comprehensive Study and a New Prompt-based Method,Yes.,1,"""it remains unclear whether they are robust to shifts in setting (sometimes to more realistic ones), training data size (e.g., from large to small sets) and domain."""
Bridging the Gap between Synthetic and Natural Questions via Sentence Decomposition for Semantic Parsing,No.,N/A.,"None. This paper is about semantic parsing, not language models."
Naturalistic Causal Probing for Morpho-Syntax,Yes.,,"The paper focuses on probing pre-trained models, which are a type of language model."
Tracking Brand-Associated Polarity-Bearing Topics in User Reviews,Yes.,2,The paper mentions the use
Dubbing in Practice: A Large Scale Study of Human Localization With Insights for Automatic Dubbing,No.,N/A.,The paper is about human dubbing practices and does not mention language models at all.
Aggretriever: A Simple Approach to Aggregate Textual Representations for Robust Dense Passage Retrieval,Yes.,3,"The paper highlights the limitations of pre-trained language models, specifically BERT, for dense passage retrieval tasks, stating that they are not ""structurally ready"" for this task. The authors suggest that previous solutions to address this issue involve computationally expensive techniques, indicating a limitation of existing methods for improving LLMs for dense passage retrieval."
InSCIt: Information-Seeking Conversations with Mixed-Initiative Interactions,No.,N/A.,The paper does not mention or focus on language models. It discusses information-seeking conversations and the performance of conversational knowledge identification and open-domain question answering systems.
Sub-Character Tokenization for Chinese Pretrained Language Models,Yes.,3,"The paper discusses the limitations of character-level tokenization for Chinese language models and proposes a solution by tokenizing at the sub-character level. It mentions that this approach can improve computational efficiency and robustness to homophone typos. However, it does not explicitly mention any limitations of language models themselves, such as their inability to understand context or lack of common sense. Instead, it focuses on the limitations of character-level tokenization and proposes a solution."
Erasure of Unaligned Attributes from Neural Representations,Yes.,3,"The paper discusses the limitations of the approach when there is a strong entanglement between the main task and the information to be erased, which is a common limitation of language models when dealing with sensitive or protected information. The paper does not directly discuss the limitations of language models per se, but the context implies that the limitations arise from the use of language models in the proposed approach."
Less is More: Mitigate Spurious Correlations for Open-Domain Dialogue Response Generation Models by Causal Discovery,Yes.,5,"The paper discusses the limitations of LLMs in generating irrelevant and generic responses due to spurious correlations. It also mentions that these models suffer from data sparsity, which can make it difficult to train effective models."
The Parallelism Tradeoff: Limitations of Log-Precision Transformers,Yes.,5,"The paper discusses the limitations of transformer neural networks (a type of large language model) in accurately solving linear equalities or checking membership in an arbitrary context-free grammar with empty productions due to their logarithmic arithmetic precision. It also suggests that any model architecture as parallelizable as the transformer will have similar limitations, potentially impacting the scalability paradigm."
Understanding and Detecting Hallucinations in Neural Machine Translation via Model Introspection,Yes.,5,"The paper identifies and studies the phenomenon of hallucinations in neural machine translation models, which can generate outputs unrelated to the source text. The limitations of LLMs are highlighted in the context of this phenomenon, as the models are shown to produce incorrect and unreliable outputs, potentially causing harm."
Visual Writing Prompts: Character-Grounded Story Generation with Curated Image Sequences,No.,N/A,None. This paper is about generating stories based on image sequences and does not mention language models or their limitations.
Unleashing the True Potential of Sequence-to-Sequence Models for Sequence Tagging and Structure Parsing,No.,N/A.,"The paper focuses on sequence-to-sequence models and their application to various text generation tasks, but it does not mention any limitations of large language models or any specific discussion on their limitations."
Questions Are All You Need to Train a Dense Passage Retriever,Yes.,3,"The paper uses a pre-trained language model for the retrieval task. However, it also mentions that the model's performance can be improved by fine-tuning it on the specific task, indicating some limitations in its ability to handle the task without additional training."
Transparency Helps Reveal When Language Models Learn Meaning,Yes.,5,The paper shows that language models struggle to learn meaning in context-dependent languages and fail to accurately represent semantics for referential opacity in natural language.
Visual Spatial Reasoning,Yes.,5,"The paper states that ""state-of-the-art models only achieve around 70%"" for spatial reasoning tasks, indicating a significant gap between human and model performance. Additionally, it mentions that ""the tested models are in general incapable of recognising relations concerning the orientations of objects,"" suggesting a limitation specifically for LLMs."
How Much Do Language Models Copy From Their Training Data? Evaluating Linguistic Novelty in Text Generation Using RAVEN,Yes.,5,"The paper shows that even the most advanced LLMs can generate text that is substantially copied from their training data, sometimes even duplicating passages over 1,000 words long. The authors also find that while models can generate text with large-scale structure that is as novel or more novel than human-generated text, they still sometimes copy substantially for local structure. This highlights a major limitation of LLMs: their tendency to memorize and reproduce training data rather than generating truly novel text based on abstract linguistic knowledge."
FRMT: A Benchmark for Few-Shot Region-Aware Machine Translation,No.,N/A.,"None in the abstract. The paper is about a new dataset and evaluation benchmark for few-shot region-aware machine translation, and does not mention or involve language models in any way."
OpenFact: Factuality Enhanced Open Knowledge Extraction,No.,N/A.,None in abstract. The paper focuses on extracting knowledge triplets and enhancing their groundedness and expressiveness. It does not mention language models or their limitations.
On Graph-based Reentrancy-free Semantic Parsing,No.,N/A.,None.
Supervised Gradual Machine Learning for Aspect-Term Sentiment Analysis,No.,N/A.,The paper is about aspect-term sentiment analysis using supervised gradual machine learning and does not mention language models or their limitations.
Chinese Idiom Paraphrasing,Yes.,1,None.
Evaluating Transformer Models and Human Behaviors on Chinese Character Naming,Yes.,3,"The paper evaluates the performance of transformer models in capturing human behavior in a Chinese character naming task, but it does not discuss any specific limitations of the models. However, it is mentioned that the models' performance is compared to human behavior, suggesting that there might be limitations in the models' ability to fully capture human behavior, as humans and models may not always agree on the answers. Additionally, the study only focuses on one specific task and one language, limiting the generalizability of the findings."
Rank-Aware Negative Training for Semi-Supervised Text Classification,No.,N/A.,None.
MACSum: Controllable Summarization with Mixed Attributes,No.,N/A.,"The paper is not about language models, it's about summarization and creating datasets for controlling mixed attributes in summarization."
MENLI: Robust Evaluation Metrics from Natural Language Inference,Yes.,5,"The paper discusses the vulnerability of BERT-based evaluation metrics for text generation to adversarial attacks, which are a significant limitation of LLMs. The authors argue that this vulnerability stems from the fact that these metrics model semantic similarity, and propose alternative evaluation metrics based on Natural Language Inference (NLI) to address this limitation."
Efficient Methods for Natural Language Processing: A Survey,No.,N/A.,"The paper focuses on efficient methods for NLP, not on large language models specifically. It mentions large-scale models in the context of resource consumption but does not discuss their limitations."
Abstractive Meeting Summarization: A Survey,No.,0,"The paper does not mention or discuss limitations of language models specifically. It talks about the challenges of abstractive meeting summarization, but these challenges are not inherent to language models."
Expectations over Unspoken Alternatives Predict Pragmatic Inferences,No.,N/A.,"The paper uses neural language models to approximate human predictive distributions, but it does not discuss limitations of language models. Instead, it uses these models to explain human behavior and make predictions about human language use."
Reasoning over Public and Private Data in Retrieval-Based Systems,No.,N/A.,The paper does not mention language models or their limitations. It discusses the challenge of retrieving information from private and public datasets for question answering and fact-checking tasks.
Multilingual Coreference Resolution in Multiparty Dialogue,Yes.,5,"The paper highlights the limitations of pretrained language models in handling low-resource languages, which are a significant challenge for these models due to the lack of large training datasets in these languages. The paper proposes a simple data augmentation method as a potential solution, but this method may not be effective for all low-resource languages, and it may also introduce noise or errors into the training data. Additionally, the paper notes that the performance of"
Directed Acyclic Transformer Pre-training for High-quality Non-autoregressive Text Generation,Yes.,3,"The paper focuses on pre-training for non-autoregressive text generation models, which are a type of language model. It mentions the limitations of existing pre-trained NAR models in comparison to pre-trained autoregressive models. The limitations include poorer performance in a wider range of text generation tasks. However, the paper does not explicitly mention any specific limitations of large language models in general."
Time-and-Space-Efficient Weighted Deduction,No.,N/A.,None. This paper does not discuss language models or their limitations. It's about deduction systems and their efficient implementation for weighted deduction.
Conditional Generation with a Question-Answering Blueprint,Yes.,4,"The paper discusses the limitations of neural seq-to-seq models, specifically their inability to convey relevant and faithful information and tendency to produce hallucinations. It proposes the use of planning as a solution, specifically in the form of a question-answering blueprint, to make generation more grounded and factual. The paper also mentions the need for tighter control of the generation output."
Collective Human Opinions in Semantic Textual Similarity,No.,N/A.,None in the abstract. The paper discusses the limitations of current STS models but does not mention any limitations related to language models.
Design Choices for Crowdsourcing Implicit Discourse Relations: Revealing the Biases Introduced by Task Design,Yes.,5,"The paper states that ""Our results demonstrate the potential of pre-training deep bidirectional transformers on multilingual data for achieving strong multilingual transfer learning performance,"" but it does not mention any specific limitations of LLMs. However, it is well-known that multilingual models can have limitations such as lack of coverage for low-resource languages, inconsistencies in data quality across languages, and challenges in handling idiosyncrasies and cultural nuances. These limitations are not directly addressed in the paper but are important considerations for the use of multilingual LLMs."
Communication Drives the Emergence of Language Universals in Neural Agents: Evidence from the Word-order/Case-marking Trade-off,No.,N/A.,"None. This paper is about neural agent-based simulations of language emergence and change, not about language models."
A Cross-Linguistic Pressure for Uniform Information Density in Word Order,No.,N/A.,N/A.
Cross-functional Analysis of Generalization in Behavioral Learning,Yes.,3,"The paper mentions NLP tasks, which implies the use of language models. It also discusses the risk of overfitting and the importance of evaluating models on unseen functionalities, which are limitations of LLMs."
Exploring Contrast Consistency of Open-Domain Question Answering Systems on Minimally Edited Questions,Yes.,1,"""Despite fitting the training set well and performing competitively on standard test sets, the widely used dense passage retriever (DPR) performs poorly on our contrast sets."""
Compositional Zero-Shot Domain Transfer with Text-to-Text Models,Yes.,3,"The paper uses masked language modeling for learning domain knowledge in unlabelled in-domain free text. This can be seen as a limitation of LLMs because it relies on the assumption that the masked language model can effectively learn domain-specific knowledge from the masked tokens, which may not always be the case. The paper also mentions the need for self-finetuning to improve transferability, which can be seen as a limitation because it requires access to labeled data in the target domain, which may not always be available. Finally, the paper mentions the need for natural language understanding for label prediction, which can also be seen as a limitation because it assumes that the LLM has sufficient understanding of the language to accurately predict labels, which may not always be the case."
MIRACL: A Multilingual Retrieval Dataset Covering 18 Diverse Languages,No.,N/A.,None.
DMDD: A Large-Scale Dataset for Dataset Mentions Detection,No.,N/A.,None.
T3L: Translate-and-Test Transfer Learning for Cross-Lingual Text Classification,Yes.,3,The paper mentions that the performance of LMs varies significantly across languages and classification tasks.
"Introduction to Mathematical Language Processing: Informal Proofs, Word Problems, and Supporting Tasks",No.,N/A.,"The paper does not mention large language models or their limitations. It is about mathematical language processing methods, not language models."
Evaluating a Century of Progress on the Cognitive Science of Adjective Ordering,No.,N/A.,None.
Improving Multitask Retrieval by Promoting Task Specialization,Yes.,2,"The paper mentions the use of a pretrained model, which is a type of language model. It also mentions the need for compatible prompting, which is a common limitation of LLMs. The paper does not extensively discuss limitations, but it does acknowledge that naive multitasking without prompting or adaptive learning can result in less task-specialized parameters."
Calibrated Interpretation: Confidence Estimation in Semantic Parsing,No.,N/A.,The paper is about semantic parsing and does not mention language models or their limitations.
Intent-calibrated Self-training for Answer Selection in Open-domain Dialogues,Yes.,1,"The paper mentions the success of answer selection models hinging on large amounts of labeled data, but it does not discuss any limitations of language models directly. It does, however, propose a method for improving the quality of pseudo answer labels using a self-training paradigm, which relies on the ability of language models to accurately predict intent labels. This could be seen as a limitation of language models if their ability to accurately predict intent labels is not high enough, but the paper does not discuss this specifically."
Benchmarking the Generation of Fact Checking Explanations,Yes.,1,"""We focus on summarization approaches over unstructured knowledge (i.e., news articles) and we experiment with several extractive and abstractive strategies."" ""Results show that in justification production summarization benefits from the claim information."""
T 2 -NER: A Two-Stage Span-Based Framework for Unified Named Entity Recognition with Templates,No.,N/A.,This paper is about named entity recognition and does not mention language models at all.
PASTA: A Dataset for Modeling PArticipant STAtes in Narratives,Yes.,5,"The paper states that ""todayâ€™s LLMs can reason about states to some degree, but there is large room for improvement, especially in problems requiring access and ability to reason with diverse types of knowledge."""
U-CORE: A Unified Deep Cluster-wise Contrastive Framework for Open Relation Extraction,No.,N/A.,The paper does not mention language models. It focuses on Open Relation Extraction and proposes a unified framework for Zero-shot and Unsupervised ORE using techniques from Contrastive Learning and Clustering.
In-Context Retrieval-Augmented Language Models,Yes.,3,"The paper mentions the problem of factually inaccurate text generation as a limitation of LMs, and shows that In-Context RALM can mitigate this problem. Additionally, the paper notes that existing RALM approaches complicate deployment, which could be seen as a limitation of the more complex LLMs."
Learning to Paraphrase Sentences to Different Complexity Levels,Yes.,3,"""Finally, we establish how a handful of Large Language Models perform on these tasks under a zero-shot setting."" This suggests that the limitations of LLMs are discussed in the context of their performance on specific tasks."
Direct Speech Translation for Automatic Subtitling,No.,N/A.,"The paper does not mention large language models or their limitations. It discusses the task of automatic subtitling and proposes a new model for it, but it does not involve language modeling in any way."
How Abstract Is Linguistic Generalization in Large Language Models? Experiments with Argument Structure,Yes.,5,"The paper shows that LLMs fail to generalize abstract relationships between contexts that were not observed during pre-training, despite their success in generalizing relationships that were seen. This is a significant limitation as it highlights the need for more abstract and diverse pre-training data to improve the generalization capabilities of LLMs."
"Multi 3 WOZ: A Multilingual, Multi-Domain, Multi-Parallel Dataset for Training and Evaluating Culturally Adapted Task-Oriented Dialog Systems",No.,N/A.,"None in the provided abstract. The paper is about creating a multilingual, multi-domain, multi-parallel ToD dataset. It mentions some limitations of existing ToD datasets but does not mention language models specifically or their limitations."
Can Authorship Representation Learning Capture Stylistic Features?,Yes.,3,"The paper discusses the use of large text corpora for learning authorship representations, which implies the use of large language models for processing and encoding the text data. However, the limitations are that the paper only focuses on text data and does not consider other modalities, and the style transfer application mentioned in the conclusion assumes that the representations captured are purely stylistic, which may not be the case."
Optimal Transport Posterior Alignment for Cross-lingual Semantic Parsing,No.,N/A.,"None. The paper discusses cross-lingual semantic parsing and the use of optimal transport for improving parsing performance, but it does not mention or discuss large language models."
