Source ,Title,Talks about LLMs,Rate,Evidence
aacl2022,Arabic Dialect Identification with a Few Labeled Examples Using Generative Adversarial Networks,Yes.,2,"""However, to fine-tune these models, a large corpus is required. Getting a large number high quality labeled examples for some Dialect Arabic classes is challenging and time-consuming."""
aacl2022,Named Entity Recognition in Twitter: A Dataset and Analysis on Short-Term Temporal Shifts,,,
aacl2022,VLStereoSet: A Study of Stereotypical Bias in Pre-trained Vision-Language Models,Yes.,4,"""Experiments on six representative pre-trained vision-language models demonstrate that stereotypical biases clearly exist in most of these models and across all four bias categories, with gender bias slightly more evident."""
aacl2022,Is Encoder-Decoder Redundant for Neural Machine Translation?,,,
aacl2022,SBERT studies Meaning Representations: Decomposing Sentence Embeddings into Explainable Semantic Features,,,
aacl2022,Unsupervised Domain Adaptation for Sparse Retrieval by Filling Vocabulary and Word Frequency Gaps,Yes.,3,"""SPLADE still struggles with exact matching of low-frequency words in training data. In addition, domain shifts in vocabulary and word frequencies deteriorate the IR performance of SPLADE."""
aacl2022,Cross-lingual Few-Shot Learning on Unseen Languages,Yes.,3,"""However, this was mostly studied for relatively resource-rich languages, where at least enough unlabeled data is available to be included in pre-training a multilingual language model."" and ""we explore the problem of cross-lingual transfer in unseen languages, where no unlabeled data is available for pre-training a model."""
aacl2022,Enhancing Financial Table and Text Question Answering with Tabular Graph and Numerical Reasoning,Yes.,3,"""their performances fall significantly when data and computational resources are limited."""
aacl2022,A Simple Yet Effective Hybrid Pre-trained Language Model for Unsupervised Sentence Acceptability Prediction,Yes.,3,"""first, low-frequency words would have a significant negative impact on the sentence likelihood derived from the language model; second, when it comes to multiple domains, the language model needs to be trained on domain-specific text for domain adaptation."""
aacl2022,Do ever larger octopi still amplify reporting biases? Evidence from judgments of typical colour,Yes.,3,"""texts rarely report on common facts, instead focusing on the unusual aspects of a situation. If LMs are only trained on text corpora and naively memorise local co-occurrence statistics, they thus naturally would learn a biased view of the physical world."""
aacl2022,Demographic-Aware Language Model Fine-tuning as a Bias Mitigation Technique,Yes.,4,"""BERT-like language models (LMs), when exposed to large unstructured datasets, are known to learn and sometimes even amplify the biases present in such data."""
aacl2022,MiQA: A Benchmark for Inference on Metaphorical Questions,Yes.,3,"""We examine the performance of state-of-the-art pre-trained models on binary-choice tasks and find a large discrepancy between the performance of small and very large models, going from chance to near-human level."" and ""We also analyse the largest model in a generative setting and find that although human performance is approached, careful multiple-shot prompting is required."""
aacl2022,CLASP: Few-Shot Cross-Lingual Data Augmentation for Semantic Parsing,Yes.,2,"""LLMs are unsuitable for runtime systems which require low latency."""
aacl2022,Toward Building a Language Model for Understanding Temporal Commonsense,Yes.,3,"""pre-trained language models such as BERT, which have recently achieved great success in a wide range of natural language processing tasks, are still considered to have poor performance in temporal reasoning."""
aacl2022,C3PO: A Lightweight Copying Mechanism for Translating Pseudocode to Code,Yes.,3,"""While large language models (LLMs) have been proposed to translate natural language pseudocode to PL code, they are costly in terms of data and compute."""
emnlp2022,RankGen: Improving Text Generation with Large Ranking Models,Yes.,5,"""modern language models often assign high probabilities to output sequences that are repetitive, incoherent, or irrelevant to the prefix; as such, model-generated text also contains such artifacts."""
emnlp2022,"Tomayto, Tomahto. Beyond Token-level Answer Equivalence for Question Answering Evaluation",No.,1,The abstract does not mention LLMs or their limitations. It focuses on the evaluation of QA systems and the shortcomings of token-level equivalence measures.
emnlp2022,UnifiedSKG: Unifying and Multi-Tasking Structured Knowledge Grounding with Text-to-Text Language Models,Yes.,3,"""we show that T0, GPT-3, and Codex struggle in zero-shot and few-shot learning for SKG."""
emnlp2022,DocInfer: Document-level Natural Language Inference using Optimal Evidence Selection,Yes.,3,"""Our evidence selection mechanism allows it to transcend the input length limitation of modern BERT-like Transformer models while presenting the entire evidence together for inferential reasoning."""
emnlp2022,Entity Extraction in Low Resource Domains with Selective Pre-training of Large Language Models,Yes.,3,"""Transformer-based language models trained on large natural language corpora have been very useful in downstream entity extraction tasks. However, they often result in poor performances when applied to domains that are different from those they are pretrained on."""
emnlp2022,How Large Language Models are Transforming Machine-Paraphrase Plagiarism,Yes.,2,"""The recent success of large language models for text generation poses a severe threat to academic integrity, as plagiarists can generate realistic paraphrases indistinguishable from original work."""
emnlp2022,ELMER: A Non-Autoregressive Pre-trained Language Model for Efficient and Effective Text Generation,,,
emnlp2022,Z-LaVI: Zero-Shot Language Solver Fueled by Visual Imagination,Yes.,3,"""However, they generally suffer from reporting bias, the phenomenon describing the lack of explicit commonsense knowledge in written text, e.g., 'an orange is orange'."""
emnlp2022,Generative Multi-hop Retrieval,Yes.,3,"""However, such a bi-encoder approach has limitations in multi-hop settings; (1) the reformulated query gets longer as the number of hops increases, which further tightens the embedding bottleneck of the query vector, and (2) it is prone to error propagation."""
emnlp2022,Extracted BERT Model Leaks More Information than You Think!,Yes.,3,"""Our extensive experiments reveal that model extraction can cause severe privacy leakage even when victim models are facilitated with state-of-the-art defensive strategies."""
emnlp2022,An Empirical Analysis of Memorization in Fine-tuned Autoregressive Language Models,Yes.,5,"""Large language models are shown to present privacy risks through memorization of training data,"" and ""we empirically study memorization of fine-tuning methods using membership inference and extraction attacks, and show that their susceptibility to attacks is very different."""
emnlp2022,EvEntS ReaLM: Event Reasoning of Entity States via Language Models,Yes.,5,"""Nominally, Large Language models (LLM) have been exposed to procedural knowledge about how objects interact, yet our benchmarking shows they fail to reason about the world."""
emnlp2022,Large language models are few-shot clinical information extractors,Yes.,1,"""large language models, such as InstructGPT (Ouyang et al., 2022), perform well at zero- and few-shot information extraction from clinical text despite not being trained specifically for the clinical domain."""
emnlp2022,Are Hard Examples also Harder to Explain? A Study with Human and Model-Generated Explanations,Yes.,3,"""for hard examples, human explanations are significantly better than GPT-3 explanations both in terms of label-supportiveness and generalizability judgements."""
emnlp2022,Gradient-based Constrained Sampling from Language Models,Yes.,3,"""Large pretrained language models are successful at generating fluent text but are notoriously hard to controllably sample from."""
emnlp2022,Rich Knowledge Sources Bring Complex Knowledge Conflicts: Recalibrating Models to Reflect Conflicting Evidence,Yes.,5,"""we simulate knowledge conflicts (i.e., where parametric knowledge suggests one answer and different passages suggest different answers) and examine model behaviors"" and ""contradictions among knowledge sources affect model confidence only marginally."""
emnlp2022,SafeText: A Benchmark for Exploring Physical Safety in Language Models,Yes.,5,"""We find that state-of-the-art large language models are susceptible to the generation of unsafe text and have difficulty rejecting unsafe advice."""
emnlp2022,Language Model Decomposition: Quantifying the Dependency and Correlation of Language Models,Yes.,2,"""To further advance SOTA we need more diverse and novel LMs that are less dependent on existing LMs."""
emnlp2022,Calibrating Zero-shot Cross-lingual (Un-)structured Predictions,Yes.,3,"""We find that models trained with data from the source language become less calibrated when applied to the target language and that calibration errors increase with intrinsic task difficulty and relative sparsity of training data."""
emnlp2022,Fast-R2D2: A Pretrained Recursive Neural Network based on Pruned CKY for Grammar Induction and Text Representation,,,
emnlp2022,Memory-assisted prompt editing to improve GPT-3 after deployment,Yes.,5,"""Large LMs such as GPT-3 are powerful, but can commit mistakes that are obvious to humans."""
emnlp2022,ROSE: Robust Selective Fine-tuning for Pre-trained Language Models,Yes.,3,"""Even though the large-scale language models have achieved excellent performances, they suffer from various adversarial attacks. A large body of defense methods has been proposed. However, they are still limited due to redundant attack search spaces and the inability to defend against various types of attacks."""
emnlp2022,Reproducibility Issues for BERT-based Evaluation Metrics,Yes.,3,"""We find that reproduction of claims and results often fails because of (i) heavy undocumented preprocessing involved in the metrics, (ii) missing code and (iii) reporting weaker results for the baseline metrics."""
emnlp2022,Generative Entity Typing with Curriculum Learning,Yes.,3,"""PLMs tend to generate coarse-grained types after fine-tuning upon the entity typing dataset."""
emnlp2022,Revisiting Pre-trained Language Models and their Evaluation for Arabic Natural Language Processing,Yes.,2,"""This work addresses two major problems in existing Arabic PLMs that limit the progress of the Arabic NLU and NLG fields."""
emnlp2022,Nearest Neighbor Zero-Shot Inference,Yes.,1,"""Retrieval-augmented language models (LMs) use non-parametric memory to substantially outperform their non-retrieval counterparts on perplexity-based evaluations, but it is an open question whether they achieve similar gains in few- and zero-shot end-task accuracy."""
emnlp2022,RLPrompt: Optimizing Discrete Text Prompts with Reinforcement Learning,Yes.,2,"""Interestingly, the resulting optimized prompts are often ungrammatical gibberish text; and surprisingly, those gibberish prompts are transferrable between different LMs to retain significant performance, indicating that LM prompting may not follow human language patterns."""
emnlp2022,BERTScore is Unfair: On Social Bias in Language Model-Based Metrics for Text Generation,Yes.,4,"""However, it has been demonstrated that PLMs encode a range of stereotypical societal biases, leading to a concern about the fairness of PLMs as metrics."" and ""We demonstrate that popular PLM-based metrics exhibit significantly higher social bias than traditional metrics on 6 sensitive attributes,"
emnlp2022,HPT: Hierarchy-aware Prompt Tuning for Hierarchical Text Classification,Yes.,3,"""there exists a huge gap between the classification tasks with sophisticated label hierarchy and the masked language model (MLM) pretraining tasks of PLMs and thus the potential of PLMs cannot be fully tapped."""
emnlp2022,Neural Theory-of-Mind? On the Limits of Social Intelligence in Large LMs,Yes.,5,"""We show that one of today’s largest language models (GPT-3; Brown et al., 2020) lacks this kind of social intelligence out-of-the box,"" and ""Our results show that models struggle substantially at these Theory of Mind tasks,"" and ""we"
emnlp2022,Improving Temporal Generalization of Pre-trained Language Models with Lexical Semantic Change,Yes.,5,"""neural language models at scale suffer from poor temporal generalization capability"" and ""language model pre-trained on static data from past years performs worse over time on emerging data."""
emnlp2022,Perturbation Augmentation for Fairer NLP,Yes.,4,"""Unwanted and often harmful social biases are becoming ever more salient in NLP research, affecting both models and datasets,"" and ""Lastly, we discuss outstanding questions about how best to evaluate the (un)fairness of large language models."""
emnlp2022,"The better your Syntax, the better your Semantics? Probing Pretrained Language Models for the English Comparative Correlative",Yes.,5,"""Our results show that all three investigated PLMs are able to recognise the structure of the CC but fail to use its meaning. While human-like performance of PLMs on many NLP tasks has been alleged, this indicates that PLMs still suffer from substantial shortcomings in central domains of linguistic knowledge."""
emnlp2022,Is a Question Decomposition Unit All We Need?,Yes.,2,"""building new LMs may not be an ideal option owing to the cost, time and environmental impact associated with it."""
emnlp2022,SLING: Sino Linguistic Evaluation of Large Language Models,Yes.,3,"""Our experiments show that the average accuracy for LMs is far below human performance (69.7% vs. 97.1%),"" and ""we find that most LMs have a strong gender and number (singular/plural) bias, and they perform better on local phenomena than hierarchical ones."""
emnlp2022,Differentially Private Language Models for Secure Data Sharing,Yes.,3,"""In practice, these approaches are often dissatisfying in terms of the quality of their output language due to the strong noise required for local differential privacy."""
emnlp2022,LittleBird: Efficient Faster & Longer Transformer for Question Answering,Yes.,5,"""But it has a limitation dealing with long inputs due to its attention mechanism."""
emnlp2022,PLOG: Table-to-Logic Pretraining for Logical Table-to-Text Generation,,,
emnlp2022,Rethinking the Authorship Verification Experimental Setups,No.,1,The abstract does not mention LLMs or any other language models.
emnlp2022,Invariant Language Modeling,Yes.,5,"""Yet, they suffer from spurious correlations, poor out-of-domain generalization, and biases."""
emnlp2022,InforMask: Unsupervised Informative Masking for Language Model Pretraining,,,
emnlp2022,Mutual Information Alleviates Hallucinations in Abstractive Summarization,Yes.,5,"""these models still exhibit the tendency to hallucinate, i.e., output content not supported by the source document."""
emnlp2022,Fine-tuned Language Models are Continual Learners,,,
emnlp2022,Bernice: A Multilingual Pre-trained Encoder for Twitter,Yes.,1,"""The language of Twitter differs significantly from that of other domains commonly included in large language model training."""
emnlp2022,Just Fine-tune Twice: Selective Differential Privacy for Large Language Models,Yes.,3,"""applying differential privacy (DP), a canonical notion with provable privacy guarantees for machine learning models, to those models remains challenging due to the trade-off between model utility and privacy loss."""
emnlp2022,Textual Manifold-based Defense Against Natural Language Adversarial Examples,Yes.,3,"""Despite the recent success of large pretrained language models in NLP, they are susceptible to adversarial examples."""
emnlp2022,FLUTE: Figurative Language Understanding through Textual Explanations,Yes.,1,"""We show how utilizing GPT-3 in conjunction with human annotators (novices and experts) can aid in scaling up the creation of datasets even for such complex linguistic phenomena as figurative language."""
emnlp2022,One size does not fit all: Investigating strategies for differentially-private learning across NLP tasks,Yes.,2,"""stricter privacy guarantees in differentially-private stochastic gradient descent (DP-SGD) generally degrade model performance."""
emnlp2022,Tutoring Helps Students Learn Better: Improving Knowledge Distillation for BERT with Tutor Network,Yes.,3,"""typical KD approaches for language models have overlooked the difficulty of training examples, suffering from incorrect teacher prediction transfer and sub-efficient training."""
emnlp2022,Multitask Instruction-based Prompting for Fallacy Recognition,Yes.,1,"""we approach these differences across datasets as multiple tasks and show how instruction-based prompting in a multitask setup based on the T5 model improves the results against approaches built for a specific dataset such as T5, BERT or GPT-3."""
emnlp2022,Towards Table-to-Text Generation with Pretrained Language Model: A Table Structure Understanding and Text Deliberating Approach,Yes.,3,"""Although remarkable progress on the neural table-to-text methods has been made, the generalization issues hinder the applicability of these models due to the limited source tables."" and ""However, how to effectively bridge the gap between the structured table and the text input by fully leveraging table information to fuel the pretrained model is still not well explored."""
emnlp2022,Rainier: Reinforced Knowledge Introspector for Commonsense Question Answering,Yes.,3,"""knowledge retrieved from knowledge bases are incomplete and knowledge generated from language models are inconsistent."""
emnlp2022,Few-shot Learning with Multilingual Generative Language Models,Yes.,3,"""their training data is dominated by English, potentially limiting their cross-lingual generalization."""
emnlp2022,Active Example Selection for In-Context Learning,Yes.,3,"""We demonstrate that in-context learning performance can be highly unstable across samples of examples, indicating the idiosyncrasies of how language models acquire information."" and ""However, the improvement diminishes on larger GPT-3 models, suggesting emerging capabilities of large language models."""
emnlp2022,Evaluating the Impact of Model Scale for Compositional Generalization in Semantic Parsing,Yes.,5,"""Despite their strong performance on many tasks, pre-trained language models have been shown to struggle on out-of-distribution compositional generalization."" and ""Overall, our study highlights limitations of current techniques for effectively leveraging model scale for compositional generalization, while our analysis also suggests promising directions for future work."""
emnlp2022,Improving Large-scale Paraphrase Acquisition and Generation,Yes.,1,"""the best pre-trained language model fine-tuned on our dataset achieves the state-of-the-art performance of 84.2 F1 for automatic paraphrase identification."""
emnlp2022,Entropy- and Distance-Based Predictors From GPT-2 Attention Patterns Predict Reading Times Over and Above GPT-2 Surprisal,Yes.,1,"""Transformer-based large language models are trained to make predictions about the next word by aggregating representations of previous tokens through their self-attention mechanism."""
emnlp2022,"Learning Cross-Task Dependencies for Joint Extraction of Entities, Events, Event Arguments, and Relations",,,
emnlp2022,Correcting Diverse Factual Errors in Abstractive Summarization via Post-Editing and Language Model Infilling,Yes.,3,"""Abstractive summarization models often generate inconsistent summaries containing factual errors or hallucinated content."""
emnlp2022,Fine-Tuning Pre-trained Transformers into Decaying Fast Weights,Yes.,3,"""Autoregressive Transformers are strong language models but incur O(T) complexity during per-token generation due to the self-attention mechanism."""
emnlp2022,Adapting a Language Model While Preserving its General Knowledge,Yes.,3,"""However, existing DA-training methods are in some sense blind as they do not explicitly identify what knowledge in the LM should be preserved and what should be changed by the domain corpus."""
emnlp2022,Continual Training of Language Models for Few-Shot Learning,Yes.,1,"""This paper proposes the problem of continually extending an LM by incrementally post-train the LM with a sequence of unlabeled domain corpora to expand its knowledge without forgetting its previous skills."""
emnlp2022,Graph-Induced Transformers for Efficient Multi-Hop Question Answering,Yes.,3,"""Previous approaches to MHQA relied on leveraging the graph information along with the pre-trained language model (PLM) encoders. However, this trend exhibits the following drawbacks"
emnlp2022,Pneg: Prompt-based Negative Response Generation for Dialogue Response Selection Task,Yes.,1,"""To overcome these limitations, this paper proposes a simple but efficient method for generating adversarial negative responses leveraging a large-scale language model."""
emnlp2022,Neighborhood Contrastive Learning for Scientific Document Representations with Citation Embeddings,Yes.,1,"""Furthermore, we demonstrate that it can train (or tune) language models sample-efficiently and that it can be combined with recent training-efficient methods."""
emnlp2022,A Systematic Investigation of Commonsense Knowledge in Large Language Models,Yes.,5,"""Our findings highlight the limitations of pre-trained LMs in acquiring commonsense knowledge without task-specific supervision; furthermore, using larger models or few-shot evaluation is insufficient to achieve human-level commonsense performance."""
emnlp2022,SEAL: Interactive Tool for Systematic Error Analysis and Labeling,Yes.,5,"""However, many times these models systematically fail on tail data or rare groups not obvious in aggregate evaluation."""
emnlp2022,Knowledge Distillation Transfer Sets and their Impact on Downstream NLU Tasks,Yes.,2,"""the generic corpora used to pretrain the teacher and the corpora associated with the downstream target domain are often significantly different, which raises a natural question"
emnlp2022,Grafting Pre-trained Models for Multimodal Headline Generation,Yes.,3,"""A major challenge in simply gluing language model and video-language model is the modality balance, which is aimed at combining visual-language complementary abilities."""
emnlp2022,QUILL: Query Intent with Large Language Models using Retrieval Augmentation and Multi-stage Distillation,Yes.,3,"""Search queries though pose a unique challenge, given their short-length and lack of nuance or context. Complicated feature engineering efforts do not always lead to downstream improvements as their performance benefits may be offset by increased complexity of knowledge distillation."""
acl2022,AlephBERT: Language Model Pre-training and Evaluation from Sub-Word to Sentence Level,Yes.,1,"""First, so far, Hebrew resources for training large language models are not of the same magnitude as their English counterparts. Second, most benchmarks available to evaluate progress in Hebrew NLP require morphological boundaries which are not available in the output of standard PLMs."""
acl2022,GLM: General Language Model Pretraining with Autoregressive Blank Infilling,Yes.,1,"""We propose a General Language Model (GLM) based on autoregressive blank infilling to address this challenge."""
acl2022,Towards Comprehensive Patent Approval Predictions:Beyond Traditional Document Classification,No.,1,The abstract focuses on patent approval predictions and does not mention language models or their limitations.
acl2022,Answer-level Calibration for Free-form Multiple Choice Question Answering,Yes.,3,"""it often requires task-specific heuristics such as length normalization, or probability calibration."""
acl2022,Meta-learning via Language Model In-context Tuning,Yes.,1,"""Inspired by the recent progress in large language models,"" and ""we fine-tune a pre-trained language model (LM) to predict the target label given the input sequence on a collection of tasks."""
acl2022,RoCBert: Robust Chinese Bert with Multimodal Contrastive Pretraining,Yes.,3,"""Large-scale pretrained language models have achieved SOTA results on NLP tasks. However, they have been shown vulnerable to adversarial attacks especially for logographic languages like Chinese."""
acl2022,Auto-Debias: Debiasing Masked Language Models with Automated Biased Prompts,Yes.,4,"""Human-like biases and undesired social stereotypes exist in large pretrained language models. Given the wide adoption of these models in real-world applications, mitigating such biases has become an emerging and important task."""
acl2022,A Closer Look at How Fine-tuning Changes BERT,Yes.,1,"""Finally, by comparing the representations before and after fine-tuning, we discover that fine-tuning does not introduce arbitrary changes to representations; instead, it adjusts the representations to downstream tasks while largely preserving the original spatial structure of the data points."""
acl2022,GPT-D: Inducing Dementia-related Linguistic Anomalies by Deliberate Degradation of Artificial Neural Language Models,Yes.,2,"""questions remain about their ability to generalize beyond the small reference sets that are publicly available for research."""
acl2022,Distributionally Robust Finetuning BERT for Covariate Drift in Spoken Language Understanding,Yes.,2,"""Experiments show that a state-of-the-art BERT-based model suffers performance loss under this drift."""
acl2022,CTRLEval: An Unsupervised Reference-Free Metric for Evaluating Controlled Text Generation,Yes.,1,"""Experimental results show that our metric has higher correlations with human judgments than other baselines, while obtaining better generalization of evaluating generated texts from different models and with different qualities."""
acl2022,Are Prompt-based Models Clueless?,Yes.,5,"""models with a task-specific head require a lot of training data, making them susceptible to learning and exploiting dataset-specific superficial cues that do not generalize to other datasets"" and ""Analyzing few-shot prompt-based models on MNLI, SNLI, HANS, and COPA has revealed that prompt-based models also exploit superficial cues. While the models perform well on instances with superficial cues"
acl2022,Contextual Representation Learning beyond Masked Language Modeling,Yes.,3,"""it adopts sampled embeddings as anchors to estimate and inject contextual semantics to representations, which limits the efficiency and effectiveness of MLMs."""
acl2022,Unsupervised Corpus Aware Language Model Pre-training for Dense Passage Retrieval,Yes.,2,"""fragility to training data noise and ii) requiring large batches to robustly learn the embedding space."""
acl2022,Confidence Based Bidirectional Global Context Aware Training Framework for Neural Machine Translation,No.,1,The abstract discusses neural machine translation (NMT) models and their limitations but does not mention LLMs or their limitations.
acl2022,TruthfulQA: Measuring How Models Mimic Human Falsehoods,Yes.,5,"""Models generated many false answers that mimic popular misconceptions and have the potential to deceive humans."" and ""The largest models were generally the least truthful."""
acl2022,ToxiGen: A Large-Scale Machine-Generated Dataset for Adversarial and Implicit Hate Speech Detection,,,
acl2022,NumGLUE: A Suite of Fundamental yet Challenging Mathematical Reasoning Tasks,,,
acl2022,Upstream Mitigation Is Not All You Need: Testing the Bias Transfer Hypothesis in Pre-Trained Language Models,Yes.,4,"""We investigate the bias transfer hypothesis"
acl2022,ePiC: Employing Proverbs in Context as a Benchmark for Abstract Language Understanding,Yes.,3,"""Our experiments show that neural language models struggle on these tasks compared to humans, and these tasks pose multiple learning challenges."""
acl2022,Bag-of-Words vs. Graph vs. Sequence in Text Classification: Questioning the Necessity of Text-Graphs and the Surprising Strength of a Wide MLP,Yes.,1,"""Moreover, we fine-tune a sequence-based BERT and a lightweight DistilBERT model, which both outperform all state-of-the-art models."""
acl2022,Compression of Generative Pre-trained Language Models via Quantization,Yes.,3,"""Despite various methods to compress BERT or its variants, there are few attempts to compress generative PLMs, and the underlying difficulty remains unclear."" and ""We find that previous quantization methods fail on generative tasks due to the homogeneous word embeddings caused by reduced capacity and the varied distribution of weights."""
acl2022,KinyaBERT: a Morphology-aware Kinyarwanda Language Model,Yes.,3,"""the unsupervised sub-word tokenization methods commonly used in these models (e.g., byte-pair encoding - BPE) are sub-optimal at handling morphologically rich languages."" and ""naive sequencing of morphemes into a standard BERT architecture is inefficient at capturing morphological compos"
acl2022,Flooding-X: Improving BERT’s Resistance to Adversarial Attacks via Loss-Restricted Fine-Tuning,Yes.,1,"""We experimentally show that our method improves BERT’s resistance to textual adversarial attacks by a large margin, and achieves state-of-the-art robust accuracy on various text classification and GLUE tasks."""
acl2022,What does the sea say to the shore? A BERT based DST style approach for speaker to dialogue attribution in novels,No.,1,The abstract does not mention LLMs or any of their limitations.
acl2022,Probing Simile Knowledge from Pre-trained Language Models,Yes.,1,"""The knowledge embedded in PLMs may be useful for SI and SG tasks. Nevertheless, there are few works to explore it."""
acl2022,SHIELD: Defending Textual Neural Networks against Multiple Black-Box Adversarial Attacks with Stochastic Multi-Expert Patcher,Yes.,2,"""In particular, the state-of-the-art transformer models (e.g., BERT, RoBERTa) require great time and computation resources."""
acl2022,A Token-level Reference-free Hallucination Detection Benchmark for Free-form Text Generation,Yes.,5,"""Large pretrained generative models like GPT-3 often suffer from hallucinating non-existent or incorrect content, which undermines their potential merits in real applications."""
acl2022,Low-Rank Softmax Can Have Unargmaxable Classes in Theory but Rarely in Practice,Yes.,3,"""In theory, the result is some words may be impossible to be predicted via argmax, irrespective of input features, and empirically, there is evidence this happens in small language models (Demeter et al., 2020)."""
acl2022,Is GPT-3 Text Indistinguishable from Human Text? Scarecrow: A Framework for Scrutinizing Machine Text,Yes.,4,"""errors in machine generations become ever subtler and harder to spot,"" and ""the ten error categories of Scarecrow—such as redundancy, commonsense errors, and incoherence."""
acl2022,Transkimmer: Transformer Learns to Layer-wise Skim,No.,1,The abstract focuses on improving the computational efficiency of Transformer-based models and does not specifically discuss LLMs or their limitations.
acl2022,ABC: Attention with Bounded-memory Control,Yes.,3,"""However, their attention mechanism comes with a quadratic complexity in sequence lengths, making the computational overhead prohibitive, especially for long sequences."""
acl2022,Cluster & Tune: Boost Cold Start Performance in Text Classification,Yes.,1,"""the common practice of fine-tuning pre-trained models, such as BERT, for a target classification task, is prone to produce poor performance."""
acl2022,Exploiting Language Model Prompts Using Similarity Measures: A Case Study on the Word-in-Context Task,Yes.,5,"""existing prompt-based techniques fail on the semantic distinction task of the Word-in-Context (WiC) dataset. Specifically, none of the existing few-shot approaches (including the in-context learning of GPT-3) can attain a performance that is meaningfully different from the random baseline."""
acl2022,Softmax Bottleneck Makes Language Models Unable to Represent Multi-mode Word Distributions,Yes.,5,"""However, we discover that this single hidden state cannot produce all probability distributions regardless of the LM size or training data size because the single hidden state embedding cannot be close to the embeddings of all the possible next words simultaneously when there are other interfering word embeddings between them."""
acl2022,Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity,,,
acl2022,Coherence boosting: When your pretrained language model is not paying enough attention,Yes.,5,"""We demonstrate that large language models have insufficiently learned the effect of distant words on next-token prediction."""
acl2022,Improving the Generalizability of Depression Detection by Leveraging Clinical Questionnaires,No.,1,The abstract does not mention LLMs or any form of language models.
acl2022,Internet-Augmented Dialogue Generation,Yes.,3,"""Large language models, even though they store an impressive amount of knowledge within their weights, are known to hallucinate facts when generating dialogue; moreover, those facts are frozen in time at the point of model training."""
acl2022,Text-Free Prosody-Aware Generative Spoken Language Modeling,Yes.,3,"""Unfortunately, because the units used in GSLM discard most prosodic information, GSLM fails to leverage prosody for better comprehension and does not generate expressive speech."""
acl2022,P-Tuning: Prompt Tuning Can Be Comparable to Fine-tuning Across Scales and Tasks,Yes.,3,"""prior work reveals that prompt tuning does not perform well for normal-sized pretrained models. We also find that existing methods of prompt tuning cannot handle hard sequence labeling tasks, indicating a lack of universality."""
acl2022,Does BERT Know that the IS-A Relation Is Transitive?,,,
acl2022,Data Contamination: From Memorization to Exploitation,Yes.,5,"""It is not clear to what extent models exploit the contaminated data for downstream tasks."" and ""Our results highlight the importance of analyzing massive web-scale datasets to verify that progress in NLP is obtained by better language understanding and not better data exploitation."""
acl2022,Kronecker Decomposition for GPT Compression,Yes.,5,"""Despite the superior performance of GPT, this overparameterized nature of GPT can be very prohibitive for deploying this model on devices with limited computational power or memory."""
acl2022,Exploiting Language Model Prompts Using Similarity Measures: A Case Study on the Word-in-Context Task,Yes.,3,"""existing prompt-based techniques fail on the semantic distinction task of the Word-in-Context (WiC) dataset"" and ""none of the existing few-shot approaches (including the in-context learning of GPT-3) can attain a performance that is meaningfully different from the random baseline."""
acl2022,"Fire Burns, Sword Cuts: Commonsense Inductive Bias for Exploration in Text-based Games",Yes.,1,"""We propose CommExpl, an exploration technique that injects external commonsense knowledge, via a pretrained language model (LM), into the agent during training."""
acl2022,"When classifying grammatical role, BERT doesn’t care about word order... except when it matters",,,
acl2022,A Recipe for Arbitrary Text Style Transfer with Large Language Models,Yes.,1,"""In this paper, we leverage large language models (LLMs) to perform zero-shot text style transfer."""
acl2022,Exploring Cross-lingual Text Detoxification with Large Multilingual Language Models.,Yes.,3,"""tested state-of-the-art models are not able to perform cross-lingual detoxification and direct fine-tuning on exact language is currently inevitable and motivating the need of further research in this direction."""
acl2022,Cue-bot: A Conversational Agent for Assistive Technology,Yes.,1,"""Language model technologies can be very powerful tools in enabling these users to carry out daily communication and social interactions."""
acl2022,Zero- and Few-Shot NLP with Pretrained Language Models,Yes.,1,"""our goal is to reveal new research opportunities to the audience, which will hopefully bring us closer to address existing challenges in this domain."""
naacl2022,Learning Natural Language Generation with Truncated Reinforcement Learning,Yes.,1,"""TrufLL thus enables to train a language agent by solely interacting with its environment without any task-specific prior knowledge; it is only guided with a task-agnostic language model."""
naacl2022,Language Model Augmented Monotonic Attention for Simultaneous Translation,Yes.,1,"""we propose a framework to aid monotonic attention with an external language model to improve its decisions."""
naacl2022,Enhancing Self-Attention with Knowledge-Assisted Attention Maps,Yes.,3,"""the attention maps, which record the attention scores between tokens in self-attention mechanism, are sometimes ineffective as they are learned implicitly without the guidance of explicit semantic knowledge."""
naacl2022,Knowledge-Grounded Dialogue Generation with a Unified Knowledge Representation,Yes.,1,"""Knowledge-grounded dialogue systems are challenging to build due to the lack of training data and heterogeneous knowledge sources."""
naacl2022,Reframing Human-AI Collaboration for Generating Free-Text Explanations,Yes.,3,"""while models often produce factual, grammatical, and sufficient explanations, they have room to improve along axes such as providing novel information and supporting the label."""
naacl2022,Provably Confidential Language Modelling,Yes.,5,"""Large language models are shown to memorize privacy information such as social security numbers in training data."""
naacl2022,"When a sentence does not introduce a discourse entity, Transformer-based models still sometimes refer to it",Yes.,5,"""We find that while the models are to a certain extent sensitive to the interactions we investigate, they are all challenged by the presence of multiple NPs and their behavior is not systematic, which suggests that even models at the scale of GPT-3 do not fully acquire basic entity tracking abilities."""
naacl2022,Towards a Progression-Aware Autonomous Dialogue Agent,Yes.,3,"""While these agents excel at generating high-quality responses that are relevant to prior context, they suffer from a lack of awareness of the overall direction in which the conversation is headed, and the likelihood of task success inherent therein."""
naacl2022,Cross-Domain Detection of GPT-2-Generated Technical Text,Yes.,1,"""we examine the problem of detecting GPT-2-generated technical research text."""
naacl2022,Context-Aware Abbreviation Expansion Using Large Language Models,,,
naacl2022,Sort by Structure: Language Model Ranking as Dependency Probing,Yes.,1,"""Making an informed choice of pre-trained language model (LM) is critical for performance, yet environmentally costly, and as such widely underexplored."""
naacl2022,SKILL: Structured Knowledge Infusion for Large Language Models,Yes.,2,"""However, it is largely unexplored whether they can better internalize knowledge from a structured data, such as a knowledge graph, or from text."""
naacl2022,MoEBERT: from BERT to Mixture-of-Experts via Importance-Guided Adaptation,,,
naacl2022,Measuring Fairness with Biased Rulers: A Comparative Study on Bias Metrics for Pre-trained Language Models,Yes.,4,"""These results indicate that fairness or bias evaluation remains challenging for contextualized language models, among other reasons because these choices remain subjective."""
naacl2022,ValCAT: Variable-Length Contextualized Adversarial Transformations Using Encoder-Decoder Language Model,Yes.,1,"""Adversarial texts help explore vulnerabilities in language models, improve model robustness, and explain their working mechanisms."""
naacl2022,KroneckerBERT: Significant Compression of Pre-trained Language Models Through Kronecker Decomposition and Knowledge Distillation,Yes.,2,"""While over-parameterization of these models is the key to their generalization power, it makes them unsuitable for deployment on low-capacity devices."""
naacl2022,Data Augmentation with Dual Training for Offensive Span Detection,Yes.,1,"""the large-scale pre-trained language model GPT-2 is employed to generate synthetic training data for OSD."""
naacl2022,Robust Conversational Agents against Imperceptible Toxicity Triggers,No.,1,The abstract does not mention LLMs or their limitations.
naacl2022,PPL-MCTS: Constrained Textual Generation Through Discriminator-Guided MCTS Decoding,Yes.,1,"""Large language models (LM) based on Transformers allow to generate plausible long texts."""
naacl2022,Privacy-Preserving Text Classification on BERT Embeddings with Homomorphic Encryption,Yes.,2,"""recent research has shown that embeddings can potentially leak private information about sensitive attributes of the text, and in some cases, can be inverted to recover the original input text."""
naacl2022,Curriculum: A Broad-Coverage Benchmark for Linguistic Phenomena in Natural Language Understanding,Yes.,5,"""current evaluation methods show some significant shortcomings,"" ""they fail to effectively map out the aspects of language understanding that remain challenging to existing models,"" and ""our experiments provide insight into the limitation of existing benchmark datasets and state-of-the-art models."""
naacl2022,Exposing the Limits of Video-Text Models through Contrast Sets,Yes.,5,"""We see that model performance suffers across all methods, erasing the gap between recent CLIP-based methods vs. the earlier methods."""
naacl2022,Knowledge Inheritance for Pre-trained Language Models,Yes.,3,"""However, it requires tremendous computational resources to train a large-scale PLM, which may be practically unaffordable."""
naacl2022,"Show, Don’t Tell: Demonstrations Outperform Descriptions for Schema-Guided Task-Oriented Dialogue",Yes.,1,"""we show that using short examples as schema representations with large language models results in state-of-the-art performance on two popular dialogue state tracking benchmarks."""
naacl2022,Does Pre-training Induce Systematic Inference? How Masked Language Models Acquire Commonsense Knowledge,Yes.,3,"""We find generalization does not improve over the course of pre-training BERT from scratch, suggesting that commonsense knowledge is acquired from surface-level, co-occurrence patterns rather than induced, systematic reasoning."""
naacl2022,Symbolic Knowledge Distillation: from General Language Models to Commonsense Models,Yes.,1,"""general language models author these commonsense knowledge graphs to train commonsense models."""
naacl2022,Quantifying Adaptability in Pre-trained Language Models with 500 Tasks,Yes.,3,"""We present a large-scale empirical study of the features and limits of LM adaptability using a new benchmark, TaskBench500, built from 500 procedurally generated sequence modeling tasks."""
naacl2022,A Study of the Attention Abnormality in Trojaned BERTs,Yes.,1,"""In this paper, we investigate the underlying mechanism of Trojaned BERT models."""
naacl2022,Lifelong Pretraining: Continually Adapting Language Models to Emerging Corpora,Yes.,3,"""a PTLM-based model must deal with data distributions that deviates from what the PTLM was initially trained on."""
naacl2022,KALA: Knowledge-Augmented Language Model Adaptation,Yes.,5,"""Simple fine-tuning of PLMs, on the other hand, might be suboptimal for domain-specific tasks because they cannot possibly cover knowledge from all domains. While adaptive pre-training of PLMs can help them obtain domain-specific knowledge, it requires a large training cost. Moreover, adaptive pre-training can harm the PLM’s performance on the downstream task by causing catastrophic forgetting of its general"
naacl2022,Building a Personalized Dialogue System with Prompt-Tuning,Yes.,1,"""Considering the trend of the rapidly increasing scale of language models, we propose an approach that uses prompt-tuning, which has low learning costs, on pre-trained large-scale language models."""
naacl2022,On the Effect of Pretraining Corpora on In-context Learning by a Large-scale Language Model,,,
naacl2022,You Don’t Know My Favorite Color: Preventing Dialogue Representations from Revealing Speakers’ Private Personas,Yes.,4,"""privacy concerns have arisen recently"
naacl2022,Methods for Estimating and Improving Robustness of Language Models,Yes.,5,"""large language models (LLMs) suffer notorious flaws related to their preference for shallow textual relations over full semantic complexity of the problem"" and ""weak ability to generalise outside of the training domain."""
naacl2022,Improving Classification of Infrequent Cognitive Distortions: Domain-Specific Model vs. Data Augmentation,Yes.,1,"""The second approach utilizes a domain-specific pretrained language model, MentalBERT."""
naacl2022,Building a Personalized Dialogue System with Prompt-Tuning,Yes.,1,"""Considering the trend of the rapidly increasing scale of language models, we propose an approach that uses prompt-tuning, which has low learning costs, on pre-trained large-scale language models."""
naacl2022,Multimodal large language models for inclusive collaboration learning tasks,Yes.,1,"""We address some concerns of integrating advances in natural language processing into downstream tasks such as the learning analytics feedback loop."""
naacl2022,Exploring the Effect of Dialect Mismatched Language Models in Telugu Automatic Speech Recognition,Yes.,5,"""We show that dialect variations that surface in the form of a different lexicon, grammar, and occasionally semantics can significantly degrade the performance of the LM under mismatched conditions."""
naacl2022,An End-to-End Dialogue Summarization System for Sales Calls,Yes.,1,"""We show how GPT-3 can be leveraged as an offline data labeler to handle training data scarcity and accommodate privacy constraints in an industrial setting."""
naacl2022,Medical Coding with Biomedical Transformer Ensembles and Zero/Few-shot Learning,Yes.,2,"""automating this task is challenging due to a large number of LLT codes (as of writing over 80\,000), limited availability of training data for long tail/emerging classes, and the general high accuracy demands of the medical domain."""
naacl2022,Knowledge extraction from aeronautical messages (NOTAMs) with self-supervised language models for aircraft pilots,Yes.,1,"""In this paper, we pretrain language models derived from BERT on circa 1 million unlabeled NOTAMs and reuse the learnt representations on three downstream tasks valuable for pilots."""
acl2023,ACLM: A Selective-Denoising based Generative Data Augmentation Approach for Low-Resource Complex NER,Yes.,1,"""In this paper, we present ACLM Attention-map aware keyword selection for Conditional Language Model fine-tuning), a novel data augmentation approach based on conditional generation, to address the data scarcity problem in low-resource complex NER."""
acl2023,MIL-Decoding: Detoxifying Language Models at Token-Level via Multiple Instance Learning,Yes.,4,"""Despite advances in large pre-trained neural language models, they are prone to generating toxic language, which brings security risks to their applications."""
acl2023,Text Adversarial Purification as Defense against Adversarial Attacks,Yes.,1,"""With the help of language models, we can inject noise by masking input texts and reconstructing the masked texts based on the masked language models."""
acl2023,Knowledge of cultural moral norms in large language models,Yes.,4,"""We find that pre-trained English language models predict empirical moral norms across countries worse than the English moral norms reported previously. However, fine-tuning language models on the survey data improves inference across countries at the expense of a less accurate estimate of the English moral norms."""
acl2023,A Causal Framework to Quantify the Robustness of Mathematical Reasoning with Language Models,Yes.,5,"""the robustness of these models has also been called into question; recent works have shown that models can rely on shallow patterns in the problem description when generating a solution"" and ""Our analysis shows that robustness does not appear to continuously improve as a function of size."""
acl2023,Increasing Diversity While Maintaining Accuracy: Text Data Generation with Large Language Models and Human Interventions,Yes.,,
acl2023,Self-Edit: Fault-Aware Code Editor for Code Generation,Yes.,3,"""However, with limited sample numbers, LLMs still suffer from poor accuracy."""
acl2023,Does GPT-3 Grasp Metaphors? Identifying Metaphor Mappings with Generative Language Models,Yes.,3,"""GPT’s most common error is a hallucinated source domain for which no indicator is present in the sentence. Other common errors include identifying a sequence as literal even though a metaphor is present and predicting the wrong source domain based on specific words in the sequence that are"
acl2023,ALERT: Adapt Language Models to Reasoning Tasks,Yes.,5,"""it is unclear whether these models are applying reasoning skills they have learnt during pre-training, or if they are simply memorizing their training corpus at finer granularity,"" and ""we also find that when language models are finetuned they tend to overfit to the prompt template, which hurts the robustness of models causing generalization"
acl2023,Glot500: Scaling Multilingual Corpora and Language Models to 500 Languages,Yes.,1,"""The NLP community has mainly focused on scaling Large Language Models (LLMs) vertically, i.e., making them better for about 100 languages."""
acl2023,Pretrained Bidirectional Distillation for Machine Translation,,,
acl2023,ThinkSum: Probabilistic reasoning over sets using large language models,Yes.,5,"""recent studies show that even the more advanced LLMs fail in scenarios that require reasoning over multiple objects or facts and making sequences of logical deductions."""
acl2023,Synthetic Text Generation with Differential Privacy: A Simple and Practical Recipe,Yes.,1,"""simply fine-tuning a pretrained generative language model with DP enables the model to generate useful synthetic text with strong privacy protection."""
acl2023,Cross-Domain Data Augmentation with Domain-Adaptive Language Modeling for Aspect-Based Sentiment Analysis,Yes.,1,"""we propose a new cross-domain Data Augmentation approach based on Domain-Adaptive Language Modeling named DA2LM"""
acl2023,Marked Personas: Using Natural Language Prompts to Measure Stereotypes in Language Models,,,
acl2023,Elaboration-Generating Commonsense Question Answering at Scale,Yes.,2,"""Yet the cost of working with such models is very high."""
acl2023,DaMSTF: Domain Adversarial Learning Enhanced Meta Self-Training for Domain Adaptation,Yes.,1,"""On the cross-domain sentiment classification task, DaMSTF improves the performance of BERT with an average of nearly 4%."""
acl2023,Do language models have coherent mental models of everyday things?,Yes.,5,"""we observe that state-of-the-art pre-trained language models (LMs) like GPT-3 and Macaw have fragments of knowledge about these everyday things, but do not have fully coherent 'parts mental models' (54-59% accurate, 19-43% conditional constraint violation)."""
acl2023,"KALM: Knowledge-Aware Integration of Local, Document, and Global Contexts for Long Document Understanding",Yes.,2,"""While existing approaches leverage external knowledge, it remains an open question how to jointly incorporate knowledge graphs represented in varying contexts"" and ""incorporating varying contexts can especially benefit long document understanding tasks that leverage pre-trained LMs, typically bounded by the input sequence length."""
acl2023,Z-ICL: Zero-Shot In-Context Learning with Pseudo-Demonstrations,Yes.,3,"""performance drops significantly when no demonstrations are available."""
acl2023,Training-free Neural Architecture Search for RNNs and Transformers,,,
acl2023,Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning by Large Language Models,Yes.,5,"""Despite the success of Zero-shot-CoT, it still suffers from three pitfalls"
acl2023,Symbolic Chain-of-Thought Distillation: Small Models Can Also “Think” Step-by-Step,Yes.,3,"""benefits appear to emerge only for sufficiently large models (beyond 50B parameters)."""
acl2023,Towards Understanding Chain-of-Thought Prompting: An Empirical Study of What Matters,Yes.,3,"""Despite its success, there is still little understanding of what makes CoT prompting effective and which aspects of the demonstrated reasoning steps contribute to its performance."""
acl2023,Dynamic and Efficient Inference for Text Generation via BERT Family,Yes.,5,"""they suffer from inefficient inference on computation and memory due to their large-scale parameters and the universal autoregressive decoding paradigm."""
acl2023,An Invariant Learning Characterization of Controlled Text Generation,Yes.,3,"""researchers hoping to deploy a large language model to produce non-toxic content may use a toxicity classifier to filter generated text"" and ""the performance of controlled generation may be poor if the distributions of text in response to user prompts differ from the distribution the predictor was trained on."""
acl2023,HyPe: Better Pre-trained Language Model Fine-tuning with Hidden Representation Perturbation,Yes.,3,"""there still poses problems when fine-tuning pre-trained language models on downstream tasks, such as over-fitting or representation collapse."""
acl2023,Decoding Symbolism in Language Models,,,
acl2023,A Survey on Zero Pronoun Translation,Yes.,3,"""ZPT is in line with the development trend of large language model"" and ""data limitation causes learning bias in languages and domains"" and ""advanced methods are still far from real-world use"" and ""general-purpose metrics are not reliable on nuances and complexities of ZPT, emphasizing the necessity of targeted metrics."""
acl2023,Alleviating Over-smoothing for Unsupervised Sentence Representation,Yes.,3,"""Experimentally, we observe that the over-smoothing problem reduces the capacity of these powerful PLMs, leading to sub-optimal sentence representations."""
acl2023,Code4Struct: Code Generation for Few-Shot Event Structure Prediction,Yes.,1,"""Large Language Model (LLM) trained on a mixture of text and code has demonstrated impressive capability in translating natural language (NL) into structured code."""
acl2023,Entity Tracking in Language Models,Yes.,3,"""we present a task probing to what extent a language model can infer the final state of an entity given an English description of the initial state and a series of state-changing operations"" and ""pretraining on text corpora alone does not make this capacity surface."""
acl2023,Faithful Question Answering with Monte-Carlo Planning,Yes.,3,"""revealing the intermediate reasoning steps that the models faithfully follow remains challenging."""
acl2023,Analyzing and Reducing the Performance Gap in Cross-Lingual Transfer with Fine-tuning Slow and Fast,Yes.,3,"""However, there is a clear gap between the performance of the source language and that of the non-source languages."""
acl2023,Social-Group-Agnostic Bias Mitigation via the Stereotype Content Model,Yes.,4,"""Existing bias mitigation methods require social-group-specific word pairs (e.g., “man” – “woman”) for each social attribute (e.g., gender), restricting the bias mitigation to only one specified social attribute. Further, this constraint renders such methods impractical and costly for mitigating bias in"
acl2023,Revisiting the Gold Standard: Grounding Summarization Evaluation with Robust Human Evaluation,Yes.,3,"""The metrics we benchmarked include recent methods based on large language models (LLMs), GPTScore and G-Eval. Furthermore, our findings have important implications for evaluating LLMs, as we show that LLMs adjusted by human feedback (e.g., GPT-3.5"
acl2023,FIREBALL: A Dataset of Dungeons and Dragons Actual-Play with Structured Game State Information,Yes.,2,"""Recent work has shown that large language models (LLMs) that have access to state information can generate higher quality game turns than LLMs that use dialog history alone. However, previous work used game state information that was heuristically created and was not a true gold standard game"
acl2023,Distilling Script Knowledge from Large Language Models for Constrained Language Planning,Yes.,2,"""Previous work has exploited language models (LMs) to plan for abstract goals of stereotypical activities (e.g., “make a cake”), but leaves more specific goals with multi-facet constraints understudied (e.g., “make a cake for diabetics”)."""
acl2023,CELDA: Leveraging Black-box Language Model as Enhanced Classifier without Labels,Yes.,3,"""Despite their efficacy, they still fall short in comparison to fully supervised counterparts and are generally brittle to slight modifications."""
acl2023,Explanation-based Finetuning Makes Models More Robust to Spurious Cues,Yes.,5,"""Large Language Models (LLMs) are so powerful that they sometimes learn correlations between labels and features that are irrelevant to the task, leading to poor generalization on out-of-distribution data."""
acl2023,"On Second Thought, Let’s Not Think Step by Step! Bias and Toxicity in Zero-Shot Reasoning",Yes.,5,"""We find that zero-shot CoT reasoning in sensitive domains significantly increases a model’s likelihood to produce harmful or undesirable output,"" and ""Our work suggests that zero-shot CoT should be used with caution on socially important tasks, especially when marginalized groups or sensitive topics are involved."""
acl2023,Solving Math Word Problems via Cooperative Reasoning induced Language Models,Yes.,3,"""However, directly applying existing PLMs to MWPs can fail as the generation process lacks sufficient supervision and thus lacks fast adaptivity as humans."""
acl2023,"Don’t Generate, Discriminate: A Proposal for Grounding Language Models to Real-World Environments",Yes.,3,"""A key missing capacity of current language models (LMs) is grounding to real-world environments."" and ""It thereby casts the burden of ensuring grammaticality, faithfulness, and controllability all on the LMs."""
acl2023,Randomized Smoothing with Masked Inference for Adversarially Robust Text Classifications,Yes.,3,"""Large-scale pre-trained language models have shown outstanding performance in a variety of NLP tasks. However, they are also known to be significantly brittle against specifically crafted adversarial examples, leading to increasing interest in probing the adversarial robustness of NLP systems."""
acl2023,MetaAdapt: Domain Adaptive Few-Shot Misinformation Detection via Meta Learning,Yes.,1,"""we perform extensive experiments to compare MetaAdapt with state-of-the-art baselines and large language models (LLMs) such as LLaMA."""
acl2023,Making Language Models Better Reasoners with Step-Aware Verifier,Yes.,3,"""Large language models like GPT-3 and PaLM have made impressive progress in this area, but they still face difficulties in reasoning tasks such as GSM8K, a benchmark for arithmetic problems."""
acl2023,MISGENDERED: Limits of Large Language Models in Understanding Pronouns,Yes.,5,"""When prompted out-of-the-box, language models perform poorly at correctly predicting neo-pronouns (averaging 7.6% accuracy) and gender-neutral pronouns (averaging 31.0% accuracy). This inability to generalize results from a lack of representation of non-binary pronouns in training data and memorized associations."""
acl2023,DISCO: Distilling Counterfactuals with Large Language Models,,,
acl2023,SCOTT: Self-Consistent Chain-of-Thought Distillation,Yes.,4,"""Even more concerning, there is little guarantee that the generated rationales are consistent with LM’s predictions or faithfully justify the decisions."""
acl2023,Evaluating Open-Domain Question Answering in the Era of Large Language Models,Yes.,5,"""The automated models struggle in detecting hallucinations in LLM answers and are thus unable to evaluate LLMs."""
acl2023,Open-Domain Hierarchical Event Schema Induction by Incremental Prompting and Verification,Yes.,1,"""we propose to treat event schemas as a form of commonsense knowledge that can be derived from large language models (LLMs)."""
acl2023,Verify-and-Edit: A Knowledge-Enhanced Chain-of-Thought Framework,Yes.,5,"""one of its most fatal disadvantages is the lack of factual correctness. Generating unfactual texts not only leads to lower performances but also degrades the trust and validity of their applications."""
acl2023,Connective Prediction for Implicit Discourse Relation Recognition via Knowledge Distillation,Yes.,1,"""To address these problems, we propose a novel Connective Prediction via Knowledge Distillation (CP-KD) approach to instruct large-scale pre-trained language models (PLMs) mining the latent correlations between connectives and discourse relations, which is meaningful for IDRR."""
acl2023,Language model acceptability judgements are not always robust to context,Yes.,5,"""We find that model judgements are generally robust when placed in randomly sampled linguistic contexts, but are unstable when contexts match the test stimuli in syntactic structure."" and ""This sensitivity to highly specific syntactic features of the context can only be explained by the models’ implicit in-context learning abilities."""
acl2023,RobuT: A Systematic Study of Table QA Robustness Against Human-Annotated Adversarial Perturbations,Yes.,5,"""Our results indicate that both state-of-the-art Table QA models and large language models (e.g., GPT-3) with few-shot learning falter in these adversarial sets."""
acl2023,Learning Non-linguistic Skills without Sacrificing Linguistic Proficiency,Yes.,5,"""non-linguistic skill injection typically comes at a cost for LLMs"
acl2023,Multilingual LLMs are Better Cross-lingual In-context Learners with Alignment,Yes.,3,"""We find that the prevalent mode of selecting random input-label pairs to construct the prompt-context is severely limited in the case of cross-lingual ICL, primarily due to the lack of alignment in the input as well as the output spaces."""
acl2023,MultiTabQA: Generating Tabular Answers for Multi-Table Question Answering,Yes.,1,"""Recent advances in tabular question answering (QA) with large language models are constrained in their coverage and only answer questions over a single table."""
acl2023,Long-Tailed Question Answering in an Open World,Yes.,1,"""we define Open Long-Tailed QA (OLTQA) as learning from long-tailed distributed data and optimizing performance over seen and unseen QA tasks. We propose an OLTQA model that encourages knowledge sharing between head, tail and unseen tasks, and explicitly mines knowledge from a large pre-trained language model (LM)."""
acl2023,Parallel Context Windows for Large Language Models,Yes.,5,"""When applied to processing long text, Large Language Models (LLMs) are limited by their context window."""
acl2023,Contrastive Learning with Adversarial Examples for Alleviating Pathology of Language Model,Yes.,5,"""However, these models also suffer from the pathology of overconfidence in the out-of-distribution examples, potentially making the model difficult to interpret and making the interpretation methods fail to provide faithful attributions."""
acl2023,FutureTOD: Teaching Future Knowledge to Pre-trained Language Model for Task-Oriented Dialogue,Yes.,3,"""the intrinsical difference of linguistic patterns between general text and task-oriented dialogues makes existing pre-trained language models less useful in practice"" and ""Current dialogue pre-training methods rely on a contrastive framework and face the challenges of both selecting true positives and hard negatives."""
acl2023,LAMBADA: Backward Chaining for Automated Reasoning in Natural Language,Yes.,3,"""These techniques search for proofs in the forward direction from axioms to the conclusion, which suffers from a combinatorial explosion of the search space, and thus high failure rates for problems requiring longer chains of reasoning."""
acl2023,SQuARe: A Large-Scale Dataset of Sensitive Questions and Acceptable Responses Created through Human-Machine Collaboration,Yes.,4,"""The potential social harms that large language models pose, such as generating offensive content and reinforcing biases, are steeply rising."""
acl2023,FLamE: Few-shot Learning from Natural Language Explanations,Yes.,3,"""Yet, recent work by Lampinen et al. has shown limited utility of natural language explanations in improving classification."" and ""human evaluation surprisingly reveals that the majority of generated explanations does not adequately justify classification decisions."""
acl2023,What social attitudes about gender does BERT encode? Leveraging insights from psycholinguistics,Yes.,3,"""We find that the language model BERT takes into account factors that shape human lexical choice of such language, but may not weigh those factors in the same way people do."" and ""Such findings illuminate how a language model"
acl2023,Are Experts Needed? On Human Evaluation of Counselling Reflection Generation,Yes.,1,"""We also discover that GPT-3 mostly produces coherent and consistent reflections, and we explore changes in evaluation results when the source of synthetic reflections changes to GPT-3 from the less powerful GPT-2."""
acl2023,When and how to paraphrase for named entity recognition?,Yes.,1,"""We find that the choice of the paraphraser greatly impacts NER performance, with one of the larger GPT-3 variants exceedingly capable of generating high quality paraphrases, yielding statistically significant improvements in NER performance with increasing paraphrasing strength, while other paraphrasers show more mixed results."""
acl2023,Are Machine Rationales (Not) Useful to Humans? Measuring and Improving Human Utility of Free-text Rationales,Yes.,4,"""We observe that human utility of existing rationales is far from satisfactory and expensive to estimate with human studies. Existing metrics like task performance of the LM generating the rationales or similarity between generated and gold rationales are not good indicators of their human utility."""
acl2023,Multi-Level Knowledge Distillation for Out-of-Distribution Detection in Text,Yes.,1,"""These approaches either train a language model from scratch or fine-tune a pre-trained language model using ID examples, and then take the perplexity output by the language model as OoD scores."""
acl2023,ByGPT5: End-to-End Style-conditioned Poetry Generation with Token-free Language Models,Yes.,1,"""We identify and address lack of training data and mismatching tokenization algorithms as possible limitations of past attempts."""
acl2023,Matching Pairs: Attributing Fine-Tuned Models to their Pre-Trained Large Language Models,Yes.,3,"""However, this leads to issues over violation of model licenses, model theft, and copyright infringement. Moreover, recent advances show that generative technology is capable of producing harmful content which exacerbates the problems of accountability within model supply chains."""
acl2023,Large Language Models Meet NL2Code: A Survey,Yes.,2,"""In addition, we discuss challenges and opportunities regarding the gap between models and humans."""
acl2023,DarkBERT: A Language Model for the Dark Side of the Internet,Yes.,1,"""We describe the steps taken to filter and compile the text data used to train DarkBERT to combat the extreme lexical and structural diversity of the Dark Web that may be detrimental to building a proper representation of the domain."""
acl2023,Are You Copying My Model? Protecting the Copyright of Large Language Models for EaaS via Backdoor Watermark,Yes.,3,"""EaaS is vulnerable to model extraction attacks, which can cause significant losses for the owners of LLMs, as training these models is extremely expensive."""
acl2023,RL4F: Generating Natural Language Feedback with Reinforcement Learning for Repairing Model Outputs,Yes.,4,"""Despite their unprecedented success, even the largest language models make mistakes,"" and ""this approach does not apply to black-box or limited access models such as ChatGPT, as they cannot be fine-tuned. Moreover, in the era of large general-purpose language agents, fine-tuning"
acl2023,DIP: Dead code Insertion based Black-box Attack for Programming Language Model,Yes.,3,"""However, these PL models are vulnerable to adversarial examples that are generated with slight perturbation."""
acl2023,Data Curation Alone Can Stabilize In-context Learning,Yes.,3,"""ICL is very sensitive to the choice of training examples"
acl2023,S2ynRE: Two-stage Self-training with Synthetic data for Low-resource Relation Extraction,Yes.,1,"""We first leverage the capability of large language models to adapt to the target domain and automatically synthesize large quantities of coherent, realistic training data."""
acl2023,DSEE: Dually Sparsity-embedded Efficient Tuning of Pre-trained Language Models,Yes.,3,"""as the pre-trained models grow bigger (e.g., 175B parameters for GPT-3), even the fine-tuning process can be time-consuming and computationally expensive"" and ""the fine-tuned model has the same size as its starting point by default, which is neither sensible due to its more specialized functionality, nor practical since many fine-tuned models will be deployed in"
acl2023,A New Dataset and Empirical Study for Sentence Simplification in Chinese,Yes.,1,"""In the end, we explore whether Large Language Models can serve as high-quality Chinese sentence simplification systems by evaluating them on CSS."""
acl2023,AD-KD: Attribution-Driven Knowledge Distillation for Language Model Compression,Yes.,3,"""existing knowledge distillation methods suffer from two limitations. First, the student model simply imitates the teacher’s behavior while ignoring the reasoning behind it. Second, these methods usually focus on the transfer of sophisticated model-specific knowledge but overlook data-specific knowledge."""
acl2023,Targeted Data Generation: Finding and Fixing Model Weaknesses,Yes.,4,"""state-of-the-art NLP models often fail systematically on specific subgroups of data, resulting in unfair outcomes and eroding user trust."""
acl2023,On “Scientific Debt” in NLP: A Case for More Rigour in Language Model Pre-Training Research,Yes.,5,"""current PLM research practices often conflate different possible sources of model improvement, without conducting proper ablation studies and principled comparisons between different models under comparable conditions. These practices (i) leave us ill-equipped to understand which pre-training approaches should be used under what circumstances; (ii) impede reproducibility and credit assignment; and (iii) render it difficult to understand"
acl2023,Element-aware Summarization with Large Language Models: Expert-aligned Evaluation and Chain-of-Thought Method,Yes.,1,"""we observe the surprising zero-shot summary ability of LLMs, which addresses the issue of the inconsistent results between human preference and automatic evaluation metrics of LLMs’ zero-shot summaries in prior work."""
acl2023,The CRINGE Loss: Learning what language not to model,Yes.,3,"""Growing evidence shows that even with very large amounts of positive training data, issues remain that can be alleviated with relatively small amounts of negative data – examples of what the model should not do."""
acl2023,"My side, your side and the evidence: Discovering aligned actor groups and the narratives they weave",Yes.,1,"""With the help of Large Language Models (LLM), we address this task by"
acl2023,WinoQueer: A Community-in-the-Loop Benchmark for Anti-LGBTQ+ Bias in Large Language Models,Yes.,5,"""We apply our benchmark to several popular LLMs and find that off-the-shelf models generally do exhibit considerable anti-queer bias."""
acl2023,Benchmarking Large Language Model Capabilities for Conditional Generation,Yes.,3,"""Despite their ubiquitous use, the generation quality of language models is rarely evaluated when these models are introduced. Additionally, it is unclear how existing generation tasks–while they can be used to compare systems at a high level–relate to the real world use cases for which people have been adopting them."""
acl2023,Searching for Needles in a Haystack: On the Role of Incidental Bilingualism in PaLM’s Translation Capability,Yes.,1,"""We investigate the role of incidental bilingualism—the unintentional consumption of bilingual signals, including translation examples—in explaining the translation capabilities of large language models, taking the Pathways Language Model (PaLM) as a case study."""
acl2023,I2D2: Inductive Knowledge Distillation with NeuroLogic and Self-Imitation,Yes.,3,"""Commonsense capabilities of pre-trained language models dramatically improve with scale, leading many to believe that scale is the only winning recipe. But is it?"" and ""can smaller language models (e.g., GPT-2) win over models that are orders of magnitude larger and better (e.g., GPT-3), if powered with novel commonsense distillation algorithms?"""
acl2023,When Not to Trust Language Models: Investigating Effectiveness of Parametric and Non-Parametric Memories,Yes.,5,"""Despite their impressive performance on diverse tasks, large language models (LMs) still struggle with tasks requiring rich world knowledge, implying the difficulty of encoding a wealth of world knowledge in their parameters."" and ""We find that LMs struggle with less popular factual knowledge, and that retrieval augmentation helps significantly in these cases."" and ""Scaling, on the other hand, mainly improves memorization of"
acl2023,SeeGULL: A Stereotype Benchmark with Broad Geo-Cultural Coverage Leveraging Generative Models,,,
acl2023,Say What You Mean! Large Language Models Speak Too Positively about Negative Commonsense Knowledge,Yes.,5,"""Our experiments reveal that LLMs frequently fail to generate valid sentences grounded in negative commonsense knowledge,"" and ""statistical shortcuts and negation reporting bias from language modeling pre-training cause this conflict."""
acl2023,Cognitive Reframing of Negative Thoughts through Human-Language Model Interaction,Yes.,1,"""Our findings provide key implications for the use of LMs to assist people in overcoming negative thoughts."""
acl2023,Interleaving Retrieval with Chain-of-Thought Reasoning for Knowledge-Intensive Multi-Step Questions,,,
acl2023,Improved Instruction Ordering in Recipe-Grounded Conversation,Yes.,3,"""Analyzing the generated output of the GPT-J model, we reveal that the primary challenge for a recipe-grounded dialog system is how to provide the instructions in the correct order."" and ""we analyze its outputs and find that it also makes mistakes (10.7% of the responses), about half of which are out-of-order"
acl2023,Token-wise Decomposition of Autoregressive Language Model Hidden States for Analyzing Model Predictions,Yes.,3,"""the complex computations performed within each layer have made their behavior somewhat opaque"" and ""collocational association and repetitions of the same token largely explain the language models’ predictions on these tasks."""
acl2023,Language Detoxification with Attribute-Discriminative Latent Space,Yes.,3,"""Transformer-based Language Models (LMs) have achieved impressive results on natural language understanding tasks, but they can also generate toxic text such as insults, threats, and profanity, limiting their real-world applications."""
acl2023,Revisiting Token Dropping Strategy in Efficient BERT Pretraining,Yes.,3,"""Token dropping is prone to a semantic loss problem and falls short in handling semantic-intense tasks."""
acl2023,Your spouse needs professional help: Determining the Contextual Appropriateness of Messages through Modeling Social Relationships,Yes.,1,"""we show that large language models can readily incorporate relationship information to accurately identify appropriateness in a given context."""
acl2023,How Do In-Context Examples Affect Compositional Generalization?,Yes.,5,"""We find that the compositional generalization performance can be easily affected by the selection of in-context examples,"" and ""two strong limitations are observed"
acl2023,Measuring Inductive Biases of In-Context Learning with Underspecified Demonstrations,Yes.,3,"""the generalization behavior of ICL remains poorly understood"" and ""we find that, while many interventions can influence the learner to prefer a particular feature, it can be difficult to overcome strong prior biases."""
acl2023,Introducing Semantics into Speech Encoders,Yes.,1,"""Recent studies find existing self-supervised speech encoders contain primarily acoustic rather than semantic information. As a result, pipelined supervised automatic speech recognition (ASR) to large language model (LLM) systems achieve state-of-the-art results on semantic spoken language tasks by utilizing rich semantic representations from the LLM."""
acl2023,SSD-LM: Semi-autoregressive Simplex-based Diffusion Language Model for Text Generation and Modular Control,Yes.,1,"""Despite the growing success of diffusion models in continuous-valued domains (e.g., images), similar efforts for discrete domains such as text have yet to match the performance of autoregressive language models."""
acl2023,"Recall, Expand, and Multi-Candidate Cross-Encode: Fast and Accurate Ultra-Fine Entity Typing",Yes.,1,"""CE concatenates a mention (and its context) with each type and feeds the pair into a pretrained language model (PLM) to score their relevance."""
acl2023,"Understanding Factual Errors in Summarization: Errors, Summarizers, Datasets, Error Detectors",Yes.,3,"""Critically, our analysis shows that much of the recent improvement in the factuality detection space has been on summaries from older (pre-Transformer) models instead of more relevant recent summarization models."""
acl2023,SLABERT Talk Pretty One Day: Modeling Second Language Acquisition with BERT,Yes.,1,"""Our findings call for further research using our novel Transformer-based SLA models and we would like to encourage it by releasing our code, data, and models."""
acl2023,Contrastive Novelty-Augmented Learning: Anticipating Outliers with Large Language Models,Yes.,3,"""existing models are often overly confident on unseen classes."""
acl2023,Rethinking the Role of Scale for In-Context Learning: An Interpretability-based Case Study at 66 Billion Scale,Yes.,3,"""Overall, our study provides several insights that indicate large language models may be under-trained for in-context learning and opens up questions on how to pre-train language models to more effectively perform in-context learning."""
acl2023,ESCOXLM-R: Multilingual Taxonomy-driven Pre-training for the Job Market Domain,Yes.,1,"""In this study, we introduce a language model called ESCOXLM-R, based on XLM-R-large, which uses domain-adaptive pre-training on the European Skills, Competences, Qualifications and Occupations (ESCO) taxonomy, covering 27 languages."""
acl2023,On the Blind Spots of Model-Based Evaluation Metrics for Text Generation,,,
acl2023,Downstream Datasets Make Surprisingly Good Pretraining Corpora,Yes.,2,"""These findings are especially relevant in light of concerns about intellectual property and offensive content in web-scale pretraining data."""
acl2023,Contrastive Decoding: Open-ended Text Generation as Optimization,Yes.,5,"""maximum probability is a poor decoding objective for open-ended generation, because it produces short and repetitive text. On the other hand, sampling can often produce incoherent text that drifts from the original topics."""
acl2023,Self-Instruct: Aligning Language Models with Self-Generated Instructions,Yes.,2,"""they depend heavily on human-written instruction data that is often limited in quantity, diversity, and creativity, therefore hindering the generality of the tuned model."""
acl2023,CHBias: Bias Evaluation and Mitigation of Chinese Conversational Language Models,Yes.,4,"""Pretrained conversational agents have been exposed to safety issues, exhibiting a range of stereotypical human biases such as gender bias."" and ""Experimental results show that these Chinese pretrained models are potentially risky for generating texts that contain social biases."""
acl2023,Mitigating Label Biases for In-context Learning,Yes.,5,"""domain-label bias restricts LLMs to random-level performance on many tasks regardless of the choice of in-context examples."""
acl2023,LLM-Blender: Ensembling Large Language Models with Pairwise Ranking and Generative Fusion,Yes.,1,"""Our framework consists of two modules"
acl2023,Python Code Generation by Asking Clarification Questions,Yes.,3,"""While recent pretrained language models demonstrate remarkable performance for this task, these models fail when the given natural language description is under-specified."""
acl2023,Towards Benchmarking and Improving the Temporal Reasoning Capability of Large Language Models,Yes.,1,"""we introduce a comprehensive probing dataset TempReason to evaluate the temporal reasoning capability of large language models."""
acl2023,Large Language Models Are Reasoning Teachers,Yes.,3,"""prompt-based CoT methods are dependent on very large models such as GPT-3 175B which are prohibitive to deploy at scale."""
acl2023,Visually-augmented pretrained language models for NLP tasks without images,Yes.,3,"""they are found lack of visual semantics or commonsense."""
acl2023,FERMAT: An Alternative to Accuracy for Numerical Reasoning,Yes.,3,"""While pre-trained language models achieve impressive performance on various NLP benchmarks, they still struggle with tasks that require numerical reasoning."" and ""Recent advances in improving numerical reasoning are mostly achieved using very large language models that contain billions of parameters and are not accessible to everyone."""
acl2023,On Improving Summarization Factual Consistency from Natural Language Feedback,Yes.,3,"""fine-tuned language models can leverage our dataset to improve the summary factual consistency, while large language models lack the zero-shot learning ability in our proposed tasks that require controllable text generation."""
acl2023,From Dogwhistles to Bullhorns: Unveiling Coded Rhetoric with Language Models,Yes.,3,"""We then assess whether a large language model (GPT-3) can identify dogwhistles and their meanings, and find that GPT-3’s performance varies widely across types of dogwhistles and targeted groups."""
acl2023,CodeIE: Large Code Generation Models are Better Few-Shot Information Extractors,Yes.,3,"""it is nontrivial to perform information extraction (IE) tasks with NL-LLMs since the output of the IE task is usually structured and therefore is hard to be converted into plain text."""
acl2023,Prompting PaLM for Translation: Assessing Strategies and Performance,Yes.,3,"""find that its performance, while impressive, still lags that of state-of-the-art supervised systems."""
acl2023,Revisiting Relation Extraction in the era of Large Language Models,Yes.,1,"""Here we push the limits of this approach, using larger language models (GPT-3 and Flan-T5 large) than considered in prior work and evaluating their performance on standard RE tasks under varying levels of supervision."""
acl2023,Can Large Language Models Be an Alternative to Human Evaluations?,Yes.,3,"""We are the first to show the potential of using LLMs to assess the quality of texts and discuss the limitations and ethical considerations of LLM evaluation."""
acl2023,An Empirical Analysis of Parameter-Efficient Methods for Debiasing Pre-Trained Language Models,,,
acl2023,XSemPLR: Cross-Lingual Semantic Parsing in Multiple Natural Languages and Meaning Representations,,,
acl2023,LENS: A Learnable Evaluation Metric for Text Simplification,Yes.,1,"""Training learnable metrics using modern language models has recently emerged as a promising method for the automatic evaluation of machine translation."""
acl2023,"RARR: Researching and Revising What Language Models Say, Using Language Models",Yes.,5,"""However, they sometimes generate unsupported or misleading content. A user cannot easily determine whether their outputs are trustworthy or not, because most LMs do not have any built-in mechanism for attribution to external evidence."""
acl2023,Ellipsis-Dependent Reasoning: a New Challenge for Large Language Models,Yes.,5,"""Test results show that the best models perform well on non-elliptical examples but struggle with all but the simplest ellipsis structures."""
acl2023,Improving Generalization in Language Model-based Text-to-SQL Semantic Parsing: Two Simple Semantic Boundary-based Techniques,Yes.,3,"""Compositional and domain generalization present significant challenges in semantic parsing, even for state-of-the-art semantic parsers based on pre-trained language models (LMs)."""
acl2023,Language Models Get a Gender Makeover: Mitigating Gender Bias with Few-Shot Data Interventions,Yes.,4,"""Societal biases present in pre-trained large language models are a critical issue as these models have been shown to propagate biases in countless downstream applications, rendering them unfair towards specific groups of people."""
acl2023,Credible without Credit: Domain Experts Assess Generative Language Models,Yes.,3,"""While we find the results are consistently cohesive and concise, we find that they are mixed in their accuracy. These results raise questions of the role language models should play in general-purpose and expert knowledge seeking."""
acl2023,MetaVL: Transferring In-Context Learning Ability From Language Models to Vision-Language Models,Yes.,2,"""However, in the vision-language domain, most large-scale pre-trained vision-language (VL) models do not possess the ability to conduct in-context learning."""
acl2023,Probing Physical Reasoning with Counter-Commonsense Context,Yes.,5,"""The results show that while large language models can use prepositions such as 'in' and 'into' in the provided context to infer size relationships, they fail to use verbs and thus make incorrect judgments led by their prior physical commonsense."""
acl2023,In and Out-of-Domain Text Adversarial Robustness via Label Smoothing,Yes.,1,"""Recently it has been shown that state-of-the-art NLP models are vulnerable to adversarial attacks, where the predictions of a model can be drastically altered by slight modifications to the input (such as synonym substitutions)."""
acl2023,LM-CPPF: Paraphrasing-Guided Data Augmentation for Contrastive Prompt-Based Few-Shot Fine-Tuning,Yes.,1,"""In recent years, there has been significant progress in developing pre-trained language models for NLP. However, these models often struggle when fine-tuned on small datasets."""
acl2023,Exploring Continual Learning for Code Generation Models,Yes.,3,"""re-training large-scale language models is computationally expensive"" and ""effective methods like Prompt Pooling (PP) suffer from catastrophic forgetting due to the unstable training of the prompt selection mechanism caused by stark distribution shifts in coding tasks."""
acl2023,A Better Way to Do Masked Language Model Scoring,,,
acl2023,ChatGPT for Zero-shot Dialogue State Tracking: A Solution or an Opportunity?,Yes.,3,"""Despite our findings, we argue that properties inherent to general purpose models limit their ability to replace specialized systems."""
acl2023,Controllable Mixed-Initiative Dialogue Generation through Prompting,Yes.,2,"""these supervised generation models are limited by the cost and quality of data annotation."""
acl2023,Trading Syntax Trees for Wordpieces: Target-oriented Opinion Words Extraction with Wordpieces and Aspect Enhancement,Yes.,3,"""These methods achieve limited gains with GCNs and have difficulty using BERT wordpieces."""
acl2023,Do GPTs Produce Less Literal Translations?,Yes.,2,"""However, there has been relatively little investigation on how such translations differ qualitatively from the translations generated by standard Neural Machine Translation (NMT) models."""
acl2023,Black-box language model explanation by context length probing,Yes.,2,"""We apply context length probing to large pre-trained language models and offer some initial analyses and insights, including the potential for studying long-range dependencies."""
acl2023,Latent Positional Information is in the Self-Attention Variance of Transformer Language Models Without Positional Embeddings,Yes.,1,"""We further extend this inquiry by demonstrating that a randomly initialized and frozen transformer language model, devoid of positional embeddings, inherently encodes strong positional information through the shrinkage of self-attention variance."""
acl2023,Towards Adaptive Prefix Tuning for Parameter-Efficient Language Model Fine-tuning,,,
acl2023,Evaluating pragmatic abilities of image captioners on A3DS,Yes.,1,"""Evaluating grounded neural language model performance with respect to pragmatic qualities like the trade off between truthfulness, contrastivity and overinformativity of generated utterances remains a challenge in absence of data collected from humans."""
acl2023,"Summarizing, Simplifying, and Synthesizing Medical Evidence using GPT-3 (with Varying Success)",Yes.,5,"""We find that while GPT-3 is able to summarize and simplify single biomedical articles faithfully, it struggles to provide accurate aggregations of findings over multiple documents."""
acl2023,Discourse-Level Representations can Improve Prediction of Degree of Anxiety,Yes.,1,"""evaluating the utility of discourse-level information in addition to lexical-level large language model embeddings."""
acl2023,Controlling the Extraction of Memorized Data from Large Language Models via Prompt-Tuning,Yes.,5,"""Large Language Models (LLMs) are known to memorize significant portions of their training data. Parts of this memorized content have been shown to be extractable by simply querying the model, which poses a privacy risk."""
acl2023,MultiTool-CoT: GPT-3 Can Use Multiple External Tools with Chain of Thought Prompting,Yes.,1,"""Large language models (LLMs) have achieved impressive performance on various reasoning tasks."""
acl2023,S3HQA: A Three-Stage Approach for Multi-hop Text-Table Hybrid Question Answering,Yes.,1,"""This includes two approaches"
acl2023,AutoConv: Automatically Generating Information-seeking Conversations with Large Language Models,Yes.,1,"""we propose AutoConv for synthetic conversation generation, which takes advantage of the few-shot learning ability and generation capacity of large language models (LLM)."""
acl2023,A Simple and Effective Framework for Strict Zero-Shot Hierarchical Classification,Yes.,5,"""these benchmarks often do not adequately address the challenges posed in the real-world, such as that of hierarchical classification. ... We observe LLMs are more prone to failure in these cases."""
acl2023,Revisiting Automated Prompting: Are We Actually Doing Better?,Yes.,3,"""We find that automated prompting does not consistently outperform simple manual prompting."""
acl2023,Lingxi: A Diversity-aware Chinese Modern Poetry Generation System,Yes.,1,"""we propose a novel sampling algorithm that flattens the high likelihood part of the predicted distribution of the language model to emphasize the comparatively low-likelihood words and increase the diversity of generated poetry."""
acl2023,LIDA: A Tool for Automatic Generation of Grammar-Agnostic Visualizations and Infographics using Large Language Models,Yes.,1,"""we pose visualization generation as a multi-stage generation problem and argue that well-orchestrated pipelines based on large language models (LLMs) and image generation models (IGMs) are suitable to addressing these tasks."""
acl2023,Pipeline for modeling causal beliefs from natural language,Yes.,1,"""We present a causal language analysis pipeline that leverages a Large Language Model to identify causal claims made in natural language documents, and aggregates claims across a corpus to produce a causal claim network."""
acl2023,OpenICL: An Open-Source Framework for In-context Learning,Yes.,1,"""In recent years, In-context Learning (ICL) has gained increasing attention and emerged as the new paradigm for large language model (LLM) evaluation."""
acl2023,Petals: Collaborative Inference and Fine-tuning of Large Models,Yes.,3,"""offloading is too slow for interactive inference, while APIs are not flexible enough for research that requires access to weights, attention or logits."""
acl2023,ChatGPT vs Human-authored Text: Insights into Controllable Text Summarization and Sentence Style Transfer,,,
acl2023,Making the Most Out of the Limited Context Length: Predictive Power Varies with Clinical Note Type and Note Section,Yes.,5,"""when the context length for a language model predictor is limited, which part of clinical notes should we choose as the input?"""
acl2023,Data Selection for Fine-tuning Large Language Models Using Transferred Shapley Values,Yes.,2,"""dataset size and model complexity constraints limit the ability to apply Shapley-based data valuation to fine-tuning large pre-trained language models."""
acl2023,Moral Mimicry: Large Language Models Produce Moral Rationalizations Tailored to Political Identity,Yes.,2,"""Large Language Models (LLMs) have demonstrated impressive capabilities in generating fluent text, as well as tendencies to reproduce undesirable social biases."""
acl2023,Authorship Attribution of Late 19th Century Novels using GAN-BERT,No.,1,The paper does not discuss LLMs or their limitations.
acl2023,Semantic Accuracy in Natural Language Generation: A Thesis Proposal,Yes.,2,"""We propose a novel method for evaluating semantic accuracy and discuss the importance of working towards a unified and objective benchmark for NLG metrics. We also review interpretability approaches which could help us pinpoint the sources of inaccuracies within the models and explore potential mitigation strategies."""
acl2023,CWSeg: An Efficient and General Approach to Chinese Word Segmentation,Yes.,3,"""The pre-trained language model (PLM) based segmentation methods have achieved state-of-the-art (SOTA) performance, whereas this paradigm also poses challenges in the deployment. It includes the balance between performance and cost, segmentation ambiguity due to domain diversity and vague words boundary, and multi-grained segmentation."""
acl2023,MathPrompter: Mathematical Reasoning using Large Language Models,Yes.,5,"""Large Language Models (LLMs) have limited performance when solving arithmetic reasoning tasks and often provide incorrect answers."" and ""To the best of our knowledge, we are not aware of any LLMs that indicate their level of confidence in their responses which fuels a trust deficit in these models impeding their adoption."""
acl2023,GKD: A General Knowledge Distillation Framework for Large-scale Pre-trained Language Model,Yes.,3,"""the deployment of knowledge distillation systems faces great challenges in real-world industrial-strength applications, which require the use of complex distillation methods on even larger-scale PLMs (over 10B), limited by memory on GPUs and the switching of methods."""
acl2023,KoSBI: A Dataset for Mitigating Social Bias Risks Towards Safer Large Language Model Applications,Yes.,5,"""Large language models (LLMs) not only learn natural text generation abilities but also social biases against different demographic groups from real-world data. This poses a critical risk when deploying LLM-based applications."" and ""This limitation requires localized social bias datasets to ensure the safe and effective deployment of LLMs."""
acl2023,The economic trade-offs of large language models: A case study,Yes.,2,"""However, their efficacy must be balanced with the cost of training and serving them."""
acl2023,Boosting Transformers and Language Models for Clinical Prediction in Immunotherapy,Yes.,1,"""The study benchmarks the efficacy of baselines and language models on prognostic prediction across multiple cancer types and investigates the impact of different pretrained language models under few-shot regimes."""
acl2023,A Static Evaluation of Code Completion by Large Language Models,Yes.,4,"""Our static analysis reveals that Undefined Name and Unused Variable are the most common errors among others made by language models."""
acl2023,SaFER: A Robust and Efficient Framework for Fine-tuning BERT-based Classifier with Noisy Labels,,,
acl2023,"Sharing Encoder Representations across Languages, Domains and Tasks in Large-Scale Spoken Language Understanding",Yes.,2,"""Larger encoders can improve accuracy for spoken language understanding (SLU) but are challenging to use given the inference latency constraints of online systems (especially on CPU machines)."""
acl2023,Exploring Zero and Few-shot Techniques for Intent Classification,Yes.,1,"""zero-shot intent classification using descriptions large language models (LLMs)"" and ""parameter-efficient fine-tuning of instruction-finetuned language models."""
acl2023,Complex Reasoning in Natural Language,,,
acl2023,"Everything you need to know about Multilingual LLMs: Towards fair, performant and reliable models for languages of the world",Yes.,4,"""Responsible AI issues such as fairness, bias and toxicity, linguistic diversity and evaluation in the context of MMLMs, specifically focusing on issues in non-English and low-resource languages."""
acl2023,Generating Text from Language Models,,,
eacl2023,WinoDict: Probing language models for in-context word acquisition,Yes.,5,"""This benchmark addresses word acquisition, one important aspect of the diachronic degradation known to afflict LLMs. As LLMs are frozen in time at the moment they are trained, they are normally unable to reflect the way language changes over time."""
eacl2023,Nationality Bias in Text Generation,Yes.,5,"""This paper examines how a text generation model, GPT-2, accentuates pre-existing societal biases about country-based demonyms"" and ""GPT-2 demonstrates significant bias against countries with lower internet users, and adversarial triggering effectively reduces the same."""
eacl2023,Do we need Label Regularization to Fine-tune Pre-trained Language Models?,Yes.,1,"""Considering the ever-growing size of pre-trained language models (PLMs), KD is often adopted in many NLP tasks involving PLMs."""
eacl2023,A Discerning Several Thousand Judgments: GPT-3 Rates the Article + Adjective + Numeral + Noun Construction,Yes.,3,"""LLMs must overcome frequency biases in order to master such constructions."""
eacl2023,"“John is 50 years old, can his son be 65?” Evaluating NLP Models’ Understanding of Feasibility",Yes.,5,"""Some recent works have also found notable failures of these models. Often these failure examples involve complex reasoning abilities."" and ""We show that even state-of-the-art models such as GPT-3, GPT-2, and T5 struggle to answer"
eacl2023,Scaling Back-Translation with Domain Text Generation for Sign Language Gloss Translation,Yes.,1,"""PGen randomly concatenates sentences from the original in-domain spoken language text data as prompts to induce a pre-trained language model (i.e., GPT-2) to generate spoken language texts in a similar style."""
eacl2023,Teacher Intervention: Improving Convergence of Quantization Aware Training for Ultra-Low Precision Transformers,Yes.,3,"""Quantization-aware training (QAT) is a promising method to lower the implementation cost and energy consumption. However, aggressive quantization below 2-bit causes considerable accuracy degradation due to unstable convergence, especially when the downstream dataset is not abundant."""
eacl2023,On Robustness of Prompt-based Semantic Parsing with Large Pre-trained Language Model: An Empirical Study on Codex,Yes.,5,"""The existing fine-tuned neural semantic parsers are vulnerable to adversarial attacks on natural-language inputs,"" and ""the robustness of smaller semantic parsers can be enhanced through adversarial training, this approach is not feasible for large language models in real-world scenarios,"" and ""the large language model of code is vulnerable to carefully crafted adversarial examples."""
eacl2023,MiniALBERT: Model Distillation via Parameter-Efficient Recursive Transformers,Yes.,5,"""the usability of LMs is constrained by computational and time complexity, along with their increasing size; an issue that has been referred to as overparameterisation."""
eacl2023,A Systematic Search for Compound Semantics in Pretrained BERT Architectures,Yes.,3,"""To date, transformer-based models such as BERT have been less successful in predicting compositionality of noun compounds than static word embeddings. This is likely related to a suboptimal use of the encoded information, reflecting an incomplete grasp of how the models represent the meanings of complex linguistic structures."""
eacl2023,SODAPOP: Open-Ended Discovery of Social Biases in Social Commonsense Reasoning Models,Yes.,4,"""A common limitation of diagnostic tests for detecting social biases in NLP models is that they may only detect stereotypic associations that are pre-specified by the designer of the test."" and ""We also test SODAPOP on debiased models and show the limitations of"
eacl2023,Robustness Challenges in Model Distillation and Pruning for Natural Language Understanding,Yes.,5,"""However, very few of these studies have analyzed the impact of compression on the generalizability and robustness of compressed models for out-of-distribution (OOD) data,"" and ""the compressed models are significantly less robust than their PLM counterparts on OOD test sets although they obtain similar performance on in-distribution development sets for a task."""
eacl2023,LEALLA: Learning Lightweight Language-agnostic Sentence Embeddings with Knowledge Distillation,Yes.,3,"""these large-scale models can suffer from inference speed and computation overhead."""
eacl2023,Extracting Victim Counts from Text,Yes.,2,"""Beyond model accuracy, we analyze extraction reliability and robustness which are key for this sensitive task. In particular, we discuss model calibration and investigate out-of-distribution and few-shot performance."""
eacl2023,Opportunities and Challenges in Neural Dialog Tutoring,Yes.,5,"""We find that although current approaches can model tutoring in constrained learning scenarios when the number of concepts to be taught and possible teacher strategies are small, they perform poorly in less constrained scenarios."" and ""Our human quality evaluation shows that both models and ground-truth annotations exhibit low performance in terms of equitable tutoring, which measures learning opportunities for"
eacl2023,Assessing Out-of-Domain Language Model Performance from Few Examples,Yes.,5,"""While pretrained language models have exhibited impressive generalization capabilities, they still behave unpredictably under certain domain shifts."" and ""given a few target-domain examples and a set of models with similar training performance, can we understand how these models will perform on OOD test data?"""
eacl2023,Bootstrapping Multilingual Semantic Parsers using Large Language Models,Yes.,2,"""Further, translation services may continue to be brittle due to domain mismatch between task-specific input text and general-purpose text used for training translation models."""
eacl2023,Towards preserving word order importance through Forced Invalidation,Yes.,5,"""However, recent findings have revealed that pre-trained language models are insensitive to word order. The performance on NLU tasks remains unchanged even after randomly permuting the word of a sentence, where crucial syntactic information is destroyed."""
eacl2023,Adding Instructions during Pretraining: Effective way of Controlling Toxicity in Language Models,Yes.,4,"""However, safely deploying them in real world applications is challenging because they generate toxic content."""
eacl2023,Real-Time Visual Feedback to Guide Benchmark Creation: A Human-and-Metric-in-the-Loop Workflow,Yes.,3,"""Recent research has shown that language models exploit ‘artifacts’ in benchmarks to solve tasks, rather than truly learning them, leading to inflated model performance."""
eacl2023,Unsupervised Improvement of Factual Knowledge in Language Models,Yes.,1,"""Masked language modeling (MLM) plays a key role in pretraining large language models. But the MLM objective is often dominated by high-frequency words that are sub-optimal for learning factual knowledge."""
eacl2023,Learning to Ignore Adversarial Attacks,No.,1,The abstract does not mention language models (LLMs) or their limitations.
eacl2023,Should You Mask 15% in Masked Language Modeling?,Yes.,1,"""Masked language models (MLMs) conventionally mask 15% of tokens due to the belief that more masking would leave insufficient context to learn good representations; this masking rate has been widely used, regardless of model sizes or masking strategies."""
eacl2023,When Do Pre-Training Biases Propagate to Downstream Tasks? A Case Study in Text Summarization,Yes.,5,"""Large language models (LLMs) are subject to sociocultural and other biases previously identified using intrinsic evaluations. However, when and how these intrinsic biases in pre-trained LM representations propagate to downstream, fine-tuned NLP tasks like summarization is not well understood."" and ""We show that these biases manifest themselves as hallucinations in summarization, leading to factually incorrect summaries."""
eacl2023,BERT Shows Garden Path Effects,Yes.,3,"""We find that the models have relatively low performance in certain instances of question answering based on garden path contexts, and the model incorrectly assigns semantic roles."""
eacl2023,DyLoRA: Parameter-Efficient Tuning of Pre-trained Models using Dynamic Search-Free Low-Rank Adaptation,Yes.,3,"""While LoRA blocks are parameter-efficient, they suffer from two major problems"
eacl2023,Language Generation Models Can Cause Harm: So What Can We Do About It? An Actionable Survey,Yes.,4,"""Going beyond enumerating the risks of harms, this work provides a survey of practical methods for addressing potential threats and societal harms from language generation models."""
eacl2023,Social Commonsense for Explanation and Cultural Bias Discovery,Yes.,2,"""We identify influential social commonsense knowledge to explain model behavior in the following ways. First, we augment large-scale language models with social knowledge and show improvements for the tasks, indicating the implicit assumptions a model requires to be successful on each dataset."""
eacl2023,"GrIPS: Gradient-free, Edit-based Instruction Search for Prompting Large Language Models",Yes.,2,"""manual rewriting is time-consuming and requires subjective interpretation, while gradient-based tuning can be extremely computationally demanding for large models and may not be feasible for API-based models."""
eacl2023,DiscoScore: Evaluating Text Generation with BERT and Discourse Coherence,No.,1,The abstract discusses BERT-based evaluation metrics and their limitations but does not address language models (LLMs or LLMs) specifically.
eacl2023,CoTEVer: Chain of Thought Prompting Annotation Toolkit for Explanation Verification,Yes.,3,"""a critical downside of CoT prompting is that the performance is greatly affected by the factuality of the generated explanation."""
emnlp2023,IAG: Induction-Augmented Generation Framework for Answering Reasoning Questions,Yes.,2,"""common knowledge bases are inherently constrained by limited coverage and noisy information, making retrieval-based approaches inadequate to answer implicit reasoning questions."""
emnlp2023,Primacy Effect of ChatGPT,Yes.,5,"""ChatGPT’s decision is sensitive to the order of labels in the prompt; ChatGPT has a clearly higher chance to select the labels at earlier positions as the answer."""
emnlp2023,Evaluating the Rationale Understanding of Critical Reasoning in Logical Reading Comprehension,Yes.,5,"""Experiments on our dataset show that recent large language models (e.g., InstructGPT) struggle to answer the subquestions even if they are able to answer the main questions correctly. We find that the models perform particularly poorly in answering subquestions written for the incorrect options"
emnlp2023,Theory of Mind for Multi-Agent Collaboration via Large Language Models,Yes.,5,"""Our results reveal limitations in LLM-based agents’ planning optimization due to systematic failures in managing long-horizon contexts and hallucination about the task state."""
emnlp2023,Establishing Trustworthiness: Rethinking Tasks and Model Evaluation,Yes.,2,"""the traditional compartmentalized notion of language tasks is breaking down, followed by an increasing challenge for evaluation and analysis."""
emnlp2023,GPTAraEval: A Comprehensive Evaluation of ChatGPT on Arabic NLP,Yes.,5,"""our work adds to a growing body of research underscoring the limitations of ChatGPT."""
emnlp2023,Evaluating Object Hallucination in Large Vision-Language Models,,,
emnlp2023,Parameter-efficient Tuning for Large Language Model without Calculating Its Gradients,Yes.,3,"""Fine-tuning all parameters of large language models (LLMs) requires significant computational resources and is time-consuming."" and ""However, they can only save approximately 30% of the training memory requirements, due to the problem that gradient computation and backpropagation are still necessary for these methods."""
emnlp2023,CompoundPiece: Evaluating and Improving Decompounding Performance of Language Models,Yes.,5,"""We find that LLMs perform poorly, especially on words which are tokenized unfavorably by subword tokenization."""
emnlp2023,How to Enhance Causal Discrimination of Utterances: A Case on Affective Reasoning,Yes.,3,"""Almost all existing models, including large language models (LLMs), excel at capturing semantic correlations within utterance embeddings but fall short in determining the specific causal relationships."""
emnlp2023,Temporal Knowledge Graph Forecasting Without Knowledge Using In-Context Learning,Yes.,1,"""We observe that naive LLMs perform on par with SOTA models,"" and ""Our analysis also reveals that ICL enables LLMs to learn irregular patterns from the historical context, going beyond frequency and recency biases."""
emnlp2023,Knowledge Graph Compression Enhances Diverse Commonsense Generation,Yes.,3,"""the extracted subgraphs may contain loosely related, redundant and irrelevant information, which can introduce noise into the model."" and ""our model achieves better quality-diversity tradeoff than a large language model with 100 times the number of parameters."""
emnlp2023,LLM-FP4: 4-Bit Floating-Point Quantized Transformers,Yes.,1,"""We propose LLM-FP4 for quantizing both weights and activations in large language models (LLMs) down to 4-bit floating-point values, in a post-training manner."""
emnlp2023,LLM-powered Data Augmentation for Enhanced Cross-lingual Performance,Yes.,3,"""LLMs such as ChatGPT and GPT-4 excel at producing natural and coherent text in most languages, however, they struggle to generate meaningful text in certain languages like Tamil"" and ""ChatGPT falls short in generating plausible alternatives compared to the original dataset."""
emnlp2023,Conceptual structure coheres in human cognition but not in large language models,Yes.,5,"""Structures estimated from the LLM behavior, while individually fairly consistent with those estimated from human behavior, depend much more upon the particular task used to generate behavior responses–responses generated by the very same model in the three tasks yield estimates of conceptual structure that cohere less with one another than do human structure"
emnlp2023,Towards LLM-driven Dialogue State Tracking,Yes.,5,"""Despite its impressive performance, ChatGPT has significant limitations including its closed-source nature, request restrictions, raising data privacy concerns, and lacking local deployment capabilities."""
emnlp2023,We’re Afraid Language Models Aren’t Modeling Ambiguity,Yes.,5,"""We find that the task remains extremely challenging, including for GPT-4, whose generated disambiguations are considered correct only 32% of the time in crowdworker evaluation, compared to 90% for disambiguations in our dataset."""
emnlp2023,"Reading Books is Great, But Not if You Are Driving! Visually Grounded Reasoning about Defeasible Commonsense Norms",Yes.,3,"""We find that state-of-the-art model judgments and explanations are not well-aligned with human annotation."""
emnlp2023,Enhancing Uncertainty-Based Hallucination Detection with Stronger Focus,Yes.,5,"""However, LLMs are prone to hallucinate untruthful or nonsensical outputs that fail to meet user expectations in many real-world applications."""
emnlp2023,Tree of Clarifications: Answering Ambiguous Questions with Retrieval-Augmented Large Language Models,Yes.,1,"""considering multiple dimensions of ambiguity and gathering corresponding knowledge remains a challenge."""
emnlp2023,Large Language Models Can Self-Improve,Yes.,3,"""fine-tuning an LLM requires extensive supervision."""
emnlp2023,CodeT5+: Open Code Large Language Models for Code Understanding and Generation,Yes.,5,"""However, existing code LLMs have two main limitations. First, they often adopt a specific architecture (encoder-only or decoder-only) or rely on a unified encoder-decoder network for different downstream tasks, lacking the flexibility to operate in the optimal architecture for a specific task. Secondly, they often employ a limited set of pretraining objectives which might not be relevant to some tasks and"
emnlp2023,SeqXGPT: Sentence-Level AI-Generated Text Detection,Yes.,2,"""raising concerns about the abuse of LLMs"" and ""Current works only consider document-level AIGT detection."""
emnlp2023,QTSumm: Query-Focused Summarization over Tabular Data,,,
emnlp2023,Towards Robust Pruning: An Adaptive Knowledge-Retention Pruning Strategy for Language Models,Yes.,3,"""Despite this, existing methods struggle to enhance robustness against adversarial attacks when continually increasing model sparsity."""
emnlp2023,Unveiling the Implicit Toxicity in Large Language Models,Yes.,5,"""We show that LLMs can generate diverse implicit toxic outputs that are exceptionally difficult to detect via simply zero-shot prompting,"" and ""Our findings suggest that LLMs pose a significant threat in generating undetectable implicit toxic outputs."""
emnlp2023,Is ChatGPT a General-Purpose Natural Language Processing Task Solver?,Yes.,2,"""With extensive empirical studies, we demonstrate both the effectiveness and limitations of the current version of ChatGPT."""
emnlp2023,ALCUNA: Large Language Models Meet New Knowledge,Yes.,5,"""We benchmark several LLMs, reveals that their performance in face of new knowledge is not satisfactory, particularly in reasoning between new and internal knowledge."""
emnlp2023,Transcending Scaling Laws with 0.1% Extra Compute,Yes.,1,"""Scaling language models improves performance but comes with significant computational costs."""
emnlp2023,CoAnnotating: Uncertainty-Guided Work Allocation between Human and Large Language Models for Data Annotation,Yes.,2,"""However, limited work has leveraged LLMs as complementary annotators, nor explored how annotation work is best allocated among humans and LLMs to achieve both quality and cost objectives."""
emnlp2023,Robust Prompt Optimization for Large Language Models Against Distribution Shifts,Yes.,5,"""We reveal that these prompt optimization techniques are vulnerable to distribution shifts such as subpopulation shifts, which are common for LLMs in real-world scenarios such as customer reviews analysis."""
emnlp2023,Increasing Coverage and Precision of Textual Information in Multilingual Knowledge Graphs,Yes.,3,"""demonstrate that state-of-the-art methods, namely, Machine Translation (MT), Web Search (WS), and Large Language Models (LLMs), struggle with this task."""
emnlp2023,Interpreting Embedding Spaces by Conceptualization,Yes.,4,"""One major drawback of this type of representation is their incomprehensibility to humans."" and ""Understanding the embedding space is crucial for several important needs, including the need to debug the embedding method and compare it to alternatives, and the need to detect biases hidden in the model."""
emnlp2023,Knowledge-Augmented Language Model Verification,Yes.,5,"""Yet, LMs often generate the factually incorrect responses to the given queries, since their knowledge may be inaccurate, incomplete, and outdated."" and ""the model may fail to retrieve the knowledge relevant to the given query, or the model may not faithfully reflect the retrieved knowledge in the generated text."""
emnlp2023,Failures Pave the Way: Enhancing Large Language Models through Tuning-free Rule Accumulation,Yes.,5,"""However, due to their inability to capture relationships among samples, these frozen LLMs inevitably keep repeating similar mistakes."""
emnlp2023,Active Instruction Tuning: Improving Cross-Task Generalization by Training on Prompt Sensitive Tasks,Yes.,1,"""Instruction tuning (IT) achieves impressive zero-shot generalization results by training large language models (LLMs) on a massive amount of diverse tasks with instructions."""
emnlp2023,“Fifty Shades of Bias”: Normative Ratings of Gender Bias in GPT Generated English Text,Yes.,4,"""With LLMs increasingly gaining human-like fluency in text generation, gaining a nuanced understanding of the biases these systems can generate is imperative."""
emnlp2023,ChatGPT to Replace Crowdsourcing of Paraphrases for Intent Classification: Higher Diversity and Comparable Model Robustness,Yes.,1,"""The emergence of generative large language models (LLMs) raises the question"
emnlp2023,Democratizing Reasoning Ability: Tailored Learning from Large Language Model,Yes.,3,"""LLMs exhibit impressive emergent abilities in natural language processing, but their democratization is hindered due to huge computation requirements and closed-source nature."""
emnlp2023,OpenAsp: A Benchmark for Multi-document Open Aspect-based Summarization,Yes.,1,"""we show that the realistic open-aspect setting realized in OpenAsp poses a challenge for current state-of-the-art summarization models, as well as for large language models."""
emnlp2023,Self-Influence Guided Data Reweighting for Language Model Pre-training,Yes.,3,"""Once the pre-training corpus has been assembled, all data samples in the corpus are treated with equal importance during LM pre-training. However, due to varying levels of relevance and quality of data, equal importance to all the data samples may not be the optimal choice."""
emnlp2023,TrueTeacher: Learning Factual Consistency Evaluation with Large Language Models,,,
emnlp2023,Larger Probes Tell a Different Story: Extending Psycholinguistic Datasets Via In-Context Learning,Yes.,3,"""We evaluate 22 models on the extended datasets, seeing model performance dip 20-57% compared to the original smaller benchmarks."" and ""Finally, we observe that while GPT3 has generated all the examples in ROLE-1500 is only able to solve 24.6% of them during probing."""
emnlp2023,MAGNIFICo: Evaluating the In-Context Learning Ability of Large Language Models to Generalize to Novel Interpretations,Yes.,4,"""LLMs have a knowledge cutoff and are costly to finetune repeatedly"" and ""our findings also highlight the need for further improvements, particularly when interpreting unfamiliar words or when composing multiple novel interpretations simultaneously in the same example."""
emnlp2023,Generating and Evaluating Tests for K-12 Students with Language Model Simulations: A Case Study on Sentence Reading Efficiency,Yes.,1,"""To generate high-quality parallel tests, we propose to fine-tune large language models (LLMs) to simulate how previous students would have responded to unseen items."""
emnlp2023,Counter Turing Test (CT2): AI-Generated Text Detection is Not as Easy as You May Think - Introducing AI Detectability Index (ADI),Yes.,3,"""Our empirical findings unequivocally highlight the fragility of the proposed AGTD methods under scrutiny."""
emnlp2023,Instructed Language Models with Retrievers Are Powerful Entity Linkers,Yes.,5,"""the generative nature still makes the generated content suffer from hallucinations, thus unsuitable for entity-centric tasks like entity linking (EL) requiring precise entity predictions over a large knowledge base."" and ""the EL task remains a persistent hurdle for general LLMs."""
emnlp2023,Does the Correctness of Factual Knowledge Matter for Factual Knowledge-Enhanced Pre-trained Language Models?,Yes.,5,"""Surprisingly, throughout our experiments, we find that although the knowledge seems to be successfully injected, the correctness of injected knowledge only has a very limited effect on the models’ downstream performance. This finding strongly challenges previous assumptions that the injected factual knowledge is the key for language models to achieve performance improvements on downstream tasks in pretrain-finetune paradigm."""
emnlp2023,"The Past, Present and Better Future of Feedback Learning in Large Language Models for Subjective Human Preferences and Values",Yes.,4,"""it is unclear how to collect and incorporate feedback in a way that is efficient, effective and unbiased, especially for highly subjective human preferences and values"" and ""we encourage a better future of feedback learning in LLMs by raising five unresolved conceptual and practical challenges."""
emnlp2023,TempTabQA: Temporal Question Answering for Semi-Structured Tables,,,
emnlp2023,Task-Level Thinking Steps Help Large Language Models for Challenging Classification Task,Yes.,3,"""the distribution of demonstrations can severely affect the performance, especially for challenging classification tasks."""
emnlp2023,G-Eval: NLG Evaluation using Gpt-4 with Better Human Alignment,Yes.,3,"""these LLM-based evaluators still have lower human correspondence than medium-size neural evaluators"" and ""highlight the potential concern of LLM-based evaluators having a bias towards the LLM-generated texts."""
emnlp2023,"The Troubling Emergence of Hallucination in Large Language Models - An Extensive Definition, Quantification, and Prescriptive Remediations",Yes.,5,"""the issue of hallucination has parallelly emerged as a by-product, posing significant concerns"" and ""we propose two solution strategies for mitigating hallucinations."""
emnlp2023,Improving Summarization with Human Edits,Yes.,1,"""Existing works use human feedback to train large language models (LLMs) in general domain abstractive summarization and have obtained summary quality exceeding traditional likelihood training."""
emnlp2023,The Skipped Beat: A Study of Sociopragmatic Understanding in LLMs for 64 Languages,Yes.,5,"""Our comprehensive analysis reveals that existing open-source instruction tuned LLMs still struggle to understand SM across various languages, performing close to a random baseline in some cases. We also find that although ChatGPT outperforms many LLMs, it still falls behind task-specific finetuned models with a gap of 12.19 SPARROW score."""
emnlp2023,Understanding the Effect of Model Compression on Social Bias in Large Language Models,Yes.,4,"""Large Language Models (LLMs) trained with self-supervision on vast corpora of web text fit to the social biases of that text. Without intervention, these social biases persist in the model’s predictions in downstream tasks, leading to representational harm."""
emnlp2023,BioPlanner: Automatic Evaluation of LLMs on Protocol Planning in Biology,Yes.,,
emnlp2023,Cross-lingual Prompting: Improving Zero-shot Chain-of-Thought Reasoning across Languages,Yes.,3,"""Despite the success of zero-shot CoT, the existing zero-shot prompting techniques remain limited to a single language, making it challenging to generalize to other languages and hindering global development."""
emnlp2023,FinGPT: Large Generative Models for a Small Language,Yes.,3,"""LLM work tends to focus on languages where nearly unlimited data is available for pretraining."""
emnlp2023,"Plan, Verify and Switch: Integrated Reasoning with Diverse X-of-Thoughts",Yes.,1,"""As large language models (LLMs) have shown effectiveness with different prompting methods, such as Chain of Thought, Program of Thought, we find that these methods have formed a great complementarity to each other on math reasoning tasks."""
emnlp2023,Critic-Driven Decoding for Mitigating Hallucinations in Data-to-text Generation,Yes.,5,"""Hallucination of text ungrounded in the input is a well-known problem in neural data-to-text generation."""
emnlp2023,Can Language Models Laugh at YouTube Short-form Videos?,Yes.,1,"""we develop a zero-shot video-to-text prompting to maximize video humor understanding of large language models (LLMs)."""
emnlp2023,API-Bank: A Comprehensive Benchmark for Tool-Augmented LLMs,Yes.,4,"""However, three pivotal questions remain unanswered"
emnlp2023,Lion: Adversarial Distillation of Proprietary Large Language Models,,,
emnlp2023,Evaluating Large Language Models on Controlled Generation Tasks,Yes.,5,"""large language models struggle at meeting fine-grained hard constraints."""
emnlp2023,"DeSIQ: Towards an Unbiased, Challenging Benchmark for Social Intelligence Understanding",Yes.,3,"""Our analysis reveals that Social-IQ contains substantial biases, which can be exploited by a moderately strong language model to learn spurious correlations to achieve perfect performance without being given the context or even the question."""
emnlp2023,"Why LLMs Hallucinate, and How to Get (Evidential) Closure: Perceptual, Intensional, and Extensional Learning for Faithful Natural Language Generation",,,
emnlp2023,Can LLMs Facilitate Interpretation of Pre-trained Language Models?,Yes.,3,"""Work done to uncover the knowledge encoded within pre-trained language models rely on annotated corpora or human-in-the-loop methods. However, these approaches are limited in terms of scalability and the scope of interpretation."""
emnlp2023,Oolong: Investigating What Makes Transfer Learning Hard with Controlled Studies,Yes.,5,"""We find that models can largely recover from syntactic-style shifts, but cannot recover from vocabulary misalignment and embedding matrix re-initialization, even with continued pretraining on 15 million tokens."""
emnlp2023,Knowledge Rumination for Pre-trained Language Models,Yes.,3,"""vanilla pre-trained language models (PLMs) lack the capacity to handle knowledge-intensive NLP tasks alone"" and ""PLMs may have already encoded rich knowledge in their pre-trained parameters but fails to fully utilize them when applying to knowledge-intensive tasks."""
emnlp2023,Struct-XLM: A Structure Discovery Multilingual Language Model for Enhancing Cross-lingual Transfer through Reinforcement Learning,Yes.,1,"""limited researches utilize it for aligning representation in multilingual pre-trained language models (PLMs)."""
emnlp2023,Dancing Between Success and Failure: Edit-level Simplification Evaluation using SALSA,Yes.,3,"""current human evaluation methods fail to provide a clear understanding of systems’ specific strengths and weaknesses"" and ""GPT-3.5 performs more quality edits than humans, but still exhibits frequent errors."""
emnlp2023,GPT-RE: In-context Learning for Relation Extraction using Large Language Models,,,
emnlp2023,INFORM : Information eNtropy based multi-step reasoning FOR large language Models,Yes.,3,"""the effectiveness of CoT prompts may fluctuate dramatically with different choices of in-context examples. Additionally, manual construction of rationale steps can be time-consuming, presenting challenges for the widespread adoption of CoT prompting."""
emnlp2023,Adaptive Gating in Mixture-of-Experts based Language Models,Yes.,2,"""Little is discussed in prior research on the trade-off between computation per token and model performance."""
emnlp2023,On the Automatic Generation and Simplification of Children’s Stories,Yes.,3,"""We find that, in spite of the growing capabilities of LLMs, they do not yet possess the ability to limit their vocabulary to levels appropriate for younger age groups."""
emnlp2023,The Curious Case of Hallucinatory (Un)answerability: Finding Truths in the Hidden States of Over-Confident Large Language Models,Yes.,5,"""A primary issue arising in this context is the management of (un)answerable queries by LLMs, which often results in hallucinatory behavior due to overconfidence."""
emnlp2023,Small Language Models Fine-tuned to Coordinate Larger Language Models improve Complex Reasoning,,,
emnlp2023,ReasoningLM: Enabling Structural Subgraph Reasoning in Pre-trained Language Models for Question Answering over Knowledge Graph,Yes.,1,"""Despite the effectiveness, due to the divergence in model architecture, the PLM and GNN are not closely integrated, limiting the knowledge sharing and fine-grained feature interactions."""
emnlp2023,Deep Natural Language Feature Learning for Interpretable Prediction,,,
emnlp2023,ROBBIE: Robust Bias Evaluation of Large Generative Language Models,Yes.,4,"""we must develop comprehensive enough tools to measure and improve their fairness,"" and ""testing LLMs on more datasets can potentially help us characterize their biases more fully,"" and ""we explore the frequency of demographic terms in common LLM pre-training corpora and how this may relate to model biases."""
emnlp2023,Adapting Language Models to Compress Contexts,Yes.,5,"""Transformer-based language models (LMs) are powerful and widely-applicable tools, but their usefulness is constrained by a finite context window and the expensive computational cost of processing long text documents."""
emnlp2023,COVID-19 Vaccine Misinformation in Middle Income Countries,Yes.,1,"""we adopt two approaches for developing COVID-19 vaccine misinformation detection models"
emnlp2023,Contrastive Learning of Sentence Embeddings from Scratch,Yes.,1,"""we explore utilizing large language models to synthesize the required data samples for contrastive learning."""
emnlp2023,DisCo: Distilled Student Models Co-training for Semi-supervised Text Mining,Yes.,3,"""a significant challenge that arises nowadays is how to maintain performance when we use a lightweight model with limited labeled samples."""
emnlp2023,Dynosaur: A Dynamic Growth Paradigm for Instruction-Tuning Data Curation,Yes.,1,"""Existing methods either manually annotate or employ LLM (e.g., GPT-series) to generate data for instruction tuning."""
emnlp2023,Sparse Low-rank Adaptation of Pre-trained Language Models,Yes.,1,"""Fine-tuning pre-trained large language models in a parameter-efficient manner is widely studied for its effectiveness and efficiency."""
emnlp2023,The Art of SOCRATIC QUESTIONING: Recursive Thinking with Large Language Models,Yes.,3,"""CoT heavily relies on the initial decisions, causing errors in early steps to accumulate and impact the final answers."""
emnlp2023,MEGA: Multilingual Evaluation of Generative AI,Yes.,3,"""We present a thorough analysis of the performance of models across languages and tasks and discuss challenges in improving the performance of generative LLMs on low-resource languages."""
emnlp2023,Large Language Models are Temporal and Causal Reasoners for Video Question Answering,Yes.,5,"""However, such priors often cause suboptimal results on VideoQA by leading the model to over-rely on questions, i.e., linguistic bias, while ignoring visual content. This is also known as ‘ungrounded guesses’ or ‘hallucinations’."""
emnlp2023,Prompting Large Language Models with Chain-of-Thought for Few-Shot Knowledge Base Question Generation,Yes.,1,"""The emergence of Large Language Models (LLMs) has shown their impressive generalization ability in few-shot tasks."""
emnlp2023,TrojanSQL: SQL Injection against Natural Language Interface to Database,Yes.,4,"""Experimental results demonstrate that both medium-sized models based on fine-tuning and LLM-based parsers using prompting techniques are vulnerable to this type of attack, with attack success rates as high as 99% and 89%, respectively."""
emnlp2023,Preserving Privacy Through Dememorization: An Unlearning Technique For Mitigating Memorization Risks In Language Models,Yes.,5,"""LLMs have shown the ability to memorize and reproduce portions of their training data when prompted by adversaries. Prior research has focused on addressing this memorization issue and preventing verbatim replication through techniques like knowledge unlearning and data pre-processing. However, these methods have limitations regarding the number of protected samples, limited privacy types, and potentially lower-quality generative models."""
emnlp2023,Meta-Learning Online Adaptation of Language Models,Yes.,5,"""the knowledge in static language models falls out of date, limiting the model’s effective 'shelf life.' While online fine-tuning can reduce this degradation, we find that naively fine-tuning on a stream of documents leads to a low level of information uptake."""
emnlp2023,Noisy Exemplars Make Large Language Models More Robust: A Domain-Agnostic Behavioral Analysis,Yes.,5,"""we find that models are more sensitive to certain perturbations such as replacing words with their synonyms."""
emnlp2023,Can Large Language Models Capture Dissenting Human Voices?,Yes.,5,"""we show LLMs exhibit limited ability in solving NLI tasks and simultaneously fail to capture human disagreement distribution. The inference and human alignment performances plunge even further on data samples with high human disagreement levels, raising concerns about their natural language understanding (NLU) ability and their representativeness to a larger human population."""
emnlp2023,DecoMT: Decomposed Prompting for Machine Translation Between Related Languages using Large Language Models,Yes.,1,The abstract discusses the use of large language models for machine translation but does not mention any explicit limitations of the models.
emnlp2023,Well Begun is Half Done: Generator-agnostic Knowledge Pre-Selection for Knowledge-Grounded Dialogue,Yes.,1,"""knowledge selection before generation is a lightweight yet effective way to facilitate LLMs (e.g., ChatGPT) to generate more informative responses."""
emnlp2023,Merging Generated and Retrieved Knowledge for Open-Domain QA,Yes.,4,"""retrieving passages from a given source is known to suffer from insufficient knowledge coverage"" and ""LLMs tend to 'hallucinate' content that conflicts with the retrieved knowledge."""
emnlp2023,A Cheaper and Better Diffusion Language Model with Soft-Masked Noise,Yes.,3,"""existing diffusion models still have some limitations in modeling discrete data, e.g., languages. For example, the generally used Gaussian noise can not handle the discrete corruption well, and the objectives in continuous spaces fail to be stable for textual data in the diffusion process especially when the dimension is high."""
emnlp2023,Cognitive Dissonance: Why Do Language Model Outputs Disagree with Internal Representations of Truthfulness?,Yes.,3,"""Past work has found that these two procedures sometimes disagree, and that probes tend to be more accurate than LM outputs."""
emnlp2023,Can We Edit Factual Knowledge by In-Context Learning?,Yes.,3,"""However, the stored knowledge could be false or outdated."""
emnlp2023,Ignore This Title and HackAPrompt: Exposing Systemic Vulnerabilities of LLMs Through a Global Prompt Hacking Competition,Yes.,5,"""These deployments are increasingly plagued by prompt injection and jailbreaking (collectively, prompt hacking), in which models are manipulated to ignore their original instructions and instead follow potentially malicious ones."""
emnlp2023,Localizing Active Objects from Egocentric Vision with Symbolic World Knowledge,Yes.,1,"""We leverage large language models (LLMs) to extract the aforementioned action-object knowledge."""
emnlp2023,Prompting is not a substitute for probability measurements in large language models,Yes.,5,"""Broadly, we find that LLMs’ metalinguistic judgments are inferior to quantities directly derived from representations. Furthermore, consistency gets worse as the prompt query diverges from direct measurements of next-word probabilities."""
emnlp2023,LINC: A Neurosymbolic Approach for Logical Reasoning by Combining Language Models with First-Order Logic Provers,Yes.,3,"""While many prompting-based strategies have been proposed to enable Large Language Models (LLMs) to do such reasoning more effectively, they still appear unsatisfactory, often failing in subtle and unpredictable ways."""
emnlp2023,LLM-Adapters: An Adapter Family for Parameter-Efficient Fine-Tuning of Large Language Models,Yes.,1,"""The success of large language models (LLMs), like GPT-4 and ChatGPT, has led to the development of numerous cost-effective and accessible alternatives that are created by finetuning open-access LLMs with task-specific data (e.g., ChatDoctor) or"
emnlp2023,PromptMix: A Class Boundary Augmentation Method for Large Language Model Distillation,,,
emnlp2023,QUDeval: The Evaluation of Questions Under Discussion Discourse Parsing,Yes.,3,"""Using QUDeval, we show that satisfying all constraints of QUD is still challenging for modern LLMs, and that existing evaluation metrics poorly approximate parser quality."""
emnlp2023,PRCA: Fitting Black-Box Large Language Models for Retrieval Question Answering via Pluggable Reward-Driven Contextual Adapter,Yes.,2,"""they are typically too large to be fine-tuned with budget constraints while some of them are only accessible via APIs."""
emnlp2023,Exploring Chain of Thought Style Prompting for Text-to-SQL,Yes.,3,"""However, its performance on text-to-SQL parsing still has much room for improvement."" and ""using detailed reasoning steps tends to have more error propagation issues."""
emnlp2023,Harnessing Black-Box Control to Boost Commonsense in LM’s Generation,Yes.,3,"""a crucial issue persists"
emnlp2023,Just Ask for Calibration: Strategies for Eliciting Calibrated Confidence Scores from Language Models Fine-Tuned with Human Feedback,,,
emnlp2023,"The Effect of Scaling, Retrieval Augmentation and Form on the Factual Consistency of Language Models",Yes.,5,"""Large Language Models (LLMs) make natural interfaces to factual knowledge, but their usefulness is limited by their tendency to deliver inconsistent answers to semantically equivalent questions."""
emnlp2023,Semi-automatic Data Enhancement for Document-Level Relation Extraction with Distant Supervision from Large Language Models,Yes.,3,"""vanilla in-context learning is infeasible for DocRE due to the plenty of predefined fine-grained relation types and the uncontrolled generations of LLMs."""
emnlp2023,Dialogue Chain-of-Thought Distillation for Commonsense-aware Conversational Agents,Yes.,3,"""Even for large language models (LLMs), the task of identifying and aggregating key evidence within a single hop presents a substantial challenge."""
emnlp2023,C-STS: Conditional Semantic Textual Similarity,,,
emnlp2023,HyperRouter: Towards Efficient Training and Inference of Sparse Mixture of Experts,Yes.,5,"""However, this strategy has two key limitations"
emnlp2023,"Fine-tuned LLMs Know More, Hallucinate Less with Few-Shot Sequence-to-Sequence Semantic Parsing over Wikidata",Yes.,5,"""While large language models (LLMs) can answer many questions correctly, they can also hallucinate and give wrong answers."""
emnlp2023,ZEROTOP: Zero-Shot Task-Oriented Semantic Parsing using Large Language Models,Yes.,3,"""LLMs are generally trained on publicly available text and code and cannot be expected to directly generalize to domain-specific parsing tasks in a zero-shot setting."" and ""We observe that current LLMs fail to detect unanswerable questions; and as a result, cannot handle questions corresponding to missing slots."""
emnlp2023,Ditto: A Simple and Efficient Approach to Improve Sentence Embeddings,Yes.,3,"""Our analysis reveals that the sentence embeddings from BERT suffer from a bias towards uninformative words, limiting the performance in semantic textual similarity (STS) tasks."""
emnlp2023,INSTRUCTSCORE: Towards Explainable Text Generation Evaluation with Automatic Feedback,Yes.,2,"""Although recent learned metrics show high correlation with human judgement, these metrics do not provide explicit explanation of their verdict, nor associate the scores with defects in the generated text."""
emnlp2023,Towards Interpretable Mental Health Analysis with Large Language Models,Yes.,3,"""However, existing relevant studies bear several limitations, including inadequate evaluations, lack of prompting strategies, and ignorance of exploring LLMs for explainability."""
emnlp2023,Beyond Factuality: A Comprehensive Evaluation of Large Language Models as Knowledge Generators,Yes.,4,"""community concerns abound regarding the factuality and potential implications of using this uncensored knowledge"" and ""Surprisingly, our study reveals that the factuality of generated knowledge, even if lower, does not significantly hinder downstream tasks."""
emnlp2023,Compressing Context to Enhance Inference Efficiency of Large Language Models,Yes.,5,"""However, they face challenges in managing long documents and extended conversations, due to significantly increased computational requirements, both in memory and inference time, and potential context truncation when the input exceeds the LLM’s fixed context length."""
emnlp2023,MoT: Memory-of-Thought Enables ChatGPT to Self-Improve,Yes.,3,"""However, fundamentally improving them depends on high-quality datasets or computationally expensive fine-tuning."""
emnlp2023,Can You Follow Me? Testing Situational Understanding for ChatGPT,Yes.,5,"""Previous works have identified certain SU limitations in non-chatbot Large Language models (LLMs),"" and ""find that despite the fundamental simplicity of the task, the model’s performance reflects an inability to retain correct environment states across time,"" and ""performance degradation is largely because ChatGPT has non-persistent in-context memory (although it can access the full dialogue history) and it is susceptible to"
emnlp2023,"Towards Reliable Misinformation Mitigation: Generalization, Uncertainty, and GPT-4",Yes.,2,"""Next, we explore generalization, revealing that GPT-4 and RoBERTa-large exhibit differences in failure modes."""
emnlp2023,HaluEval: A Large-Scale Hallucination Evaluation Benchmark for Large Language Models,Yes.,5,"""Large language models (LLMs), such as ChatGPT, are prone to generate hallucinations, i.e., content that conflicts with the source or cannot be verified by the factual knowledge."" and ""Moreover, existing LLMs face great challenges in recognizing the hallucinations in texts."""
emnlp2023,Enabling Large Language Models to Generate Text with Citations,Yes.,5,"""their generated outputs are prone to hallucination"" and ""current systems have considerable room for improvement—For example, on the ELI5 dataset, even the best models lack complete citation support 50% of the time."""
emnlp2023,Counting the Bugs in ChatGPT’s Wugs: A Multilingual Investigation into the Morphological Capabilities of a Large Language Model,Yes.,5,"""We find that ChatGPT massively underperforms purpose-built systems, particularly in English. Overall, our results—through the lens of morphology—cast a new light on the linguistic capabilities of ChatGPT, suggesting that claims of human-like language skills are premature and misleading."""
emnlp2023,Adapt in Contexts: Retrieval-Augmented Domain Adaptation via In-Context Learning,Yes.,3,"""LLMs are still facing challenges in long-tail knowledge in unseen and unfamiliar domains."""
emnlp2023,MAF: Multi-Aspect Feedback for Improving Reasoning in Large Language Models,Yes.,5,"""However, when it comes to natural language reasoning, LMs still face challenges such as hallucination, generating incorrect intermediate reasoning steps, and making mathematical errors."""
emnlp2023,Personalized Distillation: Empowering Open-Sourced LLMs with Adaptive Learning for Code Generation,Yes.,1,"""Previous distillation methods usually prompt ChatGPT to generate a set of instructions and answers, for the student model to learn. However, such standard distillation approach neglects the merits and conditions of the student model."""
emnlp2023,Do Language Models Have a Common Sense regarding Time? Revisiting Temporal Commonsense Reasoning in the Era of Large Language Models,Yes.,5,"""Our findings reveal a nuanced depiction of the capabilities and limitations of the models within temporal reasoning, offering a comprehensive reference for future research in this pivotal domain."""
emnlp2023,Evaluation of African American Language Bias in Natural Language Generation,Yes.,4,"""We present evidence of dialectal bias for six pre-trained LLMs through performance gaps on these tasks."""
emnlp2023,EtiCor: Corpus for Analyzing LLMs for Etiquettes,Yes.,2,"""Initial results indicate that LLMs, mostly fail to understand etiquettes from regions from non-Western world."""
emnlp2023,An Investigation of LLMs’ Inefficacy in Understanding Converse Relations,Yes.,5,"""The results suggest that LLMs often resort to shortcut learning and still face challenges on our proposed benchmark."""
emnlp2023,ZGUL: Zero-shot Generalization to Unseen Languages using Multi-source Ensembling of Language Adapters,Yes.,1,"""Training target LA requires unlabeled data, which may not be readily available for low resource *unseen* languages"
emnlp2023,Log-FGAER: Logic-Guided Fine-Grained Address Entity Recognition from Multi-Turn Spoken Dialogue,Yes.,1,"""we provide an ontology-based data augmentation methodology that employs ChatGPT to augment a spoken dialogue dataset with labeled address entities."""
emnlp2023,Unified Low-Resource Sequence Labeling by Sample-Aware Dynamic Sparse Finetuning,Yes.,3,"""this requires formatting them into specialized augmented format unknown to the base pretrained language model (PLMs) necessitating finetuning to the target format. This significantly bounds its usefulness in data-limited settings where finetuning large models cannot properly generalize to the target format."""
emnlp2023,Benchmarking and Improving Text-to-SQL Generation under Ambiguity,Yes.,3,"""We evaluate several Text-to-SQL systems and decoding algorithms, including those employing state-of-the-art LLMs, and find them to be far from this ideal."""
emnlp2023,Prompt-Based Monte-Carlo Tree Search for Goal-oriented Dialogue Policy Planning,Yes.,1,"""GDP-Zero prompts a large language model to act as a policy prior, value function, user simulator, and system model during the tree search."""
emnlp2023,HiddenTables and PyQTax: A Cooperative Game and Dataset For TableQA to Ensure Scale and Data Privacy Across a Myriad of Taxonomies,Yes.,5,"""A myriad of different Large Language Models (LLMs) face a common challenge in contextually analyzing table question-answering tasks. These challenges are engendered from (1) finite context windows for large tables, (2) multi-faceted discrepancies amongst tokenization patterns against cell boundaries, and (3) various limitations stemming from data confidentiality in the process of using external models such as"
emnlp2023,"Speak, Memory: An Archaeology of Books Known to ChatGPT/GPT-4",Yes.,4,"""The ability of these models to memorize an unknown set of books complicates assessments of measurement validity for cultural analytics by contaminating test data; we show that models perform much better on memorized books than on non-memorized books for downstream tasks."""
emnlp2023,Copyright Violations and Large Language Models,Yes.,5,"""This work explores the issue of copyright violations and large language models through the lens of verbatim memorization, focusing on possible redistribution of copyrighted text."""
emnlp2023,Symbolic Planning and Code Generation for Grounded Dialogue,Yes.,5,"""LLMs have had limited applicability in grounded task-oriented dialogue as they are difficult to steer toward task objectives and fail to handle novel grounding."""
emnlp2023,Universal Self-Adaptive Prompting,Yes.,3,"""zero-shot performances in LLMs are still typically weaker due to the lack of guidance and the difficulty of applying existing automatic prompt design methods in general tasks when ground-truth labels are unavailable."""
emnlp2023,Beat LLMs at Their Own Game: Zero-Shot LLM-Generated Text Detection via Querying ChatGPT,Yes.,2,"""Despite their great potential, LLMs also incur serious concerns as they are likely to be misused."""
emnlp2023,Faithful Model Evaluation for Model-Based Metrics,Yes.,3,"""Existing works usually do not consider the variance change due to metric model errors, which can lead to wrong conclusions."""
emnlp2023,Have LLMs Advanced Enough? A Challenging Problem Solving Benchmark For Large Language Models,Yes.,5,"""The typical failure modes of GPT-4, the best model, are errors in algebraic manipulation, difficulty in grounding abstract concepts into mathematical equations accurately and failure in retrieving relevant domain-specific concepts."""
emnlp2023,SCITAB: A Challenging Benchmark for Compositional Reasoning and Claim Verification on Scientific Tables,Yes.,3,"""SCITAB poses a significant challenge to state-of-the-art models, including table-based pretraining models and large language models. All models except GPT-4 achieved performance barely above random guessing."""
emnlp2023,Task-Agnostic Low-Rank Adapters for Unseen English Dialects,Yes.,4,"""Large Language Models (LLMs) are trained on corpora disproportionally weighted in favor of Standard American English. As a result, speakers of other dialects experience significantly more failures when interacting with these technologies."""
emnlp2023,Federated Learning of Large Language Models with Parameter-Efficient Prompt Tuning and Adaptive Optimization,Yes.,4,"""the training process of Large Language Models (LLMs) generally incurs the update of significant parameters, which limits the applicability of FL techniques to tackle the LLMs in real scenarios,"" and ""Prompt tuning can significantly reduce the number of parameters to update, but it either incurs performance degradation or low training efficiency,"" and ""the decentralized data is generally non-Independent and Identically Distributed ("
emnlp2023,TheoremQA: A Theorem-driven Question Answering Dataset,Yes.,2,"""However, their capabilities to solve more challenging math problems which require domain-specific knowledge (i.e. theorem) have yet to be investigated."""
emnlp2023,Automatic Prompt Optimization with “Gradient Descent” and Beam Search,,,
emnlp2023,Active Retrieval Augmented Generation,Yes.,5,"""Despite the remarkable ability of large language models (LMs) to comprehend and generate language, they have a tendency to hallucinate and create factually inaccurate output."""
emnlp2023,DialCoT Meets PPO: Decomposing and Exploring Reasoning Paths in Smaller Language Models,Yes.,3,"""Chain-of-Thought (CoT) prompting has successfully enhanced the reasoning capabilities of Large Language Models (LLMs) with at least 100 billion parameters. However, it is ineffective, or even detrimental, to the performance on reasoning tasks in Smaller Language Models (SLMs"
emnlp2023,Reasoning with Language Model is Planning with World Model,Yes.,5,"""However, LLMs can still struggle with problems that are easy for humans, such as generating action plans for executing tasks or performing complex math or logical reasoning. This is due to LLMs’ absence of an internal world model for predicting world states (e.g., environment status, variable values) and simulating"
emnlp2023,LLM-enhanced Self-training for Cross-domain Constituency Parsing,Yes.,1,"""To overcome this limitation, we propose enhancing self-training with the large language model (LLM) to generate domain-specific raw corpora iteratively."""
emnlp2023,Editing Common Sense in Transformers,Yes.,3,"""Commonsense knowledge with multiple correct answers, e.g., an apple can be green or red but not transparent, has not been studied but is as essential for enhancing transformers’ reliability and usefulness."""
emnlp2023,IfQA: A Dataset for Open-domain Question Answering under Counterfactual Presuppositions,,,
emnlp2023,How Do Large Language Models Capture the Ever-changing World Knowledge? A Review of Recent Advances,Yes.,3,"""Although large language models (LLMs) are impressive in solving various tasks, they can quickly be outdated after deployment. Maintaining their up-to-date status is a pressing concern in the current era."""
emnlp2023,DecipherPref: Analyzing Influential Factors in Human Preference Judgments via GPT-4,Yes.,2,"""It is also unclear if there are other hidden factors influencing human judgments."""
emnlp2023,Generating Data for Symbolic Language with Large Language Models,,,
emnlp2023,DALE: Generative Data Augmentation for Low-Resource Legal NLP,Yes.,1,"""DALE outperforms all our baselines, including LLMs, qualitatively and quantitatively, with absolute improvements of 1%-50%."""
emnlp2023,trlX: A Framework for Large Scale Reinforcement Learning from Human Feedback,Yes.,1,"""Reinforcement learning from human feedback (RLHF) utilizes human feedback to better align large language models with human preferences via online optimization against a learned reward model."""
emnlp2023,This is not a Dataset: A Large Negation Benchmark to Challenge Large Language Models,Yes.,5,"""they fail to interpret negation, a crucial step in Natural Language Processing,"" and ""Our findings show that, while LLMs are proficient at classifying affirmative sentences, they struggle with negative sentences and lack a deep understanding of negation, often relying on superficial cues,"" and ""the lack of generalization in handling negation is persistent, highlighting the ongoing challenges of LLMs"
emnlp2023,SOUL: Towards Sentiment and Opinion Understanding of Language,Yes.,5,"""Experimental results indicate that SOUL is a challenging task for both small and large language models, with a performance gap of up to 27% when compared to human performance. Furthermore, evaluations conducted with both human experts and GPT-4 highlight the limitations of the small language model in generating reasoning-based justifications."""
emnlp2023,Regulation and NLP (RegNLP): Taming Large Language Models,Yes.,2,"""important debates emerge regarding the benefits and risks of their development, deployment and use"" and ""highlighting the shortcomings of current NLP discussions dealing with risk assessment."""
emnlp2023,"MedEval: A Multi-Level, Multi-Task, and Multi-Domain Medical Benchmark for Language Model Evaluation",Yes.,2,"""Our evaluations reveal varying effectiveness of the two categories of language models across different tasks, from which we notice the importance of instruction tuning for few-shot usage of large language models."""
emnlp2023,Evaluation Metrics in the Era of GPT-4: Reliably Evaluating Large Language Models on Sequence to Sequence Tasks,Yes.,2,"""We aim to improve the understanding of current models’ performance by providing a preliminary and hybrid evaluation on a range of open and closed-source generative LLMs"" and ""the quality of automatic evaluation metrics is not keeping up with the pace of development of generative models."""
emnlp2023,“Mistakes Help Us Grow”: Facilitating and Evaluating Growth Mindset Supportive Language in Classrooms,Yes.,1,"""We explore whether large language models (LLMs) can provide automated, personalized coaching to support teachers’ use of GMSL."""
emnlp2023,Unnatural Error Correction: GPT-4 Can Almost Perfectly Handle Unnatural Scrambled Text,Yes.,2,"""While Large Language Models (LLMs) have achieved remarkable performance in many tasks, much about their inner workings remains unclear."""
emnlp2023,Detecting and Mitigating Hallucinations in Multilingual Summarisation,Yes.,5,"""Hallucinations pose a significant challenge to the reliability of neural models for abstractive summarisation."" and ""we assess a broad range of multilingual large language models, and find that they all tend to hallucinate often in languages different from English."""
emnlp2023,SelfCheckGPT: Zero-Resource Black-Box Hallucination Detection for Generative Large Language Models,,,
emnlp2023,Revisiting Instruction Fine-tuned Model Evaluation to Guide Industrial Applications,Yes.,1,"""Instruction Fine-Tuning (IFT) is a powerful paradigm that strengthens the zero-shot capabilities of Large Language Models (LLMs), but in doing so induces new evaluation metric requirements."""
emnlp2023,EasyQuant: An Efficient Data-free Quantization Algorithm for LLMs,Yes.,5,"""However, their expensive computations and high memory requirements are prohibitive for deployment."" and ""the quantized model was calibrated using few samples from the training data, which might affect the generalization of the quantized LLMs to unknown cases and tasks."""
emnlp2023,APrompt: Attention Prompt Tuning for Efficient Adaptation of Pre-trained Language Models,Yes.,2,"""most existing prompt tuning approaches only introduce prompts at the input layer, limiting their performance and leaving large rooms for improvement."""
emnlp2023,Learning Preference Model for LLMs via Automatic Preference Data Generation,Yes.,3,"""Despite the advanced capacities of the state-of-the-art large language models (LLMs), they suffer from issues of hallucination, stereotype, etc."""
emnlp2023,Revisiting Automated Topic Model Evaluation with Large Language Models,Yes.,2,"""the setup of the evaluation task is crucial — LLMs perform better on coherence ratings of word sets than on intrusion detection."""
emnlp2023,ORCHID: A Chinese Debate Corpus for Target-Independent Stance Detection and Argumentative Dialogue Summarization,Yes.,1,"""Dialogue agents have been receiving increasing attention for years, and this trend has been further boosted by the recent progress of large language models (LLMs)."""
emnlp2023,Explore-Instruct: Enhancing Domain-Specific Instruction Coverage through Active Exploration,Yes.,2,"""existing data employed for such tuning often exhibit an inadequate coverage of individual domains, limiting the scope for nuanced comprehension and interactions within these areas."""
emnlp2023,Just Adjust One Prompt: Enhancing In-Context Dialogue Scoring via Constructing the Optimal Subgraph of Demonstrations and Prompts,Yes.,3,"""The use of modern Large Language Models (LLMs) as chatbots still has some problems such as hallucinations and lack of empathy."""
emnlp2023,EpiK-Eval: Evaluation for Language Models as Epistemic Models,Yes.,5,"""Evaluations across various LLMs reveal significant weaknesses in this domain."" and ""We contend that these shortcomings stem from the intrinsic nature of prevailing training objectives."""
emnlp2023,On Bilingual Lexicon Induction with Large Language Models,Yes.,2,"""We also conduct a series of in-depth analyses and ablation studies, providing more insights on BLI with (m)LLMs, also along with their limitations."""
emnlp2023,"CRaSh: Clustering, Removing, and Sharing Enhance Fine-tuning without Full Large Language Model",Yes.,2,"""However, when tuning publicly accessible, centralized LLMs with private instruction data, privacy concerns are inevitable."""
emnlp2023,Large Language Models are biased to overestimate profoundness,Yes.,5,"""However, LLMs systematically overestimate the profoundness of nonsensical statements"" and ""this work provides insights into the potential biases induced by Reinforcement Learning from Human Feedback (RLHF), inducing an increase in the bias to overestimate the profoundness of statements."""
emnlp2023,SummEdits: Measuring LLM Ability at Factual Reasoning Through The Lens of Summarization,Yes.,5,"""Most LLMs struggle on SummEdits, with performance close to random chance. The best-performing model, GPT-4, is still 8% below estimated human performance, highlighting the gaps in LLMs’ ability to reason about facts and detect inconsistencies when they occur."""
emnlp2023,Quantifying the redundancy between prosody and text,Yes.,1,"""We use large language models (LLMs) to estimate how much information is redundant between prosody and the words themselves."""
emnlp2023,Label Words are Anchors: An Information Flow Perspective for Understanding In-Context Learning,Yes.,3,"""the underlying mechanism of how LLMs learn from the provided context remains under-explored."""
emnlp2023,Prompting Scientific Names for Zero-Shot Species Recognition,Yes.,3,"""However, it is underexplored how to use CLIP for zero-shot recognition of highly specialized concepts, e.g., species of birds, plants, and animals, for which their scientific names are written in Latin or Greek. Indeed, CLIP performs poorly for zero-shot species recognition with prompts that use scientific names, e.g., 'a photo of Lepus Timidus' ("
emnlp2023,Do All Languages Cost the Same? Tokenization in the Era of Commercial Language Models,Yes.,4,"""We show evidence that speakers of a large number of the supported languages are overcharged while obtaining poorer results."""
emnlp2023,MULTITuDE: Large-Scale Multilingual Machine-Generated Text Detection Benchmark,Yes.,2,"""There is a lack of research into capabilities of recent LLMs to generate convincing text in languages other than English and into performance of detectors of machine-generated text in multilingual settings."""
emnlp2023,Revisiting Block-based Quantisation: What is Important for Sub-8-bit LLM Inference?,,,
emnlp2023,Reducing Sequence Length by Predicting Edit Spans with Large Language Models,Yes.,3,"""the models that generate all target tokens in such tasks have a tendency to simply copy the input text as is, without making needed changes, because the difference between input and output texts is minimal in the training data. This is also inefficient because the computational cost grows quadratically with the target sequence length with Transformer."""
emnlp2023,Instruct and Extract: Instruction Tuning for On-Demand Information Extraction,Yes.,2,"""However, when it comes to information extraction – a classic task in natural language processing – most task-specific systems cannot align well with long-tail ad hoc extraction use cases for non-expert users."""
emnlp2023,Rethinking the Evaluation for Conversational Recommendation in the Era of Large Language Models,Yes.,2,"""revealing the inadequacy of the existing evaluation protocol"" and ""To overcome the limitation, we further propose an interactive Evaluation approach based on LLMs."""
emnlp2023,Appraising the Potential Uses and Harms of LLMs for Medical Systematic Reviews,Yes.,5,"""However, LLMs sometimes generate inaccurate (and potentially misleading) texts by hallucination or omission. In healthcare, this can make LLMs unusable at best and dangerous at worst."" and ""They also raised concerns regarding confidently composed but inaccurate LLM outputs and other potential downstream harms, including decreased accountability and proliferation of low-quality reviews."""
emnlp2023,Contrastive Learning for Inference in Dialogue,Yes.,3,"""While recent large language models show remarkable advances in inference tasks, their performance in inductive reasoning, where not all information is present in the context, is far behind deductive reasoning."""
emnlp2023,"Editing Large Language Models: Problems, Methods, and Opportunities",Yes.,3,"""Despite the ability to train capable LLMs, the methodology for maintaining their relevancy and rectifying errors remains elusive."" and ""an exhaustive overview of the task definition and challenges associated with model editing, along with an in-depth empirical analysis of the most progressive methods currently at our disposal."""
emnlp2023,Large Language Models Meet Open-World Intent Discovery and Recognition: An Evaluation of ChatGPT,Yes.,5,"""we summarize and discuss the challenges faced by LLMs including clustering, domain-specific understanding, and cross-domain in-context learning scenarios."""
emnlp2023,The Distributional Hypothesis Does Not Fully Explain the Benefits of Masked Language Model Pretraining,Yes.,3,"""Our results illustrate our limited understanding of model pretraining and provide future research directions."""
emnlp2023,Learning to Rank Context for Named Entity Recognition Using a Synthetic Dataset,Yes.,3,"""While recent pre-trained transformer-based models can perform named entity recognition (NER) with great accuracy, their limited range remains an issue when applied to long documents such as whole novels."""
emnlp2023,Improving Diversity of Demographic Representation in Large Language Models via Collective-Critiques and Self-Voting,Yes.,5,"""A crucial challenge for generative large language models (LLMs) is diversity"
emnlp2023,Hidding the Ghostwriters: An Adversarial Evaluation of AI-Generated Student Essay Detection,Yes.,4,"""the utilization of these models carries inherent risks, including but not limited to plagiarism, the dissemination of fake news, and issues in educational exercises,"" and ""the existing detectors can be easily circumvented using straightforward automatic adversarial attacks."""
emnlp2023,Contextual Interaction for Argument Post Quality Assessment,Yes.,3,"""while LLMs with in-context examples showcase a commendable ability to identify high-quality argument posts, they exhibit relatively limited efficacy in discerning between argument posts with a narrow quality gap."""
emnlp2023,Synthetic Data Generation with Large Language Models for Text Classification: Potential and Limitations,Yes.,5,"""the effectiveness of the LLM-generated synthetic data in supporting model training is inconsistent across different classification tasks"" and ""subjectivity, at both the task level and instance level, is negatively associated with the performance of the model trained on synthetic data."""
emnlp2023,People Make Better Edits: Measuring the Efficacy of LLM-Generated Counterfactually Augmented Data for Harmful Language Detection,Yes.,3,"""One key reason for the lower performance of automated methods is that the changes they introduce are often insufficient to flip the original label."""
emnlp2023,Learning from Mistakes via Cooperative Study Assistant for Large Language Models,Yes.,5,"""However, the feedback from LLM itself is often inaccurate, thereby limiting its benefits."""
emnlp2023,Conceptor-Aided Debiasing of Large Language Models,Yes.,5,"""Pre-trained large language models (LLMs) reflect the inherent social biases of their training corpus,"" and ""many methods have been proposed to mitigate this issue, but they often fail to debias or they sacrifice model accuracy."""
emnlp2023,CoMPosT: Characterizing and Evaluating Caricature in LLM Simulations,Yes.,5,"""there is growing concern that these LLM simulations are flattened caricatures of the personas that they aim to simulate, failing to capture the multidimensionality of people and perpetuating stereotypes."""
emnlp2023,Grammar-Constrained Decoding for Structured NLP Tasks without Finetuning,Yes.,3,"""Despite their impressive performance, large language models (LMs) still struggle with reliably generating complex output structures when not finetuned to follow the required output format exactly."""
emnlp2023,Evaluating Evaluation Metrics: A Framework for Analyzing NLG Evaluation Metrics using Measurement Theory,Yes.,2,"""identified issues related to conflated validity structure in human-eval and reliability in LLM-based metrics."""
emnlp2023,Revisiting the Knowledge Injection Frameworks,Yes.,5,"""we find that injecting unaligned (i.e., random) knowledge tuple into the LLMs achieves comparable (and sometimes better) results than the aligned knowledge being injected,"" and ""how to adapt these LLMs to better suit the vertical domain-specific tasks by utilizing external knowledge remains not completely solved."""
emnlp2023,Collaborative Generative AI: Integrating GPT-k for Efficient Editing in Text-to-Image Generation,Yes.,3,"""a common issue encountered by users is the need for repetitive editing of input prompts in order to receive a satisfactory image, which is time-consuming and labor-intensive."""
emnlp2023,clembench: Using Game Play to Evaluate Chat-Optimized Language Models as Conversational Agents,Yes.,1,"""showing that current chat-optimised LLMs are, to an extent, capable of following game-play instructions."""
emnlp2023,Polyglot or Not? Measuring Multilingual Encyclopedic Knowledge in Foundation Models,Yes.,4,"""an analysis of LLaMA’s errors reveals significant limitations in its ability to recall facts in languages other than English, plus difficulties related to the location and gender of fact subjects."""
emnlp2023,UDAPDR: Unsupervised Domain Adaptation via LLM Prompting and Distillation of Rerankers,Yes.,1,"""To address this challenge, we develop and motivate a method for using large language models (LLMs) to generate large numbers of synthetic queries cheaply."""
emnlp2023,Data Similarity is Not Enough to Explain Language Model Performance,Yes.,3,"""Large language models achieve high performance on many but not all downstream tasks,"" and ""This suggests that the relationship between pretraining data and downstream tasks is more complex than often assumed."""
emnlp2023,Do LLMs Understand Social Knowledge? Evaluating the Sociability of Large Language Models with SocKET Benchmark,Yes.,3,"""we demonstrate that current models attain only moderate performance but reveal significant potential for task transfer among different types and categories of tasks"" and ""points to clear room for improvement to build more socially-aware LLMs."""
emnlp2023,Integrating Language Models into Direct Speech Translation: An Inference-Time Solution to Control Gender Inflection,Yes.,4,"""The existing solutions to do so, though effective, are hardly feasible in practice as they involve dedicated model re-training on gender-labeled ST data."""
emnlp2023,StoryAnalogy: Deriving Story-level Analogies from Large Language Models to Unlock Analogical Understanding,Yes.,5,"""Interestingly, we find that the analogy identification tasks are incredibly difficult not only for sentence embedding models but also for the recent large language models (LLMs) such as ChatGPT and LLaMa."""
emnlp2023,CESAR: Automatic Induction of Compositional Instructions for Multi-turn Dialogs,Yes.,3,"""While publicly available LLMs have shown promising performance, when exposed to complex instructions with multiple constraints, they lag against state-of-the-art models like ChatGPT."""
emnlp2023,Reward-Augmented Decoding: Efficient Controlled Text Generation With a Unidirectional Reward Model,Yes.,3,"""While large language models have proven effective in a huge range of downstream applications, they often generate text that is problematic or lacks a desired attribute."""
emnlp2023,Cabbage Sweeter than Cake? Analysing the Potential of Large Language Models for Learning Conceptual Spaces,Yes.,3,"""we also find that fine-tuned models of the BERT family are able to match or even outperform the largest GPT-3 model, despite being 2 to 3 orders of magnitude smaller."""
emnlp2023,An Empirical Study of Translation Hypothesis Ensembling with Large Language Models,Yes.,4,"""Large language models (LLMs) are becoming a one-fits-many solution, but they sometimes hallucinate or produce unreliable output."""
emnlp2023,Visually-Situated Natural Language Understanding with Contrastive Reading Model and Frozen Large Language Models,Yes.,2,"""their performance on text-rich images still requires improvement."""
emnlp2023,Unlearn What You Want to Forget: Efficient Unlearning for LLMs,,,
emnlp2023,Precedent-Enhanced Legal Judgment Prediction with LLM and Domain-Model Collaboration,Yes.,1,"""These can be broken down into two categories"
emnlp2023,FActScore: Fine-grained Atomic Evaluation of Factual Precision in Long Form Text Generation,Yes.,5,"""Evaluating the factuality of long-form text generated by large language models (LMs) is non-trivial because (1) generations often contain a mixture of supported and unsupported pieces of information, making binary judgments of quality inadequate, and (2) human evaluation is time-consuming"
emnlp2023,Calc-X and Calcformers: Empowering Arithmetical Chain-of-Thought through Interaction with Symbolic Systems,Yes.,5,"""language models are notoriously inclined to make factual errors in tasks requiring arithmetic computation."""
emnlp2023,CoF-CoT: Enhancing Large Language Models with Coarse-to-Fine Chain-of-Thought Prompting for Multi-domain NLU Tasks,Yes.,1,"""While Chain-of-Thought prompting is popular in reasoning tasks, its application to Large Language Models (LLMs) in Natural Language Understanding (NLU) is under-explored."""
emnlp2023,StereoMap: Quantifying the Awareness of Human-like Stereotypes in Large Language Models,Yes.,4,"""Large Language Models (LLMs) have been observed to encode and perpetuate harmful associations present in the training data."" and ""This study contributes to the understanding of how LLMs perceive and represent social groups, shedding light on their potential biases and the perpetuation of harmful associations."""
emnlp2023,"Select, Prompt, Filter: Distilling Large Language Models for Summarizing Conversations",Yes.,3,"""Large language models (LLMs) like ChatGPT can be expensive to train, deploy, and use for specific natural language generation tasks such as text summarization and for certain domains. A promising alternative is to fine-tune relatively smaller language models (LMs) on a particular task using"
emnlp2023,UPRISE: Universal Prompt Retrieval for Improving Zero-Shot Evaluation,Yes.,2,"""the need for model-specific fine-tuning or task-specific prompt engineering can hinder their generalization"" and ""UPRISE mitigates the hallucination problem in our experiments with ChatGPT."""
emnlp2023,Large Language Models Only Pass Primary School Exams in Indonesia: A Comprehensive Test on IndoMMLU,Yes.,5,"""Our empirical evaluations show that GPT-3.5 only manages to pass the Indonesian primary school level, with limited knowledge of local Indonesian languages and culture."""
emnlp2023,Multi-Source Multi-Type Knowledge Exploration and Exploitation for Dialogue Generation,Yes.,1,"""Recently, large language models (LLMs) have shown impressive performance on natural language processing tasks."""
emnlp2023,Multilingual Large Language Models Are Not (Yet) Code-Switchers,Yes.,3,"""despite multilingual LLMs exhibiting promising outcomes in certain tasks using zero or few-shot prompting, they still underperform in comparison to fine-tuned models of much smaller scales."""
emnlp2023,Large Language Models: The Need for Nuance in Current Debates and a Pragmatic Perspective on Understanding,Yes.,5,"""critically assess three points recurring in critiques of LLM capacities"
emnlp2023,The CoT Collection: Improving Zero-shot and Few-shot Learning of Language Models via Chain-of-Thought Fine-Tuning,Yes.,2,"""Language models (LMs) with less than 100B parameters are known to perform poorly on chain-of-thought (CoT) reasoning in contrast to large LMs when solving unseen tasks."""
emnlp2023,Explaining Interactions Between Text Spans,Yes.,1,"""We then investigate the decision-making processes of multiple fine-tuned large language models in terms of the employed connections between spans in separate parts of the input and compare them to the human reasoning processes."""
emnlp2023,Question Answering as Programming for Solving Time-Sensitive Questions,Yes.,5,"""our experiments reveal that the aforementioned problems still pose a significant challenge to existing LLMs. This can be attributed to the LLMs’ inability to perform rigorous reasoning based on surface-level text semantics."""
emnlp2023,Context Compression for Auto-regressive Transformers with Sentinel Tokens,Yes.,5,"""The quadratic complexity of the attention module makes it gradually become the bulk of compute in Transformer-based LLMs during generation. Moreover, the excessive key-value cache that arises when dealing with long inputs also brings severe issues on memory footprint and inference latency."""
emnlp2023,Generative Adversarial Training with Perturbed Token Detection for Model Robustness,No.,1,The abstract does not mention LLMs or any specific limitations related to them.
emnlp2023,Large Language Models and Multimodal Retrieval for Visual Word Sense Disambiguation,Yes.,1,"""Additionally, we utilize Large Language Models (LLMs) as knowledge bases to enhance the given phrases and resolve ambiguity related to the target word."""
emnlp2023,Doolittle: Benchmarks and Corpora for Academic Writing Formalization,Yes.,2,"""Our experiments reveal that existing text transfer models and grammatical error correction models address certain aspects of AWF but still have a significant performance gap compared to human performance."""
emnlp2023,Token Prediction as Implicit Classification to Identify LLM-Generated Text,Yes.,1,"""This paper introduces a novel approach for identifying the possible large language models (LLMs) involved in text generation."""
emnlp2023,LLMLingua: Compressing Prompts for Accelerated Inference of Large Language Models,,,
emnlp2023,Conversation Chronicles: Towards Diverse Temporal and Relational Dynamics in Multi-Session Conversations,Yes.,1,"""However, a major limitation of existing open-domain chatbot research is its singular focus on short single-session dialogue, neglecting the potential need for understanding contextual information in multiple consecutive sessions that precede an ongoing dialogue."""
emnlp2023,CLAIR: Evaluating Image Captions with Large Language Models,Yes.,1,"""Here, we propose CLAIR, a novel method that leverages the zero-shot language modeling capabilities of large language models (LLMs) to evaluate candidate captions."""
emnlp2023,MoPe: Model Perturbation based Privacy Attacks on Language Models,Yes.,5,"""Recent work has shown that Large Language Models (LLMs) can unintentionally leak sensitive information present in their training data."""
emnlp2023,Aligning Large Language Models through Synthetic Feedback,Yes.,1,"""Aligning large language models (LLMs) to human values has become increasingly important as it enables sophisticated steering of LLMs."""
emnlp2023,You Told Me That Joke Twice: A Systematic Investigation of Transferability and Robustness of Humor Detection Models,Yes.,2,"""The behavior of the models on out-of-domain data is unstable, suggesting that some of the models overfit, while others learn non-specific humor characteristics."""
emnlp2023,Empower Nested Boolean Logic via Self-Supervised Curriculum Learning,Yes.,5,"""We find that any pre-trained language models even including large language models only behave like a random selector in the face of multi-nested boolean logic, a task that humans can handle with ease."""
emnlp2023,DADA: Dialect Adaptation via Dynamic Aggregation of Linguistic Rules,Yes.,3,"""Existing large language models (LLMs) that mainly focus on Standard American English (SAE) often lead to significantly worse performance when being applied to other English dialects."""
emnlp2023,Can We Edit Multimodal Large Language Models?,Yes.,3,"""Empirically, we notice that previous baselines can implement editing multimodal LLMs to some extent, but the effect is still barely satisfactory, indicating the potential difficulty of this task."""
emnlp2023,ClusterLLM: Large Language Models as a Guide for Text Clustering,Yes.,1,"""We introduce ClusterLLM, a novel text clustering framework that leverages feedback from an instruction-tuned large language model, such as ChatGPT."""
emnlp2023,Syllogistic Reasoning for Legal Judgment Analysis,Yes.,2,"""people can hardly trust the results generated by a model without reliable analysis of legal judgement."""
emnlp2023,KCTS: Knowledge-Constrained Tree Search Decoding with Token-Level Hallucination Detection,Yes.,5,"""Large Language Models (LLMs) have demonstrated remarkable human-level natural language generation capabilities. However, their potential to generate misinformation, often called the *hallucination* problem, poses a significant risk to their deployment."""
emnlp2023,CRUSH4SQL: Collective Retrieval Using Schema Hallucination For Text2SQL,Yes.,1,"""First, we use an LLM to hallucinate a minimal DB schema that it deems adequate to answer the query."""
emnlp2023,Language Models with Rationality,Yes.,5,"""This lack of interpretability is a growing impediment to widespread use of LLMs."" and ""resolve inconsistencies that may exist."""
emnlp2023,Mitigating Temporal Misalignment by Discarding Outdated Facts,Yes.,5,"""While large language models are able to retain vast amounts of world knowledge seen during pretraining, such knowledge is prone to going out of date and is nontrivial to update."""
emnlp2023,Fighting Fire with Fire: The Dual Role of LLMs in Crafting and Detecting Elusive Disinformation,Yes.,2,"""Recent ubiquity and disruptive impacts of large language models (LLMs) have raised concerns about their potential to be misused (i.e., generating large-scale harmful and misleading content)."""
emnlp2023,Let GPT be a Math Tutor: Teaching Math Word Problem Solvers with Customized Exercise Generation,Yes.,1,"""In this paper, we present a novel approach for distilling math word problem solving capabilities from large language models (LLMs) into smaller, more efficient student models."""
emnlp2023,FANToM: A Benchmark for Stress-testing Machine Theory of Mind in Interactions,Yes,5,"We show that FANToM is challenging for state-of-the-art LLMs, which perform significantly worse than humans even with chain-of-thought reasoning or fine-tuning."
emnlp2023,FreeAL: Towards Human-Free Active Learning in the Era of Large Language Models,Yes,2,their performances are still subject to human intervention.
emnlp2023,Outlier Dimensions Encode Task Specific Knowledge,Yes,3,"Previous works have argued that although ablating these outlier dimensions in LLM representations hurts downstream performance, outlier dimensions are detrimental to the representational quality of embeddings."
emnlp2023,Enhancing Computation Efficiency in Large Language Models through Weight and Activation Quantization,Yes,2,"Large Language Models (LLMs) are proficient in natural language processing tasks, but their deployment is often restricted by extensive parameter sizes and computational demands."
emnlp2023,Assessing Step-by-Step Reasoning against Lexical Negation: A Case Study on Syllogism,Yes,5,"We observed that dozens of modern LLMs were not robust against lexical negation (e.g., plausible→implausible) when performing CoT-style reasoning, and the results highlight unique limitations in each LLM family."
emnlp2023,Chain-of-Thought Tuning: Masked Language Models can also Think Step By Step in Natural Language Understanding,Yes,3,LLMs perform less well than small-scale Masked Language Models (MLMs).
emnlp2023,Is ChatGPT Good at Search? Investigating Large Language Models as Re-Ranking Agents,Yes,3,The discrepancy between the pre-training objectives of LLMs and the ranking objective poses another challenge.
emnlp2023,Dr ChatGPT tell me what I want to hear: How different prompts impact health answer correctness,Yes,5,reveal that knowledge passed in the prompt can bias the model to the detriment of answer correctness.
emnlp2023,Prompting with Pseudo-Code Instructions,Yes,1,we explore if prompting via pseudo-code instructions helps improve the performance of pre-trained language models.
emnlp2023,CRAB: Assessing the Strength of Causal Relationships Between Real-world Events,Yes,5,find that models perform worse on causal reasoning when events are derived from complex causal structures compared to simple linear causal chains.
emnlp2023,Specialist or Generalist? Instruction Tuning for Specific NLP Tasks,Yes,3,generalist data containing hallucinatory information may negatively affect the model’s performance.
emnlp2023,Making Large Language Models Better Data Creators,Yes,3,"deploying them for downstream applications is still challenging due to cost, responsiveness, control, or concerns around privacy and security."
emnlp2023,Hallucination Detection for Generative Large Language Models by Bayesian Sequential Estimation,Yes,5,"the propensity of LLMs to generate inaccurate or non-factual content, termed “hallucinations”, remains a significant challenge."
emnlp2023,Guideline Learning for In-Context Information Extraction,Yes,3,"However, the performance of In-context IE generally lags behind the state-of-the-art supervised expert models. We highlight a key reason for this shortfall: underspecified task description. The limited-length context struggles to thoroughly express the intricate IE task instructions and various edge cases, leading to misalignment in task comprehension with humans."
emnlp2023,Self-ICL: Zero-Shot In-Context Learning with Self-Generated Demonstrations,Yes,3,"different methods are proposed to select representative demonstrations from existing training corpora. However, such settings are not aligned with real-world practices, as end-users usually query LMs without access to demonstration pools."
emnlp2023,MQuAKE: Assessing Knowledge Editing in Language Models via Multi-Hop Questions,Yes,5,"current knowledge-editing approaches can recall edited facts accurately, they fail catastrophically on the constructed multi-hop questions."
emnlp2023,NL2TL: Transforming Natural Languages to Temporal Logics using Large Language Models,Yes,1,exploring the use of Large Language Models (LLMs) at multiple stages.
emnlp2023,Consistency Analysis of ChatGPT,Yes,5,"prompt designing, few-shot learning and employing larger large language models (LLMs) are unlikely to be the ultimate solution to resolve the inconsistency issue of LLMs."
emnlp2023,AnyTOD: A Programmable Task-Oriented Dialog System,Yes,1,"We view TOD as a program executed by a language model (LM), where program logic and ontology is provided by a designer as a schema."
emnlp2023,Zero-Shot Multi-Label Topic Inference with Sentence Encoders and LLMs,Yes,1,"Through extensive experimentation on seven diverse data sets, we observed that LLMs, such as ChatGPT-3.5 and PaLM, demonstrated superior generality compared to other LLMs, e.g., BLOOM and GPT-NeoX."
emnlp2023,Exploring Distributional Shifts in Large Language Models for Code Analysis,Yes,3,We establish that samples from each new domain present all the models with a significant challenge of distribution shift.
emnlp2023,A Benchmark for Reasoning with Spatial Prepositions,Yes,3,"Our results show considerable variability in the performance of smaller and larger models, as well as across prompts and languages. However, none of the models reaches human performance."
emnlp2023,Document-Level Machine Translation with Large Language Models,Yes,1,"Large language models (LLMs) such as ChatGPT can produce coherent, cohesive, relevant, and fluent answers for various natural language processing (NLP) tasks."
emnlp2023,LLM-driven Instruction Following: Progresses and Concerns,Yes,3,What concerns remain in LLM-driven instruction following?
emnlp2023,Mitigating Societal Harms in Large Language Models,Yes,5,"We will provide an overview of potential social issues in language generation, including toxicity, social biases, misinformation, factual inconsistency, and privacy violations."
emnlp2023,Creative Natural Language Generation,Yes,3,"Large language models such as GPT-3, GPT4, Claude etc., have advanced the state of the art in several natural language generation tasks such as text summarization and machine translation. However when it comes to open-ended tasks with a focus on creativity such as generating stories, poetry, or various forms of figurative language, these state-of-the-art language models are often found to be inadequate. This tutorial aims to bring awareness of the important and emerging research"
emnlp2023,Fabricator: An Open Source Toolkit for Generating Labeled Training Data with Teacher LLMs,Yes,1,"Current research addresses this bottleneck by exploring a novel paradigm called zero-shot learning via dataset generation. Here, a powerful LLM is prompted with a task description to generate labeled data that can be used to train a downstream NLP model."
emnlp2023,CHATREPORT: Democratizing Sustainability Disclosure Analysis through LLM-based Tools,Yes,3,"However, developing such tools is challenging due to (1) the hallucination of LLMs and (2) the inefficiency of bringing domain experts into the AI development loop."
emnlp2023,RaLLe: A Framework for Developing and Evaluating Retrieval-Augmented Large Language Models,Yes,2,current libraries for building R-LLMs provide high-level abstractions without sufficient transparency for evaluating and optimizing prompts within specific inference processes such as retrieval and generation.
emnlp2023,H2O Open Ecosystem for State-of-the-art Large Language Models,Yes,5,"LLMs represent a revolution in AI. However, they also pose many significant risks, such as the presence of biased, private, copyrighted or harmful text."
emnlp2023,FLEEK: Factual Error Detection and Correction with Evidence Retrieved from External Knowledge,Yes,5,LLMs’ inability to attribute their claims to external knowledge and their tendency to hallucinate makes it difficult to rely on their responses.
emnlp2023,CLEVA: Chinese Language Models EVAluation Platform,Yes,4,"The absence of a comprehensive Chinese benchmark that thoroughly assesses a model’s performance, the unstandardized and incomparable prompting procedure, and the prevalent risk of contamination pose major challenges in the current evaluation of Chinese LLMs."
emnlp2023,MusicAgent: An AI Agent for Music Understanding and Generation with Large Language Models,Yes,1,"Inspired by the recent success of large language models (LLMs) in task automation, we develop a system, named MusicAgent, which integrates numerous music-related tools and an autonomous workflow to address user requirements."
emnlp2023,MiniChain: A Small Library for Coding with Large Language Models,Yes,3,"LLMs are accurate enough, on average, to replace core functionality, yet make basic mistakes that demonstrate a lack of robustness."
emnlp2023,Okapi: Instruction-tuned Large Language Models in Multiple Languages with Reinforcement Learning from Human Feedback,Yes,2,"existing open-source LLMs have only been instruction-tuned for English and a few popular languages, thus hindering their accessibility to many other languages in the world."
emnlp2023,InsightPilot: An LLM-Empowered Automated Data Exploration System,Yes,1,"we introduce InsightPilot, an LLM (Large Language Model)-based, automated data exploration system designed to simplify the data exploration process."
emnlp2023,Prompt2Model: Generating Deployable Models from Natural Language Instructions,Yes,3,LLMs are a step backward from traditional special-purpose NLP models; they require extensive computational resources for deployment and can be gated behind APIs.
emnlp2023,NeMo Guardrails: A Toolkit for Controllable and Safe LLM Applications with Programmable Rails,Yes,1,NeMo Guardrails is an open-source toolkit for easily adding programmable guardrails to LLM-based conversational systems.
emnlp2023,LM-Polygraph: Uncertainty Estimation for Language Models,Yes,5,"However, a significant challenge arises as these models often “hallucinate”, i.e., fabricate facts without providing users an apparent means to discern the veracity of their statements."
emnlp2023,Prompterator: Iterate Efficiently towards More Effective Prompts,Yes,1,"Finding well-performing prompts, however, is a non-trivial task which requires experimentation in order to arrive at a prompt that solves a specific task."
emnlp2023,Video-LLaMA: An Instruction-tuned Audio-Visual Language Model for Video Understanding,Yes,1,"Video-LLaMA enables video comprehension by tackling two challenges: (1) capturing the temporal changes in visual scenes, (2) integrating audio-visual signals."
emnlp2023,Gatekeeper to save COGS and improve efficiency of Text Prediction,Yes,3,"As LLMs require massive amounts of computation and storage, such an approach incurs network and high execution cost."
emnlp2023,Text2Topic: Multi-Label Text Classification System for Efficient Topic Detection in User Generated Content with Zero-Shot Capabilities,Yes,1,"The final model achieves accurate and comprehensive results compared to state-of-the-art baselines, including large language models (LLMs)."
emnlp2023,Investigating Table-to-Text Generation Capabilities of Large Language Models in Real-World Information Seeking Scenarios,Yes,2,"a significant performance gap still exists between other open-sourced LLMs (e.g., Vicuna and LLaMA-2) and GPT-4 models."
emnlp2023,WordArt Designer: User-Driven Artistic Typography Synthesis using Large Language Models,Yes,1,"This paper introduces WordArt Designer, a user-driven framework for artistic typography synthesis, relying on the Large Language Model (LLM). The system incorporates four key modules: the LLM Engine, SemTypo, StyTypo, and TexTypo modules. 1) The LLM Engine, empowered by the LLM (e.g. GPT-3.5), interprets user inputs and"
emnlp2023,Empower Large Language Model to Perform Better on Industrial Domain-Specific Question Answering,Yes,3,"Large Language Model (LLM) has gained popularity and achieved remarkable results in open-domain tasks, but its performance in real industrial domain-specific scenarios is average due to its lack of specific domain knowledge. This issue has attracted widespread attention, but there are few relevant benchmarks available. In this paper, we provide a benchmark Question Answering (QA) dataset named MSQA, centered around Microsoft products and IT technical"
emnlp2023,Building Real-World Meeting Summarization Systems using Large Language Models: A Practical Perspective,Yes,3,"Considering the privacy concerns of closed-source models for only being accessible via API, alongside the high cost associated with using fine-tuned versions of the closed-source models."
emnlp2023,Building Real-World Meeting Summarization Systems using Large Language Models: A Practical Perspective,Yes.,2,"""Considering the privacy concerns of closed-source models for only being accessible via API, alongside the high cost associated with using fine-tuned versions of the closed-source models."""
emnlp2023,AART: AI-Assisted Red-Teaming with Diverse Data Generation for New LLM-powered Applications,Yes.,3,"""This provides transparency of developers evaluation intentions and enables quick adaptation to new use cases and newly discovered model weaknesses."""
emnlp2023,Are ChatGPT and GPT-4 General-Purpose Solvers for Financial Text Analytics? A Study on Several Typical Tasks,Yes.,2,"""We report both the strengths and limitations of the current models by comparing them to the state-of-the-art fine-tuned approaches and the recently released domain-specific pretrained models."""
emnlp2023,PILLOW: Enhancing Efficient Instruction Fine-tuning via Prompt Matching,Yes.,2,"""Instruction fine-tuning has conventionally been employed to adapt Large Language Models (LLMs) to a variety of diverse tasks. Nonetheless, this technique often necessitates substantial computational resources, making it impractical for deployment by individuals or small-scale entities."""
emnlp2023,CarExpert: Leveraging Large Language Models for In-Car Conversational Question Answering,Yes.,5,"""leveraging LLMs for domain-specific question answering suffers from severe limitations. The generated answer tends to hallucinate due to the training data collection time (when using off-the-shelf), complex user utterance and wrong retrieval (in retrieval-augmented generation). Furthermore, due to the"
emnlp2023,JarviX: A LLM No code Platform for Tabular Data Analysis and Optimization,Yes.,1,"""JarviX is designed to employ Large Language Models (LLMs) to facilitate an automated guide and execute high-precision data analyzes on tabular datasets."""
emnlp2023,"Self-Criticism: Aligning Large Language Models with their Understanding of Helpfulness, Honesty, and Harmlessness",Yes.,3,"""RLHF, which incorporates independent reward models trained on high-quality human feedback datasets, incurs high costs in terms of hardware resources and human efforts."""
emnlp2023,InstructPTS: Instruction-Tuning LLMs for Product Title Summarization,,,
emnlp2023,LLM4Vis: Explainable Visualization Recommendation using ChatGPT,Yes.,1,"""To address this research gap, we propose LLM4Vis, a novel ChatGPT-based prompting approach to perform visualization recommendation and return human-like explanations using very few demonstration examples."""
emnlp2023,Harnessing LLMs for Temporal Data - A Study on Explainable Financial Time Series Forecasting,Yes.,1,"""Furthermore, fine-tuned public LLMs, such as Open-LLaMA, can generate reasonable and explainable forecasts, although they underperform compared to GPT-4."""
emnlp2023,"ViGPTQA - State-of-the-Art LLMs for Vietnamese Question Answering: System Overview, Core Models Training, and Evaluations",Yes.,3,"""Large language models (LLMs) and their applications in low-resource languages (such as in Vietnamese) are limited due to lack of training data and benchmarking datasets."""
emnlp2023,On Sample-Efficient Code Generation,Yes.,3,"""Large language models often struggle to predict runtime behavior in code generation tasks, leading to a reliance on rejection sampling (best-of-n) to generate multiple code snippets then select the best."""
emnlp2023,Graph Meets LLM: A Novel Approach to Collaborative Filtering for Robust Conversational Understanding,Yes.,1,"""This paper then further explores the use of Large Language Models (LLMs) in conjunction with graph traversal, leading to a significant increase in index coverage for unseen interactions."""
emnlp2023,DELPHI: Data for Evaluating LLMs’ Performance in Handling Controversial Issues,Yes.,4,"""This dataset presents challenges concerning knowledge recency, safety, fairness, and bias."""
ArXiv2024,Knowledge-Centric Templatic Views of Documents,Yes.,1,"""we consider each of these documents to be templatic views of the same underlying knowledge, and we aim to unify the generation and evaluation of these templatic views of documents. We begin by introducing an LLM-powered method to extract the most important information from an input document and represent this information in a structured format."""
ArXiv2024,Improved Zero-Shot Classification by Adapting VLMs with Text Descriptions,Yes.,2,"""The zero-shot performance of existing vision-language models (VLMs) such as CLIP is limited by the availability of large-scale, aligned image and text datasets in specific domains."""
ArXiv2024,Medusa: Simple LLM Inference Acceleration Framework with Multiple Decoding Heads,Yes.,1,"""The inference process in Large Language Models (LLMs) is often limited due to the absence of parallelism in the auto-regressive decoding process, resulting in most operations being restricted by the memory bandwidth of accelerators."""
ArXiv2024,A Study on Large Language Models' Limitations in Multiple-Choice Question Answering,Yes.,5,"""Despite their ubiquitous use, there is no systematic analysis of their specific capabilities and limitations."" and ""We analyze 26 small open-source models and find that 65% of the models do not understand the task, only 4 models properly select an answer from the given choices, and only 5 of these models are choice order independent."""
ArXiv2024,TREC iKAT 2023: The Interactive Knowledge Assistance Track Overview,Yes.,1,"""Most of the runs leveraged Large Language Models (LLMs) in their pipelines, with a few focusing on a generate-then-retrieve approach."""
ArXiv2024,Baichuan2-Sum: Instruction Finetune Baichuan2-7B Model for Dialogue Summarization,Yes.,1,"""Large language models (LLMs) like Llama, Baichuan and Bloom models show remarkable ability with instruction fine-tuning in many natural language tasks."""
ArXiv2024,Fast and Optimal Weight Update for Pruned Large Language Models,Yes.,1,"""Pruning large language models (LLMs) is a challenging task due to their enormous size."""
ArXiv2024,CheX-GPT: Harnessing Large Language Models for Enhanced Chest X-ray Report Labeling,Yes.,1,"""Traditional rule-based labeling methods fall short of capturing the nuances of diverse free-text patterns. Moreover, models using expert-annotated data are limited by data scarcity and pre-defined classes, impacting their performance, flexibility and scalability."""
ArXiv2024,A Survey of Resource-efficient LLM and Multimodal Foundation Models,Yes.,3,"""the substantial advancements in versatility and performance these models offer come at a significant cost in terms of hardware resources."""
ArXiv2024,E-EVAL: A Comprehensive Chinese K-12 Education Evaluation Benchmark for Large Language Models,Yes.,3,"""almost all models perform poorly in complex subjects such as mathematics"" and ""most Chinese-dominant LLMs did not achieve higher scores at the primary school level compared to the middle school level"" and ""the mastery of higher-order knowledge by the model does not necessarily imply the mastery of lower-order knowledge as well."""
ArXiv2024,Monte Carlo Tree Search for Recipe Generation using GPT-2,Yes.,3,"""Existing research on using LLMs to generate recipes has shown that LLMs can be finetuned to generate realistic-sounding recipes. However, on close examination, these generated recipes often fail to meet basic requirements like including chicken as an ingredient in chicken dishes."""
ArXiv2024,The Dawn After the Dark: An Empirical Study on Factuality Hallucination in Large Language Models,Yes.,5,"""hallucination (i.e., the tendency to generate factually incorrect content) poses great challenge to trustworthy and reliable deployment of LLMs in real-world applications"" and ""To tackle the LLM hallucination, three key questions should be well studied"
ArXiv2024,The Impact of Reasoning Step Length on Large Language Models,Yes.,3,"""However, the correlation between the effectiveness of CoT and the length of reasoning steps in prompts remains largely unknown."""
ArXiv2024,"A Survey on the Applications of Frontier AI, Foundation Models, and Large Language Models to Intelligent Transportation Systems",Yes.,1,"""The paper further surveys interactions between LLMs and various aspects of ITS, exploring roles in traffic management, facilitating autonomous vehicles, and contributing to smart city development, while addressing challenges brought by frontier AI and foundation models."""
ArXiv2024,XUAT-Copilot: Multi-Agent Collaborative System for Automated User Acceptance Testing with Large Language Model,Yes.,1,"""With recent notable successes, large language models (LLMs) demonstrate significant potential in attaining human-like intelligence and there has been a growing research area that employs LLMs as autonomous agents to obtain human-like decision-making capabilities."""
ArXiv2024,Astraios: Parameter-Efficient Instruction Tuning Code Large Language Models,Yes.,3,"""Further investigation into the effects of these methods on both model robustness and code security reveals that larger models tend to demonstrate reduced robustness and less security."""
ArXiv2024,"Are Language Models More Like Libraries or Like Librarians? Bibliotechnism, the Novel Reference Problem, and the Attitudes of LLMs",Yes.,2,"""We begin (Part I) with a sustained defense of bibliotechnism against this challenge showing how even entirely novel text may be meaningful only in a derivative sense, and arguing that, in particular, much novel text generated by LLMs is only derivatively meaningful."""
ArXiv2024,Assessing and Understanding Creativity in Large Language Models,Yes.,3,"""We found that the creativity of LLMs primarily falls short in originality, while excelling in elaboration."""
ArXiv2024,LLM on FHIR -- Demystifying Health Records,Yes.,4,"""However, challenges included variability in LLM responses and the need for precise filtering of health data."" and ""While promising, the implementation and pilot also highlight risks such as inconsistent responses and the importance of replicable output."""
ArXiv2024,Large Language Model Evaluation via Matrix Entropy,Yes.,1,"""Large language models (LLMs) have revolutionized the field of natural language processing, extending their strong capabilities into multi-modal domains."""
ArXiv2024,CharPoet: A Chinese Classical Poetry Generation System Based on Token-free LLM,Yes.,3,"""Large language models (LLMs) improve content control by allowing unrestricted user instructions, but the token-by-token generation process frequently makes format errors."""
ArXiv2024,RoTBench: A Multi-Level Benchmark for Evaluating the Robustness of Large Language Models in Tool Learning,Yes.,5,"""Current research predominantly emphasizes LLMs' capacity to utilize tools in well-structured environments while overlooking their stability when confronted with the inevitable noise of the real world."" and ""the performance of GPT-4 even drops significantly from 80.00 to 58"
ArXiv2024,AutoRT: Embodied Foundation Models for Large Scale Orchestration of Robotic Agents,Yes.,1,"""one of the key challenges of training embodied foundation models is the lack of data grounded in the physical world."""
ArXiv2024,TAT-LLM: A Specialized Language Model for Discrete Reasoning over Tabular and Textual Data,Yes.,2,"""utilizing an online LLM like GPT-4 holds various challenges in terms of cost, latency, and data security risk."""
ArXiv2024,Lightning Attention-2: A Free Lunch for Handling Unlimited Sequence Lengths in Large Language Models,Yes.,2,"""However, due to the issue with cumulative summation (cumsum), current linear attention algorithms cannot demonstrate their theoretical advantage in a causal setting."""
ArXiv2024,A Preliminary Study on Using Large Language Models in Software Pentesting,Yes.,1,"""Large language models (LLM) are perceived to offer promising potentials for automating security tasks, such as those found in security operation centers (SOCs)."""
ArXiv2024,"The What, Why, and How of Context Length Extension Techniques in Large Language Models -- A Detailed Survey",Yes.,5,"""However, amidst these advancements, it is noteworthy that LLMs often face a limitation in terms of context length extrapolation."""
ArXiv2024,LLMs for Relational Reasoning: How Far are We?,Yes.,5,"""Recent efforts have demonstrated that the LLMs are poor at solving sequential decision-making problems that require common-sense planning by evaluating their performance on the reinforcement learning benchmarks."" and ""Our evaluations illustrate that compared with the neural program induction systems which are much smaller in model size, the state-of-the-art LLMs are much poorer in terms of reasoning ability by achieving much lower performance and"
ArXiv2024,Large Language Model Adaptation for Financial Sentiment Analysis,Yes.,3,"""Generalist language models tend to fall short in tasks specifically tailored for finance, even when using large language models (LLMs) with great natural language understanding and generative capabilities."""
ArXiv2024,Pruning for Protection: Increasing Jailbreak Resistance in Aligned LLMs Without Fine-Tuning,Yes.,4,"""Large Language Models (LLMs) are vulnerable to `Jailbreaking' prompts, a type of attack that can coax these models into generating harmful and illegal content."" and ""prominent chat models, such as LLaMA-2 Chat, Vicuna, and Mistral Instruct exhibit high susceptibility to jailbreaking attacks, with some categories achieving nearly 70-100%"
ArXiv2024,FFSplit: Split Feed-Forward Network For Optimizing Accuracy-Efficiency Trade-off in Language Model Inference,Yes.,5,"""The large number of parameters in Pretrained Language Models enhance their performance, but also make them resource-intensive, making it challenging to deploy them on commodity hardware like a single GPU."" and ""Due to the memory and power limitations of these devices, model compression techniques are often used to decrease both the model's size and its inference latency. This usually results in a trade-off between model accuracy"
ArXiv2024,IDoFew: Intermediate Training Using Dual-Clustering in Language Models for Few Labels Text Classification,Yes.,2,"""However, some tasks still pose challenges for these models, including text classification with limited labels. This can result in a cold-start problem."""
ArXiv2024,VoroNav: Voronoi-based Zero-shot Object Navigation with Large Language Model,Yes.,1,"""By harnessing topological and semantic information, VoroNav designs text-based descriptions of paths and images that are readily interpretable by a large language model (LLM)."""
ArXiv2024,MAPLE: Multilingual Evaluation of Parameter Efficient Finetuning of Large Language Models,Yes.,2,"""there is a large gap between the performance of LLMs on English and other languages"" and ""finetuning sometimes improves performance on low-resource languages, while degrading performance on high-resource languages."""
ArXiv2024,Evaluating Gender Bias in Large Language Models via Chain-of-Thought Prompting,,,
ArXiv2024,LLMs for Test Input Generation for Semantic Caches,Yes.,4,"""However, these models are computationally expensive. At scale, the cost of serving thousands of users increases massively affecting also user experience."" and ""Due to the nature of these semantic cache techniques that rely on query embeddings, there is a high chance of errors impacting user confidence in the system."""
ArXiv2024,Knowledge Distillation for Closed-Source Language Models,Yes.,3,"""due to the incapability to directly access the weights, hidden states, and output distributions of these closed-source models, the distillation can only be performed by fine-tuning smaller models with data samples generated by closed-source language models, which constrains the effectiveness of knowledge distillation."""
ArXiv2024,DataFrame QA: A Universal LLM Framework on DataFrame Question Answering Without Data Exposure,Yes.,1,"""This paper introduces DataFrame question answering (QA), a novel task that utilizes large language models (LLMs) to generate Pandas queries for information retrieval and data analysis on dataframes, emphasizing safe and non-revealing data handling."""
ArXiv2024,GRATH: Gradual Self-Truthifying for Large Language Models,Yes.,5,"""existing LLMs still struggle with generating truthful content, as evidenced by their modest performance on benchmarks like TruthfulQA."""
ArXiv2024,Large Language Models are Superpositions of All Characters: Attaining Arbitrary Role-play via Self-Alignment,Yes.,1,"""we present the first comprehensive cross-supervision alignment experiment in the role-play domain, revealing that the intrinsic capabilities of LLMs confine the knowledge within role-play."""
ArXiv2024,Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling,Yes.,5,"""This is infeasible both because of the large compute costs and duration associated with pre-training, and the impending scarcity of high-quality data on the web."""
ArXiv2024,Universal Vulnerabilities in Large Language Models: Backdoor Attacks for In-context Learning,Yes.,5,"""Despite being widely applied, in-context learning is vulnerable to malicious attacks."" and ""Our studies demonstrate that an attacker can manipulate the behavior of large language models by poisoning the demonstration context, without the need for fine-tuning the model."""
ArXiv2024,AugSumm: towards generalizable speech summarization using synthetic labels from large language model,Yes.,1,"""We tackle this challenge by proposing AugSumm, a method to leverage large language models (LLMs) as a proxy for human annotators to generate augmented summaries for training and evaluation."""
ArXiv2024,Less Could Be Better: Parameter-efficient Fine-tuning Advances Medical Vision Foundation Models,Yes.,1,"""Parameter-efficient fine-tuning (PEFT) that was initially developed for exploiting pre-trained large language models has recently emerged as an effective approach to perform transfer learning on computer vision tasks."""
ArXiv2024,WARM: On the Benefits of Weight Averaged Reward Models,Yes.,3,"""Aligning large language models (LLMs) with human preferences through reinforcement learning (RLHF) can lead to reward hacking, where LLMs exploit failures in the reward model (RM) to achieve seemingly high rewards without meeting the underlying objectives."" and ""We identify two primary challenges when designing RMs to mitigate reward hacking"
ArXiv2024,"A Fast, Performant, Secure Distributed Training Framework For Large Language Model",Yes.,3,"""maliciously stealing model parameters and data from the server or client side has become an urgent problem to be solved."""
ArXiv2024,Transfer Learning for Text Diffusion Models,Yes.,1,"""We are particularly interested to see whether pretrained AR models can be transformed into text diffusion models through a lightweight adaptation procedure we call 'AR2Diff'."""
ArXiv2024,InfiAgent-DABench: Evaluating Agents on Data Analysis Tasks,Yes.,3,"""Our extensive benchmarking of 34 LLMs uncovers the current challenges encountered in data analysis tasks."""
ArXiv2024,UniMS-RAG: A Unified Multi-source Retrieval-Augmented Generation for Personalized Dialogue Systems,Yes.,2,"""Large Language Models (LLMs) has shown exceptional capabilities in many natural language understanding and generation tasks. However, the personalization issue still remains a much-coveted property, especially when it comes to the multiple sources involved in the dialogue system."""
ArXiv2024,Assertion Detection Large Language Model In-context Learning LoRA Fine-tuning,,,
ArXiv2024,LLaVA-MoLE: Sparse Mixture of LoRA Experts for Mitigating Data Conflicts in Instruction Finetuning MLLMs,Yes.,3,"""we have discovered that data conflicts are inevitable when mixing instruction data from distinct domains, which can result in performance drops for tasks of a specific domain."""
ArXiv2024,Enhancing Large Language Model Performance To Answer Questions and Extract Information More Accurately,Yes.,5,"""Large Language Models (LLMs) generate responses to questions; however, their effectiveness is often hindered by sub-optimal quality of answers and occasional failures to provide accurate responses to questions."""
ArXiv2024,Cheetah: Natural Language Generation for 517 African Languages,Yes.,1,"""In this paper, we develop Cheetah, a massively multilingual NLG language model for African languages."""
ArXiv2024,TrustLLM: Trustworthiness in Large Language Models,Yes.,5,"""Nonetheless, these LLMs present many challenges, particularly in the realm of trustworthiness. ... discussion of open challenges and future directions. ... our observations reveal that proprietary LLMs generally outperform most open-source counterparts in terms of trustworthiness, raising concerns about the potential risks of widely accessible open-source LLMs. ... some LLMs may be overly calibrated towards exhibiting trustworthiness"
ArXiv2024,A Comprehensive Study of Knowledge Editing for Large Language Models,Yes.,3,"""a primary limitation lies in the significant computational demands during training, arising from their extensive parameterization"" and ""necessitating frequent updates to LLMs to correct outdated information or integrate new knowledge."""
ArXiv2024,Single Word Change is All You Need: Designing Attacks and Defenses for Text Classifiers,No.,1,"The paper discusses adversarial examples and text classifiers, but does not mention language models (LLMs or LMs)."
ArXiv2024,Contextualization Distillation from Large Language Model for Knowledge Graph Completion,Yes.,2,"""the static and noisy nature of existing corpora collected from Wikipedia articles or synsets definitions often limits the potential of PLM-based KGC models."""
ArXiv2024,Open the Pandora's Box of LLMs: Jailbreaking LLMs through Representation Engineering,Yes.,5,"""Jailbreaking techniques aim to probe the boundaries of safety in large language models (LLMs) by inducing them to generate toxic responses to malicious queries, a significant concern within the LLM community."""
ArXiv2024,Chain of LoRA: Efficient Fine-tuning of Language Models via Residual Learning,Yes.,3,"""Despite its advantages, LoRA falls short of full-parameter fine-tuning in terms of generalization error for certain tasks."""
ArXiv2024,A Dataset and Benchmark for Copyright Protection from Text-to-Image Diffusion Models,No.,1,"The abstract focuses on text-to-image generation techniques and copyright protection, without mentioning language models."
ArXiv2024,Few-Shot Detection of Machine-Generated Text using Style Representations,Yes.,3,"""model under-specification poses an unavoidable challenge for neural network-based detectors, making them brittle in the face of data shifts, such as the release of newer language models producing still more fluent text than the models used to train the detectors."""
ArXiv2024,Assessing AI Detectors in Identifying AI-Generated Code: Implications for Education,Yes.,2,"""Educators are increasingly concerned about the usage of Large Language Models (LLMs) such as ChatGPT in programming education, particularly regarding the potential exploitation of imperfections in Artificial Intelligence Generated Content (AIGC) Detectors for academic misconduct."""
ArXiv2024,Reinforcement Learning for Optimizing RAG for Domain Chatbots,Yes.,1,"""With the advent of Large Language Models (LLM), conversational assistants have become prevalent for domain use cases."""
ArXiv2024,TransportationGames: Benchmarking Transportation Knowledge of (Multimodal) Large Language Models,Yes.,3,"""The experimental results show that although some models perform well in some tasks, there is still much room for improvement overall."""
ArXiv2024,Parameter-Efficient Detoxification with Contrastive Decoding,Yes.,1,"""We evaluate DETOXIGEN on the commonly used REALTOXICITYPROMPTS benchmark (Gehman et al., 2020) with various language models as generators."""
ArXiv2024,Zero Resource Cross-Lingual Part Of Speech Tagging,Yes.,1,"""Existing systems use two main techniques for POS tagging i.e. pretrained multilingual large language models(LLM) or project the source language labels into the zero resource target language and train a sequence labeling model on it."""
ArXiv2024,EASYTOOL: Enhancing LLM-based Agents with Concise Tool Instruction,Yes.,3,"""it usually requires LLMs to understand many tool functions from different tool documentation. But these documentations could be diverse, redundant or incomplete, which immensely affects the capability of LLMs in using tools."""
ArXiv2024,Knowledge Distillation from Language-Oriented to Emergent Communication for Multi-Agent Remote Control,Yes.,3,"""it is shown that EC incurs high training cost and struggles when using multimodal data, whereas LSC yields high inference computing cost due to the LLM's large size."""
ArXiv2024,Language Detection for Transliterated Content,Yes.,1,"""Emphasizing the pivotal role of comprehensive datasets for training Large Language Models LLMs like BERT."""
ArXiv2024,CHAMP: A Competition-level Dataset for Fine-Grained Analyses of LLMs' Mathematical Reasoning Capabilities,Yes.,5,"""Recent large language models (LLMs) have shown indications of mathematical reasoning ability. However it has not been clear how they would fare on more challenging competition-level problems."" and ""Using this corpus, we find that models often arrive at the correct final answer"
ArXiv2024,Comparing Template-based and Template-free Language Model Probing,Yes.,1,"""The differences between cloze-task language model (LM) probing with 1) expert-made templates and 2) naturally-occurring text have often been overlooked."""
ArXiv2024,Multi-Candidate Speculative Decoding,Yes.,3,"""the acceptance rate of candidate tokens receives limitations from several factors, such as the model, the dataset, and the decoding setup."""
ArXiv2024,Large Language Model Guided Knowledge Distillation for Time Series Anomaly Detection,Yes.,1,"""we propose AnomalyLLM, a knowledge distillation-based time series anomaly detection approach where the student network is trained to mimic the features of the large language model (LLM)-based teacher network that is pretrained on large-scale datasets."""
ArXiv2024,Holistic Autonomous Driving Understanding by Bird's-Eye-View Injected Multi-Modal Large Models,Yes.,3,"""existing research typically focuses on limited tasks and often omits key multi-view and temporal information which is crucial for robust autonomous driving."""
ArXiv2024,MLLM-Tool: A Multimodal Large Language Model For Tool Agent Learning,Yes.,3,"""However, the current LLMs' perceiving tool-use ability is limited to a single text query, which may result in ambiguity in understanding the users' real intentions."""
ArXiv2024,Tiny Time Mixers (TTMs): Fast Pre-trained Models for Enhanced Zero/Few-Shot Forecasting of Multivariate Time Series,Yes.,3,"""Large pre-trained models for zero/few-shot learning excel in language and vision domains but encounter challenges in multivariate time series (TS) due to the diverse nature and scarcity of publicly available pre-training data."" and ""However, these models are typically very slow and large (~billion parameters) and do not consider cross-channel correlations."""
ArXiv2024,A Computational Framework for Behavioral Assessment of LLM Therapists,Yes.,5,"""Understanding their behavior across a wide range of clients and situations is crucial to accurately assess their capabilities and limitations in the high-risk setting of mental health, where undesirable behaviors can lead to severe consequences."" and ""Our analysis framework suggests that despite the ability of LLMs to generate anecdotal examples that appear similar to human therapists, LLM therapists are currently not fully consistent with high-quality care"
ArXiv2024,TeenyTinyLlama: open-source tiny language models trained in Brazilian Portuguese,Yes.,3,"""While most LLMs are trained in high-resource languages like English, multilingual models generally underperform monolingual ones. Additionally, aspects of their multilingual foundation sometimes restrict the byproducts they produce, like computational demands and licensing regimes."""
ArXiv2024,T3: Transparent Tracking & Triggering for Fine-grained Overlap of Compute & Collectives,Yes.,1,"""Large Language Models increasingly rely on distributed techniques for their training and inference."""
ArXiv2024,Towards Language-Driven Video Inpainting via Multimodal Large Language Models,Yes.,1,"""This approach overcomes the limitations of traditional video inpainting methods that depend on manually labeled binary masks, a process often tedious and labor-intensive."""
ArXiv2024,"Prompt-RAG: Pioneering Vector Embedding-Free Retrieval-Augmented Generation in Niche Domains, Exemplified by Korean Medicine",Yes.,2,"""Conventional RAG methods mostly require vector embeddings, yet the suitability of generic LLM-based embedding representations for specialized domains remains uncertain."" and ""Despite challenges like content structuring and response latency, the advancements in LLMs are expected to encourage the use of Prompt-RAG."""
ArXiv2024,Prompting Large Language Models for Zero-Shot Clinical Prediction with Structured Longitudinal Electronic Health Record Data,,,
ArXiv2024,Using Zero-shot Prompting in the Automatic Creation and Expansion of Topic Taxonomies for Tagging Retail Banking Transactions,Yes.,1,"""This work presents an unsupervised method for automatically constructing and expanding topic taxonomies using instruction-based fine-tuned LLMs (Large Language Models)."""
ArXiv2024,Training microrobots to swim by a large language model,Yes.,1,"""We discuss the nuanced aspects of prompt design, particularly emphasizing the reduction of monetary expenses of using GPT-4."""
ArXiv2024,Navigating the OverKill in Large Language Models,Yes.,5,"""Large language models are meticulously aligned to be both helpful and harmless. However, recent research points to a potential overkill which means models may refuse to answer benign queries."""
ArXiv2024,E^2-LLM: Efficient and Extreme Length Extension of Large Language Models,Yes.,5,"""Typically, training LLMs with long context sizes is computationally expensive, requiring extensive training hours and GPU resources."""
ArXiv2024,LoMA: Lossless Compressed Memory Attention,Yes.,5,"""Large Language Models (LLMs) face limitations due to the high demand on GPU memory and computational resources when handling long contexts."""
ArXiv2024,"Uni3D-LLM: Unifying Point Cloud Perception, Generation and Editing with Large Language Models",Yes.,1,"""In this paper, we introduce Uni3D-LLM, a unified framework that leverages a Large Language Model (LLM) to integrate tasks of 3D perception, generation, and editing within point cloud scenes."""
ArXiv2024,Can AI Assistants Know What They Don't Know?,Yes.,5,"""Although LLMs possess intensive world knowledge, they still make factual errors when facing some knowledge intensive tasks, like open-domain question answering. These untruthful responses from the AI assistant may cause significant risks in practical applications."""
ArXiv2024,CoCoT: Contrastive Chain-of-Thought Prompting for Large Multimodal Models with Multiple Image Inputs,Yes.,5,"""Large Multimodal Models (LMMs) encounter two issues in such scenarios"
ArXiv2024,"When Geoscience Meets Generative AI and Large Language Models: Foundations, Trends, and Future Challenges",Yes.,2,"""Some challenges still remain such as ensuring physical interpretation, nefarious use cases, and trustworthiness."""
ArXiv2024,CANDLE: Iterative Conceptualization and Instantiation Distillation from Large Language Models for Commonsense Reasoning,Yes.,2,"""existing works tend to undervalue the step of instantiation and heavily rely on pre-built concept taxonomies and human annotations to collect both types of knowledge, resulting in a lack of instantiated knowledge to complete reasoning, high cost, and limited scalability."""
ArXiv2024,ConSmax: Hardware-Friendly Alternative Softmax with Learnable Parameters,Yes.,5,"""achieving real-time LLM inference on silicon is challenging due to the extensively used Softmax in self-attention. Apart from the non-linearity, the low arithmetic intensity greatly reduces the processing parallelism, which becomes the bottleneck especially when dealing with a longer context."""
ArXiv2024,Clue-Guided Path Exploration: An Efficient Knowledge Base Question-Answering Framework with Low Computational Resource Consumption,Yes.,3,"""However, updating their knowledge poses challenges, potentially leading to inaccuracies when confronted with unfamiliar queries."" and ""This is particularly unsuitable for LLMs with lower computational costs and relatively poorer performance."""
ArXiv2024,Analyzing the Effectiveness of Large Language Models on Text-to-SQL Synthesis,Yes.,3,"""Most if not all of the queries fall into these categories and it is insightful to understanding where the faults still lie with LLM program synthesis and where they can be improved."""
ArXiv2024,TeleChat Technical Report,Yes.,1,"""It includes pretrained language models as well as fine-tuned chat models that is aligned with human preferences."""
ArXiv2024,Physio: An LLM-Based Physiotherapy Advisor,Yes.,5,"""However, the fact that these models generate plausible, yet incorrect text poses a constraint when considering their use in several domains. Healthcare is a prime example of a domain where text-generative trustworthiness is a hard requirement to safeguard patient well-being."""
ArXiv2024,Infini-gram: Scaling Unbounded n-gram Language Models to a Trillion Tokens,Yes.,3,"""we also observe irregularities in the machine--$\infty$-gram agreement level with respect to the suffix length, which indicates deficiencies in neural LLM pretraining and the positional embeddings of Transformers."""
ArXiv2024,Exploring the Reasoning Abilities of Multimodal Large Language Models (MLLMs): A Comprehensive Survey on Emerging Trends in Multimodal Reasoning,Yes.,1,"""However, the reasoning abilities of MLLMs have not been systematically investigated."""
ArXiv2024,Do Language Models Exhibit the Same Cognitive Biases in Problem Solving as Human Learners?,Yes.,3,"""We find evidence that LLMs, with and without instruction-tuning, exhibit human-like biases in both the text-comprehension and the solution-planning steps of the solving process, but not during the final step which relies on the problem's arithmetic expressions (solution execution)."""
ArXiv2024,Segment Anything Model Can Not Segment Anything: Assessing AI Foundation Model's Generalizability in Permafrost Mapping,Yes.,1,"""Built upon the tremendous success achieved by Large Language Models (LLMs) as the foundation models for language tasks, this paper discusses the challenges of building foundation models for geospatial artificial intelligence (GeoAI) vision tasks."""
ArXiv2024,"Using LLM such as ChatGPT for Designing and Implementing a RISC Processor: Execution,Challenges and Limitations",Yes.,5,"""In all the cases, the generated code had significant errors and human intervention was always required to fix the bugs."""
ArXiv2024,Cross-target Stance Detection by Exploiting Target Analytical Perspectives,Yes.,1,"""formulating instructions based on large language model (LLM)."""
ArXiv2024,Bootstrapping LLM-based Task-Oriented Dialogue Agents via Self-Talk,Yes.,3,"""specializing them towards fulfilling a specific function can be challenging"" and ""requires a number of data samples that a) might not be available or b) costly to generate."""
ArXiv2024,ToolEyes: Fine-Grained Evaluation for Tool Learning Capabilities of Large Language Models in Real-world Scenarios,Yes.,5,"""Evaluations involving ten LLMs across three categories reveal a preference for specific scenarios and limited cognitive abilities in tool learning. Intriguingly, expanding the model size even exacerbates the hindrance to tool learning."""
ArXiv2024,Hierarchical Continual Reinforcement Learning via Large Language Model,Yes.,1,"""Hierarchical Continual reinforcement learning via large language model (Hi-Core), designed to facilitate the transfer of high-level knowledge."""
ArXiv2024,ML-On-Rails: Safeguarding Machine Learning Models in Software Systems A Case Study,Yes.,2,"""The transition from ML model prototyping to production use within software systems presents several challenges. These challenges primarily revolve around ensuring safety, security, and transparency, subsequently influencing the overall robustness and trustworthiness of ML models."""
ArXiv2024,F-Eval: Asssessing Fundamental Abilities with Refined Evaluation Methods,Yes.,3,"""Previous subjective evaluation methods mainly rely on scoring by API models. However, in the absence of references, large models have shown limited ability to discern subtle differences."""
ArXiv2024,"Survey of Natural Language Processing for Education: Taxonomy, Systematic Review, and Future Trends",,,
ArXiv2024,Incorporating Visual Experts to Resolve the Information Loss in Multimodal Large Language Models,,,
ArXiv2024,ChIRAAG: ChatGPT Informed Rapid and Automated Assertion Generation,Yes.,1,"""Only 33% of LLM-generated raw assertions had errors."""
ArXiv2024,DeepEdit: Knowledge Editing as Decoding with Constraints,Yes.,1,"""We propose a new perspective of knowledge editing (KE) for large language models (LLMs) that treats it as a constrained decoding problem."""
ArXiv2024,Reinforcement learning for question answering in programming domain using public community scoring as a human feedback,Yes.,3,"""demonstrates the limitations of conventional linguistic metrics in evaluating responses in the programming domain."""
ArXiv2024,From Random to Informed Data Selection: A Diversity-Based Approach to Optimize Human Annotation and Few-Shot Learning,Yes.,2,"""Recent advancements driven by large language models show potential, but struggle to adapt to specialized domains with severely limited data."""
ArXiv2024,Can Large Language Models Replace Economic Choice Prediction Labs?,Yes.,1,"""The AI community has recently contributed to that effort in two ways"
ArXiv2024,Dynamic Q&A of Clinical Documents with Large Language Models,Yes.,4,"""Promising results indicate potential, yet challenges such as model hallucinations and limited diverse medical case evaluations remain."""
ArXiv2024,Robust Prompt Optimization for Defending Language Models Against Jailbreaking Attacks,Yes.,5,"""language models (LM) remain vulnerable to adversarial attacks or jailbreaking, in which adversaries modify input prompts to induce harmful behavior."""
ArXiv2024,TQCompressor: improving tensor decomposition methods in neural networks via permutations,Yes.,1,"""We explore the challenges posed by the computational and storage demands of pre-trained language models in NLP tasks."""
ArXiv2024,Security Code Review by LLMs: A Deep Dive into Responses,Yes.,5,"""Our results indicate that the responses produced by LLMs often suffer from verbosity, vagueness, and incompleteness, highlighting the necessity to enhance their conciseness, understandability, and compliance to security defect detection."""
ArXiv2024,Evolving Code with A Large Language Model,Yes.,1,"""We cover design and LLM-usage considerations as well as the scientific challenges that arise when using an LLM for genetic programming."""
ArXiv2024,Interactions with Prompt Problems: A New Way to Teach Programming with Large Language Models,Yes.,1,"""Large Language Models (LLMs) have upended decades of pedagogy in computing education."""
ArXiv2024,Employing Label Models on ChatGPT Answers Improves Legal Text Entailment Performance,,,
ArXiv2024,AiGen-FoodReview: A Multimodal Dataset of Machine-Generated Restaurant Reviews and Images on Social Media,Yes.,2,"""Recent advances in Large Language Models (LLMs) may pave the way to fabricate indistinguishable fake generated content at a much lower cost."""
ArXiv2024,ProtAgents: Protein discovery via large language model multi-agent collaborations combining physics and machine learning,Yes.,1,"""The flexibility in designing the agents, on one hand, and their capacity in autonomous collaboration through the dynamic LLM-based multi-agent environment on the other hand, unleashes great potentials of LLMs in addressing multi-objective materials problems and opens up new avenues for autonomous materials discovery and design."""
ArXiv2024,EpilepsyLLM: Domain-Specific Large Language Model Fine-tuned with Epilepsy Medical Knowledge,Yes.,4,"""However, the existing fine-tuned medical LLMs are limited to general medical knowledge with English language. For disease-specific problems, the model's response is inaccurate and sometimes even completely irrelevant, especially when using a language other than English."""
ArXiv2024,Enhancing Robustness of LLM-Synthetic Text Detectors for Academic Writing: A Comprehensive Analysis,Yes.,4,"""However, most existing methods prioritize achieving higher accuracy on restricted datasets, neglecting the crucial aspect of generalizability. This limitation hinders their practical application in real-life scenarios where reliability is paramount."""
ArXiv2024,How well can large language models explain business processes?,Yes.,5,"""Since the use of LLMs for SAX is also accompanied by a certain degree of doubt related to its capacity to adequately fulfill SAX along with its tendency for hallucination and lack of inherent capacity to reason."""
ArXiv2024,KVQuant: Towards 10 Million Context Length LLM Inference with KV Cache Quantization,Yes.,1,"""LLMs are seeing growing use for applications such as document analysis and summarization which require large context windows."""
ArXiv2024,QACP: An Annotated Question Answering Dataset for Assisting Chinese Python Programming Learners,Yes.,2,"""highlighting the potential limitations of general LLMs as intelligent teaching assistants in computer programming courses."""
ArXiv2024,Temporal Insight Enhancement: Mitigating Temporal Hallucination in Multimodal Large Language Models,Yes.,5,"""a critical challenge faced by these models, especially when processing video inputs, is the occurrence of hallucinations - erroneous perceptions or interpretations, particularly at the event level."""
ArXiv2024,Large Language Models for Mathematical Reasoning: Progresses and Challenges,Yes.,4,"""an overview of factors and concerns affecting LLMs in solving math"" and ""an elucidation of the persisting challenges within this domain."""
ArXiv2024,Navigating Uncertainty: Optimizing API Dependency for Hallucination Reduction in Closed-Book Question Answering,Yes.,5,"""While Large Language Models (LLM) are able to accumulate and restore knowledge, they are still prone to hallucination. Especially when faced with factual questions, LLM cannot only rely on knowledge stored in parameters to guarantee truthful and correct answers."""
ArXiv2024,Scientific Large Language Models: A Survey on Biological & Chemical Domains,Yes.,2,"""Finally, we critically examine the prevailing challenges and point out promising research directions along with the advances of LLMs."""
ArXiv2024,Bridging Research and Readers: A Multi-Modal Automated Academic Papers Interpretation System,Yes.,3,"""prevailing models, both commercial and open-source, confront notable challenges"
ArXiv2024,Seven Failure Points When Engineering a Retrieval Augmented Generation System,Yes.,4,"""RAG systems aim to"
ArXiv2024,Introducing Bode: A Fine-Tuned Large Language Model for Portuguese Prompt-Based Task,Yes.,3,"""LLMs trained on multilingual datasets normally struggle to respond to prompts in Portuguese satisfactorily, presenting, for example, code switching in their responses."""
ArXiv2024,Fine-tuning and Utilization Methods of Domain-specific LLMs,Yes.,2,"""The study explores the potential of LLMs in the financial domain, identifies limitations, and proposes directions for improvement."""
ArXiv2024,Advancing Large Multi-modal Models with Explicit Chain-of-Reasoning and Visual Question Generation,Yes.,1,"""This paper presents a novel approach to imbue an LMM with the ability to conduct explicit reasoning based on visual content and textual instructions."""
ArXiv2024,LLMs for Robotic Object Disambiguation,Yes.,5,"""Despite multiple query attempts with zero-shot prompt engineering (details can be found in the Appendix), the LLM struggled to inquire about features not explicitly provided in the scene description."""
ArXiv2024,VisualWebArena: Evaluating Multimodal Agents on Realistic Visual Web Tasks,Yes.,5,"""Through extensive quantitative and qualitative analysis, we identify several limitations of text-only LLM agents, and reveal gaps in the capabilities of state-of-the-art multimodal language agents."""
ArXiv2024,Quantized Side Tuning: Fast and Memory-Efficient Tuning of Quantized Large Language Models,Yes.,1,"""Existing approaches to finetuning an LLM either focus on parameter-efficient finetuning, which only updates a small number of trainable parameters, or attempt to reduce the memory footprint during the training phase of the finetuning."""
ArXiv2024,DocFinQA: A Long-Context Financial Reasoning Dataset,Yes.,5,"""DocFinQA proves a significant challenge for even state-of-the-art systems. We also provide a case-study on the longest documents in DocFinQA and find that models particularly struggle on these documents."""
ArXiv2024,Combining Confidence Elicitation and Sample-based Methods for Uncertainty Quantification in Misinformation Mitigation,Yes.,5,"""existing approaches struggle with hallucinations and overconfident predictions."""
ArXiv2024,CMMMU: A Chinese Massive Multi-discipline Multimodal Understanding Benchmark,Yes.,1,"""We evaluate 11 open-source LLMs and one proprietary GPT-4V(ision). Even GPT-4V only achieves accuracies of 42%, indicating a large space for improvement."""
ArXiv2024,Prompting open-source and commercial language models for grammatical error correction of English learner text,Yes.,3,"""Our results indicate that LLMs do not always outperform supervised English GEC models except in specific contexts"" and ""We find that several open-source models outperform commercial ones on minimal edit benchmarks, and that in some settings zero-shot prompting is just as competitive as few-shot prompting."""
ArXiv2024,FinSQL: Model-Agnostic LLMs-based Text-to-SQL Framework for Financial Analysis,Yes.,1,"""propose a model-agnostic Large Language Model (LLMs)-based Text-to-SQL framework for financial analysis."""
ArXiv2024,Evaluating Large Language Models on the GMAT: Implications for the Future of Business Education,Yes.,2,"""While AI's promise in education, assessment, and tutoring is clear, challenges remain."""
ArXiv2024,Divide and Conquer: Language Models can Plan and Self-Correct for Compositional Text-to-Image Generation,Yes.,1,"""Despite significant advancements in text-to-image models for generating high-quality images, these methods still struggle to ensure the controllability of text prompts over images in the context of complex text prompts, especially when it comes to retaining object attributes and relationships."""
ArXiv2024,Are self-explanations from Large Language Models faithful?,Yes.,5,"""convincing and wrong self-explanations can lead to unsupported confidence in LLMs, thus increasing risk"" and ""showing self-explanations should not be trusted in general."""
ArXiv2024,MultiHop-RAG: Benchmarking Retrieval-Augmented Generation for Multi-Hop Queries,Yes.,4,"""However, we find that existing RAG systems are inadequate in answering multi-hop queries, which require retrieving and reasoning over multiple pieces of supporting evidence."""
ArXiv2024,Zero-Shot RTL Code Generation with Attention Sink Augmented Large Language Models,Yes.,1,"""This paper discusses the possibility of exploiting large language models to streamline the code generation process in hardware design."""
ArXiv2024,Tuning Language Models by Proxy,Yes.,2,"""tuning these models has become increasingly resource-intensive, or impossible when model weights are private."""
ArXiv2024,CMMU: A Benchmark for Chinese Multi-modal Multi-type Question Understanding and Reasoning,Yes.,4,"""However, the mastery of domain-specific knowledge, which is essential for evaluating the intelligence of MLLMs, continues to be a challenge."" and ""The results demonstrate that CMMU poses a significant challenge to the recent MLLMs."""
ArXiv2024,JumpCoder: Go Beyond Autoregressive Coder via Online Modification,Yes.,5,"""While existing code large language models (code LLMs) exhibit impressive capabilities in code generation, their autoregressive sequential generation inherently lacks reversibility. This limitation hinders them from timely correcting previous missing statements during coding as humans do, often leading to error propagation and suboptimal performance."""
ArXiv2024,"PsySafe: A Comprehensive Framework for Psychological-based Attack, Defense, and Evaluation of Multi-agent System Safety",Yes.,2,"""the potential misuse of this intelligence for malicious purposes presents significant risks."""
ArXiv2024,"Personal LLM Agents: Insights and Survey about the Capability, Efficiency and Security",Yes.,3,"""Next, we discuss several key challenges to achieve intelligent, efficient and secure Personal LLM Agents, followed by a comprehensive survey of representative solutions to address these challenges."""
ArXiv2024,General Flow as Foundation Affordance for Scalable Robot Learning,Yes.,1,"""Inspired by the success of large-scale auto-regressive prediction in Large Language Models (LLMs), we hold the belief that identifying an appropriate prediction target capable of leveraging large-scale datasets is crucial for achieving efficient and universal learning."""
ArXiv2024,L-AutoDA: Leveraging Large Language Models for Automated Decision-based Adversarial Attacks,Yes.,1,"""This work introduces L-AutoDA (Large Language Model-based Automated Decision-based Adversarial Attacks), a novel approach leveraging the generative capabilities of Large Language Models (LLMs) to automate the design of these attacks."""
ArXiv2024,Assistive Large Language Model Agents for Socially-Aware Negotiation Dialogues,Yes.,1,"""To address this limitation, we introduce a value impact based In-Context Learning (ICL) method to identify high-quality ICL examples for the LLM-based remediation agents."""
ArXiv2024,Pre-trained Large Language Models for Financial Sentiment Analysis,Yes.,1,"""In this paper, we focus on the classification of financial news title, which is a challenging task due to a lack of large amount of training samples. To overcome this difficulty, we propose to adapt the pretrained large language models (LLMs) [1, 2, 3] to solve this problem."""
ArXiv2024,LightHouse: A Survey of AGI Hallucination,Yes.,4,"""numerous studies indicate that hallucinations within these large models are a bottleneck hindering the development of AI research"" and ""Previous explorations have been conducted in researching hallucinations within LLMs (Large Language Models)."""
ArXiv2024,A Vision Check-up for Language Models,Yes.,1,"""Although LLM-generated images do not look like natural images, results on image generation and the ability of models to correct these generated images indicate that precise modeling of strings can teach language models about numerous aspects of the visual world."""
ArXiv2024,Mementos: A Comprehensive Benchmark for Multimodal Large Language Model Reasoning over Image Sequences,Yes.,5,"""we find that they struggle to accurately describe dynamic information about given image sequences, often leading to hallucinations/misrepresentations of objects and their corresponding behaviors."""
ArXiv2024,Health-LLM: Large Language Models for Health Prediction via Wearable Sensor Data,Yes.,2,"""Large language models (LLMs) are capable of many natural language tasks, yet they are far from perfect."""
ArXiv2024,Improving Domain Adaptation through Extended-Text Reading Comprehension,Yes.,3,"""regex-based patterns are incapable of parsing raw corpora using domain-specific knowledge. Furthermore, the question and answer pairs are extracted directly from the corpus in predefined formats offers limited context."""
ArXiv2024,Sketch-Guided Constrained Decoding for Boosting Blackbox Large Language Models without Logit Access,Yes.,3,"""Its application is, however, typically restricted to models that give users access to next-token distributions (usually via softmax logits), which poses a limitation with blackbox large language models (LLMs)."""
ArXiv2024,Compensatory Biases Under Cognitive Load: Reducing Selection Bias in Large Language Models,Yes.,5,"""Unfortunately, these models' inherent biases, akin to human cognitive biases, adversely affect their performance."" and ""This research critically examines these biases and quantifies the effects on a representative list selection task."""
ArXiv2024,"Blending Is All You Need: Cheaper, Better Alternative to Trillion-Parameters LLM",Yes.,3,"""While these expansive models tend to generate increasingly better chat responses, they demand significant computational resources and memory."""
ArXiv2024,A match made in consistency heaven: when large language models meet evolutionary algorithms,Yes.,1,"""Based on this consistency perspective, existing coupling studies are analyzed, including evolutionary fine-tuning and LLM-enhanced EAs. Leveraging these insights, we outline a fundamental roadmap for future research in coupling LLMs and EAs, while highlighting key challenges along the way."""
ArXiv2024,Towards Goal-oriented Large Language Model Prompting: A Survey,Yes.,2,"""highlight the limitation of designing prompts while holding an anthropomorphic assumption that expects LLMs to think like humans."""
ArXiv2024,Mutual Enhancement of Large Language and Reinforcement Learning Models through Bi-Directional Feedback Mechanisms: A Case Study,Yes.,2,"""However, the problems of LLMs and RL model collaboration still need to be solved."""
ArXiv2024,Integration of Large Language Models in Control of EHD Pumps for Precise Color Synthesis,Yes.,2,"""While highlighting the limitations and the need for real-world testing, this study opens new avenues for AI applications in physical system control and sets a foundation for future advancements in AI-driven automation technologies."""
ArXiv2024,AntEval: Evaluation of Social Interaction Competencies in LLM-Driven Agents,Yes.,3,"""However, their capability in handling complex, multi-character social interactions has yet to be fully explored, primarily due to the absence of robust, quantitative evaluation methods."""
ArXiv2024,Adaptive Text Watermark for Large Language Models,Yes.,2,"""it is challenging to generate high-quality watermarked text while maintaining strong security, robustness, and the ability to detect watermarks without prior knowledge of the prompt or model."""
ArXiv2024,EAGLE: Speculative Sampling Requires Rethinking Feature Uncertainty,Yes.,3,"""the inherent uncertainty in feature (second-to-top-layer) level autoregression constrains its performance."""
ArXiv2024,Contrastive Preference Optimization: Pushing the Boundaries of LLM Performance in Machine Translation,Yes.,3,"""even the top-performing 13B LLM-based translation models, like ALMA, does not match the performance of state-of-the-art conventional encoder-decoder translation models or larger-scale LLMs such as GPT-4."" and ""we first assess the shortcomings of supervised fine-tuning for LLMs in the MT task, emphasizing the quality issues present in the reference data,"
ArXiv2024,MouSi: Poly-Visual-Expert Vision-Language Models,Yes.,4,"""Current large vision-language models (VLMs) often encounter challenges such as insufficient capabilities of a single visual component and excessively long visual tokens. These issues can limit the model's effectiveness in accurately interpreting complex visual information and over-lengthy contextual information."""
ArXiv2024,Identifying and Analyzing Task-Encoding Tokens in Large Language Models,Yes.,3,"""unexpectedly large changes in performance can arise from small changes in the prompt, leaving prompt design a largely empirical endeavour."""
ArXiv2024,Code-Aware Prompting: A study of Coverage Guided Test Generation in Regression Setting using LLM,Yes.,3,"""LLM-generated testsuites still suffer from low coverage."""
ArXiv2024,ReGAL: Refactoring Programs to Discover Generalizable Abstractions,Yes.,3,"""While large language models (LLMs) are increasingly being used for program synthesis, they lack the global view needed to develop useful abstractions; they generally predict programs one at a time, often repeating the same functionality."""
ArXiv2024,Why Solving Multi-agent Path Finding with Large Language Model has not Succeeded Yet,Yes.,5,"""We present our position on why directly solving MAPF with LLMs has not been successful yet, and we use various experiments to support our hypothesis."""
ArXiv2024,Empathy and the Right to Be an Exception: What LLMs Can and Cannot Do,Yes.,5,"""We ask whether LLMs' inability to empathize precludes them from honoring an individual's right to be an exception,"" and ""Can LLMs seriously consider an individual's claim that their case is different based on internal mental states like beliefs, desires, and intentions, or are they limited to judging that case based on its similarities to others?"""
ArXiv2024,Eyes Wide Shut? Exploring the Visual Shortcomings of Multimodal LLMs,Yes.,5,"""Our research reveals that the visual capabilities in recent multimodal LLMs (MLLMs) still exhibit systematic shortcomings,"" and ""MMVP exposes areas where state-of-the-art systems, including GPT-4V, struggle with straightforward questions across nine basic visual patterns, often providing incorrect answers and hallucinated explanations."""
ArXiv2024,"Generative AI in EU Law: Liability, Privacy, Intellectual Property, and Cybersecurity",Yes.,3,"""the complexity and emergent autonomy of these models introduce challenges in predictability and legal compliance"" and ""The paper identifies potential gaps and shortcomings in the legislative framework."""
ArXiv2024,ANGO: A Next-Level Evaluation Benchmark For Generation-Oriented Language Models In Chinese Domain,Yes.,1,"""Recently, various Large Language Models (LLMs) evaluation datasets have emerged, but most of them have issues with distorted rankings and difficulty in model capabilities analysis."""
ArXiv2024,Detecting mental disorder on social media: a ChatGPT-augmented explainable approach,Yes.,1,"""This paper addresses the challenge of interpretable depression detection by proposing a novel methodology that effectively combines Large Language Models (LLMs) with eXplainable Artificial Intelligence (XAI) and conversational agents like ChatGPT."""
ArXiv2024,"The Stronger the Diffusion Model, the Easier the Backdoor: Data Poisoning to Induce Copyright Breaches Without Adjusting Finetuning Pipeline",Yes.,1,"""This data, comprising poisoning images equipped with prompts, is generated by leveraging the powerful capabilities of multimodal large language models and text-guided image inpainting techniques."""
ArXiv2024,APT: Adaptive Pruning and Tuning Pretrained Language Models for Efficient Training and Inference,Yes.,2,"""Fine-tuning and inference with large Language Models (LM) are generally known to be expensive."""
ArXiv2024,PACE: A Pragmatic Agent for Enhancing Communication Efficiency Using Large Language Models,Yes.,1,"""This paper proposes an image pragmatic communication framework based on a Pragmatic Agent for Communication Efficiency (PACE) using Large Language Models (LLM)."""
ArXiv2024,AboutMe: Using Self-Descriptions in Webpages to Document the Effects of English Pretraining Data Filters,Yes.,3,"""decisions around what data is retained or removed during this initial stage is under-scrutinized"" and ""we conduct the first study investigating how ten 'quality' and English language identification (langID) filters affect webpages that vary along these social dimensions."""
ArXiv2024,Metacognition is all you need? Using Introspection in Generative Agents to Improve Goal-directed Behavior,Yes.,3,"""Recent advances in Large Language Models (LLMs) have shown impressive capabilities in various applications, yet LLMs face challenges such as limited context windows and difficulties in generalization."""
ArXiv2024,"Mastering Text-to-Image Diffusion: Recaptioning, Planning, and Generating with Multimodal LLMs",Yes.,3,"""existing methods often face challenges when handling complex text prompts that involve multiple objects with multiple attributes and relationships."""
ArXiv2024,Transformers and Cortical Waves: Encoders for Pulling In Context Across Time,Yes.,1,"""The capabilities of transformer networks such as ChatGPT and other Large Language Models (LLMs) have captured the world's attention."""
ArXiv2024,δ-CAUSAL: Exploring Defeasibility in Causal Reasoning,Yes.,2,"""We further demonstrate even Large Language Models (LLMs) like GPT-3.5 still lag 4.5 and 10.7 points behind humans in generating supporters and defeaters, emphasizing the challenge posed by {\delta}-CAUSAL."""
ArXiv2024,Arrows of Time for Large Language Models,Yes.,3,"""We empirically find a time asymmetry exhibited by such models in their ability to model natural language"
ArXiv2024,Equipping Language Models with Tool Use Capability for Tabular Data Analysis in Finance,Yes.,5,"""Large language models (LLMs) have exhibited an array of reasoning capabilities but face challenges like error propagation and hallucination, particularly in specialised areas like finance, where data is heterogeneous, and precision is paramount."""
ArXiv2024,Leveraging Print Debugging to Improve Code Generation in Large Language Models,Yes.,3,"""Large language models (LLMs) have made significant progress in code generation tasks, but their performance in tackling programming problems with complex data structures and algorithms remains suboptimal."""
ArXiv2024,Under the Surface: Tracking the Artifactuality of LLM-Generated Data,Yes.,5,"""This paper reveals significant hidden disparities, especially in complex tasks where LLMs often miss the nuanced understanding of intrinsic human-generated content,"" and ""It highlights the LLMs' shortcomings in replicating human traits and behaviors, underscoring the importance of addressing biases and artifacts produced in LLM-generated content for future research and development."""
ArXiv2024,Evaluation of General Large Language Models in Contextually Assessing Semantic Concepts Extracted from Adult Critical Care Electronic Health Record Notes,Yes.,2,"""However, their performance in actual clinical applications has been underexplored."" and ""This gap highlights the need for more in-depth and practical assessments of LLMs in real-world healthcare settings."""
ArXiv2024,"Improving Classification Performance With Human Feedback: Label a few, we label the rest",Yes.,1,"""By employing Large Language Models (LLMs) such as GPT-3.5, BERT, and SetFit, we aim to analyze the efficacy of using a limited number of labeled examples to substantially improve model accuracy."""
ArXiv2024,Entity Recognition from Colloquial Text,Yes.,3,"""Despite the recent advances in training large language models for a variety of natural language processing tasks, the developed models and techniques have mainly focused on formal texts and do not perform as well on colloquial data, which is characterized by a number of distinct challenges."""
ArXiv2024,Generalist embedding models are better at short-context clinical semantic search than specialized embedding models,Yes.,4,"""Their use in this highly critical and sensitive domain has thus raised important questions about their robustness, especially in response to variations in input, and the reliability of the generated outputs."" and ""The highlighted problem of specialized models may be due to the fact that they have not been trained on sufficient data, and in particular on datasets that are not diverse enough to have a reliable global language understanding,"
ArXiv2024,"Exploring Large Language Model based Intelligent Agents: Definitions, Methods, and Prospects",Yes.,1,"""Benefiting from recent progress in large language models (LLMs), LLM-based agents that use universal natural language as an interface exhibit robust generalization capabilities across various applications."""
ArXiv2024,Code Prompting Elicits Conditional Reasoning Abilities in Text+Code LLMs,Yes.,1,"""Recent prompting techniques, such as chain of thought, have consistently improved LLMs' performance on various reasoning tasks. Nevertheless, there is still little understanding of what triggers reasoning abilities in LLMs in the inference stage."""
ArXiv2024,LongAlign: A Recipe for Long Context Alignment of Large Language Models,Yes.,5,"""Extending large language models to effectively handle long contexts requires instruction fine-tuning on input sequences of similar length."""
ArXiv2024,CodeAid: Evaluating a Classroom Deployment of an LLM-based Programming Assistant that Balances Student and Educator Needs,Yes.,3,"""LLM-powered tools like ChatGPT offer instant support, but reveal direct answers with code, which may hinder deep conceptual engagement."""
ArXiv2024,A Study on Training and Developing Large Language Models for Behavior Tree Generation,Yes.,1,"""we propose a novel methodology that leverages the robust representation and reasoning abilities of LLMs."""
ArXiv2024,Benchmarking Large Language Models on Controllable Generation under Diversified Instructions,Yes.,5,"""revealing their limitations in following instructions with specific constraints and there is still a significant gap between open-source and commercial closed-source LLMs."""
ArXiv2024,An Example of Evolutionary Computation + Large Language Model Beating Human: Design of Efficient Guided Local Search,Yes.,1,"""AEL combines the power of a large language model and the paradigm of evolutionary computation to design, combine, and modify algorithms automatically."""
ArXiv2024,Gender Bias in Machine Translation and The Era of Large Language Models,Yes.,4,"""The findings emphasize the ongoing need for advancements in mitigating bias in Machine Translation systems and underscore the importance of fostering fairness and inclusivity in language technologies."""
ArXiv2024,Pheme: Efficient and Conversational Speech Generation,,,
ArXiv2024,Signed-Prompt: A New Approach to Prevent Prompt Injection Attacks Against LLM-Integrated Applications,Yes.,4,"""The critical challenge of prompt injection attacks in Large Language Models (LLMs) integrated applications, a growing concern in the Artificial Intelligence (AI) field. Such attacks, which manipulate LLMs through natural language inputs, pose a significant threat to the security of these applications. Traditional defense strategies, including output and input filtering, as well as delimiter use, have proven inadequate."""
ArXiv2024,Multilingual Instruction Tuning With Just a Pinch of Multilinguality,Yes.,1,"""As instruction-tuned large language models (LLMs) gain global adoption, their ability to follow instructions in multiple languages becomes increasingly crucial."""
ArXiv2024,Leveraging Large Language Models for NLG Evaluation: A Survey,Yes.,4,"""Our detailed exploration includes critically assessing various LLM-based methodologies, as well as comparing their strengths and limitations in evaluating NLG outputs. By discussing unresolved challenges, including bias, robustness, domain-specificity, and unified evaluation, this survey seeks to offer insights to researchers and advocate for fairer and more advanced NLG evaluation techniques."""
ArXiv2024,Prompting Large Vision-Language Models for Compositional Reasoning,Yes.,5,"""However, these embedding-based models still face challenges in effectively matching images and texts with similar visio-linguistic compositionality, as evidenced by their performance on the recent Winoground dataset."" and ""this limitation stems from two factors"
ArXiv2024,Empirical Study of Large Language Models as Automated Essay Scoring Tools in English Composition__Taking TOEFL Independent Writing Task for Example,Yes.,3,"""The primary objective is to assess the capabilities and constraints of ChatGPT, a prominent representative of large language models, within the context of automated essay scoring."""
ArXiv2024,DiffusionGPT: LLM-Driven Text-to-Image Generation System,Yes.,1,"""However, a major challenge persists in current text-to-image systems are often unable to handle diverse inputs, or are limited to single model results."""
ArXiv2024,INACIA: Integrating Large Language Models in Brazilian Audit Courts: Opportunities and Challenges,Yes.,3,"""These results underscore INACIA's potential in complex legal task handling while also acknowledging the current limitations."""
ArXiv2024,Cross-lingual Editing in Multilingual Language Models,Yes.,3,"""The results reveal notable performance limitations of state-of-the-art METs under the XME setting, mainly when the languages involved belong to two distinct script families."""
ArXiv2024,MT-Eval: A Multi-Turn Capabilities Evaluation Benchmark for Large Language Models,Yes.,5,"""We observe significant performance degradation in multi-turn settings compared to single-turn settings in most models, which is not correlated with the models' fundamental capabilities. Moreover, we identify the distance to relevant content and susceptibility to error propagation as the key factors influencing multi-turn performance."""
ArXiv2024,Scaling Sparse Fine-Tuning to Large Language Models,Yes.,3,"""Large Language Models (LLMs) are difficult to fully fine-tune (e.g., with instructions or human feedback) due to their sheer number of parameters."" and ""their memory requirements increase proportionally to the size of the LLMs."""
ArXiv2024,Wordflow: Social Prompt Engineering for Large Language Models,Yes.,1,"""Large language models (LLMs) require well-crafted prompts for effective use."""
ArXiv2024,OOP: Object-Oriented Programming Evaluation Benchmark for Large Language Models,Yes.,5,"""The poor performance of all advanced LLMs on our OOP benchmark highlights a critical need for improvements in this field."""
ArXiv2024,Consolidating Trees of Robotic Plans Generated Using Large Language Models to Improve Reliability,Yes.,5,"""LLMs have been used to generate task plans, but they are unreliable and may contain wrong, questionable, or high-cost steps."""
ArXiv2024,De-identification is not always enough,Yes.,3,"""We observed that when synthetically generated notes closely match the performance of real data, they also exhibit similar privacy concerns to the real data."""
ArXiv2024,Transformers are Multi-State RNNs,Yes.,3,"""They also lay out the option of mitigating one of their most painful computational bottlenecks - the size of their cache memory."""
ArXiv2024,DevEval: Evaluating Code Generation in Practical Software Projects,Yes.,3,"""Many benchmarks have been proposed but are inconsistent with practical software projects, e.g., unreal program distributions, insufficient dependencies, and small-scale project contexts."""
ArXiv2024,Question Translation Training for Better Multilingual Reasoning,Yes.,3,"""Large language models show compelling performance on reasoning tasks but they tend to perform much worse in languages other than English. This is unsurprising given that their training data largely consists of English text and instructions."""
ArXiv2024,ZS4C: Zero-Shot Synthesis of Compilable Code for Incomplete Code Snippets using ChatGPT,Yes.,1,"""To address this problem, we propose ZS4C, a lightweight approach to perform zero-shot synthesis of compilable code from incomplete code snippets using Large Language Model (LLM)."""
ArXiv2024,From Prompt Engineering to Prompt Science With Human in the Loop,Yes.,5,"""we need to be concerned about how it may affect that research, its findings, or any future works based on that research,"" and ""they are often focused more on achieving desirable outcomes rather than producing replicable and generalizable knowledge with sufficient transparency, objectivity, or rigor."""
ArXiv2024,When Large Language Models Meet Vector Databases: A Survey,Yes.,5,"""With the proliferation of LLMs comes a host of challenges, including hallucinations, outdated knowledge, prohibitive commercial application costs, and memory issues."""
ArXiv2024,"When Large Language Model Agents Meet 6G Networks: Perception, Grounding, and Alignment",Yes.,2,"""Nevertheless, the limited capacity of mobile devices constrains the effectiveness of deploying and executing local LLMs, which necessitates offloading complex tasks to global LLMs running on edge servers during long-horizon interactions."""
ArXiv2024,OpenMoE: An Early Effort on Open Mixture-of-Experts Language Models,Yes.,5,"""This imperfect routing can result in performance degradation, particularly in sequential tasks like multi-turn conversations, where tokens appearing later in a sequence are more likely to be dropped."""
ArXiv2024,Predicting challenge moments from students' discourse: A comparison of GPT-4 to two traditional natural language processing approaches,Yes.,5,"""although LLMs provide many advantages, they are unlikely to be the panacea to issues of the detection and feedback provision of socially shared regulation of learning due to their lack of reliability, as well as issues of validity evaluation, privacy and confabulation."""
ArXiv2024,Prompt4Vis: Prompting Large Language Models with Example Mining and Schema Filtering for Tabular Data Visualization,Yes.,1,"""Large language models (LLMs) such as ChatGPT and GPT-4, have established new benchmarks in a variety of NLP tasks, fundamentally altering the landscape of the field."""
ArXiv2024,InfoLossQA: Characterizing and Recovering Information Loss in Text Simplification,Yes.,5,"""our expert evaluation reveals that models struggle to reliably identify information loss and applying similar standards as humans at what constitutes information loss."""
ArXiv2024,ICE-GRT: Instruction Context Enhancement by Generative Reinforcement based Transformers,Yes.,5,"""The emergence of Large Language Models (LLMs) such as ChatGPT and LLaMA encounter limitations in domain-specific tasks, with these models often lacking depth and accuracy in specialized areas, and exhibiting a decrease in general capabilities when fine-tuned, particularly analysis ability in small sized models."""
ArXiv2024,Agent Alignment in Evolving Social Norms,Yes.,2,"""The current alignment of AI systems primarily focuses on passively aligning LLMs through human intervention. However, agents possess characteristics like receiving environmental feedback and self-evolution, rendering the LLM alignment methods inadequate."""
ArXiv2024,Security and Privacy Challenges of Large Language Models: A Survey,Yes.,5,"""While offering significant advantages, these models are also vulnerable to security and privacy attacks, such as jailbreaking attacks, data poisoning attacks, and Personally Identifiable Information (PII) leakage attacks."""
ArXiv2024,Hallucination Benchmark in Medical Visual Question Answering,Yes.,5,"""these models are not extensively tested on the hallucination phenomenon in clinical settings"" and ""The study provides an in-depth analysis of current models' limitations."""
ArXiv2024,Enhancing Recommendation Diversity by Re-ranking with Large Language Models,Yes.,2,"""We find that LLM-based re-ranking outperforms random re-ranking across all the metrics that we use but does not perform as well as the traditional re-ranking methods."""
ArXiv2024,Breaking Free Transformer Models: Task-specific Context Attribution Promises Improved Generalizability Without Fine-tuning Pre-trained LLMs,Yes.,2,"""Fine-tuning large pre-trained language models (LLMs) on particular datasets is a commonly employed strategy in Natural Language Processing (NLP) classification tasks. However, this approach usually results in a loss of models generalizability."""
ArXiv2024,Knowledge Verification to Nip Hallucination in the Bud,Yes.,5,"""they may still generate responses that sound plausible but contradict factual knowledge, a phenomenon known as hallucination."""
ArXiv2024,"Tuning LLMs with Contrastive Alignment Instructions for Machine Translation in Unseen, Low-resource Languages",Yes.,2,"""One is the expansion of supported languages to previously unseen ones. The second relates to the lack of data in low-resource languages."" and ""MTInstruct is limited by weak cross-lingual signals inherent in the second challenge."""
ArXiv2024,LLM4Vuln: A Unified Evaluation Framework for Decoupling and Enhancing LLMs' Vulnerability Reasoning,Yes.,3,"""recent attempts to use LLMs for vulnerability detection are still preliminary, as they lack an in-depth understanding of a subject LLM's vulnerability reasoning capability -- whether it originates from the model itself or from external assistance, such as invoking tool support and retrieving vulnerability knowledge."""
ArXiv2024,DCR-Consistency: Divide-Conquer-Reasoning for Consistency Evaluation and Improvement of Large Language Models,Yes.,3,"""Traditional evaluation methods, such as ROUGE and BERTScore, which measure token similarity, often fail to capture the holistic semantic equivalence. This results in a low correlation with human judgments and intuition, which is especially problematic in high-stakes applications like healthcare and finance where reliability, safety, and robust decision-making are highly critical."""
ArXiv2024,Evaluation of LLM Chatbots for OSINT-based Cyber Threat Awareness,Yes.,5,"""However, concerning cybersecurity entity recognition, all evaluated chatbots have limitations and are less effective."" and ""Our results shed light on the limitations of the LLM chatbots when compared to specialized models."""
ArXiv2024,Informed AI Regulation: Comparing the Ethical Frameworks of Leading LLM Chatbots Using an Ethics-Based Audit to Assess Moral Reasoning and Normative Values,Yes.,4,"""troubling findings include underlying normative frameworks with clear bias towards particular cultural norms. Many models also exhibit disturbing authoritarian tendencies."""
ArXiv2024,Towards Optimizing the Costs of LLM Usage,Yes.,2,"""enterprises are already incurring huge costs of operating or using LLMs for their respective use cases."""
ArXiv2024,Chain-of-Table: Evolving Tables in the Reasoning Chain for Table Understanding,,,
ArXiv2024,Machine Translation Meta Evaluation through Translation Accuracy Challenge Sets,Yes.,3,"""We also investigate claims that Large Language Models (LLMs) are effective as MT evaluators by evaluating on ACES. Our results demonstrate that different metric families struggle with different phenomena and that LLM-based methods fail to demonstrate reliable performance."""
ArXiv2024,Emojis Decoded: Leveraging ChatGPT for Enhanced Understanding in Social Media Communications,Yes.,1,"""Large Language Models (LLMs) have achieved significant success in various annotation tasks, with ChatGPT demonstrating expertise across multiple domains."""
ArXiv2024,Hidden Flaws Behind Expert-Level Accuracy of GPT-4 Vision in Medicine,Yes.,5,"""we discovered that GPT-4V frequently presents flawed rationales in cases where it makes the correct final choices (27.3%), most prominent in image comprehension (21.6%). Regardless of GPT-4V's high accuracy in multi-choice questions, our findings emphasize the necessity for further in-depth evaluations of its rationales before integrating such models into clinical workflows."""
ArXiv2024,ChatGraph: Chat with Your Graphs,Yes.,1,"""To address the limitations, we propose a large language model (LLM)-based framework called ChatGraph."""
ArXiv2024,Do We Need Language-Specific Fact-Checking Models? The Case of Chinese,Yes.,3,"""We first demonstrate the limitations of translation-based methods and multilingual large language models (e.g., GPT-4), highlighting the need for language-specific systems."""
ArXiv2024,On Prompt-Driven Safeguarding for Large Language Models,Yes.,5,"""We find that in models' representation space, harmful and harmless queries can be largely distinguished, but this is not noticeably enhanced by safety prompts. Instead, the queries' representations are moved by safety prompts in similar directions where models become more prone to refusal (i.e., refusing to provide assistance) even when the queries are harmless."""
ArXiv2024,Large language model empowered participatory urban planning,Yes.,1,"""This research introduces an innovative urban planning approach integrating Large Language Models (LLMs) within the participatory process."""
ArXiv2024,MULTIVERSE: Exposing Large Language Model Alignment Problems in Diverse Worlds,,,
ArXiv2024,CAT-LLM: Prompting Large Language Models with Text Style Definition for Chinese Article-style Transfer,Yes.,1,"""CAT-LLM incorporates a bespoke, pluggable Text Style Definition (TSD) module aimed at comprehensively analyzing text features in articles, prompting LLMs to efficiently transfer Chinese article-style."""
ArXiv2024,APAR: LLMs Can Do Auto-Parallel Auto-Regressive Decoding,Yes.,1,"""the auto-regressive decoding process, which is fundamental to how most LLMs generate text, poses challenges to achieve efficient serving."""
ArXiv2024,Large Language Models Are Neurosymbolic Reasoners,Yes.,1,"""This paper investigates the potential application of Large Language Models (LLMs) as symbolic reasoners."""
ArXiv2024,Lost in the Source Language: How Large Language Models Evaluate the Quality of Machine Translation,Yes.,5,"""Surprisingly, we find that reference information significantly enhances the evaluation accuracy, while source information sometimes is counterproductive, indicating a lack of cross-lingual capability when using LLMs to evaluate translations."""
ArXiv2024,Detection of Machine-Generated Text: Literature Survey,Yes.,4,"""Concerns regarding the possible influence of advanced language models on society have also arisen, needing a fuller knowledge of these processes."" and ""To mitigate the hazardous implications that may arise from the use of these models, preventative measures must be implemented."""
ArXiv2024,Extreme Compression of Large Language Models via Additive Quantization,Yes.,1,"""The emergence of accurate open large language models (LLMs) has led to a race towards quantization techniques for such models enabling execution on end-user devices."""
ArXiv2024,The Neglected Tails of Vision-Language Models,,,
ArXiv2024,TOFU: A Task of Fictitious Unlearning for LLMs,Yes.,5,"""Large language models trained on massive corpora of data from the web can memorize and reproduce sensitive or private data raising both legal and ethical concerns."" and ""Importantly, none of the baselines we consider show effective unlearning motivating continued efforts to develop approaches for unlearning that effectively tune models so that they truly behave as if they were never trained on the forget data at all."""
ArXiv2024,An Exploratory Study on Automatic Identification of Assumptions in the Development of Deep Learning Frameworks,Yes.,3,"""Though ChatGPT is the most popular large language model, we do not recommend using it to identify assumptions in DL framework development because of its low performance on the task."""
ArXiv2024,InFoBench: Evaluating Instruction Following Ability in Large Language Models,Yes.,3,"""The evaluation of several advanced LLMs using this framework reveals their strengths and areas needing improvement, particularly in complex instruction-following."""
ArXiv2024,AI Revolution on Chat Bot: Evidence from a Randomized Controlled Experiment,Yes.,1,"""Despite recent advances, field experiments applying LLM-based tools in realistic settings are limited."""
ArXiv2024,Towards Conversational Diagnostic AI,Yes.,2,"""Our research has several limitations and should be interpreted with appropriate caution. Clinicians were limited to unfamiliar synchronous text-chat which permits large-scale LLM-patient interactions but is not representative of usual clinical practice."""
ArXiv2024,Extending LLMs' Context Window with 100 Samples,Yes.,5,"""Large Language Models (LLMs) are known to have limited extrapolation ability beyond their pre-trained context window, constraining their application in downstream tasks with lengthy inputs."""
ArXiv2024,MARIO: MAth Reasoning with code Interpreter Output -- A Reproducible Pipeline,Yes.,5,"""there remains a gap to bridge before attaining true artificial general intelligence, especially concerning shortcomings in mathematical reasoning capabilities. We postulate that the inherent nature of LLM training, which focuses on predicting probabilities of next token, presents challenges in effectively modeling mathematical reasoning that demands exact calculations, both from data-driven and theoretical standpoints."""
ArXiv2024,"Risk Taxonomy, Mitigation, and Assessment Benchmarks of Large Language Model Systems",Yes.,5,"""the safety and security issues of LLM systems have become the major obstacle to their widespread application"" and ""potential risks associated with each module of an LLM system and discusses the corresponding mitigation strategies."""
ArXiv2024,SliceGPT: Compress Large Language Models by Deleting Rows and Columns,Yes.,3,"""Large language models have become the cornerstone of natural language processing, but their use comes with substantial costs in terms of compute and memory resources."""
ArXiv2024,"Planning, Creation, Usage: Benchmarking LLMs for Comprehensive Tool Utilization in Real-World Complex Scenarios",Yes.,1,"""existing benchmarks typically focus on simple synthesized queries that do not reflect real-world complexity, thereby offering limited perspectives in evaluating tool utilization."""
ArXiv2024,Few-Shot Learning for Chronic Disease Management: Leveraging Large Language Models and Multi-Prompt Engineering with Medical Knowledge Injection,Yes.,1,"""we propose a novel framework that leverages advanced AI techniques, including large language models and multi-prompt engineering."""
ArXiv2024,Video Anomaly Detection and Explanation via Large Language Models,Yes.,3,"""We introduce a novel network module Long-Term Context (LTC) to mitigate the incapability of VLLMs in long-range context modeling."""
ArXiv2024,Finetuning Large Language Models for Vulnerability Detection,Yes.,1,"""This demonstrates the potential for transfer learning by finetuning large pretrained language models for specialized source code analysis tasks."""
ArXiv2024,Efficient Tool Use with Chain-of-Abstraction Reasoning,Yes.,2,"""there remains challenges for fine-tuning LLM agents (e.g., Toolformer) to invoke tools in multi-step reasoning problems, where inter-connected tool calls require holistic and efficient tool usage planning."""
ArXiv2024,An Experimental Design Framework for Label-Efficient Supervised Finetuning of Large Language Models,Yes.,3,"""the annotation efforts required to produce high quality responses for instructions are becoming prohibitively expensive"" and ""its high computational cost remains a barrier to its widespread applicability in the context of LLMs."""
ArXiv2024,Improving Medical Reasoning through Retrieval and Self-Reflection with Retrieval-Augmented Large Language Models,Yes.,3,"""To address challenges that still cannot be handled with the encoded knowledge of LLMs,"" and ""poor generalization becomes apparent, leading to fetching incorrect documents or making inaccurate judgments."""
ArXiv2024,Assessing Large Language Models in Mechanical Engineering Education: A Study on Mechanics-Focused Conceptual Understanding,Yes.,1,"""The findings reveal GPT-4's superior performance over the other two LLMs and human cohorts in answering questions across various mechanics topics, except for Continuum Mechanics. This signals the potential future improvements for GPT models in handling symbolic calculations and tensor analyses."""
ArXiv2024,xCoT: Cross-lingual Instruction Tuning for Cross-lingual Chain-of-Thought Reasoning,Yes.,3,"""CoT mainly demonstrates excellent performance in English, but its usage in low-resource languages is constrained due to poor language generalization."""
ArXiv2024,Generative Large Language Models are autonomous practitioners of evidence-based medicine,Yes.,3,"""Limitations were observed in terms of model ability to handle complex guidelines and diagnostic nuances."""
ArXiv2024,StrokeNUWA: Tokenizing Strokes for Vector Graphic Synthesis,Yes.,3,"""To leverage LLMs for visual synthesis, traditional methods convert raster image information into discrete grid tokens through specialized visual modules, while disrupting the model's ability to capture the true semantic representation of visual scenes."""
ArXiv2024,YODA: Teacher-Student Progressive Learning for Language Models,Yes.,3,"""Although large language models (LLMs) have demonstrated adeptness in a range of tasks, they still lag behind human learning efficiency."""
ArXiv2024,ChemDFM: Dialogue Foundation Model for Chemistry,Yes.,3,"""the existence of specialized language and knowledge in the field of chemistry, such as the highly informative SMILES notation, hinders the performance of general-domain LLMs in chemistry."""
ArXiv2024,Towards Consistent Natural-Language Explanations via Explanation-Consistency Finetuning,Yes.,5,"""Large language models (LLMs) often generate convincing, fluent explanations. However, different from humans, they often generate inconsistent explanations on different inputs."""
ArXiv2024,Harnessing Large Language Models Over Transformer Models for Detecting Bengali Depressive Social Media Text: A Comprehensive Study,Yes.,1,"""The work emphasizes the effectiveness and flexibility of LLMs in a variety of linguistic circumstances, providing insightful information about the complex field of depression detection models."""
ArXiv2024,Large Language Models Can Learn Temporal Reasoning,,,
ArXiv2024,Can A Cognitive Architecture Fundamentally Enhance LLMs? Or Vice Versa?,Yes.,5,"""The paper discusses what is needed to address the limitations of current LLM-centered AI systems."""
ArXiv2024,"""You tell me"": A Dataset of GPT-4-Based Behaviour Change Support Conversations",Yes.,1,"""Research in this context so far has been largely system-focused, foregoing the aspect of user behaviour and the impact this can have on LLM-generated texts."""
ArXiv2024,Automated Fact-Checking of Climate Change Claims with Large Language Models,Yes.,1,"""While our research is subject to certain limitations and necessitates careful interpretation, our approach holds significant potential."""
ArXiv2024,LLsM: Generative Linguistic Steganography with Large Language Model,,,
ArXiv2024,Attendre: Wait To Attend By Retrieval With Evicted Queries in Memory-Based Transformers for Long Context Processing,Yes.,3,"""However, this approach requires a large memory and/or takes into the consideration the specific LM architecture. Moreover, due to the causal nature between the key-values in prior context and the queries at present, this approach cannot be extended to bidirectional attention such as in an encoder-decoder or PrefixLM decoder-only architecture."""
ArXiv2024,Small Language Model Can Self-correct,Yes.,5,"""one of their most prominent drawbacks is generating inaccurate or false information with a confident tone"" and ""large LMs are explicitly prompted to verify and modify its answers separately rather than completing all steps spontaneously like humans."""
ArXiv2024,Conditional and Modal Reasoning in Large Language Models,Yes.,5,"""Among the LLMs we tested, all but GPT-4 often make basic mistakes with conditionals. Moreover, even GPT-4 displays logically inconsistent judgments across inference patterns involving epistemic modals."""
ArXiv2024,PRE: A Peer Review Based Large Language Model Evaluator,Yes.,3,"""Existing paradigms rely on either human annotators or model-based evaluators to evaluate the performance of LLMs on different tasks. However, these paradigms often suffer from high cost, low generalizability, and inherited biases in practice, which make them incapable of supporting the sustainable development of LLMs in long term."""
ArXiv2024,Distortions in Judged Spatial Relations in Large Language Models: The Dawn of Natural Language Geographic Data?,Yes.,5,"""The models showed significantly reduced accuracy on tasks with suspected hierarchical bias."""
ArXiv2024,LLM4SecHW: Leveraging Domain Specific Large Language Model for Hardware Debugging,Yes.,2,"""Despite the success of LLMs in automating various software development tasks, their application in the hardware security domain has been limited due to the constraints of commercial LLMs and the scarcity of domain specific data."""
ArXiv2024,Misconfidence-based Demonstration Selection for LLM In-Context Learning,Yes.,3,"""However, its success hinges on carefully selecting demonstrations, which remains an obstacle in practice."""
ArXiv2024,Supporting Student Decisions on Learning Recommendations: An LLM-Based Chatbot with Knowledge Graph Contextualization for Conversational Explainability and Mentoring,Yes.,4,"""The capabilities of chatbots, however, are still not sufficient to replace a human mentor, despite the advancements of generative AI (GenAI) and large language models (LLM)."" and ""highlight the potential requirements and limitations of utilizing chatbots in conversational explainability."""
ArXiv2024,On Detecting Cherry-picking in News Coverage Using Large Language Models,Yes.,1,"""Our approach relies on language models that consider contextual information from other news sources to classify statements based on their importance to the event covered in the target news story."""
ArXiv2024,Learning Shortcuts: On the Misleading Promise of NLU in Language Models,Yes.,5,"""LLMs often resort to shortcuts when performing tasks, creating an illusion of enhanced performance while lacking generalizability in their decision rules."""
ArXiv2024,SpeechComposer: Unifying Multiple Speech Tasks with Prompt Composition,Yes.,3,"""Existing speech language models typically utilize task-dependent prompt tokens to unify various speech tasks in a single model. However, this design omits the intrinsic connections between different speech tasks, which can potentially boost the performance of each task."""
ArXiv2024,Generating Zero-shot Abstractive Explanations for Rumour Verification,Yes.,1,"""To evaluate the informativeness of the explanatory summaries, we exploit the few-shot learning capabilities of a large language model (LLM)."""
ArXiv2024,Performance Assessment of ChatGPT vs Bard in Detecting Alzheimer's Dementia,Yes.,2,"""Overall, three LLM chatbots identify AD vs CN surpassing chance-levels but do not currently satisfy clinical application."""
ArXiv2024,Detecting Multimedia Generated by Large AI Models: A Survey,Yes.,4,"""this content presents significant risks, including potential misuse, societal disruptions, and ethical concerns."" and ""we identify current challenges in detection and propose directions for future research that address unexplored, ongoing, and emerging issues in detecting multimedia generated by LAIMs."""
ArXiv2024,SocraSynth: Multi-LLM Reasoning with Conditional Statistics,Yes.,4,"""Large language models (LLMs), while promising, face criticisms for biases, hallucinations, and a lack of reasoning capability."""
ArXiv2024,Critical Data Size of Language Models from a Grokking Perspective,Yes.,1,"""Our experiments reveal smoother phase transitions occurring at the critical dataset size for language datasets. As the model size increases, this critical point also becomes larger, indicating that larger models require more data."""
ArXiv2024,Veagle: Advancements in Multimodal Representation Learning,Yes.,3,"""While these models have showcased significant advancements, challenges persist in accurately interpreting images and answering the question, a common occurrence in real-world scenarios."""
ArXiv2024,Enhanced Automated Code Vulnerability Repair using Large Language Models,Yes.,2,"""The research also offers a critical assessment of current evaluation metrics, such as perfect predictions, and their limitations in reflecting the true capabilities of automated repair models in real-world scenarios."""
ArXiv2024,Beyond Behaviorist Representational Harms: A Plan for Measurement and Mitigation,Yes.,5,"""Our work highlights the unique vulnerabilities of large language models to perpetrating representational harms, particularly when these harms go unmeasured and unmitigated."""
ArXiv2024,The Butterfly Effect of Altering Prompts: How Small Changes and Jailbreaks Affect Large Language Model Performance,Yes.,5,"""We find that even the smallest of perturbations, such as adding a space at the end of a prompt, can cause the LLM to change its answer. Further, we find that requesting responses in XML and commonly used jailbreaks can have cataclysmic effects on the data labeled by LLMs."""
ArXiv2024,Large Multi-Modal Models (LMMs) as Universal Foundation Models for AI-Native Wireless Systems,Yes.,2,"""However, recent efforts on LLMs for wireless networks are limited to a direct application of existing language models that were designed for natural language processing (NLP) applications."""
ArXiv2024,MLLM-Protector: Ensuring MLLM's Safety without Hurting Performance,Yes.,5,"""This vulnerability is exacerbated by the fact that open-source MLLMs are predominantly fine-tuned on limited image-text pairs that is much less than the extensive text-based pretraining corpus, which makes the MLLMs more prone to catastrophic forgetting of their original abilities during explicit alignment tuning."""
ArXiv2024,TP-Aware Dequantization,Yes.,1,"""Our contribution is an optimized inference deployment scheme that address the current limitations of state-of-the-art quantization kernels when used in conjunction with Tensor Parallel (TP)."""
ArXiv2024,Exploring the Frontiers of LLMs in Psychological Applications: A Comprehensive Review,Yes.,4,"""the paper also cautions about their technical and ethical challenges. There are issues like data privacy, the ethical implications of using LLMs in psychological research, and the need for a deeper understanding of these models' limitations."""
ArXiv2024,Vulnerabilities Unveiled: Adversarially Attacking a Multimodal Vision Language Model for Pathology Imaging,Yes.,5,"""The outcomes reveal a 100% success rate in manipulating PLIP's predictions, underscoring its susceptibility to adversarial perturbations."""
ArXiv2024,A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models,Yes.,5,"""a key challenge remains around their tendency to hallucinate generating content that appears factual but is ungrounded,"" and ""The journey toward widespread adoption of LLMs in practical settings heavily relies on addressing and mitigating hallucinations,"" and ""we analyze the challenges and limitations inherent in these techniques, providing a solid foundation for future research in addressing hallucinations and related phenomena within the realm of L"
ArXiv2024,GPT4Battery: An LLM-driven Framework for Adaptive State of Health Estimation of Raw Li-ion Batteries,Yes.,1,"""utilizes the strong generalization capability of large language model (LLM) to proposes a novel framework for adaptable SOH estimation across diverse batteries."""
ArXiv2024,Copilot Refinement: Addressing Code Smells in Copilot-Generated Python Code,,,
ArXiv2024,"""Which LLM should I use?"": Evaluating LLMs for tasks performed by Undergraduate Computer Science Students",Yes.,2,"""Evaluation for these tasks was carried out by pre-final year and final year undergraduate computer science students and provides insights into the models' strengths and limitations."""
ArXiv2024,The Reasoning Under Uncertainty Trap: A Structural AI Risk,Yes.,5,"""we 1) do not currently sufficiently understand LLM capabilities in this regard, and 2) have no guarantees of performance given fundamental computational explosiveness and deep uncertainty constraints on accuracy."""
